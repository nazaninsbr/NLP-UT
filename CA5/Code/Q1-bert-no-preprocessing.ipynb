{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q1-bert-no-preprocessing.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPcJYx8kNB0Usn4PEFDOCR8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8JL4OAlSip-W","colab_type":"text"},"source":["# Connect to drive & import libraries"]},{"cell_type":"code","metadata":{"id":"caEGNDMzfRAh","colab_type":"code","outputId":"825e8c9c-649a-4d05-9721-0ff970f86adf","executionInfo":{"status":"ok","timestamp":1588621968858,"user_tz":-270,"elapsed":85113,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tEzV-luAJRsZ","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuOEBW9Liwfv","colab_type":"code","outputId":"e6830ac6-7be8-4a12-d931-1e895907cb7e","executionInfo":{"status":"ok","timestamp":1588622077339,"user_tz":-270,"elapsed":2946,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","from keras.engine import Layer\n","import matplotlib.pyplot as plt\n","import keras\n","import numpy as np\n","import nltk\n","import tqdm\n","import tensorflow_hub as hub\n","import string\n","from keras import backend as K"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BGuIwsXXJekG","colab_type":"code","outputId":"0eba40a1-597a-4c42-94e6-28f16faa973e","executionInfo":{"status":"ok","timestamp":1588622089507,"user_tz":-270,"elapsed":1062,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.0-rc3'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ps76V6J_edIs","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn import metrics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNTXCjhyQFp7","colab_type":"code","outputId":"1794712c-e9b4-4af4-b37f-ba26e9e5f59f","executionInfo":{"status":"ok","timestamp":1588622110728,"user_tz":-270,"elapsed":9926,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sQU4wuWtkaf","colab_type":"code","outputId":"4a643e91-f6f1-4878-9124-4e0eed8fd042","executionInfo":{"status":"ok","timestamp":1588622110731,"user_tz":-270,"elapsed":8904,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"pqHDaPXXop-k","colab_type":"code","outputId":"5a4e3a98-e5ce-4733-b915-b9e0fad29c0e","executionInfo":{"status":"ok","timestamp":1588622119380,"user_tz":-270,"elapsed":16305,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":480}},"source":["!pip install bert-for-tf2"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n","\r\u001b[K     |████████                        | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.8MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.38.0)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=1a7b7fba82faa94b6749c1143117804f1d69b37154364e1f2cbfe11673cf81c9\n","  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=868a94d5711313e74dc7d88c72a77c7503510f2e43680f593137bc2b5d135446\n","  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=18882c9e56436659d016c3e31edde74b9cf8248bc92f53a4ed5444253019b909\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vybgl8VvoqOG","colab_type":"code","colab":{}},"source":["import bert"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4b2ADngPjIZo","colab_type":"text"},"source":["# Constants"]},{"cell_type":"code","metadata":{"id":"zxO3Fs12ivVm","colab_type":"code","colab":{}},"source":["# data parameters\n","dataset_address = 'drive/My Drive/CA5_Sabri_810198312/Datasets/spam.csv'\n","test_data_percentage = 0.2\n","# model parameters\n","learning_rate = 0.0002\n","batch_size = 32\n","max_sequence_length = 128\n","number_of_epochs = [1, 10]\n","# model links\n","bert_model_hub_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'\n","elmo_model_hub_link = 'https://tfhub.dev/google/elmo/3'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8NwVmAJGi0vh","colab_type":"text"},"source":["# Reading & Pre-processing the data"]},{"cell_type":"code","metadata":{"id":"fI056jLjj0oU","colab_type":"code","outputId":"613d07b6-ccd2-4d4b-abf8-c3e0135f3f00","executionInfo":{"status":"ok","timestamp":1588622124874,"user_tz":-270,"elapsed":1930,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["df = pd.read_csv(dataset_address, sep=',', encoding = \"ISO-8859-1\")\n","df.head(3)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1  ... Unnamed: 4\n","0   ham  ...        NaN\n","1   ham  ...        NaN\n","2  spam  ...        NaN\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"_spPPJ7oj05q","colab_type":"code","colab":{}},"source":["all_Y = df.v1.values\n","all_X = df.v2.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQ_r5tFLnH7O","colab_type":"text"},"source":["## Create bert tokenizer"]},{"cell_type":"code","metadata":{"id":"VO_FMTtnnMCY","colab_type":"code","colab":{}},"source":["bert_layer = hub.KerasLayer(bert_model_hub_link)\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","bert_tokenizer_instance = bert.bert_tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYuXzRGY1DpG","colab_type":"text"},"source":["### Bert functions for mask and id and segment id"]},{"cell_type":"code","metadata":{"id":"W-UjqYR71I5I","colab_type":"code","colab":{}},"source":["def convert_text_to_number_and_fix_length(this_x, tokenizer_mod):\n","  this_x_ids = tokenizer_mod.convert_tokens_to_ids(this_x,)\n","  if len(this_x_ids) >= max_sequence_length:\n","    this_x_fix_len = this_x_ids[:max_sequence_length]\n","  else:\n","    this_x_fix_len = this_x_ids + [0]*(max_sequence_length - len(this_x_ids)) \n","  return this_x_fix_len\n","\n","def create_mask_for_input(this_x):\n","  if len(this_x) >= max_sequence_length:\n","    this_x_masks = [1]*max_sequence_length\n","  else:\n","    this_x_masks = [1]*len(this_x) + [0] * (max_sequence_length - len(this_x))\n","  return this_x_masks\n","\n","def create_req_bert_inputs(all_X, tokenizer_mod):\n","  X_input_ids, X_input_masks, X_segment_ids = [], [], []\n","\n","  for this_x in tqdm.tqdm(all_X, position=0, leave=True):\n","    X_input_ids.append(convert_text_to_number_and_fix_length(this_x, tokenizer_mod))\n","    X_input_masks.append(create_mask_for_input(this_x))\n","    X_segment_ids.append([0 for _ in range(max_sequence_length)])\n","\n","  return X_input_ids, X_input_masks, X_segment_ids"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8T7Dfndvf0Z","colab_type":"text"},"source":["## Clean and tokenize "]},{"cell_type":"code","metadata":{"id":"Ruj1PKWZj005","colab_type":"code","colab":{}},"source":["def clean_text(all_X, tokenizer_mod=None):\n","  nltk_eng_stopwords = nltk.corpus.stopwords.words('english')\n","  converted_X = []\n","  for this_x in all_X:\n","    this_x_tokenized = tokenizer_mod.tokenize(this_x)\n","    converted_X.append(this_x_tokenized)\n","  return converted_X\n","\n","def convert_y_to_0_and_1(all_Y):\n","  label_number_mapping = {'ham': [1, 0], 'spam': [0, 1]}\n","  converted_y = [label_number_mapping[val] for val in all_Y]\n","  return converted_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uqp90zJbtdG7","colab_type":"code","colab":{}},"source":["all_X_cleaned_using_bert = clean_text(all_X, bert_tokenizer_instance)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77rTdgAdvnaU","colab_type":"code","colab":{}},"source":["all_y_converted = convert_y_to_0_and_1(all_Y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HgQX9l3xxzUX","colab_type":"text"},"source":["### Testing BERT results"]},{"cell_type":"code","metadata":{"id":"eMAxUp7Cthrz","colab_type":"code","outputId":"a8fd6c51-356d-40aa-8a01-31effae3486d","executionInfo":{"status":"ok","timestamp":1588622164769,"user_tz":-270,"elapsed":809,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["print('X[0] => before: {} and after: {}'.format(all_X[0], all_X_cleaned_using_bert[0]))\n","print('Y[0] => before: {} and after: {}'.format(all_Y[0], all_y_converted[0]))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["X[0] => before: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... and after: ['go', 'until', 'ju', '##rong', 'point', ',', 'crazy', '.', '.', 'available', 'only', 'in', 'bug', '##is', 'n', 'great', 'world', 'la', 'e', 'buffet', '.', '.', '.', 'ci', '##ne', 'there', 'got', 'amore', 'wat', '.', '.', '.']\n","Y[0] => before: ham and after: [1, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z8BQlRI2zL2j","colab_type":"text"},"source":["## Test Train split"]},{"cell_type":"code","metadata":{"id":"sk2kYytNzLdn","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(all_X_cleaned_using_bert, all_y_converted, test_size=test_data_percentage, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MztG_Ei6x3ul","colab_type":"text"},"source":["# Creating Model"]},{"cell_type":"markdown","metadata":{"id":"CX9WnCmUx58B","colab_type":"text"},"source":["## Using Bert"]},{"cell_type":"code","metadata":{"id":"680fZdfa2qun","colab_type":"code","outputId":"1a41e0a0-7d9f-4d81-966a-a5e514414155","executionInfo":{"status":"ok","timestamp":1588622940028,"user_tz":-270,"elapsed":977,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["train_input_ids, train_input_masks, train_segment_ids = create_req_bert_inputs(X_train, bert_tokenizer_instance)\n","test_input_ids, test_input_masks, test_segment_ids = create_req_bert_inputs(X_test, bert_tokenizer_instance)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["100%|██████████| 4457/4457 [00:00<00:00, 63937.82it/s]\n","100%|██████████| 1115/1115 [00:00<00:00, 73140.07it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"thrzRZ04R5Vt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"dcbbb9db-f907-4db6-bb8b-f1b60e11460f","executionInfo":{"status":"ok","timestamp":1588622941373,"user_tz":-270,"elapsed":635,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}}},"source":["type(train_input_masks)\n","np.asarray(train_input_masks, dtype=np.int32)"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"fRJQNWXDKWyw","colab_type":"code","outputId":"20110359-f062-47f4-cff0-3cbc392e43e3","executionInfo":{"status":"ok","timestamp":1588622946479,"user_tz":-270,"elapsed":1237,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bert_model_preped_input = [np.asarray(train_input_ids, dtype=np.int32), np.asarray(train_input_masks, dtype=np.int32), np.asarray(train_segment_ids, dtype=np.int32)]\n","len(bert_model_preped_input), bert_model_preped_input[0].shape, bert_model_preped_input[0][1].shape"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, (4457, 128), (128,))"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"_xNby7WbLSw5","colab_type":"code","outputId":"4b4ec008-1ffd-469a-dabf-62bf39219923","executionInfo":{"status":"ok","timestamp":1588622949732,"user_tz":-270,"elapsed":897,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["y_train = np.asarray(y_train)\n","type(bert_model_preped_input), type(bert_model_preped_input[0]), type(y_train), bert_model_preped_input[0][0]"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(list,\n"," numpy.ndarray,\n"," numpy.ndarray,\n"," array([ 2053,  1045,  1005,  1049,  1999,  1996,  2168,  4049,  1012,\n","         2145,  2182,  2012,  2026,  3566,  2015,  1012,  4638,  2033,\n","         2041,  2006, 10930,  1012,  1045,  1005,  1049,  2431,  6248,\n","         1012,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0], dtype=int32))"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"iREClz0e25nV","colab_type":"code","colab":{}},"source":["this_optimizer = tf.keras.optimizers.Adam(\n","    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n","    name='Adam')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpHXcNdNvUvm","colab_type":"code","colab":{}},"source":["def create_model():\n","  input_word_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,name=\"input_word_ids\")\n","  input_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,name=\"input_mask\")\n","  segment_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,name=\"segment_ids\")\n","  bert_layer = hub.KerasLayer(bert_model_hub_link,trainable=True)\n","  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","  pooling_lay = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n","  dense = tf.keras.layers.Dense(768, activation='relu')(pooling_lay)\n","  pred = tf.keras.layers.Dense(2, activation='softmax')(dense)\n","  model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pred)\n","  return model "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQHP6X_h4Pnh","colab_type":"code","colab":{}},"source":["def plot_accuracy_and_loss(file_save_name, history):\n","  plt.plot(history.history['accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.savefig(file_save_name+'_accuracy.png')\n","  plt.cla()\n","  plt.plot(history.history['loss'])\n","  plt.title('model loss')\n","  plt.ylabel('loss')\n","  plt.xlabel('epoch')\n","  plt.savefig(file_save_name+'_loss.png')\n","  plt.cla()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGC5twGSdw4D","colab_type":"code","colab":{}},"source":["def evaluate_model(model):\n","  bert_model_test_input = [np.asarray(test_input_ids, dtype=np.int32), np.asarray(test_input_masks, dtype=np.int32), np.asarray(test_segment_ids, dtype=np.int32)]\n","  predicted_y = model.predict(bert_model_test_input)\n","  number_label_mapping = {0: 'ham', 1:'spam'}\n","  y_test_conv = [number_label_mapping[np.argmax(val)] for val in y_test]\n","  predicted_y_conv = [number_label_mapping[np.argmax(val)] for val in predicted_y]\n","  print('Accuracy:', accuracy_score(y_test_conv, predicted_y_conv))\n","  print('Classification report:', classification_report(y_test_conv, predicted_y_conv))\n","  print('F1 (Micro):', f1_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('F1 (Macro):', f1_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('F1 (Weighted):', f1_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  print('Recall (Micro):', recall_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('Recall (Macro):', recall_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('Recall (Weighted):', recall_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  print('Precision (Micro):', precision_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('Precision (Macro):', precision_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('Precision (Weighted):', precision_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  y_test_for_auc = [np.argmax(val) for val in y_test]\n","  y_predicted_for_auc = [np.argmax(val) for val in predicted_y]\n","  fpr, tpr, thresholds = metrics.roc_curve(y_test_for_auc, y_predicted_for_auc, pos_label=1)\n","  print('AUC:', metrics.auc(fpr, tpr))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"41a92QXmo6Kd","colab_type":"text"},"source":["**1 Epoch**\n","\n","\n","```\n","Accuracy: 0.8654708520179372\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.87      1.00      0.93       965\n","        spam       0.00      0.00      0.00       150\n","\n","    accuracy                           0.87      1115\n","   macro avg       0.43      0.50      0.46      1115\n","weighted avg       0.75      0.87      0.80      1115\n","\n","F1 (Micro): 0.8654708520179372\n","F1 (Macro): 0.46394230769230765\n","F1 (Weighted): 0.803057088651259\n","Recall (Micro): 0.8654708520179372\n","Recall (Macro): 0.5\n","Recall (Weighted): 0.8654708520179372\n","Precision (Micro): 0.8654708520179372\n","Precision (Macro): 0.4327354260089686\n","Precision (Weighted): 0.7490397956926541\n","AUC: 0.5\n","```\n","\n","**10 Epochs**\n","\n","```\n","Accuracy: 0.8654708520179372\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.87      1.00      0.93       965\n","        spam       0.00      0.00      0.00       150\n","\n","    accuracy                           0.87      1115\n","   macro avg       0.43      0.50      0.46      1115\n","weighted avg       0.75      0.87      0.80      1115\n","\n","F1 (Micro): 0.8654708520179372\n","F1 (Macro): 0.46394230769230765\n","F1 (Weighted): 0.803057088651259\n","Recall (Micro): 0.8654708520179372\n","Recall (Macro): 0.5\n","Recall (Weighted): 0.8654708520179372\n","Precision (Micro): 0.8654708520179372\n","Precision (Macro): 0.4327354260089686\n","Precision (Weighted): 0.7490397956926541\n","AUC: 0.5\n","```"]},{"cell_type":"code","metadata":{"id":"eqAW2g-ZCbGi","colab_type":"code","outputId":"cb4e4aa0-e91e-4f5c-e142-57a1c278c8d7","executionInfo":{"status":"ok","timestamp":1588622685704,"user_tz":-270,"elapsed":1353,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["val_counts_in_train_y = {}\n","for val in y_train:\n","  if not str(val) in val_counts_in_train_y:\n","    val_counts_in_train_y[str(val)] = 0\n","  val_counts_in_train_y[str(val)] += 1\n","val_counts_in_train_y"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'[0 1]': 597, '[1 0]': 3860}"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"mUksObv2zJZ3","colab_type":"code","outputId":"26ffe786-b6a1-4132-9cf8-c8fe0e4ddd3c","executionInfo":{"status":"ok","timestamp":1588623692009,"user_tz":-270,"elapsed":734467,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epochs in number_of_epochs:\n","  print('Number of epochs:', epochs)\n","  model = create_model()\n","  print(model.summary())\n","  model.compile(loss='binary_crossentropy', optimizer=this_optimizer, metrics=['accuracy'])\n","  history = model.fit(\n","      bert_model_preped_input, \n","      y_train,\n","      epochs=epochs,\n","      batch_size=batch_size\n","  )\n","  print('Done training')\n","  image_save_file_name = 'drive/My Drive/CA5_Sabri_810198312/Results/Q1_bert_model‌_no_preprocess_{}_epochs'.format(epochs)\n","  plot_accuracy_and_loss(image_save_file_name, history)\n","  evaluate_model(model)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Number of epochs: 1\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","keras_layer_2 (KerasLayer)      [(None, 768), (None, 109482241   input_word_ids[0][0]             \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           keras_layer_2[0][1]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 768)          590592      global_average_pooling1d_1[0][0] \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 2)            1538        dense_2[0][0]                    \n","==================================================================================================\n","Total params: 110,074,371\n","Trainable params: 110,074,370\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n","None\n","140/140 [==============================] - 61s 437ms/step - loss: 0.3405 - accuracy: 0.8829\n","Done training\n","Accuracy: 0.8654708520179372\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.87      1.00      0.93       965\n","        spam       0.00      0.00      0.00       150\n","\n","    accuracy                           0.87      1115\n","   macro avg       0.43      0.50      0.46      1115\n","weighted avg       0.75      0.87      0.80      1115\n","\n","F1 (Micro): 0.8654708520179372\n","F1 (Macro): 0.46394230769230765\n","F1 (Weighted): 0.803057088651259\n","Recall (Micro): 0.8654708520179372\n","Recall (Macro): 0.5\n","Recall (Weighted): 0.8654708520179372\n","Precision (Micro): 0.8654708520179372\n","Precision (Macro): 0.4327354260089686\n","Precision (Weighted): 0.7490397956926541\n","AUC: 0.5\n","Number of epochs: 10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","keras_layer_3 (KerasLayer)      [(None, 768), (None, 109482241   input_word_ids[0][0]             \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","global_average_pooling1d_2 (Glo (None, 768)          0           keras_layer_3[0][1]              \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 768)          590592      global_average_pooling1d_2[0][0] \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 2)            1538        dense_4[0][0]                    \n","==================================================================================================\n","Total params: 110,074,371\n","Trainable params: 110,074,370\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/10\n","140/140 [==============================] - 61s 437ms/step - loss: 0.4013 - accuracy: 0.8562\n","Epoch 2/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4410 - accuracy: 0.8645\n","Epoch 3/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4075 - accuracy: 0.8661\n","Epoch 4/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4104 - accuracy: 0.8661\n","Epoch 5/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4009 - accuracy: 0.8661\n","Epoch 6/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4019 - accuracy: 0.8661\n","Epoch 7/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.4008 - accuracy: 0.8661\n","Epoch 8/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.3966 - accuracy: 0.8661\n","Epoch 9/10\n","140/140 [==============================] - 61s 437ms/step - loss: 0.4002 - accuracy: 0.8661\n","Epoch 10/10\n","140/140 [==============================] - 61s 436ms/step - loss: 0.3993 - accuracy: 0.8661\n","Done training\n","Accuracy: 0.8654708520179372\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.87      1.00      0.93       965\n","        spam       0.00      0.00      0.00       150\n","\n","    accuracy                           0.87      1115\n","   macro avg       0.43      0.50      0.46      1115\n","weighted avg       0.75      0.87      0.80      1115\n","\n","F1 (Micro): 0.8654708520179372\n","F1 (Macro): 0.46394230769230765\n","F1 (Weighted): 0.803057088651259\n","Recall (Micro): 0.8654708520179372\n","Recall (Macro): 0.5\n","Recall (Weighted): 0.8654708520179372\n","Precision (Micro): 0.8654708520179372\n","Precision (Macro): 0.4327354260089686\n","Precision (Weighted): 0.7490397956926541\n","AUC: 0.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"2Osr0LYh-cBf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}