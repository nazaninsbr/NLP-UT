{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q3-Elmo-repeat-q1-part-2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMUL9iTCy/ECb740GIxRWTS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8JL4OAlSip-W","colab_type":"text"},"source":["# Connect to drive & import libraries"]},{"cell_type":"code","metadata":{"id":"caEGNDMzfRAh","colab_type":"code","outputId":"2af0ff09-16cf-4681-a917-49d5b33be143","executionInfo":{"status":"ok","timestamp":1588647962227,"user_tz":-270,"elapsed":67123,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N__8PghpbNdw","colab_type":"code","outputId":"df5c331c-479d-4c4a-93b1-717cfa50bd9f","executionInfo":{"status":"ok","timestamp":1588647966200,"user_tz":-270,"elapsed":1294,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iuOEBW9Liwfv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e98dd502-cda2-4dfa-f369-5b4d70ad4ce3","executionInfo":{"status":"ok","timestamp":1588647972919,"user_tz":-270,"elapsed":6759,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","from keras.engine import Layer\n","from keras.layers import Lambda, Input, Dense\n","from keras.models import Model\n","import matplotlib.pyplot as plt\n","import keras\n","import numpy as np\n","import nltk\n","import tqdm\n","import tensorflow_hub as hub\n","import string\n","from keras import backend as K\n","import tensorflow as tf\n","import tensorflow.keras.backend as B\n","import tensorflow_hub as hub\n","from tensorflow.python.keras.engine import Layer"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"RkO5xxlUbjkS","colab_type":"code","outputId":"eafb4e03-5aa6-4ccc-c52a-3a723809d93d","executionInfo":{"status":"ok","timestamp":1588647974240,"user_tz":-270,"elapsed":925,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"XIt47YtdrPbU","colab_type":"code","outputId":"6508019c-8927-4b6d-946a-62e1fd3654f6","executionInfo":{"status":"ok","timestamp":1588647974241,"user_tz":-270,"elapsed":908,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["hub.__version__"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.8.0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ps76V6J_edIs","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn import metrics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNTXCjhyQFp7","colab_type":"code","outputId":"4159bef3-0e32-48e9-930a-6d76917822ec","executionInfo":{"status":"ok","timestamp":1588647981010,"user_tz":-270,"elapsed":2720,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sQU4wuWtkaf","colab_type":"code","outputId":"29d35c3b-dcae-4a1d-9392-e80eee995e73","executionInfo":{"status":"ok","timestamp":1588647984449,"user_tz":-270,"elapsed":2733,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"4b2ADngPjIZo","colab_type":"text"},"source":["# Constants"]},{"cell_type":"code","metadata":{"id":"zxO3Fs12ivVm","colab_type":"code","colab":{}},"source":["# data parameters\n","dataset_address = 'drive/My Drive/CA5_Sabri_810198312/Datasets/spam.csv'\n","test_data_percentage = 0.2\n","# model parameters\n","learning_rate = 0.0002\n","batch_size = 32\n","max_sequence_length = 128\n","number_of_epochs = 20\n","number_of_hidden_layers = [1, 2, 5, 7]\n","# model links\n","bert_model_hub_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'\n","elmo_model_hub_link = 'https://tfhub.dev/google/elmo/3'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8NwVmAJGi0vh","colab_type":"text"},"source":["# Reading & Pre-processing the data"]},{"cell_type":"code","metadata":{"id":"fI056jLjj0oU","colab_type":"code","outputId":"75230fc1-e415-40a1-dd77-9770818aa35e","executionInfo":{"status":"ok","timestamp":1588647991057,"user_tz":-270,"elapsed":2017,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["df = pd.read_csv(dataset_address, sep=',', encoding = \"ISO-8859-1\")\n","df.head(3)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1  ... Unnamed: 4\n","0   ham  ...        NaN\n","1   ham  ...        NaN\n","2  spam  ...        NaN\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"_spPPJ7oj05q","colab_type":"code","colab":{}},"source":["all_Y = df.v1.values\n","all_X = df.v2.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8T7Dfndvf0Z","colab_type":"text"},"source":["## Clean and tokenize "]},{"cell_type":"code","metadata":{"id":"Ruj1PKWZj005","colab_type":"code","colab":{}},"source":["def clean_text(all_X, tokenizer_mod=None):\n","  nltk_eng_stopwords = nltk.corpus.stopwords.words('english')\n","  converted_X = []\n","  for this_x in all_X:\n","    this_x_lower = this_x.lower()\n","    this_x_no_punc = this_x_lower.translate(str.maketrans('', '', string.punctuation))\n","    this_x_tokenized = nltk.tokenize.word_tokenize(this_x_no_punc)\n","    this_x_no_stopword = [val for val in this_x_tokenized if not val in nltk_eng_stopwords]\n","    converted_X.append(this_x_no_stopword)\n","  return converted_X\n","\n","def convert_y_to_0_and_1(all_Y):\n","  label_number_mapping = {'ham': [1, 0], 'spam': [0, 1]}\n","  converted_y = [label_number_mapping[val] for val in all_Y]\n","  return converted_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uqp90zJbtdG7","colab_type":"code","colab":{}},"source":["all_X_cleaned_for_elmo = clean_text(all_X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77rTdgAdvnaU","colab_type":"code","colab":{}},"source":["all_y_converted = convert_y_to_0_and_1(all_Y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HgQX9l3xxzUX","colab_type":"text"},"source":["### Testing Elmo results"]},{"cell_type":"code","metadata":{"id":"eMAxUp7Cthrz","colab_type":"code","outputId":"033d8eca-49b9-44f3-bb90-dd3cd37808b1","executionInfo":{"status":"ok","timestamp":1588648003938,"user_tz":-270,"elapsed":770,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["print('X[0] => before: {} and after: {}'.format(all_X[0], all_X_cleaned_for_elmo[0]))\n","print('Y[0] => before: {} and after: {}'.format(all_Y[0], all_y_converted[0]))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["X[0] => before: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... and after: ['go', 'jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amore', 'wat']\n","Y[0] => before: ham and after: [1, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MztG_Ei6x3ul","colab_type":"text"},"source":["# Creating Model"]},{"cell_type":"code","metadata":{"id":"iREClz0e25nV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"d276ac00-3367-4fc7-8fcf-372f12d74fd4","executionInfo":{"status":"ok","timestamp":1588648006984,"user_tz":-270,"elapsed":1011,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}}},"source":["this_optimizer = keras.optimizers.Adam(lr = learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CQHP6X_h4Pnh","colab_type":"code","colab":{}},"source":["def plot_accuracy_and_loss(file_save_name, history):\n","  plt.plot(history.history['accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.savefig(file_save_name+'_accuracy.png')\n","  plt.cla()\n","  plt.plot(history.history['loss'])\n","  plt.title('model loss')\n","  plt.ylabel('loss')\n","  plt.xlabel('epoch')\n","  plt.savefig(file_save_name+'_loss.png')\n","  plt.cla()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5XhH10TzwD_","colab_type":"text"},"source":["## Using Elmo"]},{"cell_type":"code","metadata":{"id":"4F5TgoDNHaef","colab_type":"code","colab":{}},"source":["def create_req_elmo_inputs(all_X):\n","  X_input_tokens, X_input_seqlens = [], []\n","\n","  for this_x in tqdm.tqdm(all_X, position=0, leave=True):\n","    this_x_possible_section = this_x[:max_sequence_length]\n","    X_input_tokens.append(\" \".join(this_x_possible_section))\n","    X_input_seqlens.append(len(this_x_possible_section))\n","\n","  return X_input_tokens, X_input_seqlens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yu9LUID3jl9w","colab_type":"code","colab":{}},"source":["all_X_preped_for_elmo = np.array([\" \".join(val[:max_sequence_length]) for val in all_X_cleaned_for_elmo], dtype=object)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7XM5eZs8r-U","colab_type":"code","colab":{}},"source":["X_train_elmo, X_test_elmo, y_train_elmo, y_test_elmo = train_test_split(all_X_preped_for_elmo, all_y_converted, test_size=test_data_percentage, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OezIKKKuwsmj","colab_type":"code","outputId":"ce09cb4f-788b-4711-859b-70e946d8ee16","executionInfo":{"status":"ok","timestamp":1588648026727,"user_tz":-270,"elapsed":2070,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train_elmo[0]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'im boat still moms check yo im half naked'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"ZR8AnVRpvbH4","colab_type":"code","colab":{}},"source":["X_train_elmo = np.asarray(X_train_elmo, dtype=\"str\")\n","X_test_elmo = np.asarray(X_test_elmo, dtype=\"str\")\n","y_train_elmo = np.asarray(y_train_elmo, dtype=np.int32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVR0rF75mj9l","colab_type":"code","outputId":"34563cd6-9b9a-4fae-9da2-b5194f1218e0","executionInfo":{"status":"ok","timestamp":1588648028843,"user_tz":-270,"elapsed":1143,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train_elmo.shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4457, 2)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"WsAlqB8xHMQy","colab_type":"code","colab":{}},"source":["# X_train_elmo_tokens, X_train_elmo_seqlens = create_req_elmo_inputs(X_train_elmo)\n","# X_test_elmo_tokens, X_test_elmo_seqlens = create_req_elmo_inputs(X_test_elmo)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B75oAq9InDSx","colab_type":"code","colab":{}},"source":["# elmo_train_input = [np.array(X_train_elmo_tokens), np.array(X_train_elmo_seqlens)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jy6n8CbsjErC","colab_type":"code","colab":{}},"source":["elmo = hub.Module(elmo_model_hub_link, trainable = True)\n","def get_elmo_embedding_for_each_input_using_lambda_function(inp):\n","  return elmo(tf.squeeze(tf.cast(inp, tf.string)), signature='default', as_dict=True)['default']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6PyXKThhGVm","colab_type":"code","colab":{}},"source":["def create_elmo_using_model(num_hid_layers):\n","  input_text = Input(shape=(1,), dtype=\"string\")\n","  embeddings = Lambda(get_elmo_embedding_for_each_input_using_lambda_function, output_shape=(1024, ))(input_text)\n","  \n","  if num_hid_layers == 1:\n","    final_dense = Dense(1024, activation='relu')(embeddings)\n","  elif num_hid_layers == 2:\n","    first_dense = Dense(1024, activation='relu')(embeddings)\n","    final_dense = Dense(1024, activation='relu')(first_dense)\n","  elif num_hid_layers == 5:\n","    first_dense = Dense(1024, activation='relu')(embeddings)\n","    second_dense = Dense(1024, activation='relu')(first_dense)\n","    third_dense = Dense(1024, activation='relu')(second_dense)\n","    fourth_dense = Dense(1024, activation='relu')(third_dense)\n","    final_dense = Dense(1024, activation='relu')(fourth_dense)\n","  elif num_hid_layers == 7:\n","    first_dense = Dense(1024, activation='relu')(embeddings)\n","    second_dense = Dense(1024, activation='relu')(first_dense)\n","    third_dense = Dense(1024, activation='relu')(second_dense)\n","    fourth_dense = Dense(1024, activation='relu')(third_dense)\n","    fifth_dense = Dense(1024, activation='relu')(fourth_dense)\n","    sixth_dense = Dense(1024, activation='relu')(fifth_dense)\n","    final_dense = Dense(1024, activation='relu')(sixth_dense)\n","\n","  pred = Dense(2, activation='softmax')(final_dense)\n","  model = Model(inputs=[input_text], outputs=pred)\n","  return model "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjO7jnXN9sbK","colab_type":"code","colab":{}},"source":["def evaluate_model_elmo(model):\n","  # elmo_test_input = [np.array(X_test_elmo_tokens), np.array(X_test_elmo_seqlens)]\n","  predicted_y = model.predict(X_test_elmo)\n","  number_label_mapping = {0: 'ham', 1:'spam'}\n","  y_test_conv = [number_label_mapping[np.argmax(val)] for val in y_test_elmo]\n","  predicted_y_conv = [number_label_mapping[np.argmax(val)] for val in predicted_y]\n","  print('Accuracy:', accuracy_score(y_test_conv, predicted_y_conv))\n","  print('Classification report:', classification_report(y_test_conv, predicted_y_conv))\n","  print('F1 (Micro):', f1_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('F1 (Macro):', f1_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('F1 (Weighted):', f1_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  print('Recall (Micro):', recall_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('Recall (Macro):', recall_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('Recall (Weighted):', recall_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  print('Precision (Micro):', precision_score(y_test_conv, predicted_y_conv, average='micro'))\n","  print('Precision (Macro):', precision_score(y_test_conv, predicted_y_conv, average='macro'))\n","  print('Precision (Weighted):', precision_score(y_test_conv, predicted_y_conv, average='weighted'))\n","  y_test_for_auc = [np.argmax(val) for val in y_test_elmo]\n","  y_predicted_for_auc = [np.argmax(val) for val in predicted_y]\n","  fpr, tpr, thresholds = metrics.roc_curve(y_test_for_auc, y_predicted_for_auc, pos_label=1)\n","  print('AUC:', metrics.auc(fpr, tpr))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZKm1YkO9atE","colab_type":"code","outputId":"cafa83f7-3066-46fd-e0df-3c76c1fe6804","executionInfo":{"status":"ok","timestamp":1588649560698,"user_tz":-270,"elapsed":1521752,"user":{"displayName":"Ranking R","photoUrl":"","userId":"08956235012566838232"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for num_hid_layers in number_of_hidden_layers:\n","  print('Number of FF layers:', num_hid_layers)\n","  model = create_elmo_using_model(num_hid_layers)\n","  print(model.summary())\n","  model.compile(loss='binary_crossentropy', optimizer=this_optimizer, metrics=['accuracy'])\n","  history = model.fit(\n","      X_train_elmo, \n","      y_train_elmo,\n","      epochs=number_of_epochs,\n","      batch_size=batch_size\n","  )\n","  print('Done training')\n","  image_save_file_name = 'drive/My Drive/CA5_Sabri_810198312/Results/Q3_repeat_q1_part_2_elmo_model_{}_layers'.format(num_hid_layers)\n","  plot_accuracy_and_loss(image_save_file_name, history)\n","  evaluate_model_elmo(model)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Number of FF layers: 1\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 1)                 0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 2050      \n","=================================================================\n","Total params: 1,051,650\n","Trainable params: 1,051,650\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","4457/4457 [==============================] - 27s 6ms/step - loss: 0.0934 - accuracy: 0.9679\n","Epoch 2/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0439 - accuracy: 0.9870\n","Epoch 3/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0323 - accuracy: 0.9897\n","Epoch 4/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0246 - accuracy: 0.9928\n","Epoch 5/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0194 - accuracy: 0.9951\n","Epoch 6/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0150 - accuracy: 0.9957\n","Epoch 7/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0098 - accuracy: 0.9975\n","Epoch 8/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0083 - accuracy: 0.9980\n","Epoch 9/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0061 - accuracy: 0.9989\n","Epoch 10/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0037 - accuracy: 0.9996\n","Epoch 11/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 12/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 13/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 14/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 15/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 16/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 17/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 9.0107e-04 - accuracy: 1.0000\n","Epoch 18/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 7.8928e-04 - accuracy: 1.0000\n","Epoch 19/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 6.8495e-04 - accuracy: 1.0000\n","Epoch 20/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 5.9708e-04 - accuracy: 1.0000\n","Done training\n","Accuracy: 0.9901345291479821\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.95      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9901345291479821\n","F1 (Macro): 0.978513554942408\n","F1 (Weighted): 0.9900636695491676\n","Recall (Micro): 0.9901345291479821\n","Recall (Macro): 0.9717789291882556\n","Recall (Weighted): 0.9901345291479821\n","Precision (Micro): 0.9901345291479821\n","Precision (Macro): 0.9855314610735869\n","Precision (Weighted): 0.990078734383444\n","AUC: 0.9717789291882556\n","Number of FF layers: 2\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 1)                 0         \n","_________________________________________________________________\n","lambda_2 (Lambda)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 2050      \n","=================================================================\n","Total params: 2,101,250\n","Trainable params: 2,101,250\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0866 - accuracy: 0.9666\n","Epoch 2/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0337 - accuracy: 0.9906\n","Epoch 3/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0196 - accuracy: 0.9933\n","Epoch 4/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0124 - accuracy: 0.9951\n","Epoch 5/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0087 - accuracy: 0.9973\n","Epoch 6/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0054 - accuracy: 0.9984\n","Epoch 7/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 8/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0013 - accuracy: 0.9998\n","Epoch 9/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 3.3085e-04 - accuracy: 1.0000\n","Epoch 10/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 2.2337e-04 - accuracy: 1.0000\n","Epoch 11/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 1.6818e-04 - accuracy: 1.0000\n","Epoch 12/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 1.3586e-04 - accuracy: 1.0000\n","Epoch 13/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 1.0731e-04 - accuracy: 1.0000\n","Epoch 14/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 8.7170e-05 - accuracy: 1.0000\n","Epoch 15/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 7.2417e-05 - accuracy: 1.0000\n","Epoch 16/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 5.9170e-05 - accuracy: 1.0000\n","Epoch 17/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 4.9319e-05 - accuracy: 1.0000\n","Epoch 18/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 4.1927e-05 - accuracy: 1.0000\n","Epoch 19/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 3.4690e-05 - accuracy: 1.0000\n","Epoch 20/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 2.9561e-05 - accuracy: 1.0000\n","Done training\n","Accuracy: 0.9901345291479821\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.95      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9901345291479821\n","F1 (Macro): 0.978513554942408\n","F1 (Weighted): 0.9900636695491676\n","Recall (Micro): 0.9901345291479821\n","Recall (Macro): 0.9717789291882556\n","Recall (Weighted): 0.9901345291479821\n","Precision (Micro): 0.9901345291479821\n","Precision (Macro): 0.9855314610735869\n","Precision (Weighted): 0.990078734383444\n","AUC: 0.9717789291882556\n","Number of FF layers: 5\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 1)                 0         \n","_________________________________________________________________\n","lambda_3 (Lambda)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 2)                 2050      \n","=================================================================\n","Total params: 5,250,050\n","Trainable params: 5,250,050\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.1101 - accuracy: 0.9616\n","Epoch 2/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0404 - accuracy: 0.9877\n","Epoch 3/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0289 - accuracy: 0.9915\n","Epoch 4/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0206 - accuracy: 0.9930\n","Epoch 5/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0119 - accuracy: 0.9960\n","Epoch 6/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0106 - accuracy: 0.9966\n","Epoch 7/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0059 - accuracy: 0.9978\n","Epoch 8/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0055 - accuracy: 0.9982\n","Epoch 9/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0030 - accuracy: 0.9998\n","Epoch 10/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0037 - accuracy: 0.9982\n","Epoch 11/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0099 - accuracy: 0.9973\n","Epoch 12/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 3.4832e-04 - accuracy: 1.0000\n","Epoch 13/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 6.3408e-05 - accuracy: 1.0000\n","Epoch 14/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 3.3335e-05 - accuracy: 1.0000\n","Epoch 15/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 1.6751e-05 - accuracy: 1.0000\n","Epoch 16/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 9.1069e-06 - accuracy: 1.0000\n","Epoch 17/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 5.5472e-06 - accuracy: 1.0000\n","Epoch 18/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 3.7345e-06 - accuracy: 1.0000\n","Epoch 19/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 2.6676e-06 - accuracy: 1.0000\n","Epoch 20/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 1.9782e-06 - accuracy: 1.0000\n","Done training\n","Accuracy: 0.989237668161435\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.94      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.98      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.989237668161435\n","F1 (Macro): 0.9764926631809748\n","F1 (Weighted): 0.9891445256159017\n","Recall (Micro): 0.989237668161435\n","Recall (Macro): 0.9684455958549223\n","Recall (Weighted): 0.989237668161435\n","Precision (Micro): 0.989237668161435\n","Precision (Macro): 0.984948935805012\n","Precision (Weighted): 0.9891754374621882\n","AUC: 0.9684455958549223\n","Number of FF layers: 7\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         (None, 1)                 0         \n","_________________________________________________________________\n","lambda_4 (Lambda)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 2)                 2050      \n","=================================================================\n","Total params: 7,349,250\n","Trainable params: 7,349,250\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.1348 - accuracy: 0.9560\n","Epoch 2/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0459 - accuracy: 0.9861\n","Epoch 3/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0327 - accuracy: 0.9895\n","Epoch 4/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0251 - accuracy: 0.9933\n","Epoch 5/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0166 - accuracy: 0.9942\n","Epoch 6/20\n","4457/4457 [==============================] - 18s 4ms/step - loss: 0.0098 - accuracy: 0.9969\n","Epoch 7/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0063 - accuracy: 0.9978\n","Epoch 8/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0079 - accuracy: 0.9975\n","Epoch 9/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0128 - accuracy: 0.9969\n","Epoch 10/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0064 - accuracy: 0.9980\n","Epoch 11/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 0.0029 - accuracy: 0.9989\n","Epoch 12/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 5.9992e-05 - accuracy: 1.0000\n","Epoch 13/20\n","4457/4457 [==============================] - 20s 4ms/step - loss: 2.8979e-05 - accuracy: 1.0000\n","Epoch 14/20\n","4457/4457 [==============================] - 20s 4ms/step - loss: 1.8415e-05 - accuracy: 1.0000\n","Epoch 15/20\n","4457/4457 [==============================] - 20s 4ms/step - loss: 1.2895e-05 - accuracy: 1.0000\n","Epoch 16/20\n","4457/4457 [==============================] - 20s 4ms/step - loss: 9.3839e-06 - accuracy: 1.0000\n","Epoch 17/20\n","4457/4457 [==============================] - 20s 4ms/step - loss: 7.2062e-06 - accuracy: 1.0000\n","Epoch 18/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 5.5246e-06 - accuracy: 1.0000\n","Epoch 19/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 4.3542e-06 - accuracy: 1.0000\n","Epoch 20/20\n","4457/4457 [==============================] - 19s 4ms/step - loss: 3.5025e-06 - accuracy: 1.0000\n","Done training\n","Accuracy: 0.9910313901345291\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.99      0.95      0.97       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9910313901345291\n","F1 (Macro): 0.9804105526508125\n","F1 (Weighted): 0.9909537713465848\n","Recall (Micro): 0.9910313901345291\n","Recall (Macro): 0.9722970639032815\n","Recall (Weighted): 0.9910313901345291\n","Precision (Micro): 0.9910313901345291\n","Precision (Macro): 0.9889360910859366\n","Precision (Weighted): 0.9910009867626027\n","AUC: 0.9722970639032815\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4D-I8wiMzWsv","colab_type":"text"},"source":["**1 Layer**\n","\n","\n","```\n","Accuracy: 0.9901345291479821\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.95      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9901345291479821\n","F1 (Macro): 0.978513554942408\n","F1 (Weighted): 0.9900636695491676\n","Recall (Micro): 0.9901345291479821\n","Recall (Macro): 0.9717789291882556\n","Recall (Weighted): 0.9901345291479821\n","Precision (Micro): 0.9901345291479821\n","Precision (Macro): 0.9855314610735869\n","Precision (Weighted): 0.990078734383444\n","AUC: 0.9717789291882556\n","```\n","\n","**2 Layers**\n","\n","```\n","Accuracy: 0.9901345291479821\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.95      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9901345291479821\n","F1 (Macro): 0.978513554942408\n","F1 (Weighted): 0.9900636695491676\n","Recall (Micro): 0.9901345291479821\n","Recall (Macro): 0.9717789291882556\n","Recall (Weighted): 0.9901345291479821\n","Precision (Micro): 0.9901345291479821\n","Precision (Macro): 0.9855314610735869\n","Precision (Weighted): 0.990078734383444\n","AUC: 0.9717789291882556\n","```\n","\n","**5 Layers**\n","\n","```\n","Accuracy: 0.989237668161435\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.98      0.94      0.96       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.98      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.989237668161435\n","F1 (Macro): 0.9764926631809748\n","F1 (Weighted): 0.9891445256159017\n","Recall (Micro): 0.989237668161435\n","Recall (Macro): 0.9684455958549223\n","Recall (Weighted): 0.989237668161435\n","Precision (Micro): 0.989237668161435\n","Precision (Macro): 0.984948935805012\n","Precision (Weighted): 0.9891754374621882\n","AUC: 0.9684455958549223\n","```\n","\n","**7 Layers**\n","\n","```\n","Accuracy: 0.9910313901345291\n","Classification report:               precision    recall  f1-score   support\n","\n","         ham       0.99      1.00      0.99       965\n","        spam       0.99      0.95      0.97       150\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.97      0.98      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","F1 (Micro): 0.9910313901345291\n","F1 (Macro): 0.9804105526508125\n","F1 (Weighted): 0.9909537713465848\n","Recall (Micro): 0.9910313901345291\n","Recall (Macro): 0.9722970639032815\n","Recall (Weighted): 0.9910313901345291\n","Precision (Micro): 0.9910313901345291\n","Precision (Macro): 0.9889360910859366\n","Precision (Weighted): 0.9910009867626027\n","AUC: 0.9722970639032815\n","```"]},{"cell_type":"code","metadata":{"id":"hrYVEPjmnldj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}