{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2 elmo_with_nopreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JL4OAlSip-W",
        "colab_type": "text"
      },
      "source": [
        "# Connect to drive & import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caEGNDMzfRAh",
        "colab_type": "code",
        "outputId": "4a2e36aa-c742-4cae-d262-2ce8c5b8ec4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEzV-luAJRsZ",
        "colab_type": "code",
        "outputId": "8e88f9e8-0f98-4967-af96-100fad87b705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuOEBW9Liwfv",
        "colab_type": "code",
        "outputId": "79d8f51b-61e8-4b7e-8ac2-a1616941a16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "import nltk\n",
        "import tqdm\n",
        "import tensorflow_hub as hub\n",
        "import string\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as B\n",
        "import tensorflow_hub as hub\n",
        "import re\n",
        "from tensorflow.python.keras.engine import Layer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGuIwsXXJekG",
        "colab_type": "code",
        "outputId": "bd12287d-b13b-4ddb-be69-1e4b799bbd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps76V6J_edIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNTXCjhyQFp7",
        "colab_type": "code",
        "outputId": "cb0a9472-76af-43fa-b01b-d0e93f1d05f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQU4wuWtkaf",
        "colab_type": "code",
        "outputId": "42920323-451f-42ef-9c1f-e5f6b5e864cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2ADngPjIZo",
        "colab_type": "text"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxO3Fs12ivVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data parameters\n",
        "dataset_address = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "test_data_percentage = 0.2\n",
        "# model parameters\n",
        "learning_rate = 0.0002\n",
        "batch_size = 32\n",
        "max_sequence_length = 128\n",
        "number_of_epochs = [10]\n",
        "# model links\n",
        "bert_model_hub_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'\n",
        "elmo_model_hub_link = 'https://tfhub.dev/google/elmo/3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NwVmAJGi0vh",
        "colab_type": "text"
      },
      "source": [
        "# Reading & Pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI056jLjj0oU",
        "colab_type": "code",
        "outputId": "5e5cf135-975d-42ef-de30-7a3f0a8fab33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = tf.keras.utils.get_file(\n",
        "        fname=\"aclImdb.tar.gz\", \n",
        "        origin=dataset_address, \n",
        "        extract=True)\n",
        "  \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                         \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                          \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        " \n",
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jofDLpoMkDtq",
        "colab_type": "code",
        "outputId": "d9cfea16-c69b-4cc5-b806-319c61e137a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "train.head(7)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes, a true classic! This is what British dram...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I didn't expect much when I first saw the DVD ...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thanks to a dull, dimensionless screenplay by ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>First off, I had my doubts just looking at the...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this was a fantastic episode. i saw a clip fro...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I saw this 25 years ago on PBS. It was very di...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>While the original titillates the intellect, t...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment  polarity\n",
              "0  Yes, a true classic! This is what British dram...         9         1\n",
              "1  I didn't expect much when I first saw the DVD ...         8         1\n",
              "2  Thanks to a dull, dimensionless screenplay by ...         1         0\n",
              "3  First off, I had my doubts just looking at the...         1         0\n",
              "4  this was a fantastic episode. i saw a clip fro...        10         1\n",
              "5  I saw this 25 years ago on PBS. It was very di...        10         1\n",
              "6  While the original titillates the intellect, t...         2         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SjOfHPSgtuk",
        "colab_type": "code",
        "outputId": "a9dfe0b3-d824-4b09-889d-c636ca095813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X = train.sentence.values\n",
        "train_Y = train.polarity.values\n",
        "\n",
        "test_X = test.sentence.values\n",
        "test_Y = test.polarity.values\n",
        "print(len(train_X), len(test_X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8T7Dfndvf0Z",
        "colab_type": "text"
      },
      "source": [
        "## Clean and tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruj1PKWZj005",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(all_X, tokenizer_mod=None):\n",
        "  nltk_eng_stopwords = nltk.corpus.stopwords.words('english')\n",
        "  converted_X = []\n",
        "  for this_x in all_X:\n",
        "    if tokenizer_mod == None:\n",
        "      this_x_no_stopword = this_x.split()\n",
        "      converted_X.append(this_x_no_stopword)\n",
        "    else:\n",
        "      this_x_no_stopword = \" \".join([val for val in nltk.tokenize.word_tokenize(this_x_no_punc) if not val in nltk_eng_stopwords])\n",
        "      this_x_tokenized = tokenizer_mod.tokenize(this_x_no_stopword)\n",
        "      converted_X.append(this_x_tokenized)\n",
        "  return converted_X\n",
        "\n",
        "def convert_y_to_0_and_1(all_Y):\n",
        "  label_number_mapping = {0: [1, 0], 1: [0, 1]}\n",
        "  converted_y = [label_number_mapping[val] for val in all_Y]\n",
        "  return converted_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqp90zJbtdG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_X_cleaned = clean_text(train_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BeWULz8hzhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test_X_cleaned = clean_text(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rTdgAdvnaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_y_converted = convert_y_to_0_and_1(train_Y)\n",
        "all_test_y_converted = convert_y_to_0_and_1(test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgQX9l3xxzUX",
        "colab_type": "text"
      },
      "source": [
        "### Testing Elmo results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAxUp7Cthrz",
        "colab_type": "code",
        "outputId": "e9fae53a-c6d1-41eb-b90e-d56b841d25b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print('X[0] => before: {} and after: {}'.format(train_X[0], all_train_X_cleaned[0]))\n",
        "print('Y[0] => before: {} and after: {}'.format(train_Y[0], all_train_y_converted[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X[0] => before: Yes, a true classic! This is what British drama is all about,realism and the minimal use of special effects (and over inflated budgets). I last saw this drama when it was last screened on British terrestial TV in 1994. It truly should be viewed by everyone who likes a scary plot,no big names but non-the-less great acting.Sadly the copywrite is now owned by someone unknown and as such this great drama is unlikely to be aired anytime soon.I myself recently acquired The Woman In Black on VHS,so now once again I shall be able to enjoy this truly great British drama. You should try and enjoy it too!<br /><br />Mark R. Horobin and after: ['Yes,', 'a', 'true', 'classic!', 'This', 'is', 'what', 'British', 'drama', 'is', 'all', 'about,realism', 'and', 'the', 'minimal', 'use', 'of', 'special', 'effects', '(and', 'over', 'inflated', 'budgets).', 'I', 'last', 'saw', 'this', 'drama', 'when', 'it', 'was', 'last', 'screened', 'on', 'British', 'terrestial', 'TV', 'in', '1994.', 'It', 'truly', 'should', 'be', 'viewed', 'by', 'everyone', 'who', 'likes', 'a', 'scary', 'plot,no', 'big', 'names', 'but', 'non-the-less', 'great', 'acting.Sadly', 'the', 'copywrite', 'is', 'now', 'owned', 'by', 'someone', 'unknown', 'and', 'as', 'such', 'this', 'great', 'drama', 'is', 'unlikely', 'to', 'be', 'aired', 'anytime', 'soon.I', 'myself', 'recently', 'acquired', 'The', 'Woman', 'In', 'Black', 'on', 'VHS,so', 'now', 'once', 'again', 'I', 'shall', 'be', 'able', 'to', 'enjoy', 'this', 'truly', 'great', 'British', 'drama.', 'You', 'should', 'try', 'and', 'enjoy', 'it', 'too!<br', '/><br', '/>Mark', 'R.', 'Horobin']\n",
            "Y[0] => before: 1 and after: [0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MztG_Ei6x3ul",
        "colab_type": "text"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX9WnCmUx58B",
        "colab_type": "text"
      },
      "source": [
        "## Using Elmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVJgNB0Xk7m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_X_preped_for_elmo_train = []\n",
        "for val in all_train_X_cleaned:\n",
        "  val_splitted = val[:max_sequence_length]\n",
        "  val_to_add = ' '.join(val_splitted)\n",
        "  all_X_preped_for_elmo_train.append(val_to_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhmKzElolAKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_X_preped_for_elmo_test = []\n",
        "for val in all_test_X_cleaned:\n",
        "  val_splitted = val[:max_sequence_length]\n",
        "  val_to_add = ' '.join(val_splitted)\n",
        "  all_X_preped_for_elmo_test.append(val_to_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TCzXXT1lATg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_elmo = np.asarray(all_X_preped_for_elmo_train, dtype=\"str\")\n",
        "X_test_elmo = np.asarray(all_X_preped_for_elmo_test, dtype=\"str\")\n",
        "y_train_elmo = np.asarray(all_train_y_converted, dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKXqh2RlAcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = hub.Module(elmo_model_hub_link, trainable = True)\n",
        "def get_elmo_embedding_for_each_input_using_lambda_function(inp):\n",
        "  return elmo(tf.squeeze(tf.cast(inp, tf.string)), signature='default', as_dict=True)['default']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdRP5kwhlAjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_elmo_using_model():\n",
        "  input_text = Input(shape=(1,), dtype=\"string\")\n",
        "  embeddings = Lambda(get_elmo_embedding_for_each_input_using_lambda_function, output_shape=(1024, ))(input_text)\n",
        "  dense = Dense(1024, activation='relu')(embeddings)\n",
        "  pred = Dense(2, activation='softmax')(dense)\n",
        "  model = Model(inputs=[input_text], outputs=pred)\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6R_Pu1alAun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_elmo(model):\n",
        "  # elmo_test_input = [np.array(X_test_elmo_tokens), np.array(X_test_elmo_seqlens)]\n",
        "  predicted_y = model.predict(X_test_elmo)\n",
        "  y_test_conv = [np.argmax(val) for val in all_test_y_converted]\n",
        "  predicted_y_conv = [np.argmax(val) for val in predicted_y]\n",
        "  print('Accuracy:', accuracy_score(y_test_conv, predicted_y_conv))\n",
        "  print('Classification report:', classification_report(y_test_conv, predicted_y_conv))\n",
        "  print('F1 (Micro):', f1_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('F1 (Macro):', f1_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('F1 (Weighted):', f1_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  print('Recall (Micro):', recall_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('Recall (Macro):', recall_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('Recall (Weighted):', recall_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  print('Precision (Micro):', precision_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('Precision (Macro):', precision_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('Precision (Weighted):', precision_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test_conv, predicted_y_conv, pos_label=1)\n",
        "  print('AUC:', metrics.auc(fpr, tpr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV3xddVlstg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy_and_loss(file_save_name, history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.savefig(file_save_name+'_accuracy.png')\n",
        "  plt.cla()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.savefig(file_save_name+'_loss.png')\n",
        "  plt.cla()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTHA7_HolA6q",
        "colab_type": "code",
        "outputId": "ba302745-8efa-4242-bf82-abe65989c353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "this_optimizer = keras.optimizers.Adam(lr = learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSl81RL-lBKH",
        "colab_type": "code",
        "outputId": "951002ad-f347-47d7-b274-8a63d8678b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epochs in number_of_epochs:\n",
        "  print('Number of epochs:', epochs)\n",
        "  model = create_elmo_using_model()\n",
        "  print(model.summary())\n",
        "  model.compile(loss='binary_crossentropy', optimizer=this_optimizer, metrics=['accuracy'])\n",
        "  history = model.fit(\n",
        "      X_train_elmo, \n",
        "      y_train_elmo,\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  print('Done training')\n",
        "  image_save_file_name = 'drive/My Drive/CA5_Sabri_810198312/Results/Q2_elmo_nopreprocess_model_{}_epochs'.format(epochs)\n",
        "  plot_accuracy_and_loss(image_save_file_name, history)\n",
        "  evaluate_model_elmo(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of epochs: 10\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,051,650\n",
            "Trainable params: 1,051,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 1038s 42ms/step - loss: 0.4664 - accuracy: 0.7748\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 1032s 41ms/step - loss: 0.4189 - accuracy: 0.8062\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 1031s 41ms/step - loss: 0.4041 - accuracy: 0.8138\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 1032s 41ms/step - loss: 0.3898 - accuracy: 0.8211\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 1030s 41ms/step - loss: 0.3813 - accuracy: 0.8265\n",
            "Epoch 6/10\n",
            "19232/25000 [======================>.......] - ETA: 3:57 - loss: 0.3665 - accuracy: 0.8343"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSCPW2jrFq5N",
        "colab_type": "text"
      },
      "source": [
        "**10 Epochs**\n",
        "\n",
        "```\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAYVpdyjiTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}