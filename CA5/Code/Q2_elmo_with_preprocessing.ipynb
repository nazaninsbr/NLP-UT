{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2_elmo_with_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JL4OAlSip-W",
        "colab_type": "text"
      },
      "source": [
        "# Connect to drive & import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caEGNDMzfRAh",
        "colab_type": "code",
        "outputId": "1ba830d1-57d9-4588-caba-9feae1bd1687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEzV-luAJRsZ",
        "colab_type": "code",
        "outputId": "9767e275-6e2d-4118-9d75-148cea9c0629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuOEBW9Liwfv",
        "colab_type": "code",
        "outputId": "99d5320f-a272-41a5-a89e-3e0b0ee5ceaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "import nltk\n",
        "import tqdm\n",
        "import tensorflow_hub as hub\n",
        "import string\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as B\n",
        "import tensorflow_hub as hub\n",
        "import re\n",
        "from tensorflow.python.keras.engine import Layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGuIwsXXJekG",
        "colab_type": "code",
        "outputId": "e58f56c1-5e14-42ef-9036-002154271b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps76V6J_edIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNTXCjhyQFp7",
        "colab_type": "code",
        "outputId": "8c673976-de1f-4d4f-c8e6-87e5e90d8342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQU4wuWtkaf",
        "colab_type": "code",
        "outputId": "2f875eae-30ef-4cc9-f88c-1eb737f3de46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2ADngPjIZo",
        "colab_type": "text"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxO3Fs12ivVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data parameters\n",
        "dataset_address = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "test_data_percentage = 0.2\n",
        "# model parameters\n",
        "learning_rate = 0.0002\n",
        "batch_size = 32\n",
        "max_sequence_length = 128\n",
        "number_of_epochs = [1, 10, 20, 50]\n",
        "# model links\n",
        "bert_model_hub_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1'\n",
        "elmo_model_hub_link = 'https://tfhub.dev/google/elmo/3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NwVmAJGi0vh",
        "colab_type": "text"
      },
      "source": [
        "# Reading & Pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI056jLjj0oU",
        "colab_type": "code",
        "outputId": "73baf6c1-53b9-4eea-ce14-eec3a9905f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = tf.keras.utils.get_file(\n",
        "        fname=\"aclImdb.tar.gz\", \n",
        "        origin=dataset_address, \n",
        "        extract=True)\n",
        "  \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                         \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                          \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        " \n",
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jofDLpoMkDtq",
        "colab_type": "code",
        "outputId": "5822d968-54cf-4b04-9d48-7890e30e7752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "train.head(7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Slaughter High is about a boy named Marty. He ...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Poor Whoopi Goldberg. Imagine her at a friend'...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Joan Crawford had just begun her \"working girl...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a timeless classic, wonderfully acted with per...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I admit to liking a lot of the so-called \"frat...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A most recommendable masterpiece, not only for...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I really enjoyed this thriller! I wanted to se...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment  polarity\n",
              "0  Slaughter High is about a boy named Marty. He ...         8         1\n",
              "1  Poor Whoopi Goldberg. Imagine her at a friend'...         1         0\n",
              "2  Joan Crawford had just begun her \"working girl...         8         1\n",
              "3  a timeless classic, wonderfully acted with per...        10         1\n",
              "4  I admit to liking a lot of the so-called \"frat...         2         0\n",
              "5  A most recommendable masterpiece, not only for...        10         1\n",
              "6  I really enjoyed this thriller! I wanted to se...        10         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SjOfHPSgtuk",
        "colab_type": "code",
        "outputId": "c11e83a8-8dcd-4fdf-ae98-e52a6130acfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X = train.sentence.values\n",
        "train_Y = train.polarity.values\n",
        "\n",
        "test_X = test.sentence.values\n",
        "test_Y = test.polarity.values\n",
        "print(len(train_X), len(test_X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8T7Dfndvf0Z",
        "colab_type": "text"
      },
      "source": [
        "## Clean and tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruj1PKWZj005",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(all_X, tokenizer_mod=None):\n",
        "  nltk_eng_stopwords = nltk.corpus.stopwords.words('english')\n",
        "  converted_X = []\n",
        "  for this_x in all_X:\n",
        "    this_x_lower = this_x.lower()\n",
        "    this_x_no_punc = this_x_lower.translate(str.maketrans('', '', string.punctuation))\n",
        "    if tokenizer_mod == None:\n",
        "      this_x_tokenized = nltk.tokenize.word_tokenize(this_x_no_punc)\n",
        "      this_x_no_stopword = [val for val in this_x_tokenized if not val in nltk_eng_stopwords]\n",
        "      converted_X.append(this_x_no_stopword)\n",
        "    else:\n",
        "      this_x_no_stopword = \" \".join([val for val in nltk.tokenize.word_tokenize(this_x_no_punc) if not val in nltk_eng_stopwords])\n",
        "      this_x_tokenized = tokenizer_mod.tokenize(this_x_no_stopword)\n",
        "      converted_X.append(this_x_tokenized)\n",
        "  return converted_X\n",
        "\n",
        "def convert_y_to_0_and_1(all_Y):\n",
        "  label_number_mapping = {0: [1, 0], 1: [0, 1]}\n",
        "  converted_y = [label_number_mapping[val] for val in all_Y]\n",
        "  return converted_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqp90zJbtdG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_X_cleaned = clean_text(train_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BeWULz8hzhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test_X_cleaned = clean_text(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rTdgAdvnaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_y_converted = convert_y_to_0_and_1(train_Y)\n",
        "all_test_y_converted = convert_y_to_0_and_1(test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgQX9l3xxzUX",
        "colab_type": "text"
      },
      "source": [
        "### Testing Elmo results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAxUp7Cthrz",
        "colab_type": "code",
        "outputId": "d9894b25-0637-42ae-8785-a5c96c01fb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print('X[0] => before: {} and after: {}'.format(train_X[0], all_train_X_cleaned[0]))\n",
        "print('Y[0] => before: {} and after: {}'.format(train_Y[0], all_train_y_converted[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X[0] => before: Slaughter High is about a boy named Marty. He was harassed, and picked on in high school. A group of kids played several pranks on him, and these pranks were REALLY bad. The last prank ended tragically.<br /><br />cue to 5 years later. The gang of kids meet up again for a reunion. One of them set it up at the old high school. The school is now abandoned, and they have to break in. For some reason, the Janitor is still there, but he tells them to go ahead and have fun because they give him a beer.<br /><br />They start partying ,and looking at their old lockers, and they see something of Marty's. One girl feels sorry for Marty but another guy calms her down.<br /><br />Once the kills begin, it is great. Every kills is creative and gory. We see a figure in a jester mask, hunting them one by one throughout the school. It appears Marty is back to exact revenge. After the first person is killed, they find out they are locked in the school. They begin looking for a way out.<br /><br />Now, there are a number of illogical things in this movie. First of all, I don't know anyone who has a 5 year reunion. Second of all, after the first kid dies, a girl gets blood all over her. They all run away in a panic, yet she runs to the bathroom, and finds a bathtub. Hrr friend has just been killed, and she decides to take a bath!? More importantly, why is there a bathtub in a school bathroom. Anyways, the bathtub doesn't seem to really work....and she dies a horrible death this is an 80s movie. it is a horror slasher. WHO CARES if it has some illogical parts. I for one don't. This movie has really great deaths. The ending.... there is a twist. Having recently seen Haute Tension, I can compare the two. The only way they are similar is that there is a twist, which kind of left me disappointed.....THEN right after the twist, comes a great, if not the best kill, in the movie.<br /><br />After the last kill, the killer looks at the screen and also does something crazy, and it was the perfect way to end the movie. It has me going \"wow...\" and after: ['slaughter', 'high', 'boy', 'named', 'marty', 'harassed', 'picked', 'high', 'school', 'group', 'kids', 'played', 'several', 'pranks', 'pranks', 'really', 'bad', 'last', 'prank', 'ended', 'tragicallybr', 'br', 'cue', '5', 'years', 'later', 'gang', 'kids', 'meet', 'reunion', 'one', 'set', 'old', 'high', 'school', 'school', 'abandoned', 'break', 'reason', 'janitor', 'still', 'tells', 'go', 'ahead', 'fun', 'give', 'beerbr', 'br', 'start', 'partying', 'looking', 'old', 'lockers', 'see', 'something', 'martys', 'one', 'girl', 'feels', 'sorry', 'marty', 'another', 'guy', 'calms', 'downbr', 'br', 'kills', 'begin', 'great', 'every', 'kills', 'creative', 'gory', 'see', 'figure', 'jester', 'mask', 'hunting', 'one', 'one', 'throughout', 'school', 'appears', 'marty', 'back', 'exact', 'revenge', 'first', 'person', 'killed', 'find', 'locked', 'school', 'begin', 'looking', 'way', 'outbr', 'br', 'number', 'illogical', 'things', 'movie', 'first', 'dont', 'know', 'anyone', '5', 'year', 'reunion', 'second', 'first', 'kid', 'dies', 'girl', 'gets', 'blood', 'run', 'away', 'panic', 'yet', 'runs', 'bathroom', 'finds', 'bathtub', 'hrr', 'friend', 'killed', 'decides', 'take', 'bath', 'importantly', 'bathtub', 'school', 'bathroom', 'anyways', 'bathtub', 'doesnt', 'seem', 'really', 'workand', 'dies', 'horrible', 'death', '80s', 'movie', 'horror', 'slasher', 'cares', 'illogical', 'parts', 'one', 'dont', 'movie', 'really', 'great', 'deaths', 'ending', 'twist', 'recently', 'seen', 'haute', 'tension', 'compare', 'two', 'way', 'similar', 'twist', 'kind', 'left', 'disappointedthen', 'right', 'twist', 'comes', 'great', 'best', 'kill', 'moviebr', 'br', 'last', 'kill', 'killer', 'looks', 'screen', 'also', 'something', 'crazy', 'perfect', 'way', 'end', 'movie', 'going', 'wow']\n",
            "Y[0] => before: 1 and after: [0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MztG_Ei6x3ul",
        "colab_type": "text"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX9WnCmUx58B",
        "colab_type": "text"
      },
      "source": [
        "## Using Elmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVJgNB0Xk7m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_X_preped_for_elmo_train = []\n",
        "for val in all_train_X_cleaned:\n",
        "  val_splitted = val[:max_sequence_length]\n",
        "  val_to_add = ' '.join(val_splitted)\n",
        "  all_X_preped_for_elmo_train.append(val_to_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhmKzElolAKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_X_preped_for_elmo_test = []\n",
        "for val in all_test_X_cleaned:\n",
        "  val_splitted = val[:max_sequence_length]\n",
        "  val_to_add = ' '.join(val_splitted)\n",
        "  all_X_preped_for_elmo_test.append(val_to_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TCzXXT1lATg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_elmo = np.asarray(all_X_preped_for_elmo_train, dtype=\"str\")\n",
        "X_test_elmo = np.asarray(all_X_preped_for_elmo_test, dtype=\"str\")\n",
        "y_train_elmo = np.asarray(all_train_y_converted, dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKXqh2RlAcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = hub.Module(elmo_model_hub_link, trainable = True)\n",
        "def get_elmo_embedding_for_each_input_using_lambda_function(inp):\n",
        "  return elmo(tf.squeeze(tf.cast(inp, tf.string)), signature='default', as_dict=True)['default']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdRP5kwhlAjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_elmo_using_model():\n",
        "  input_text = Input(shape=(1,), dtype=\"string\")\n",
        "  embeddings = Lambda(get_elmo_embedding_for_each_input_using_lambda_function, output_shape=(1024, ))(input_text)\n",
        "  dense = Dense(1024, activation='relu')(embeddings)\n",
        "  pred = Dense(2, activation='softmax')(dense)\n",
        "  model = Model(inputs=[input_text], outputs=pred)\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6R_Pu1alAun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_elmo(model):\n",
        "  # elmo_test_input = [np.array(X_test_elmo_tokens), np.array(X_test_elmo_seqlens)]\n",
        "  predicted_y = model.predict(X_test_elmo)\n",
        "  y_test_conv = [np.argmax(val) for val in all_test_y_converted]\n",
        "  predicted_y_conv = [np.argmax(val) for val in predicted_y]\n",
        "  print('Accuracy:', accuracy_score(y_test_conv, predicted_y_conv))\n",
        "  print('Classification report:', classification_report(y_test_conv, predicted_y_conv))\n",
        "  print('F1 (Micro):', f1_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('F1 (Macro):', f1_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('F1 (Weighted):', f1_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  print('Recall (Micro):', recall_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('Recall (Macro):', recall_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('Recall (Weighted):', recall_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  print('Precision (Micro):', precision_score(y_test_conv, predicted_y_conv, average='micro'))\n",
        "  print('Precision (Macro):', precision_score(y_test_conv, predicted_y_conv, average='macro'))\n",
        "  print('Precision (Weighted):', precision_score(y_test_conv, predicted_y_conv, average='weighted'))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test_conv, predicted_y_conv, pos_label=1)\n",
        "  print('AUC:', metrics.auc(fpr, tpr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV3xddVlstg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy_and_loss(file_save_name, history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.savefig(file_save_name+'_accuracy.png')\n",
        "  plt.cla()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.savefig(file_save_name+'_loss.png')\n",
        "  plt.cla()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTHA7_HolA6q",
        "colab_type": "code",
        "outputId": "c7f5173a-354d-46d5-fa7b-12e1458238c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "this_optimizer = keras.optimizers.Adam(lr = learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSl81RL-lBKH",
        "colab_type": "code",
        "outputId": "1016bd16-37fa-4b5d-8efc-6f48ad1f4e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epochs in number_of_epochs[1:]:\n",
        "  print('Number of epochs:', epochs)\n",
        "  model = create_elmo_using_model()\n",
        "  print(model.summary())\n",
        "  model.compile(loss='binary_crossentropy', optimizer=this_optimizer, metrics=['accuracy'])\n",
        "  history = model.fit(\n",
        "      X_train_elmo, \n",
        "      y_train_elmo,\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "  print('Done training')\n",
        "  image_save_file_name = 'drive/My Drive/CA5_Sabri_810198312/Results/Q2_elmo_model_{}_epochs'.format(epochs)\n",
        "  plot_accuracy_and_loss(image_save_file_name, history)\n",
        "  evaluate_model_elmo(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of epochs: 10\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,051,650\n",
            "Trainable params: 1,051,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 336s 13ms/step - loss: 0.4550 - accuracy: 0.7833\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.4088 - accuracy: 0.8145\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3881 - accuracy: 0.8262\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3788 - accuracy: 0.8282\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3698 - accuracy: 0.8362\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 327s 13ms/step - loss: 0.3643 - accuracy: 0.8368\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3511 - accuracy: 0.8466\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3457 - accuracy: 0.8462\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.3332 - accuracy: 0.8543\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3277 - accuracy: 0.8572\n",
            "Done training\n",
            "Accuracy: 0.78856\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.82     12500\n",
            "           1       0.92      0.63      0.75     12500\n",
            "\n",
            "    accuracy                           0.79     25000\n",
            "   macro avg       0.82      0.79      0.78     25000\n",
            "weighted avg       0.82      0.79      0.78     25000\n",
            "\n",
            "F1 (Micro): 0.7885600000000001\n",
            "F1 (Macro): 0.7834400601022906\n",
            "F1 (Weighted): 0.7834400601022906\n",
            "Recall (Micro): 0.78856\n",
            "Recall (Macro): 0.78856\n",
            "Recall (Weighted): 0.78856\n",
            "Precision (Micro): 0.78856\n",
            "Precision (Macro): 0.8186988922546037\n",
            "Precision (Weighted): 0.8186988922546037\n",
            "AUC: 0.78856\n",
            "Number of epochs: 20\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,051,650\n",
            "Trainable params: 1,051,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 331s 13ms/step - loss: 0.4517 - accuracy: 0.7894\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.4018 - accuracy: 0.8165\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3883 - accuracy: 0.8232\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3754 - accuracy: 0.8313\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3692 - accuracy: 0.8349\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3604 - accuracy: 0.8394\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3537 - accuracy: 0.8433\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3479 - accuracy: 0.8463\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3412 - accuracy: 0.8496\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3354 - accuracy: 0.8526\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3309 - accuracy: 0.8556\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3210 - accuracy: 0.8615\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3148 - accuracy: 0.8634\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3103 - accuracy: 0.8640\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.2999 - accuracy: 0.8726\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.2947 - accuracy: 0.8749\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2857 - accuracy: 0.8796\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2788 - accuracy: 0.8834\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2713 - accuracy: 0.8846\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2638 - accuracy: 0.8882\n",
            "Done training\n",
            "Accuracy: 0.83\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83     12500\n",
            "           1       0.85      0.81      0.83     12500\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.83      0.83      0.83     25000\n",
            "weighted avg       0.83      0.83      0.83     25000\n",
            "\n",
            "F1 (Micro): 0.83\n",
            "F1 (Macro): 0.829917080086353\n",
            "F1 (Weighted): 0.8299170800863529\n",
            "Recall (Micro): 0.83\n",
            "Recall (Macro): 0.83\n",
            "Recall (Weighted): 0.83\n",
            "Precision (Micro): 0.83\n",
            "Precision (Macro): 0.830644792260999\n",
            "Precision (Weighted): 0.8306447922609991\n",
            "AUC: 0.83\n",
            "Number of epochs: 50\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,051,650\n",
            "Trainable params: 1,051,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.4619 - accuracy: 0.7826\n",
            "Epoch 2/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.4030 - accuracy: 0.8174\n",
            "Epoch 3/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3890 - accuracy: 0.8240\n",
            "Epoch 4/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3797 - accuracy: 0.8295\n",
            "Epoch 5/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3699 - accuracy: 0.8353\n",
            "Epoch 6/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3660 - accuracy: 0.8364\n",
            "Epoch 7/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3582 - accuracy: 0.8412\n",
            "Epoch 8/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3536 - accuracy: 0.8428\n",
            "Epoch 9/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.3487 - accuracy: 0.8433\n",
            "Epoch 10/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3389 - accuracy: 0.8514\n",
            "Epoch 11/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3366 - accuracy: 0.8520\n",
            "Epoch 12/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3285 - accuracy: 0.8569\n",
            "Epoch 13/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3215 - accuracy: 0.8599\n",
            "Epoch 14/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3146 - accuracy: 0.8654\n",
            "Epoch 15/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3096 - accuracy: 0.8661\n",
            "Epoch 16/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3023 - accuracy: 0.8699\n",
            "Epoch 17/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2966 - accuracy: 0.8757\n",
            "Epoch 18/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2897 - accuracy: 0.8752\n",
            "Epoch 19/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2833 - accuracy: 0.8799\n",
            "Epoch 20/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2761 - accuracy: 0.8843\n",
            "Epoch 21/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2688 - accuracy: 0.8874\n",
            "Epoch 22/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2620 - accuracy: 0.8928\n",
            "Epoch 23/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2553 - accuracy: 0.8938\n",
            "Epoch 24/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2448 - accuracy: 0.8989\n",
            "Epoch 25/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2401 - accuracy: 0.9014\n",
            "Epoch 26/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2319 - accuracy: 0.9066\n",
            "Epoch 27/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2226 - accuracy: 0.9112\n",
            "Epoch 28/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2174 - accuracy: 0.9132\n",
            "Epoch 29/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.2087 - accuracy: 0.9183\n",
            "Epoch 30/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.2053 - accuracy: 0.9198\n",
            "Epoch 31/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1950 - accuracy: 0.9246\n",
            "Epoch 32/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1887 - accuracy: 0.9286\n",
            "Epoch 33/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1796 - accuracy: 0.9332\n",
            "Epoch 34/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1717 - accuracy: 0.9370\n",
            "Epoch 35/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1663 - accuracy: 0.9388\n",
            "Epoch 36/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1589 - accuracy: 0.9418\n",
            "Epoch 37/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1497 - accuracy: 0.9462\n",
            "Epoch 38/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1428 - accuracy: 0.9494\n",
            "Epoch 39/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1349 - accuracy: 0.9548\n",
            "Epoch 40/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1306 - accuracy: 0.9561\n",
            "Epoch 41/50\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.1257 - accuracy: 0.9562\n",
            "Epoch 42/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1168 - accuracy: 0.9622\n",
            "Epoch 43/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1139 - accuracy: 0.9626\n",
            "Epoch 44/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.1074 - accuracy: 0.9653\n",
            "Epoch 45/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.1002 - accuracy: 0.9698\n",
            "Epoch 46/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.0909 - accuracy: 0.9741\n",
            "Epoch 47/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.0894 - accuracy: 0.9739\n",
            "Epoch 48/50\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.0855 - accuracy: 0.9753\n",
            "Epoch 49/50\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 0.0802 - accuracy: 0.9781\n",
            "Epoch 50/50\n",
            "25000/25000 [==============================] - 330s 13ms/step - loss: 0.0736 - accuracy: 0.9809\n",
            "Done training\n",
            "Accuracy: 0.80944\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82     12500\n",
            "           1       0.84      0.76      0.80     12500\n",
            "\n",
            "    accuracy                           0.81     25000\n",
            "   macro avg       0.81      0.81      0.81     25000\n",
            "weighted avg       0.81      0.81      0.81     25000\n",
            "\n",
            "F1 (Micro): 0.80944\n",
            "F1 (Macro): 0.8089500697247227\n",
            "F1 (Weighted): 0.8089500697247227\n",
            "Recall (Micro): 0.80944\n",
            "Recall (Macro): 0.8094399999999999\n",
            "Recall (Weighted): 0.80944\n",
            "Precision (Micro): 0.80944\n",
            "Precision (Macro): 0.8126470200788058\n",
            "Precision (Weighted): 0.8126470200788058\n",
            "AUC: 0.8094399999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHpQm4xGlBWg",
        "colab_type": "code",
        "outputId": "9c3e25ec-f9cd-433f-bc81-659d3221e137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.78264,\n",
              "  0.81744,\n",
              "  0.82404,\n",
              "  0.82952,\n",
              "  0.83532,\n",
              "  0.83636,\n",
              "  0.84124,\n",
              "  0.84284,\n",
              "  0.84328,\n",
              "  0.85144,\n",
              "  0.85204,\n",
              "  0.85688,\n",
              "  0.85992,\n",
              "  0.8654,\n",
              "  0.86612,\n",
              "  0.86988,\n",
              "  0.87568,\n",
              "  0.8752,\n",
              "  0.87992,\n",
              "  0.88428,\n",
              "  0.88736,\n",
              "  0.89276,\n",
              "  0.8938,\n",
              "  0.89888,\n",
              "  0.9014,\n",
              "  0.90664,\n",
              "  0.9112,\n",
              "  0.91316,\n",
              "  0.91832,\n",
              "  0.91976,\n",
              "  0.9246,\n",
              "  0.92864,\n",
              "  0.93316,\n",
              "  0.93704,\n",
              "  0.9388,\n",
              "  0.94176,\n",
              "  0.94616,\n",
              "  0.94944,\n",
              "  0.9548,\n",
              "  0.95608,\n",
              "  0.9562,\n",
              "  0.9622,\n",
              "  0.96256,\n",
              "  0.96532,\n",
              "  0.96984,\n",
              "  0.97412,\n",
              "  0.97392,\n",
              "  0.97528,\n",
              "  0.97808,\n",
              "  0.98088],\n",
              " 'loss': [0.46185063940048215,\n",
              "  0.4029558487224579,\n",
              "  0.38897464941978455,\n",
              "  0.37973092075347903,\n",
              "  0.36989936302661897,\n",
              "  0.36597238519191744,\n",
              "  0.3581571912574768,\n",
              "  0.35363118392944337,\n",
              "  0.3487360620975494,\n",
              "  0.3388598433494568,\n",
              "  0.3366235333275795,\n",
              "  0.3285354618263245,\n",
              "  0.3214976783657074,\n",
              "  0.3145997780704498,\n",
              "  0.3095957474780083,\n",
              "  0.3022749171257019,\n",
              "  0.296624139509201,\n",
              "  0.28967799945831296,\n",
              "  0.28327900399327277,\n",
              "  0.2761333114719391,\n",
              "  0.26880134283542634,\n",
              "  0.2620167379331589,\n",
              "  0.2552604341864586,\n",
              "  0.24480880146980286,\n",
              "  0.24007113710641861,\n",
              "  0.231890044901371,\n",
              "  0.22262396357417108,\n",
              "  0.21737509826660156,\n",
              "  0.2086652726793289,\n",
              "  0.2053064494419098,\n",
              "  0.19502319422483444,\n",
              "  0.18873266756892204,\n",
              "  0.17957351647377015,\n",
              "  0.1717365567857027,\n",
              "  0.16632661947011948,\n",
              "  0.15885332166433333,\n",
              "  0.1497316368627548,\n",
              "  0.14276690078735352,\n",
              "  0.13486581278562546,\n",
              "  0.13059425347328185,\n",
              "  0.1256645044398308,\n",
              "  0.11684104262530803,\n",
              "  0.11390890883594751,\n",
              "  0.10737430637121201,\n",
              "  0.10021344306468964,\n",
              "  0.09090254858970642,\n",
              "  0.0894243633723259,\n",
              "  0.08548225455522537,\n",
              "  0.08017283029556274,\n",
              "  0.07356586628913879]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAYVpdyjiTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}