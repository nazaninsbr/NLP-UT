{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpgq2KISOHBo",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 - English to Farsi\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMHtQpfS-c5",
        "colab_type": "code",
        "outputId": "e79b475f-3835-4a29-d673-80880575e571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hsy2reHW_Mc",
        "colab_type": "code",
        "outputId": "2938a3d1-5775-4a06-f5dd-913acdee22ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/Corpora/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Corpora\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2aK_d7VNA3",
        "colab_type": "code",
        "outputId": "fbad0740-e095-4235-c684-5f08987f2823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os \n",
        "os.listdir('.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['En2Fa-Translation',\n",
              " 'Transliteration',\n",
              " 'OpenNMT-py',\n",
              " 'model_step_5000.pt',\n",
              " 'model_step_10000.pt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKrzegS2O1t3",
        "colab_type": "text"
      },
      "source": [
        "# Git Clone\n",
        "First Git clone the OpenNMT source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-kDi11Xx5bs",
        "colab_type": "code",
        "outputId": "3eba7797-9522-411b-ef93-50fd9a423991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'OpenNMT-py' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TlIyXGzO61s",
        "colab_type": "text"
      },
      "source": [
        "# Please install requirements.txt use by pip\n",
        "\n",
        "> Error : You must restart the runtime in order to use newly installed versions.<br>\n",
        "Solution : Click Restart Runtime => Redo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waRzBre1cMIU",
        "colab_type": "code",
        "outputId": "4f606c79-88c1-4214-f360-e2200c956d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "!pip install -r ./OpenNMT-py/floyd_requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pytorch/text (from -r ./OpenNMT-py/floyd_requirements.txt (line 1))\n",
            "  Cloning https://github.com/pytorch/text to /tmp/pip-req-build-cg4kru45\n",
            "  Running command git clone -q https://github.com/pytorch/text /tmp/pip-req-build-cg4kru45\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (1.18.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (2.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0a0+e709553->-r ./OpenNMT-py/floyd_requirements.txt (line 1)) (0.16.0)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.6.0a0+e709553-cp36-cp36m-linux_x86_64.whl size=2149165 sha256=667bb39f1c43bfc2eae725e85f3f385e215e790aeee5703a9a2bbe80b9ba46ec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-knnp7e71/wheels/73/14/71/ed033fd999ae4933e17df3e91be2014e61c2f312a88a164ff5\n",
            "Successfully built torchtext\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0a0+e709553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gq-o1qtyFR0",
        "colab_type": "code",
        "outputId": "ae9eea3f-48b0-4120-d36e-de6134e98a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "!pip install torchtext==0.4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.5.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.18.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.4) (0.16.0)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH5hxHPSeojN",
        "colab_type": "code",
        "outputId": "704ab90c-f692-4261-d6bf-692416072020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "!pip install configargparse"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting configargparse\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n",
            "\r\u001b[K     |███████▊                        | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: configargparse\n",
            "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19328 sha256=59d4e61e390ae9f645f1dcd56e1bd9470dad56aa0ade01d481840d7cf9611244\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n",
            "Successfully built configargparse\n",
            "Installing collected packages: configargparse\n",
            "Successfully installed configargparse-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOY1leRFg10w",
        "colab_type": "text"
      },
      "source": [
        "# Q1: RNN + No bpe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuSb7DFwYdol",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZhkVv1rYdOb",
        "colab_type": "code",
        "outputId": "02564d8b-d7ff-42b3-ec60-974b6c4f244e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "!python OpenNMT-py/preprocess.py -train_src En2Fa-Translation/Train/train.en -train_tgt En2Fa-Translation/Train/train.fa -valid_src En2Fa-Translation/Dev/dev.en -valid_tgt En2Fa-Translation/Dev/dev.fa -save_data En2Fa-Translation/Cleaned"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 10:43:42,869 INFO] Extracting features...\n",
            "[2020-06-01 10:43:44,310 INFO]  * number of source features: 0.\n",
            "[2020-06-01 10:43:44,311 INFO]  * number of target features: 0.\n",
            "[2020-06-01 10:43:44,311 INFO] Building `Fields` object...\n",
            "[2020-06-01 10:43:44,311 INFO] Building & saving training data...\n",
            "[2020-06-01 10:43:45,611 INFO] Building shard 0.\n",
            "[2020-06-01 10:43:46,596 INFO]  * saving 0th train data shard to En2Fa-Translation/Cleaned.train.0.pt.\n",
            "[2020-06-01 10:43:47,441 INFO]  * tgt vocab size: 5908.\n",
            "[2020-06-01 10:43:47,445 INFO]  * src vocab size: 3116.\n",
            "[2020-06-01 10:43:47,522 INFO] Building & saving validation data...\n",
            "[2020-06-01 10:43:48,907 INFO] Building shard 0.\n",
            "[2020-06-01 10:43:48,913 INFO]  * saving 0th valid data shard to En2Fa-Translation/Cleaned.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-YdtlYHfctl",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pjisHT3fb9k",
        "colab_type": "code",
        "outputId": "49459292-3c16-4d69-db16-89651e167c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  1 10:48:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_QFMiArgBSd",
        "colab_type": "code",
        "outputId": "8897d3a1-f9ef-441d-cf3a-1260059cf47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "os.listdir('En2Fa-Translation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Train',\n",
              " 'Dev',\n",
              " 'Test',\n",
              " 'Cleaned',\n",
              " 'Cleaned.train.0.pt',\n",
              " 'Cleaned.vocab.pt',\n",
              " 'Cleaned.valid.0.pt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEvWj7Eg8l6",
        "colab_type": "text"
      },
      "source": [
        "#### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5s5AzXbg_Ic",
        "colab_type": "code",
        "outputId": "f2f4869a-aa42-4225-92ff-8f7daffa5293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python OpenNMT-py/train.py -data En2Fa-Translation/Cleaned -save_model En2Fa-Translation/rnn_model -world_size 1 -gpu_rank 0 --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 50000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 12:34:06,935 INFO]  * src vocab size = 3116\n",
            "[2020-06-01 12:34:06,935 INFO]  * tgt vocab size = 5908\n",
            "[2020-06-01 12:34:06,935 INFO] Building model...\n",
            "[2020-06-01 12:34:09,471 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3116, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5908, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=5908, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-01 12:34:09,471 INFO] encoder: 9938416\n",
            "[2020-06-01 12:34:09,472 INFO] decoder: 16200228\n",
            "[2020-06-01 12:34:09,472 INFO] * number of parameters: 26138644\n",
            "[2020-06-01 12:34:09,475 INFO] Starting training on GPU: [0]\n",
            "[2020-06-01 12:34:09,475 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-01 12:34:09,476 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:34:09,727 INFO] number of examples: 26142\n",
            "[2020-06-01 12:34:16,431 INFO] Step 50/50000; acc:   7.63; ppl: 152951.84; xent: 11.94; lr: 1.00000; 4740/4683 tok/s;      7 sec\n",
            "[2020-06-01 12:34:23,223 INFO] Step 100/50000; acc:   6.74; ppl: 4735.93; xent: 8.46; lr: 1.00000; 5113/5074 tok/s;     14 sec\n",
            "[2020-06-01 12:34:29,456 INFO] Step 150/50000; acc:   7.96; ppl: 815.03; xent: 6.70; lr: 1.00000; 4893/5154 tok/s;     20 sec\n",
            "[2020-06-01 12:34:35,045 INFO] Step 200/50000; acc:   9.08; ppl: 525.70; xent: 6.26; lr: 1.00000; 5022/5140 tok/s;     26 sec\n",
            "[2020-06-01 12:34:41,473 INFO] Step 250/50000; acc:  10.94; ppl: 336.73; xent: 5.82; lr: 1.00000; 5103/5204 tok/s;     32 sec\n",
            "[2020-06-01 12:34:47,006 INFO] Step 300/50000; acc:  16.61; ppl: 196.44; xent: 5.28; lr: 1.00000; 5153/5304 tok/s;     38 sec\n",
            "[2020-06-01 12:34:53,912 INFO] Step 350/50000; acc:  14.17; ppl: 223.74; xent: 5.41; lr: 1.00000; 5319/5408 tok/s;     44 sec\n",
            "[2020-06-01 12:35:00,925 INFO] Step 400/50000; acc:  14.51; ppl: 200.84; xent: 5.30; lr: 1.00000; 5108/5147 tok/s;     51 sec\n",
            "[2020-06-01 12:35:01,721 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:35:02,069 INFO] number of examples: 26142\n",
            "[2020-06-01 12:35:07,295 INFO] Step 450/50000; acc:  17.32; ppl: 144.43; xent: 4.97; lr: 1.00000; 4806/4695 tok/s;     58 sec\n",
            "[2020-06-01 12:35:14,208 INFO] Step 500/50000; acc:  15.06; ppl: 166.06; xent: 5.11; lr: 1.00000; 5163/5257 tok/s;     65 sec\n",
            "[2020-06-01 12:35:20,374 INFO] Step 550/50000; acc:  18.90; ppl: 118.35; xent: 4.77; lr: 1.00000; 4942/5027 tok/s;     71 sec\n",
            "[2020-06-01 12:35:26,166 INFO] Step 600/50000; acc:  19.02; ppl: 117.87; xent: 4.77; lr: 1.00000; 5066/5270 tok/s;     77 sec\n",
            "[2020-06-01 12:35:32,134 INFO] Step 650/50000; acc:  20.60; ppl: 107.30; xent: 4.68; lr: 1.00000; 5121/5171 tok/s;     83 sec\n",
            "[2020-06-01 12:35:37,620 INFO] Step 700/50000; acc:  21.92; ppl: 92.84; xent: 4.53; lr: 1.00000; 5082/5255 tok/s;     88 sec\n",
            "[2020-06-01 12:35:44,799 INFO] Step 750/50000; acc:  17.70; ppl: 126.05; xent: 4.84; lr: 1.00000; 5283/5453 tok/s;     95 sec\n",
            "[2020-06-01 12:35:51,393 INFO] Step 800/50000; acc:  21.19; ppl: 102.13; xent: 4.63; lr: 1.00000; 5173/5144 tok/s;    102 sec\n",
            "[2020-06-01 12:35:53,691 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:35:53,949 INFO] number of examples: 26142\n",
            "[2020-06-01 12:35:58,259 INFO] Step 850/50000; acc:  21.44; ppl: 92.06; xent: 4.52; lr: 1.00000; 4787/4707 tok/s;    109 sec\n",
            "[2020-06-01 12:36:04,860 INFO] Step 900/50000; acc:  22.19; ppl: 88.21; xent: 4.48; lr: 1.00000; 5184/5242 tok/s;    115 sec\n",
            "[2020-06-01 12:36:11,396 INFO] Step 950/50000; acc:  23.96; ppl: 78.13; xent: 4.36; lr: 1.00000; 5020/5054 tok/s;    122 sec\n",
            "[2020-06-01 12:36:17,092 INFO] Step 1000/50000; acc:  26.71; ppl: 65.53; xent: 4.18; lr: 1.00000; 4888/5229 tok/s;    128 sec\n",
            "[2020-06-01 12:36:23,180 INFO] Step 1050/50000; acc:  27.24; ppl: 65.94; xent: 4.19; lr: 1.00000; 5177/5171 tok/s;    134 sec\n",
            "[2020-06-01 12:36:28,665 INFO] Step 1100/50000; acc:  28.87; ppl: 57.51; xent: 4.05; lr: 1.00000; 5106/5216 tok/s;    139 sec\n",
            "[2020-06-01 12:36:35,785 INFO] Step 1150/50000; acc:  24.69; ppl: 71.22; xent: 4.27; lr: 1.00000; 5246/5462 tok/s;    146 sec\n",
            "[2020-06-01 12:36:42,300 INFO] Step 1200/50000; acc:  27.52; ppl: 61.87; xent: 4.12; lr: 1.00000; 5108/5108 tok/s;    153 sec\n",
            "[2020-06-01 12:36:45,739 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:36:46,009 INFO] number of examples: 26142\n",
            "[2020-06-01 12:36:49,012 INFO] Step 1250/50000; acc:  29.02; ppl: 56.27; xent: 4.03; lr: 1.00000; 4860/4844 tok/s;    160 sec\n",
            "[2020-06-01 12:36:55,546 INFO] Step 1300/50000; acc:  29.30; ppl: 51.89; xent: 3.95; lr: 1.00000; 5315/5236 tok/s;    166 sec\n",
            "[2020-06-01 12:37:02,324 INFO] Step 1350/50000; acc:  29.19; ppl: 52.42; xent: 3.96; lr: 1.00000; 5012/5035 tok/s;    173 sec\n",
            "[2020-06-01 12:37:08,047 INFO] Step 1400/50000; acc:  34.05; ppl: 38.97; xent: 3.66; lr: 1.00000; 4818/5252 tok/s;    179 sec\n",
            "[2020-06-01 12:37:13,841 INFO] Step 1450/50000; acc:  33.96; ppl: 40.44; xent: 3.70; lr: 1.00000; 5125/5126 tok/s;    184 sec\n",
            "[2020-06-01 12:37:19,944 INFO] Step 1500/50000; acc:  32.96; ppl: 42.86; xent: 3.76; lr: 1.00000; 5222/5240 tok/s;    190 sec\n",
            "[2020-06-01 12:37:26,361 INFO] Step 1550/50000; acc:  32.61; ppl: 41.95; xent: 3.74; lr: 1.00000; 5152/5428 tok/s;    197 sec\n",
            "[2020-06-01 12:37:32,742 INFO] Step 1600/50000; acc:  33.19; ppl: 41.58; xent: 3.73; lr: 1.00000; 5380/5367 tok/s;    203 sec\n",
            "[2020-06-01 12:37:37,670 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:37:37,973 INFO] number of examples: 26142\n",
            "[2020-06-01 12:37:39,854 INFO] Step 1650/50000; acc:  33.13; ppl: 42.97; xent: 3.76; lr: 1.00000; 4601/4657 tok/s;    210 sec\n",
            "[2020-06-01 12:37:45,951 INFO] Step 1700/50000; acc:  36.22; ppl: 34.29; xent: 3.53; lr: 1.00000; 5182/5200 tok/s;    216 sec\n",
            "[2020-06-01 12:37:53,148 INFO] Step 1750/50000; acc:  32.96; ppl: 41.23; xent: 3.72; lr: 1.00000; 5218/5043 tok/s;    224 sec\n",
            "[2020-06-01 12:37:59,076 INFO] Step 1800/50000; acc:  38.02; ppl: 29.59; xent: 3.39; lr: 1.00000; 4925/5337 tok/s;    230 sec\n",
            "[2020-06-01 12:38:04,923 INFO] Step 1850/50000; acc:  38.02; ppl: 30.83; xent: 3.43; lr: 1.00000; 5063/5065 tok/s;    235 sec\n",
            "[2020-06-01 12:38:10,947 INFO] Step 1900/50000; acc:  37.68; ppl: 30.21; xent: 3.41; lr: 1.00000; 5110/5240 tok/s;    241 sec\n",
            "[2020-06-01 12:38:16,756 INFO] Step 1950/50000; acc:  38.62; ppl: 28.22; xent: 3.34; lr: 1.00000; 5068/5435 tok/s;    247 sec\n",
            "[2020-06-01 12:38:23,899 INFO] Step 2000/50000; acc:  34.85; ppl: 36.11; xent: 3.59; lr: 1.00000; 5474/5389 tok/s;    254 sec\n",
            "[2020-06-01 12:38:29,662 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:38:29,987 INFO] number of examples: 26142\n",
            "[2020-06-01 12:38:30,741 INFO] Step 2050/50000; acc:  37.82; ppl: 30.91; xent: 3.43; lr: 1.00000; 4568/4680 tok/s;    261 sec\n",
            "[2020-06-01 12:38:36,934 INFO] Step 2100/50000; acc:  39.35; ppl: 27.02; xent: 3.30; lr: 1.00000; 5215/5093 tok/s;    267 sec\n",
            "[2020-06-01 12:38:44,035 INFO] Step 2150/50000; acc:  36.26; ppl: 31.77; xent: 3.46; lr: 1.00000; 5195/5082 tok/s;    275 sec\n",
            "[2020-06-01 12:38:50,228 INFO] Step 2200/50000; acc:  40.55; ppl: 24.56; xent: 3.20; lr: 1.00000; 4978/5300 tok/s;    281 sec\n",
            "[2020-06-01 12:38:55,909 INFO] Step 2250/50000; acc:  41.17; ppl: 23.93; xent: 3.18; lr: 1.00000; 4997/5088 tok/s;    286 sec\n",
            "[2020-06-01 12:39:02,059 INFO] Step 2300/50000; acc:  40.58; ppl: 24.13; xent: 3.18; lr: 1.00000; 5151/5244 tok/s;    293 sec\n",
            "[2020-06-01 12:39:07,575 INFO] Step 2350/50000; acc:  42.57; ppl: 21.61; xent: 3.07; lr: 1.00000; 5059/5375 tok/s;    298 sec\n",
            "[2020-06-01 12:39:14,638 INFO] Step 2400/50000; acc:  37.29; ppl: 28.93; xent: 3.37; lr: 1.00000; 5373/5368 tok/s;    305 sec\n",
            "[2020-06-01 12:39:21,268 INFO] Step 2450/50000; acc:  39.41; ppl: 26.78; xent: 3.29; lr: 1.00000; 5027/5092 tok/s;    312 sec\n",
            "[2020-06-01 12:39:21,646 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:39:21,972 INFO] number of examples: 26142\n",
            "[2020-06-01 12:39:27,835 INFO] Step 2500/50000; acc:  41.40; ppl: 22.52; xent: 3.11; lr: 1.00000; 4837/4775 tok/s;    318 sec\n",
            "[2020-06-01 12:39:34,851 INFO] Step 2550/50000; acc:  38.71; ppl: 25.68; xent: 3.25; lr: 1.00000; 5158/5116 tok/s;    325 sec\n",
            "[2020-06-01 12:39:40,913 INFO] Step 2600/50000; acc:  43.55; ppl: 19.42; xent: 2.97; lr: 1.00000; 4893/5164 tok/s;    331 sec\n",
            "[2020-06-01 12:39:46,573 INFO] Step 2650/50000; acc:  43.59; ppl: 19.64; xent: 2.98; lr: 1.00000; 5115/5219 tok/s;    337 sec\n",
            "[2020-06-01 12:39:52,881 INFO] Step 2700/50000; acc:  42.59; ppl: 20.32; xent: 3.01; lr: 1.00000; 5080/5192 tok/s;    343 sec\n",
            "[2020-06-01 12:39:58,357 INFO] Step 2750/50000; acc:  45.16; ppl: 17.65; xent: 2.87; lr: 1.00000; 5113/5288 tok/s;    349 sec\n",
            "[2020-06-01 12:40:05,438 INFO] Step 2800/50000; acc:  39.65; ppl: 24.26; xent: 3.19; lr: 1.00000; 5338/5401 tok/s;    356 sec\n",
            "[2020-06-01 12:40:12,305 INFO] Step 2850/50000; acc:  40.59; ppl: 23.25; xent: 3.15; lr: 1.00000; 5025/5064 tok/s;    363 sec\n",
            "[2020-06-01 12:40:13,693 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:40:14,047 INFO] number of examples: 26142\n",
            "[2020-06-01 12:40:18,715 INFO] Step 2900/50000; acc:  44.06; ppl: 18.36; xent: 2.91; lr: 1.00000; 4766/4682 tok/s;    369 sec\n",
            "[2020-06-01 12:40:25,680 INFO] Step 2950/50000; acc:  41.20; ppl: 21.28; xent: 3.06; lr: 1.00000; 5171/5260 tok/s;    376 sec\n",
            "[2020-06-01 12:40:32,012 INFO] Step 3000/50000; acc:  44.46; ppl: 17.80; xent: 2.88; lr: 1.00000; 4984/5010 tok/s;    383 sec\n",
            "[2020-06-01 12:40:37,705 INFO] Step 3050/50000; acc:  45.91; ppl: 16.34; xent: 2.79; lr: 1.00000; 4952/5242 tok/s;    388 sec\n",
            "[2020-06-01 12:40:43,839 INFO] Step 3100/50000; acc:  44.79; ppl: 16.84; xent: 2.82; lr: 1.00000; 5170/5136 tok/s;    394 sec\n",
            "[2020-06-01 12:40:49,375 INFO] Step 3150/50000; acc:  46.56; ppl: 15.57; xent: 2.75; lr: 1.00000; 5082/5247 tok/s;    400 sec\n",
            "[2020-06-01 12:40:56,505 INFO] Step 3200/50000; acc:  41.99; ppl: 19.92; xent: 2.99; lr: 1.00000; 5230/5436 tok/s;    407 sec\n",
            "[2020-06-01 12:41:03,037 INFO] Step 3250/50000; acc:  43.36; ppl: 18.72; xent: 2.93; lr: 1.00000; 5104/5094 tok/s;    414 sec\n",
            "[2020-06-01 12:41:05,887 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:41:06,217 INFO] number of examples: 26142\n",
            "[2020-06-01 12:41:09,720 INFO] Step 3300/50000; acc:  44.96; ppl: 17.23; xent: 2.85; lr: 1.00000; 4795/4764 tok/s;    420 sec\n",
            "[2020-06-01 12:41:16,322 INFO] Step 3350/50000; acc:  44.54; ppl: 16.71; xent: 2.82; lr: 1.00000; 5251/5230 tok/s;    427 sec\n",
            "[2020-06-01 12:41:23,252 INFO] Step 3400/50000; acc:  44.24; ppl: 17.68; xent: 2.87; lr: 1.00000; 4946/4991 tok/s;    434 sec\n",
            "[2020-06-01 12:41:28,830 INFO] Step 3450/50000; acc:  49.18; ppl: 13.05; xent: 2.57; lr: 1.00000; 4852/5184 tok/s;    439 sec\n",
            "[2020-06-01 12:41:34,770 INFO] Step 3500/50000; acc:  46.99; ppl: 14.33; xent: 2.66; lr: 1.00000; 5120/5161 tok/s;    445 sec\n",
            "[2020-06-01 12:41:40,674 INFO] Step 3550/50000; acc:  47.20; ppl: 14.54; xent: 2.68; lr: 1.00000; 5116/5191 tok/s;    451 sec\n",
            "[2020-06-01 12:41:47,457 INFO] Step 3600/50000; acc:  44.98; ppl: 16.24; xent: 2.79; lr: 1.00000; 5185/5397 tok/s;    458 sec\n",
            "[2020-06-01 12:41:53,837 INFO] Step 3650/50000; acc:  45.91; ppl: 15.43; xent: 2.74; lr: 1.00000; 5167/5168 tok/s;    464 sec\n",
            "[2020-06-01 12:41:58,143 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:41:58,484 INFO] number of examples: 26142\n",
            "[2020-06-01 12:42:00,938 INFO] Step 3700/50000; acc:  45.09; ppl: 16.22; xent: 2.79; lr: 1.00000; 4710/4758 tok/s;    471 sec\n",
            "[2020-06-01 12:42:07,340 INFO] Step 3750/50000; acc:  46.56; ppl: 14.17; xent: 2.65; lr: 1.00000; 5265/5185 tok/s;    478 sec\n",
            "[2020-06-01 12:42:14,411 INFO] Step 3800/50000; acc:  44.86; ppl: 16.12; xent: 2.78; lr: 1.00000; 5076/5021 tok/s;    485 sec\n",
            "[2020-06-01 12:42:20,333 INFO] Step 3850/50000; acc:  49.97; ppl: 11.94; xent: 2.48; lr: 1.00000; 4819/5222 tok/s;    491 sec\n",
            "[2020-06-01 12:42:26,236 INFO] Step 3900/50000; acc:  48.45; ppl: 13.07; xent: 2.57; lr: 1.00000; 5095/5101 tok/s;    497 sec\n",
            "[2020-06-01 12:42:32,177 INFO] Step 3950/50000; acc:  49.36; ppl: 12.34; xent: 2.51; lr: 1.00000; 5095/5198 tok/s;    503 sec\n",
            "[2020-06-01 12:42:38,421 INFO] Step 4000/50000; acc:  48.55; ppl: 12.85; xent: 2.55; lr: 1.00000; 5049/5368 tok/s;    509 sec\n",
            "[2020-06-01 12:42:45,105 INFO] Step 4050/50000; acc:  46.24; ppl: 14.29; xent: 2.66; lr: 1.00000; 5385/5334 tok/s;    516 sec\n",
            "[2020-06-01 12:42:50,529 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:42:50,884 INFO] number of examples: 26142\n",
            "[2020-06-01 12:42:52,109 INFO] Step 4100/50000; acc:  47.21; ppl: 14.07; xent: 2.64; lr: 1.00000; 4554/4629 tok/s;    523 sec\n",
            "[2020-06-01 12:42:58,502 INFO] Step 4150/50000; acc:  48.54; ppl: 12.53; xent: 2.53; lr: 1.00000; 5162/5103 tok/s;    529 sec\n",
            "[2020-06-01 12:43:05,648 INFO] Step 4200/50000; acc:  45.79; ppl: 14.68; xent: 2.69; lr: 1.00000; 5175/5006 tok/s;    536 sec\n",
            "[2020-06-01 12:43:11,759 INFO] Step 4250/50000; acc:  51.21; ppl: 10.84; xent: 2.38; lr: 1.00000; 4893/5306 tok/s;    542 sec\n",
            "[2020-06-01 12:43:17,519 INFO] Step 4300/50000; acc:  50.57; ppl: 11.29; xent: 2.42; lr: 1.00000; 4951/5015 tok/s;    548 sec\n",
            "[2020-06-01 12:43:23,701 INFO] Step 4350/50000; acc:  50.07; ppl: 11.50; xent: 2.44; lr: 1.00000; 5155/5212 tok/s;    554 sec\n",
            "[2020-06-01 12:43:29,507 INFO] Step 4400/50000; acc:  51.47; ppl: 10.74; xent: 2.37; lr: 1.00000; 5060/5386 tok/s;    560 sec\n",
            "[2020-06-01 12:43:36,627 INFO] Step 4450/50000; acc:  47.13; ppl: 13.44; xent: 2.60; lr: 1.00000; 5357/5334 tok/s;    567 sec\n",
            "[2020-06-01 12:43:42,918 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:43:43,273 INFO] number of examples: 26142\n",
            "[2020-06-01 12:43:43,473 INFO] Step 4500/50000; acc:  49.30; ppl: 12.24; xent: 2.50; lr: 1.00000; 4588/4660 tok/s;    574 sec\n",
            "[2020-06-01 12:43:49,870 INFO] Step 4550/50000; acc:  49.84; ppl: 11.25; xent: 2.42; lr: 1.00000; 5134/5054 tok/s;    580 sec\n",
            "[2020-06-01 12:43:56,663 INFO] Step 4600/50000; acc:  48.42; ppl: 12.32; xent: 2.51; lr: 1.00000; 5112/5073 tok/s;    587 sec\n",
            "[2020-06-01 12:44:02,997 INFO] Step 4650/50000; acc:  51.37; ppl: 10.36; xent: 2.34; lr: 1.00000; 4867/5143 tok/s;    594 sec\n",
            "[2020-06-01 12:44:08,611 INFO] Step 4700/50000; acc:  52.30; ppl:  9.79; xent: 2.28; lr: 1.00000; 5029/5116 tok/s;    599 sec\n",
            "[2020-06-01 12:44:15,232 INFO] Step 4750/50000; acc:  50.38; ppl: 10.88; xent: 2.39; lr: 1.00000; 5137/5205 tok/s;    606 sec\n",
            "[2020-06-01 12:44:20,515 INFO] Step 4800/50000; acc:  54.98; ppl:  8.72; xent: 2.17; lr: 1.00000; 5076/5281 tok/s;    611 sec\n",
            "[2020-06-01 12:44:27,591 INFO] Step 4850/50000; acc:  48.99; ppl: 11.83; xent: 2.47; lr: 1.00000; 5255/5351 tok/s;    618 sec\n",
            "[2020-06-01 12:44:34,577 INFO] Step 4900/50000; acc:  48.76; ppl: 12.29; xent: 2.51; lr: 1.00000; 5082/5111 tok/s;    625 sec\n",
            "[2020-06-01 12:44:35,311 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:44:35,670 INFO] number of examples: 26142\n",
            "[2020-06-01 12:44:41,099 INFO] Step 4950/50000; acc:  52.08; ppl:  9.76; xent: 2.28; lr: 1.00000; 4802/4684 tok/s;    632 sec\n",
            "[2020-06-01 12:44:48,183 INFO] Step 5000/50000; acc:  49.56; ppl: 11.16; xent: 2.41; lr: 1.00000; 5092/5150 tok/s;    639 sec\n",
            "[2020-06-01 12:44:48,216 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_5000.pt\n",
            "[2020-06-01 12:44:54,758 INFO] Step 5050/50000; acc:  53.23; ppl:  9.16; xent: 2.21; lr: 1.00000; 4578/4728 tok/s;    645 sec\n",
            "[2020-06-01 12:45:00,541 INFO] Step 5100/50000; acc:  53.77; ppl:  8.88; xent: 2.18; lr: 1.00000; 5007/5150 tok/s;    651 sec\n",
            "[2020-06-01 12:45:06,618 INFO] Step 5150/50000; acc:  53.61; ppl:  8.73; xent: 2.17; lr: 1.00000; 5061/5131 tok/s;    657 sec\n",
            "[2020-06-01 12:45:12,185 INFO] Step 5200/50000; acc:  55.02; ppl:  8.33; xent: 2.12; lr: 1.00000; 5043/5219 tok/s;    663 sec\n",
            "[2020-06-01 12:45:19,384 INFO] Step 5250/50000; acc:  50.10; ppl: 10.80; xent: 2.38; lr: 1.00000; 5250/5399 tok/s;    670 sec\n",
            "[2020-06-01 12:45:26,101 INFO] Step 5300/50000; acc:  50.99; ppl: 10.63; xent: 2.36; lr: 1.00000; 5071/5082 tok/s;    677 sec\n",
            "[2020-06-01 12:45:28,205 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:45:28,575 INFO] number of examples: 26142\n",
            "[2020-06-01 12:45:32,972 INFO] Step 5350/50000; acc:  52.09; ppl:  9.61; xent: 2.26; lr: 1.00000; 4799/4682 tok/s;    683 sec\n",
            "[2020-06-01 12:45:39,528 INFO] Step 5400/50000; acc:  52.39; ppl:  9.29; xent: 2.23; lr: 1.00000; 5112/5191 tok/s;    690 sec\n",
            "[2020-06-01 12:45:46,175 INFO] Step 5450/50000; acc:  52.30; ppl:  9.44; xent: 2.25; lr: 1.00000; 4975/5018 tok/s;    697 sec\n",
            "[2020-06-01 12:45:51,999 INFO] Step 5500/50000; acc:  55.65; ppl:  7.83; xent: 2.06; lr: 1.00000; 4878/5187 tok/s;    703 sec\n",
            "[2020-06-01 12:45:58,046 INFO] Step 5550/50000; acc:  54.63; ppl:  8.16; xent: 2.10; lr: 1.00000; 5128/5115 tok/s;    709 sec\n",
            "[2020-06-01 12:46:03,630 INFO] Step 5600/50000; acc:  56.20; ppl:  7.70; xent: 2.04; lr: 1.00000; 5073/5203 tok/s;    714 sec\n",
            "[2020-06-01 12:46:10,775 INFO] Step 5650/50000; acc:  52.34; ppl:  9.38; xent: 2.24; lr: 1.00000; 5182/5424 tok/s;    721 sec\n",
            "[2020-06-01 12:46:17,348 INFO] Step 5700/50000; acc:  52.33; ppl:  9.48; xent: 2.25; lr: 1.00000; 5092/5083 tok/s;    728 sec\n",
            "[2020-06-01 12:46:20,669 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:46:20,941 INFO] number of examples: 26142\n",
            "[2020-06-01 12:46:24,049 INFO] Step 5750/50000; acc:  53.65; ppl:  8.77; xent: 2.17; lr: 1.00000; 4829/4784 tok/s;    735 sec\n",
            "[2020-06-01 12:46:30,639 INFO] Step 5800/50000; acc:  54.06; ppl:  8.27; xent: 2.11; lr: 1.00000; 5242/5193 tok/s;    741 sec\n",
            "[2020-06-01 12:46:37,554 INFO] Step 5850/50000; acc:  52.30; ppl:  9.33; xent: 2.23; lr: 1.00000; 4956/4955 tok/s;    748 sec\n",
            "[2020-06-01 12:46:43,305 INFO] Step 5900/50000; acc:  58.06; ppl:  6.82; xent: 1.92; lr: 1.00000; 4773/5199 tok/s;    754 sec\n",
            "[2020-06-01 12:46:49,161 INFO] Step 5950/50000; acc:  56.47; ppl:  7.34; xent: 1.99; lr: 1.00000; 5129/5127 tok/s;    760 sec\n",
            "[2020-06-01 12:46:55,271 INFO] Step 6000/50000; acc:  55.91; ppl:  7.69; xent: 2.04; lr: 1.00000; 5132/5173 tok/s;    766 sec\n",
            "[2020-06-01 12:47:02,005 INFO] Step 6050/50000; acc:  54.61; ppl:  8.20; xent: 2.10; lr: 1.00000; 5119/5351 tok/s;    773 sec\n",
            "[2020-06-01 12:47:08,204 INFO] Step 6100/50000; acc:  55.64; ppl:  7.64; xent: 2.03; lr: 1.00000; 5301/5322 tok/s;    779 sec\n",
            "[2020-06-01 12:47:13,118 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:47:13,457 INFO] number of examples: 26142\n",
            "[2020-06-01 12:47:15,417 INFO] Step 6150/50000; acc:  53.80; ppl:  8.76; xent: 2.17; lr: 1.00000; 4545/4600 tok/s;    786 sec\n",
            "[2020-06-01 12:47:21,663 INFO] Step 6200/50000; acc:  56.25; ppl:  7.24; xent: 1.98; lr: 1.00000; 5203/5175 tok/s;    792 sec\n",
            "[2020-06-01 12:47:28,889 INFO] Step 6250/50000; acc:  52.99; ppl:  8.93; xent: 2.19; lr: 1.00000; 5118/4991 tok/s;    799 sec\n",
            "[2020-06-01 12:47:34,837 INFO] Step 6300/50000; acc:  58.57; ppl:  6.48; xent: 1.87; lr: 1.00000; 4866/5265 tok/s;    805 sec\n",
            "[2020-06-01 12:47:40,801 INFO] Step 6350/50000; acc:  56.82; ppl:  7.03; xent: 1.95; lr: 1.00000; 5017/5029 tok/s;    811 sec\n",
            "[2020-06-01 12:47:46,792 INFO] Step 6400/50000; acc:  57.70; ppl:  6.78; xent: 1.91; lr: 1.00000; 5074/5183 tok/s;    817 sec\n",
            "[2020-06-01 12:47:52,831 INFO] Step 6450/50000; acc:  57.72; ppl:  6.73; xent: 1.91; lr: 1.00000; 5055/5410 tok/s;    823 sec\n",
            "[2020-06-01 12:47:59,906 INFO] Step 6500/50000; acc:  54.34; ppl:  7.96; xent: 2.07; lr: 1.00000; 5401/5313 tok/s;    830 sec\n",
            "[2020-06-01 12:48:05,603 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:48:05,933 INFO] number of examples: 26142\n",
            "[2020-06-01 12:48:06,844 INFO] Step 6550/50000; acc:  55.56; ppl:  7.73; xent: 2.04; lr: 1.00000; 4532/4635 tok/s;    837 sec\n",
            "[2020-06-01 12:48:13,092 INFO] Step 6600/50000; acc:  57.68; ppl:  6.72; xent: 1.91; lr: 1.00000; 5169/5067 tok/s;    844 sec\n",
            "[2020-06-01 12:48:20,331 INFO] Step 6650/50000; acc:  53.57; ppl:  8.26; xent: 2.11; lr: 1.00000; 5211/5042 tok/s;    851 sec\n",
            "[2020-06-01 12:48:26,484 INFO] Step 6700/50000; acc:  58.89; ppl:  6.31; xent: 1.84; lr: 1.00000; 4874/5287 tok/s;    857 sec\n",
            "[2020-06-01 12:48:32,167 INFO] Step 6750/50000; acc:  59.05; ppl:  6.21; xent: 1.83; lr: 1.00000; 4951/5008 tok/s;    863 sec\n",
            "[2020-06-01 12:48:38,479 INFO] Step 6800/50000; acc:  58.43; ppl:  6.38; xent: 1.85; lr: 1.00000; 5110/5224 tok/s;    869 sec\n",
            "[2020-06-01 12:48:43,997 INFO] Step 6850/50000; acc:  60.77; ppl:  5.65; xent: 1.73; lr: 1.00000; 5022/5349 tok/s;    875 sec\n",
            "[2020-06-01 12:48:51,044 INFO] Step 6900/50000; acc:  55.43; ppl:  7.42; xent: 2.00; lr: 1.00000; 5367/5315 tok/s;    882 sec\n",
            "[2020-06-01 12:48:57,701 INFO] Step 6950/50000; acc:  56.32; ppl:  7.31; xent: 1.99; lr: 1.00000; 4988/5072 tok/s;    888 sec\n",
            "[2020-06-01 12:48:57,981 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:48:58,301 INFO] number of examples: 26142\n",
            "[2020-06-01 12:49:04,369 INFO] Step 7000/50000; acc:  58.74; ppl:  6.26; xent: 1.83; lr: 1.00000; 4821/4770 tok/s;    895 sec\n",
            "[2020-06-01 12:49:11,313 INFO] Step 7050/50000; acc:  56.35; ppl:  7.03; xent: 1.95; lr: 1.00000; 5100/5058 tok/s;    902 sec\n",
            "[2020-06-01 12:49:17,418 INFO] Step 7100/50000; acc:  60.01; ppl:  5.81; xent: 1.76; lr: 1.00000; 4859/5127 tok/s;    908 sec\n",
            "[2020-06-01 12:49:23,108 INFO] Step 7150/50000; acc:  60.27; ppl:  5.74; xent: 1.75; lr: 1.00000; 5080/5185 tok/s;    914 sec\n",
            "[2020-06-01 12:49:29,610 INFO] Step 7200/50000; acc:  59.26; ppl:  5.99; xent: 1.79; lr: 1.00000; 5123/5195 tok/s;    920 sec\n",
            "[2020-06-01 12:49:34,962 INFO] Step 7250/50000; acc:  62.99; ppl:  5.11; xent: 1.63; lr: 1.00000; 5053/5244 tok/s;    925 sec\n",
            "[2020-06-01 12:49:42,079 INFO] Step 7300/50000; acc:  56.70; ppl:  6.90; xent: 1.93; lr: 1.00000; 5302/5390 tok/s;    933 sec\n",
            "[2020-06-01 12:49:49,151 INFO] Step 7350/50000; acc:  56.34; ppl:  7.16; xent: 1.97; lr: 1.00000; 5051/5078 tok/s;    940 sec\n",
            "[2020-06-01 12:49:50,266 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:49:50,599 INFO] number of examples: 26142\n",
            "[2020-06-01 12:49:55,415 INFO] Step 7400/50000; acc:  60.41; ppl:  5.60; xent: 1.72; lr: 1.00000; 4784/4656 tok/s;    946 sec\n",
            "[2020-06-01 12:50:02,359 INFO] Step 7450/50000; acc:  58.18; ppl:  6.35; xent: 1.85; lr: 1.00000; 5122/5256 tok/s;    953 sec\n",
            "[2020-06-01 12:50:08,715 INFO] Step 7500/50000; acc:  59.82; ppl:  5.73; xent: 1.74; lr: 1.00000; 4975/4988 tok/s;    959 sec\n",
            "[2020-06-01 12:50:14,469 INFO] Step 7550/50000; acc:  61.48; ppl:  5.40; xent: 1.69; lr: 1.00000; 4977/5238 tok/s;    965 sec\n",
            "[2020-06-01 12:50:20,633 INFO] Step 7600/50000; acc:  61.64; ppl:  5.24; xent: 1.66; lr: 1.00000; 5114/5131 tok/s;    971 sec\n",
            "[2020-06-01 12:50:26,092 INFO] Step 7650/50000; acc:  63.26; ppl:  4.93; xent: 1.60; lr: 1.00000; 5060/5213 tok/s;    977 sec\n",
            "[2020-06-01 12:50:33,318 INFO] Step 7700/50000; acc:  58.33; ppl:  6.30; xent: 1.84; lr: 1.00000; 5230/5416 tok/s;    984 sec\n",
            "[2020-06-01 12:50:39,784 INFO] Step 7750/50000; acc:  59.39; ppl:  5.93; xent: 1.78; lr: 1.00000; 5078/5078 tok/s;    990 sec\n",
            "[2020-06-01 12:50:42,565 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:50:42,899 INFO] number of examples: 26142\n",
            "[2020-06-01 12:50:46,487 INFO] Step 7800/50000; acc:  60.06; ppl:  5.71; xent: 1.74; lr: 1.00000; 4753/4739 tok/s;    997 sec\n",
            "[2020-06-01 12:50:53,423 INFO] Step 7850/50000; acc:  59.53; ppl:  5.79; xent: 1.76; lr: 1.00000; 5259/5203 tok/s;   1004 sec\n",
            "[2020-06-01 12:51:00,072 INFO] Step 7900/50000; acc:  60.39; ppl:  5.70; xent: 1.74; lr: 1.00000; 4929/4993 tok/s;   1011 sec\n",
            "[2020-06-01 12:51:05,615 INFO] Step 7950/50000; acc:  64.30; ppl:  4.65; xent: 1.54; lr: 1.00000; 4837/5193 tok/s;   1016 sec\n",
            "[2020-06-01 12:51:11,668 INFO] Step 8000/50000; acc:  62.78; ppl:  4.87; xent: 1.58; lr: 1.00000; 5151/5188 tok/s;   1022 sec\n",
            "[2020-06-01 12:51:17,491 INFO] Step 8050/50000; acc:  63.08; ppl:  4.96; xent: 1.60; lr: 1.00000; 5077/5164 tok/s;   1028 sec\n",
            "[2020-06-01 12:51:24,361 INFO] Step 8100/50000; acc:  60.67; ppl:  5.54; xent: 1.71; lr: 1.00000; 5194/5363 tok/s;   1035 sec\n",
            "[2020-06-01 12:51:30,745 INFO] Step 8150/50000; acc:  61.32; ppl:  5.32; xent: 1.67; lr: 1.00000; 5133/5177 tok/s;   1041 sec\n",
            "[2020-06-01 12:51:34,904 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:51:35,260 INFO] number of examples: 26142\n",
            "[2020-06-01 12:51:37,954 INFO] Step 8200/50000; acc:  59.81; ppl:  5.81; xent: 1.76; lr: 1.00000; 4765/4771 tok/s;   1048 sec\n",
            "[2020-06-01 12:51:44,248 INFO] Step 8250/50000; acc:  62.94; ppl:  4.69; xent: 1.55; lr: 1.00000; 5274/5186 tok/s;   1055 sec\n",
            "[2020-06-01 12:51:51,204 INFO] Step 8300/50000; acc:  59.52; ppl:  5.88; xent: 1.77; lr: 1.00000; 5031/5014 tok/s;   1062 sec\n",
            "[2020-06-01 12:51:57,136 INFO] Step 8350/50000; acc:  64.53; ppl:  4.51; xent: 1.51; lr: 1.00000; 4809/5222 tok/s;   1068 sec\n",
            "[2020-06-01 12:52:03,076 INFO] Step 8400/50000; acc:  63.61; ppl:  4.66; xent: 1.54; lr: 1.00000; 5096/5093 tok/s;   1074 sec\n",
            "[2020-06-01 12:52:09,075 INFO] Step 8450/50000; acc:  64.02; ppl:  4.61; xent: 1.53; lr: 1.00000; 5110/5201 tok/s;   1080 sec\n",
            "[2020-06-01 12:52:15,330 INFO] Step 8500/50000; acc:  63.91; ppl:  4.68; xent: 1.54; lr: 1.00000; 5060/5361 tok/s;   1086 sec\n",
            "[2020-06-01 12:52:21,920 INFO] Step 8550/50000; acc:  61.76; ppl:  5.15; xent: 1.64; lr: 1.00000; 5384/5349 tok/s;   1092 sec\n",
            "[2020-06-01 12:52:27,274 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:52:27,635 INFO] number of examples: 26142\n",
            "[2020-06-01 12:52:29,008 INFO] Step 8600/50000; acc:  61.70; ppl:  5.29; xent: 1.67; lr: 1.00000; 4581/4646 tok/s;   1100 sec\n",
            "[2020-06-01 12:52:35,335 INFO] Step 8650/50000; acc:  63.59; ppl:  4.57; xent: 1.52; lr: 1.00000; 5145/5096 tok/s;   1106 sec\n",
            "[2020-06-01 12:52:42,573 INFO] Step 8700/50000; acc:  60.41; ppl:  5.63; xent: 1.73; lr: 1.00000; 5198/5022 tok/s;   1113 sec\n",
            "[2020-06-01 12:52:48,566 INFO] Step 8750/50000; acc:  65.32; ppl:  4.21; xent: 1.44; lr: 1.00000; 4851/5296 tok/s;   1119 sec\n",
            "[2020-06-01 12:52:54,403 INFO] Step 8800/50000; acc:  64.75; ppl:  4.35; xent: 1.47; lr: 1.00000; 4974/5022 tok/s;   1125 sec\n",
            "[2020-06-01 12:53:00,519 INFO] Step 8850/50000; acc:  64.98; ppl:  4.38; xent: 1.48; lr: 1.00000; 5169/5206 tok/s;   1131 sec\n",
            "[2020-06-01 12:53:06,410 INFO] Step 8900/50000; acc:  66.11; ppl:  4.11; xent: 1.41; lr: 1.00000; 5019/5374 tok/s;   1137 sec\n",
            "[2020-06-01 12:53:13,557 INFO] Step 8950/50000; acc:  61.94; ppl:  5.09; xent: 1.63; lr: 1.00000; 5372/5332 tok/s;   1144 sec\n",
            "[2020-06-01 12:53:19,671 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:53:20,025 INFO] number of examples: 26142\n",
            "[2020-06-01 12:53:20,322 INFO] Step 9000/50000; acc:  63.72; ppl:  4.72; xent: 1.55; lr: 1.00000; 4545/4636 tok/s;   1151 sec\n",
            "[2020-06-01 12:53:26,685 INFO] Step 9050/50000; acc:  64.38; ppl:  4.43; xent: 1.49; lr: 1.00000; 5196/5096 tok/s;   1157 sec\n",
            "[2020-06-01 12:53:33,448 INFO] Step 9100/50000; acc:  63.32; ppl:  4.76; xent: 1.56; lr: 1.00000; 5106/5095 tok/s;   1164 sec\n",
            "[2020-06-01 12:53:39,820 INFO] Step 9150/50000; acc:  65.27; ppl:  4.28; xent: 1.45; lr: 1.00000; 4937/5190 tok/s;   1170 sec\n",
            "[2020-06-01 12:53:45,390 INFO] Step 9200/50000; acc:  67.06; ppl:  3.84; xent: 1.35; lr: 1.00000; 5023/5100 tok/s;   1176 sec\n",
            "[2020-06-01 12:53:52,006 INFO] Step 9250/50000; acc:  64.97; ppl:  4.39; xent: 1.48; lr: 1.00000; 5121/5199 tok/s;   1183 sec\n",
            "[2020-06-01 12:53:57,440 INFO] Step 9300/50000; acc:  68.20; ppl:  3.68; xent: 1.30; lr: 1.00000; 5076/5297 tok/s;   1188 sec\n",
            "[2020-06-01 12:54:04,507 INFO] Step 9350/50000; acc:  63.76; ppl:  4.60; xent: 1.53; lr: 1.00000; 5271/5351 tok/s;   1195 sec\n",
            "[2020-06-01 12:54:11,344 INFO] Step 9400/50000; acc:  63.34; ppl:  4.80; xent: 1.57; lr: 1.00000; 5052/5082 tok/s;   1202 sec\n",
            "[2020-06-01 12:54:11,992 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:54:12,245 INFO] number of examples: 26142\n",
            "[2020-06-01 12:54:17,997 INFO] Step 9450/50000; acc:  66.09; ppl:  4.10; xent: 1.41; lr: 1.00000; 4832/4723 tok/s;   1209 sec\n",
            "[2020-06-01 12:54:24,883 INFO] Step 9500/50000; acc:  64.65; ppl:  4.47; xent: 1.50; lr: 1.00000; 5080/5143 tok/s;   1215 sec\n",
            "[2020-06-01 12:54:31,079 INFO] Step 9550/50000; acc:  66.97; ppl:  3.86; xent: 1.35; lr: 1.00000; 4868/5038 tok/s;   1222 sec\n",
            "[2020-06-01 12:54:36,854 INFO] Step 9600/50000; acc:  67.50; ppl:  3.80; xent: 1.33; lr: 1.00000; 5114/5224 tok/s;   1227 sec\n",
            "[2020-06-01 12:54:43,020 INFO] Step 9650/50000; acc:  67.51; ppl:  3.81; xent: 1.34; lr: 1.00000; 5030/5140 tok/s;   1234 sec\n",
            "[2020-06-01 12:54:48,517 INFO] Step 9700/50000; acc:  69.14; ppl:  3.49; xent: 1.25; lr: 1.00000; 5071/5253 tok/s;   1239 sec\n",
            "[2020-06-01 12:54:55,654 INFO] Step 9750/50000; acc:  64.52; ppl:  4.41; xent: 1.48; lr: 1.00000; 5278/5380 tok/s;   1246 sec\n",
            "[2020-06-01 12:55:02,357 INFO] Step 9800/50000; acc:  64.71; ppl:  4.37; xent: 1.47; lr: 1.00000; 5034/5097 tok/s;   1253 sec\n",
            "[2020-06-01 12:55:04,331 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:55:04,583 INFO] number of examples: 26142\n",
            "[2020-06-01 12:55:09,074 INFO] Step 9850/50000; acc:  66.20; ppl:  4.06; xent: 1.40; lr: 1.00000; 4919/4766 tok/s;   1260 sec\n",
            "[2020-06-01 12:55:15,606 INFO] Step 9900/50000; acc:  66.72; ppl:  3.90; xent: 1.36; lr: 1.00000; 5140/5218 tok/s;   1266 sec\n",
            "[2020-06-01 12:55:22,203 INFO] Step 9950/50000; acc:  66.23; ppl:  4.06; xent: 1.40; lr: 1.00000; 4984/5037 tok/s;   1273 sec\n",
            "[2020-06-01 12:55:28,093 INFO] Step 10000/50000; acc:  68.17; ppl:  3.67; xent: 1.30; lr: 1.00000; 4933/5227 tok/s;   1279 sec\n",
            "[2020-06-01 12:55:28,093 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 12:55:28,097 INFO] number of examples: 276\n",
            "[2020-06-01 12:55:28,650 INFO] Validation perplexity: 53.9323\n",
            "[2020-06-01 12:55:28,650 INFO] Validation accuracy: 41.8257\n",
            "[2020-06-01 12:55:28,682 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_10000.pt\n",
            "[2020-06-01 12:55:35,046 INFO] Step 10050/50000; acc:  69.19; ppl:  3.47; xent: 1.24; lr: 1.00000; 4478/4422 tok/s;   1286 sec\n",
            "[2020-06-01 12:55:40,611 INFO] Step 10100/50000; acc:  69.94; ppl:  3.36; xent: 1.21; lr: 1.00000; 4987/5162 tok/s;   1291 sec\n",
            "[2020-06-01 12:55:47,884 INFO] Step 10150/50000; acc:  65.36; ppl:  4.19; xent: 1.43; lr: 1.00000; 5214/5434 tok/s;   1298 sec\n",
            "[2020-06-01 12:55:54,329 INFO] Step 10200/50000; acc:  66.60; ppl:  3.98; xent: 1.38; lr: 1.00000; 5074/5075 tok/s;   1305 sec\n",
            "[2020-06-01 12:55:57,526 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:55:57,850 INFO] number of examples: 26142\n",
            "[2020-06-01 12:56:01,043 INFO] Step 10250/50000; acc:  67.58; ppl:  3.75; xent: 1.32; lr: 1.00000; 4773/4756 tok/s;   1312 sec\n",
            "[2020-06-01 12:56:07,735 INFO] Step 10300/50000; acc:  67.75; ppl:  3.66; xent: 1.30; lr: 1.00000; 5277/5223 tok/s;   1318 sec\n",
            "[2020-06-01 12:56:14,530 INFO] Step 10350/50000; acc:  66.06; ppl:  4.12; xent: 1.42; lr: 1.00000; 4940/4944 tok/s;   1325 sec\n",
            "[2020-06-01 12:56:20,220 INFO] Step 10400/50000; acc:  70.47; ppl:  3.25; xent: 1.18; lr: 1.00000; 4790/5210 tok/s;   1331 sec\n",
            "[2020-06-01 12:56:26,123 INFO] Step 10450/50000; acc:  69.97; ppl:  3.32; xent: 1.20; lr: 1.00000; 5152/5140 tok/s;   1337 sec\n",
            "[2020-06-01 12:56:32,119 INFO] Step 10500/50000; acc:  69.03; ppl:  3.47; xent: 1.24; lr: 1.00000; 5145/5207 tok/s;   1343 sec\n",
            "[2020-06-01 12:56:38,883 INFO] Step 10550/50000; acc:  67.69; ppl:  3.75; xent: 1.32; lr: 1.00000; 5153/5374 tok/s;   1349 sec\n",
            "[2020-06-01 12:56:45,003 INFO] Step 10600/50000; acc:  69.27; ppl:  3.43; xent: 1.23; lr: 1.00000; 5306/5338 tok/s;   1356 sec\n",
            "[2020-06-01 12:56:49,876 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:56:50,208 INFO] number of examples: 26142\n",
            "[2020-06-01 12:56:52,386 INFO] Step 10650/50000; acc:  66.54; ppl:  4.01; xent: 1.39; lr: 1.00000; 4614/4643 tok/s;   1363 sec\n",
            "[2020-06-01 12:56:58,546 INFO] Step 10700/50000; acc:  70.19; ppl:  3.21; xent: 1.17; lr: 1.00000; 5181/5175 tok/s;   1369 sec\n",
            "[2020-06-01 12:57:05,710 INFO] Step 10750/50000; acc:  66.50; ppl:  4.01; xent: 1.39; lr: 1.00000; 5117/5010 tok/s;   1376 sec\n",
            "[2020-06-01 12:57:11,574 INFO] Step 10800/50000; acc:  71.09; ppl:  3.14; xent: 1.15; lr: 1.00000; 4903/5279 tok/s;   1382 sec\n",
            "[2020-06-01 12:57:17,529 INFO] Step 10850/50000; acc:  70.31; ppl:  3.32; xent: 1.20; lr: 1.00000; 5025/5049 tok/s;   1388 sec\n",
            "[2020-06-01 12:57:23,527 INFO] Step 10900/50000; acc:  70.97; ppl:  3.23; xent: 1.17; lr: 1.00000; 5100/5199 tok/s;   1394 sec\n",
            "[2020-06-01 12:57:29,642 INFO] Step 10950/50000; acc:  70.50; ppl:  3.26; xent: 1.18; lr: 1.00000; 5065/5432 tok/s;   1400 sec\n",
            "[2020-06-01 12:57:36,597 INFO] Step 11000/50000; acc:  67.97; ppl:  3.63; xent: 1.29; lr: 1.00000; 5411/5317 tok/s;   1407 sec\n",
            "[2020-06-01 12:57:42,198 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:57:42,527 INFO] number of examples: 26142\n",
            "[2020-06-01 12:57:43,539 INFO] Step 11050/50000; acc:  68.48; ppl:  3.65; xent: 1.30; lr: 1.00000; 4585/4651 tok/s;   1414 sec\n",
            "[2020-06-01 12:57:49,771 INFO] Step 11100/50000; acc:  70.75; ppl:  3.20; xent: 1.16; lr: 1.00000; 5162/5090 tok/s;   1420 sec\n",
            "[2020-06-01 12:57:57,034 INFO] Step 11150/50000; acc:  67.13; ppl:  3.89; xent: 1.36; lr: 1.00000; 5171/5015 tok/s;   1428 sec\n",
            "[2020-06-01 12:58:03,150 INFO] Step 11200/50000; acc:  71.17; ppl:  3.12; xent: 1.14; lr: 1.00000; 4899/5300 tok/s;   1434 sec\n",
            "[2020-06-01 12:58:08,846 INFO] Step 11250/50000; acc:  71.69; ppl:  3.09; xent: 1.13; lr: 1.00000; 4929/4998 tok/s;   1439 sec\n",
            "[2020-06-01 12:58:15,141 INFO] Step 11300/50000; acc:  71.08; ppl:  3.16; xent: 1.15; lr: 1.00000; 5124/5227 tok/s;   1446 sec\n",
            "[2020-06-01 12:58:20,750 INFO] Step 11350/50000; acc:  73.09; ppl:  2.83; xent: 1.04; lr: 1.00000; 5044/5331 tok/s;   1451 sec\n",
            "[2020-06-01 12:58:27,810 INFO] Step 11400/50000; acc:  68.99; ppl:  3.49; xent: 1.25; lr: 1.00000; 5348/5314 tok/s;   1458 sec\n",
            "[2020-06-01 12:58:34,397 INFO] Step 11450/50000; acc:  68.90; ppl:  3.53; xent: 1.26; lr: 1.00000; 4972/5048 tok/s;   1465 sec\n",
            "[2020-06-01 12:58:34,606 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:58:34,939 INFO] number of examples: 26142\n",
            "[2020-06-01 12:58:41,177 INFO] Step 11500/50000; acc:  70.94; ppl:  3.16; xent: 1.15; lr: 1.00000; 4807/4791 tok/s;   1472 sec\n",
            "[2020-06-01 12:58:48,064 INFO] Step 11550/50000; acc:  69.64; ppl:  3.39; xent: 1.22; lr: 1.00000; 5096/5038 tok/s;   1479 sec\n",
            "[2020-06-01 12:58:54,154 INFO] Step 11600/50000; acc:  72.12; ppl:  2.97; xent: 1.09; lr: 1.00000; 4861/5119 tok/s;   1485 sec\n",
            "[2020-06-01 12:58:59,911 INFO] Step 11650/50000; acc:  72.90; ppl:  2.87; xent: 1.06; lr: 1.00000; 5065/5181 tok/s;   1490 sec\n",
            "[2020-06-01 12:59:06,382 INFO] Step 11700/50000; acc:  71.91; ppl:  3.06; xent: 1.12; lr: 1.00000; 5108/5180 tok/s;   1497 sec\n",
            "[2020-06-01 12:59:11,880 INFO] Step 11750/50000; acc:  73.76; ppl:  2.78; xent: 1.02; lr: 1.00000; 5046/5256 tok/s;   1502 sec\n",
            "[2020-06-01 12:59:18,826 INFO] Step 11800/50000; acc:  70.15; ppl:  3.31; xent: 1.20; lr: 1.00000; 5276/5357 tok/s;   1509 sec\n",
            "[2020-06-01 12:59:25,903 INFO] Step 11850/50000; acc:  69.18; ppl:  3.49; xent: 1.25; lr: 1.00000; 5048/5075 tok/s;   1516 sec\n",
            "[2020-06-01 12:59:26,976 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 12:59:27,305 INFO] number of examples: 26142\n",
            "[2020-06-01 12:59:32,239 INFO] Step 11900/50000; acc:  73.27; ppl:  2.85; xent: 1.05; lr: 1.00000; 4791/4670 tok/s;   1523 sec\n",
            "[2020-06-01 12:59:39,343 INFO] Step 11950/50000; acc:  69.68; ppl:  3.36; xent: 1.21; lr: 1.00000; 5160/5252 tok/s;   1530 sec\n",
            "[2020-06-01 12:59:45,533 INFO] Step 12000/50000; acc:  73.13; ppl:  2.83; xent: 1.04; lr: 1.00000; 4901/4965 tok/s;   1536 sec\n",
            "[2020-06-01 12:59:51,334 INFO] Step 12050/50000; acc:  72.77; ppl:  2.89; xent: 1.06; lr: 1.00000; 5003/5229 tok/s;   1542 sec\n",
            "[2020-06-01 12:59:57,442 INFO] Step 12100/50000; acc:  74.12; ppl:  2.76; xent: 1.01; lr: 1.00000; 5098/5136 tok/s;   1548 sec\n",
            "[2020-06-01 13:00:02,954 INFO] Step 12150/50000; acc:  74.91; ppl:  2.65; xent: 0.98; lr: 1.00000; 5047/5209 tok/s;   1553 sec\n",
            "[2020-06-01 13:00:10,211 INFO] Step 12200/50000; acc:  70.17; ppl:  3.26; xent: 1.18; lr: 1.00000; 5235/5411 tok/s;   1561 sec\n",
            "[2020-06-01 13:00:16,684 INFO] Step 12250/50000; acc:  71.72; ppl:  3.07; xent: 1.12; lr: 1.00000; 5092/5045 tok/s;   1567 sec\n",
            "[2020-06-01 13:00:19,338 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:00:19,659 INFO] number of examples: 26142\n",
            "[2020-06-01 13:00:23,437 INFO] Step 12300/50000; acc:  72.16; ppl:  2.98; xent: 1.09; lr: 1.00000; 4784/4781 tok/s;   1574 sec\n",
            "[2020-06-01 13:00:30,274 INFO] Step 12350/50000; acc:  71.85; ppl:  3.02; xent: 1.10; lr: 1.00000; 5195/5190 tok/s;   1581 sec\n",
            "[2020-06-01 13:00:36,937 INFO] Step 12400/50000; acc:  72.04; ppl:  3.02; xent: 1.11; lr: 1.00000; 4928/4982 tok/s;   1587 sec\n",
            "[2020-06-01 13:00:42,493 INFO] Step 12450/50000; acc:  75.05; ppl:  2.61; xent: 0.96; lr: 1.00000; 4792/5150 tok/s;   1593 sec\n",
            "[2020-06-01 13:00:48,755 INFO] Step 12500/50000; acc:  73.95; ppl:  2.76; xent: 1.01; lr: 1.00000; 5146/5164 tok/s;   1599 sec\n",
            "[2020-06-01 13:00:54,424 INFO] Step 12550/50000; acc:  74.79; ppl:  2.63; xent: 0.97; lr: 1.00000; 5121/5193 tok/s;   1605 sec\n",
            "[2020-06-01 13:01:01,356 INFO] Step 12600/50000; acc:  72.18; ppl:  3.00; xent: 1.10; lr: 1.00000; 5194/5387 tok/s;   1612 sec\n",
            "[2020-06-01 13:01:07,922 INFO] Step 12650/50000; acc:  71.82; ppl:  3.04; xent: 1.11; lr: 1.00000; 5098/5096 tok/s;   1618 sec\n",
            "[2020-06-01 13:01:11,728 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:01:12,072 INFO] number of examples: 26142\n",
            "[2020-06-01 13:01:14,836 INFO] Step 12700/50000; acc:  72.57; ppl:  2.94; xent: 1.08; lr: 1.00000; 4764/4787 tok/s;   1625 sec\n",
            "[2020-06-01 13:01:21,219 INFO] Step 12750/50000; acc:  74.81; ppl:  2.58; xent: 0.95; lr: 1.00000; 5300/5209 tok/s;   1632 sec\n",
            "[2020-06-01 13:01:28,146 INFO] Step 12800/50000; acc:  70.78; ppl:  3.18; xent: 1.16; lr: 1.00000; 4987/4992 tok/s;   1639 sec\n",
            "[2020-06-01 13:01:34,094 INFO] Step 12850/50000; acc:  74.39; ppl:  2.65; xent: 0.97; lr: 1.00000; 4808/5220 tok/s;   1645 sec\n",
            "[2020-06-01 13:01:39,964 INFO] Step 12900/50000; acc:  75.39; ppl:  2.56; xent: 0.94; lr: 1.00000; 5102/5098 tok/s;   1650 sec\n",
            "[2020-06-01 13:01:45,991 INFO] Step 12950/50000; acc:  75.18; ppl:  2.59; xent: 0.95; lr: 1.00000; 5150/5201 tok/s;   1657 sec\n",
            "[2020-06-01 13:01:52,289 INFO] Step 13000/50000; acc:  74.51; ppl:  2.62; xent: 0.96; lr: 1.00000; 5087/5366 tok/s;   1663 sec\n",
            "[2020-06-01 13:01:58,838 INFO] Step 13050/50000; acc:  73.12; ppl:  2.84; xent: 1.05; lr: 1.00000; 5360/5353 tok/s;   1669 sec\n",
            "[2020-06-01 13:02:04,068 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:02:04,410 INFO] number of examples: 26142\n",
            "[2020-06-01 13:02:05,852 INFO] Step 13100/50000; acc:  72.69; ppl:  2.93; xent: 1.07; lr: 1.00000; 4574/4664 tok/s;   1676 sec\n",
            "[2020-06-01 13:02:12,278 INFO] Step 13150/50000; acc:  74.60; ppl:  2.63; xent: 0.97; lr: 1.00000; 5145/5111 tok/s;   1683 sec\n",
            "[2020-06-01 13:02:19,396 INFO] Step 13200/50000; acc:  71.01; ppl:  3.15; xent: 1.15; lr: 1.00000; 5195/5004 tok/s;   1690 sec\n",
            "[2020-06-01 13:02:25,444 INFO] Step 13250/50000; acc:  76.06; ppl:  2.48; xent: 0.91; lr: 1.00000; 4860/5301 tok/s;   1696 sec\n",
            "[2020-06-01 13:02:31,266 INFO] Step 13300/50000; acc:  75.96; ppl:  2.54; xent: 0.93; lr: 1.00000; 5008/5024 tok/s;   1702 sec\n",
            "[2020-06-01 13:02:37,411 INFO] Step 13350/50000; acc:  74.97; ppl:  2.59; xent: 0.95; lr: 1.00000; 5134/5213 tok/s;   1708 sec\n",
            "[2020-06-01 13:02:43,268 INFO] Step 13400/50000; acc:  76.44; ppl:  2.43; xent: 0.89; lr: 1.00000; 5038/5395 tok/s;   1714 sec\n",
            "[2020-06-01 13:02:50,438 INFO] Step 13450/50000; acc:  73.14; ppl:  2.84; xent: 1.04; lr: 1.00000; 5391/5342 tok/s;   1721 sec\n",
            "[2020-06-01 13:02:56,414 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:02:56,757 INFO] number of examples: 26142\n",
            "[2020-06-01 13:02:57,168 INFO] Step 13500/50000; acc:  73.95; ppl:  2.75; xent: 1.01; lr: 1.00000; 4567/4630 tok/s;   1728 sec\n",
            "[2020-06-01 13:03:03,548 INFO] Step 13550/50000; acc:  74.97; ppl:  2.60; xent: 0.95; lr: 1.00000; 5173/5094 tok/s;   1734 sec\n",
            "[2020-06-01 13:03:10,428 INFO] Step 13600/50000; acc:  73.27; ppl:  2.84; xent: 1.05; lr: 1.00000; 5121/5075 tok/s;   1741 sec\n",
            "[2020-06-01 13:03:16,812 INFO] Step 13650/50000; acc:  75.18; ppl:  2.57; xent: 0.94; lr: 1.00000; 4918/5168 tok/s;   1747 sec\n",
            "[2020-06-01 13:03:22,384 INFO] Step 13700/50000; acc:  77.66; ppl:  2.29; xent: 0.83; lr: 1.00000; 4975/5105 tok/s;   1753 sec\n",
            "[2020-06-01 13:03:28,902 INFO] Step 13750/50000; acc:  74.75; ppl:  2.66; xent: 0.98; lr: 1.00000; 5110/5193 tok/s;   1759 sec\n",
            "[2020-06-01 13:03:34,357 INFO] Step 13800/50000; acc:  78.06; ppl:  2.26; xent: 0.81; lr: 1.00000; 5080/5294 tok/s;   1765 sec\n",
            "[2020-06-01 13:03:41,443 INFO] Step 13850/50000; acc:  73.77; ppl:  2.73; xent: 1.01; lr: 1.00000; 5274/5332 tok/s;   1772 sec\n",
            "[2020-06-01 13:03:48,258 INFO] Step 13900/50000; acc:  73.46; ppl:  2.81; xent: 1.03; lr: 1.00000; 5022/5080 tok/s;   1779 sec\n",
            "[2020-06-01 13:03:48,818 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:03:49,169 INFO] number of examples: 26142\n",
            "[2020-06-01 13:03:54,918 INFO] Step 13950/50000; acc:  75.75; ppl:  2.48; xent: 0.91; lr: 1.00000; 4827/4727 tok/s;   1785 sec\n",
            "[2020-06-01 13:04:01,822 INFO] Step 14000/50000; acc:  74.08; ppl:  2.73; xent: 1.00; lr: 1.00000; 5113/5130 tok/s;   1792 sec\n",
            "[2020-06-01 13:04:08,099 INFO] Step 14050/50000; acc:  76.51; ppl:  2.41; xent: 0.88; lr: 1.00000; 4867/5065 tok/s;   1799 sec\n",
            "[2020-06-01 13:04:13,733 INFO] Step 14100/50000; acc:  77.56; ppl:  2.30; xent: 0.83; lr: 1.00000; 5071/5195 tok/s;   1804 sec\n",
            "[2020-06-01 13:04:19,981 INFO] Step 14150/50000; acc:  76.83; ppl:  2.42; xent: 0.88; lr: 1.00000; 5036/5133 tok/s;   1811 sec\n",
            "[2020-06-01 13:04:25,519 INFO] Step 14200/50000; acc:  78.32; ppl:  2.26; xent: 0.81; lr: 1.00000; 5068/5258 tok/s;   1816 sec\n",
            "[2020-06-01 13:04:32,717 INFO] Step 14250/50000; acc:  74.15; ppl:  2.70; xent: 0.99; lr: 1.00000; 5296/5379 tok/s;   1823 sec\n",
            "[2020-06-01 13:04:39,447 INFO] Step 14300/50000; acc:  74.47; ppl:  2.68; xent: 0.98; lr: 1.00000; 4994/5030 tok/s;   1830 sec\n",
            "[2020-06-01 13:04:41,184 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:04:41,531 INFO] number of examples: 26142\n",
            "[2020-06-01 13:04:46,078 INFO] Step 14350/50000; acc:  76.10; ppl:  2.50; xent: 0.92; lr: 1.00000; 4838/4733 tok/s;   1837 sec\n",
            "[2020-06-01 13:04:52,913 INFO] Step 14400/50000; acc:  75.16; ppl:  2.58; xent: 0.95; lr: 1.00000; 5129/5198 tok/s;   1843 sec\n",
            "[2020-06-01 13:04:59,389 INFO] Step 14450/50000; acc:  76.29; ppl:  2.43; xent: 0.89; lr: 1.00000; 4997/5038 tok/s;   1850 sec\n",
            "[2020-06-01 13:05:05,158 INFO] Step 14500/50000; acc:  77.15; ppl:  2.33; xent: 0.85; lr: 1.00000; 4881/5202 tok/s;   1856 sec\n",
            "[2020-06-01 13:05:11,269 INFO] Step 14550/50000; acc:  78.18; ppl:  2.24; xent: 0.80; lr: 1.00000; 5137/5093 tok/s;   1862 sec\n",
            "[2020-06-01 13:05:16,791 INFO] Step 14600/50000; acc:  78.86; ppl:  2.20; xent: 0.79; lr: 1.00000; 5049/5191 tok/s;   1867 sec\n",
            "[2020-06-01 13:05:24,039 INFO] Step 14650/50000; acc:  74.77; ppl:  2.62; xent: 0.96; lr: 1.00000; 5197/5418 tok/s;   1875 sec\n",
            "[2020-06-01 13:05:30,535 INFO] Step 14700/50000; acc:  76.29; ppl:  2.47; xent: 0.90; lr: 1.00000; 5063/5083 tok/s;   1881 sec\n",
            "[2020-06-01 13:05:33,612 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:05:33,858 INFO] number of examples: 26142\n",
            "[2020-06-01 13:05:37,237 INFO] Step 14750/50000; acc:  76.52; ppl:  2.41; xent: 0.88; lr: 1.00000; 4886/4817 tok/s;   1888 sec\n",
            "[2020-06-01 13:05:43,840 INFO] Step 14800/50000; acc:  77.34; ppl:  2.32; xent: 0.84; lr: 1.00000; 5241/5211 tok/s;   1894 sec\n",
            "[2020-06-01 13:05:50,671 INFO] Step 14850/50000; acc:  74.46; ppl:  2.70; xent: 0.99; lr: 1.00000; 4971/4994 tok/s;   1901 sec\n",
            "[2020-06-01 13:05:56,363 INFO] Step 14900/50000; acc:  79.05; ppl:  2.16; xent: 0.77; lr: 1.00000; 4800/5185 tok/s;   1907 sec\n",
            "[2020-06-01 13:06:02,208 INFO] Step 14950/50000; acc:  78.70; ppl:  2.19; xent: 0.79; lr: 1.00000; 5104/5114 tok/s;   1913 sec\n",
            "[2020-06-01 13:06:08,199 INFO] Step 15000/50000; acc:  77.54; ppl:  2.30; xent: 0.83; lr: 1.00000; 5106/5180 tok/s;   1919 sec\n",
            "[2020-06-01 13:06:08,232 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_15000.pt\n",
            "[2020-06-01 13:06:15,455 INFO] Step 15050/50000; acc:  76.89; ppl:  2.40; xent: 0.87; lr: 1.00000; 4847/5054 tok/s;   1926 sec\n",
            "[2020-06-01 13:06:21,968 INFO] Step 15100/50000; acc:  76.96; ppl:  2.37; xent: 0.86; lr: 1.00000; 5100/5101 tok/s;   1932 sec\n",
            "[2020-06-01 13:06:26,435 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:06:26,752 INFO] number of examples: 26142\n",
            "[2020-06-01 13:06:29,074 INFO] Step 15150/50000; acc:  76.50; ppl:  2.47; xent: 0.90; lr: 1.00000; 4716/4763 tok/s;   1940 sec\n",
            "[2020-06-01 13:06:35,328 INFO] Step 15200/50000; acc:  78.53; ppl:  2.18; xent: 0.78; lr: 1.00000; 5175/5172 tok/s;   1946 sec\n",
            "[2020-06-01 13:06:42,360 INFO] Step 15250/50000; acc:  74.98; ppl:  2.61; xent: 0.96; lr: 1.00000; 5086/4974 tok/s;   1953 sec\n",
            "[2020-06-01 13:06:48,468 INFO] Step 15300/50000; acc:  78.02; ppl:  2.24; xent: 0.81; lr: 1.00000; 4902/5245 tok/s;   1959 sec\n",
            "[2020-06-01 13:06:54,281 INFO] Step 15350/50000; acc:  79.06; ppl:  2.18; xent: 0.78; lr: 1.00000; 5053/5136 tok/s;   1965 sec\n",
            "[2020-06-01 13:07:00,153 INFO] Step 15400/50000; acc:  79.18; ppl:  2.15; xent: 0.77; lr: 1.00000; 5111/5173 tok/s;   1971 sec\n",
            "[2020-06-01 13:07:06,334 INFO] Step 15450/50000; acc:  78.50; ppl:  2.20; xent: 0.79; lr: 1.00000; 5074/5426 tok/s;   1977 sec\n",
            "[2020-06-01 13:07:13,280 INFO] Step 15500/50000; acc:  76.61; ppl:  2.38; xent: 0.87; lr: 1.00000; 5390/5295 tok/s;   1984 sec\n",
            "[2020-06-01 13:07:18,820 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:07:19,150 INFO] number of examples: 26142\n",
            "[2020-06-01 13:07:20,236 INFO] Step 15550/50000; acc:  76.73; ppl:  2.42; xent: 0.88; lr: 1.00000; 4548/4643 tok/s;   1991 sec\n",
            "[2020-06-01 13:07:26,503 INFO] Step 15600/50000; acc:  78.54; ppl:  2.17; xent: 0.78; lr: 1.00000; 5153/5071 tok/s;   1997 sec\n",
            "[2020-06-01 13:07:33,815 INFO] Step 15650/50000; acc:  75.33; ppl:  2.58; xent: 0.95; lr: 1.00000; 5171/5007 tok/s;   2004 sec\n",
            "[2020-06-01 13:07:39,863 INFO] Step 15700/50000; acc:  79.08; ppl:  2.15; xent: 0.76; lr: 1.00000; 4871/5298 tok/s;   2010 sec\n",
            "[2020-06-01 13:07:45,637 INFO] Step 15750/50000; acc:  79.40; ppl:  2.15; xent: 0.76; lr: 1.00000; 4950/5014 tok/s;   2016 sec\n",
            "[2020-06-01 13:07:51,890 INFO] Step 15800/50000; acc:  79.12; ppl:  2.16; xent: 0.77; lr: 1.00000; 5107/5204 tok/s;   2022 sec\n",
            "[2020-06-01 13:07:57,494 INFO] Step 15850/50000; acc:  81.04; ppl:  1.98; xent: 0.68; lr: 1.00000; 5025/5323 tok/s;   2028 sec\n",
            "[2020-06-01 13:08:04,661 INFO] Step 15900/50000; acc:  77.11; ppl:  2.35; xent: 0.85; lr: 1.00000; 5358/5324 tok/s;   2035 sec\n",
            "[2020-06-01 13:08:11,243 INFO] Step 15950/50000; acc:  76.70; ppl:  2.40; xent: 0.88; lr: 1.00000; 4967/5032 tok/s;   2042 sec\n",
            "[2020-06-01 13:08:11,310 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:08:11,620 INFO] number of examples: 26142\n",
            "[2020-06-01 13:08:18,048 INFO] Step 16000/50000; acc:  78.74; ppl:  2.20; xent: 0.79; lr: 1.00000; 4807/4748 tok/s;   2049 sec\n",
            "[2020-06-01 13:08:24,888 INFO] Step 16050/50000; acc:  77.58; ppl:  2.33; xent: 0.85; lr: 1.00000; 5105/5066 tok/s;   2055 sec\n",
            "[2020-06-01 13:08:31,080 INFO] Step 16100/50000; acc:  78.94; ppl:  2.17; xent: 0.77; lr: 1.00000; 4863/5136 tok/s;   2062 sec\n",
            "[2020-06-01 13:08:36,733 INFO] Step 16150/50000; acc:  80.91; ppl:  1.98; xent: 0.68; lr: 1.00000; 5022/5149 tok/s;   2067 sec\n",
            "[2020-06-01 13:08:43,222 INFO] Step 16200/50000; acc:  79.21; ppl:  2.17; xent: 0.77; lr: 1.00000; 5094/5174 tok/s;   2074 sec\n",
            "[2020-06-01 13:08:48,723 INFO] Step 16250/50000; acc:  80.71; ppl:  2.01; xent: 0.70; lr: 1.00000; 5067/5242 tok/s;   2079 sec\n",
            "[2020-06-01 13:08:55,742 INFO] Step 16300/50000; acc:  77.65; ppl:  2.30; xent: 0.83; lr: 1.00000; 5293/5359 tok/s;   2086 sec\n",
            "[2020-06-01 13:09:02,858 INFO] Step 16350/50000; acc:  76.43; ppl:  2.42; xent: 0.88; lr: 1.00000; 5021/5080 tok/s;   2093 sec\n",
            "[2020-06-01 13:09:03,744 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:09:04,078 INFO] number of examples: 26142\n",
            "[2020-06-01 13:09:09,204 INFO] Step 16400/50000; acc:  80.39; ppl:  2.05; xent: 0.72; lr: 1.00000; 4773/4638 tok/s;   2100 sec\n",
            "[2020-06-01 13:09:16,227 INFO] Step 16450/50000; acc:  77.80; ppl:  2.30; xent: 0.83; lr: 1.00000; 5129/5243 tok/s;   2107 sec\n",
            "[2020-06-01 13:09:22,420 INFO] Step 16500/50000; acc:  80.17; ppl:  2.03; xent: 0.71; lr: 1.00000; 4910/4973 tok/s;   2113 sec\n",
            "[2020-06-01 13:09:28,252 INFO] Step 16550/50000; acc:  80.01; ppl:  2.06; xent: 0.72; lr: 1.00000; 5020/5223 tok/s;   2119 sec\n",
            "[2020-06-01 13:09:34,297 INFO] Step 16600/50000; acc:  80.75; ppl:  2.02; xent: 0.70; lr: 1.00000; 5088/5126 tok/s;   2125 sec\n",
            "[2020-06-01 13:09:39,832 INFO] Step 16650/50000; acc:  81.64; ppl:  1.95; xent: 0.67; lr: 1.00000; 5037/5197 tok/s;   2130 sec\n",
            "[2020-06-01 13:09:47,052 INFO] Step 16700/50000; acc:  77.31; ppl:  2.30; xent: 0.83; lr: 1.00000; 5244/5432 tok/s;   2138 sec\n",
            "[2020-06-01 13:09:53,585 INFO] Step 16750/50000; acc:  79.11; ppl:  2.18; xent: 0.78; lr: 1.00000; 5113/5077 tok/s;   2144 sec\n",
            "[2020-06-01 13:09:56,095 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:09:56,426 INFO] number of examples: 26142\n",
            "[2020-06-01 13:10:00,343 INFO] Step 16800/50000; acc:  79.00; ppl:  2.16; xent: 0.77; lr: 1.00000; 4800/4769 tok/s;   2151 sec\n",
            "[2020-06-01 13:10:07,219 INFO] Step 16850/50000; acc:  78.60; ppl:  2.19; xent: 0.79; lr: 1.00000; 5150/5165 tok/s;   2158 sec\n",
            "[2020-06-01 13:10:13,716 INFO] Step 16900/50000; acc:  78.92; ppl:  2.18; xent: 0.78; lr: 1.00000; 4962/5016 tok/s;   2164 sec\n",
            "[2020-06-01 13:10:19,413 INFO] Step 16950/50000; acc:  80.83; ppl:  1.98; xent: 0.68; lr: 1.00000; 4841/5199 tok/s;   2170 sec\n",
            "[2020-06-01 13:10:25,560 INFO] Step 17000/50000; acc:  81.07; ppl:  1.99; xent: 0.69; lr: 1.00000; 5149/5137 tok/s;   2176 sec\n",
            "[2020-06-01 13:10:31,192 INFO] Step 17050/50000; acc:  81.48; ppl:  1.96; xent: 0.67; lr: 1.00000; 5110/5194 tok/s;   2182 sec\n",
            "[2020-06-01 13:10:38,253 INFO] Step 17100/50000; acc:  79.09; ppl:  2.14; xent: 0.76; lr: 1.00000; 5207/5405 tok/s;   2189 sec\n",
            "[2020-06-01 13:10:44,856 INFO] Step 17150/50000; acc:  78.53; ppl:  2.22; xent: 0.80; lr: 1.00000; 5069/5092 tok/s;   2195 sec\n",
            "[2020-06-01 13:10:48,442 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:10:48,782 INFO] number of examples: 26142\n",
            "[2020-06-01 13:10:51,675 INFO] Step 17200/50000; acc:  79.73; ppl:  2.08; xent: 0.73; lr: 1.00000; 4774/4788 tok/s;   2202 sec\n",
            "[2020-06-01 13:10:58,232 INFO] Step 17250/50000; acc:  80.69; ppl:  2.01; xent: 0.70; lr: 1.00000; 5278/5186 tok/s;   2209 sec\n",
            "[2020-06-01 13:11:05,143 INFO] Step 17300/50000; acc:  77.62; ppl:  2.30; xent: 0.83; lr: 1.00000; 5008/5011 tok/s;   2216 sec\n",
            "[2020-06-01 13:11:10,921 INFO] Step 17350/50000; acc:  81.88; ppl:  1.89; xent: 0.63; lr: 1.00000; 4794/5213 tok/s;   2221 sec\n",
            "[2020-06-01 13:11:16,727 INFO] Step 17400/50000; acc:  81.70; ppl:  1.95; xent: 0.67; lr: 1.00000; 5082/5083 tok/s;   2227 sec\n",
            "[2020-06-01 13:11:22,797 INFO] Step 17450/50000; acc:  81.33; ppl:  1.96; xent: 0.68; lr: 1.00000; 5155/5185 tok/s;   2233 sec\n",
            "[2020-06-01 13:11:29,180 INFO] Step 17500/50000; acc:  81.01; ppl:  1.97; xent: 0.68; lr: 1.00000; 5090/5376 tok/s;   2240 sec\n",
            "[2020-06-01 13:11:35,669 INFO] Step 17550/50000; acc:  79.76; ppl:  2.09; xent: 0.74; lr: 1.00000; 5340/5333 tok/s;   2246 sec\n",
            "[2020-06-01 13:11:40,827 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:11:41,188 INFO] number of examples: 26142\n",
            "[2020-06-01 13:11:42,948 INFO] Step 17600/50000; acc:  78.67; ppl:  2.21; xent: 0.79; lr: 1.00000; 4565/4598 tok/s;   2253 sec\n",
            "[2020-06-01 13:11:49,150 INFO] Step 17650/50000; acc:  81.68; ppl:  1.92; xent: 0.65; lr: 1.00000; 5146/5153 tok/s;   2260 sec\n",
            "[2020-06-01 13:11:56,335 INFO] Step 17700/50000; acc:  78.18; ppl:  2.27; xent: 0.82; lr: 1.00000; 5192/5013 tok/s;   2267 sec\n",
            "[2020-06-01 13:12:02,332 INFO] Step 17750/50000; acc:  81.68; ppl:  1.90; xent: 0.64; lr: 1.00000; 4858/5301 tok/s;   2273 sec\n",
            "[2020-06-01 13:12:08,262 INFO] Step 17800/50000; acc:  81.61; ppl:  1.96; xent: 0.67; lr: 1.00000; 5036/5026 tok/s;   2279 sec\n",
            "[2020-06-01 13:12:14,310 INFO] Step 17850/50000; acc:  81.78; ppl:  1.94; xent: 0.66; lr: 1.00000; 5090/5195 tok/s;   2285 sec\n",
            "[2020-06-01 13:12:20,190 INFO] Step 17900/50000; acc:  82.61; ppl:  1.85; xent: 0.62; lr: 1.00000; 5007/5394 tok/s;   2291 sec\n",
            "[2020-06-01 13:12:27,432 INFO] Step 17950/50000; acc:  79.18; ppl:  2.13; xent: 0.75; lr: 1.00000; 5435/5342 tok/s;   2298 sec\n",
            "[2020-06-01 13:12:33,270 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:12:33,606 INFO] number of examples: 26142\n",
            "[2020-06-01 13:12:34,126 INFO] Step 18000/50000; acc:  80.27; ppl:  2.06; xent: 0.72; lr: 1.00000; 4516/4607 tok/s;   2305 sec\n",
            "[2020-06-01 13:12:40,477 INFO] Step 18050/50000; acc:  80.74; ppl:  2.00; xent: 0.69; lr: 1.00000; 5166/5081 tok/s;   2311 sec\n",
            "[2020-06-01 13:12:47,497 INFO] Step 18100/50000; acc:  79.08; ppl:  2.16; xent: 0.77; lr: 1.00000; 5174/5093 tok/s;   2318 sec\n",
            "[2020-06-01 13:12:53,822 INFO] Step 18150/50000; acc:  81.55; ppl:  1.93; xent: 0.66; lr: 1.00000; 4882/5171 tok/s;   2324 sec\n",
            "[2020-06-01 13:12:59,340 INFO] Step 18200/50000; acc:  83.66; ppl:  1.76; xent: 0.56; lr: 1.00000; 4966/5086 tok/s;   2330 sec\n",
            "[2020-06-01 13:13:05,826 INFO] Step 18250/50000; acc:  80.53; ppl:  2.06; xent: 0.72; lr: 1.00000; 5086/5171 tok/s;   2336 sec\n",
            "[2020-06-01 13:13:11,372 INFO] Step 18300/50000; acc:  83.68; ppl:  1.77; xent: 0.57; lr: 1.00000; 5067/5297 tok/s;   2342 sec\n",
            "[2020-06-01 13:13:18,426 INFO] Step 18350/50000; acc:  79.77; ppl:  2.06; xent: 0.72; lr: 1.00000; 5289/5329 tok/s;   2349 sec\n",
            "[2020-06-01 13:13:25,177 INFO] Step 18400/50000; acc:  79.30; ppl:  2.14; xent: 0.76; lr: 1.00000; 5013/5081 tok/s;   2356 sec\n",
            "[2020-06-01 13:13:25,693 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:13:26,050 INFO] number of examples: 26142\n",
            "[2020-06-01 13:13:31,912 INFO] Step 18450/50000; acc:  81.56; ppl:  1.92; xent: 0.65; lr: 1.00000; 4811/4731 tok/s;   2362 sec\n",
            "[2020-06-01 13:13:38,892 INFO] Step 18500/50000; acc:  80.11; ppl:  2.07; xent: 0.73; lr: 1.00000; 5093/5069 tok/s;   2369 sec\n",
            "[2020-06-01 13:13:45,037 INFO] Step 18550/50000; acc:  82.21; ppl:  1.88; xent: 0.63; lr: 1.00000; 4879/5115 tok/s;   2376 sec\n",
            "[2020-06-01 13:13:50,732 INFO] Step 18600/50000; acc:  83.14; ppl:  1.80; xent: 0.59; lr: 1.00000; 5073/5187 tok/s;   2381 sec\n",
            "[2020-06-01 13:13:57,072 INFO] Step 18650/50000; acc:  82.31; ppl:  1.89; xent: 0.64; lr: 1.00000; 5053/5139 tok/s;   2388 sec\n",
            "[2020-06-01 13:14:02,575 INFO] Step 18700/50000; acc:  84.20; ppl:  1.75; xent: 0.56; lr: 1.00000; 5054/5257 tok/s;   2393 sec\n",
            "[2020-06-01 13:14:09,710 INFO] Step 18750/50000; acc:  80.18; ppl:  2.05; xent: 0.72; lr: 1.00000; 5262/5354 tok/s;   2400 sec\n",
            "[2020-06-01 13:14:16,613 INFO] Step 18800/50000; acc:  80.29; ppl:  2.04; xent: 0.72; lr: 1.00000; 5017/5037 tok/s;   2407 sec\n",
            "[2020-06-01 13:14:18,157 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:14:18,410 INFO] number of examples: 26142\n",
            "[2020-06-01 13:14:22,997 INFO] Step 18850/50000; acc:  82.09; ppl:  1.92; xent: 0.65; lr: 1.00000; 4856/4763 tok/s;   2414 sec\n",
            "[2020-06-01 13:14:29,940 INFO] Step 18900/50000; acc:  80.96; ppl:  1.99; xent: 0.69; lr: 1.00000; 5113/5207 tok/s;   2420 sec\n",
            "[2020-06-01 13:14:36,384 INFO] Step 18950/50000; acc:  81.93; ppl:  1.90; xent: 0.64; lr: 1.00000; 4967/4983 tok/s;   2427 sec\n",
            "[2020-06-01 13:14:42,101 INFO] Step 19000/50000; acc:  82.53; ppl:  1.85; xent: 0.61; lr: 1.00000; 4909/5230 tok/s;   2433 sec\n",
            "[2020-06-01 13:14:48,251 INFO] Step 19050/50000; acc:  83.60; ppl:  1.80; xent: 0.59; lr: 1.00000; 5136/5092 tok/s;   2439 sec\n",
            "[2020-06-01 13:14:53,809 INFO] Step 19100/50000; acc:  83.94; ppl:  1.76; xent: 0.57; lr: 1.00000; 5051/5180 tok/s;   2444 sec\n",
            "[2020-06-01 13:15:01,075 INFO] Step 19150/50000; acc:  80.53; ppl:  2.00; xent: 0.70; lr: 1.00000; 5193/5422 tok/s;   2452 sec\n",
            "[2020-06-01 13:15:07,545 INFO] Step 19200/50000; acc:  81.45; ppl:  1.95; xent: 0.67; lr: 1.00000; 5064/5074 tok/s;   2458 sec\n",
            "[2020-06-01 13:15:10,534 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:15:10,857 INFO] number of examples: 26142\n",
            "[2020-06-01 13:15:14,271 INFO] Step 19250/50000; acc:  82.07; ppl:  1.90; xent: 0.64; lr: 1.00000; 4821/4771 tok/s;   2465 sec\n",
            "[2020-06-01 13:15:20,894 INFO] Step 19300/50000; acc:  82.73; ppl:  1.84; xent: 0.61; lr: 1.00000; 5244/5205 tok/s;   2471 sec\n",
            "[2020-06-01 13:15:27,841 INFO] Step 19350/50000; acc:  79.84; ppl:  2.09; xent: 0.74; lr: 1.00000; 4943/4966 tok/s;   2478 sec\n",
            "[2020-06-01 13:15:33,502 INFO] Step 19400/50000; acc:  83.92; ppl:  1.76; xent: 0.57; lr: 1.00000; 4827/5180 tok/s;   2484 sec\n",
            "[2020-06-01 13:15:39,383 INFO] Step 19450/50000; acc:  83.49; ppl:  1.81; xent: 0.59; lr: 1.00000; 5095/5136 tok/s;   2490 sec\n",
            "[2020-06-01 13:15:45,304 INFO] Step 19500/50000; acc:  82.98; ppl:  1.84; xent: 0.61; lr: 1.00000; 5102/5176 tok/s;   2496 sec\n",
            "[2020-06-01 13:15:52,205 INFO] Step 19550/50000; acc:  81.75; ppl:  1.91; xent: 0.65; lr: 1.00000; 5162/5370 tok/s;   2503 sec\n",
            "[2020-06-01 13:15:58,557 INFO] Step 19600/50000; acc:  81.98; ppl:  1.89; xent: 0.64; lr: 1.00000; 5118/5139 tok/s;   2509 sec\n",
            "[2020-06-01 13:16:02,984 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:16:03,302 INFO] number of examples: 26142\n",
            "[2020-06-01 13:16:05,713 INFO] Step 19650/50000; acc:  82.04; ppl:  1.90; xent: 0.64; lr: 1.00000; 4728/4757 tok/s;   2516 sec\n",
            "[2020-06-01 13:16:12,048 INFO] Step 19700/50000; acc:  83.63; ppl:  1.77; xent: 0.57; lr: 1.00000; 5210/5174 tok/s;   2523 sec\n",
            "[2020-06-01 13:16:19,140 INFO] Step 19750/50000; acc:  80.09; ppl:  2.07; xent: 0.73; lr: 1.00000; 5070/4974 tok/s;   2530 sec\n",
            "[2020-06-01 13:16:25,185 INFO] Step 19800/50000; acc:  83.28; ppl:  1.79; xent: 0.58; lr: 1.00000; 4837/5232 tok/s;   2536 sec\n",
            "[2020-06-01 13:16:31,014 INFO] Step 19850/50000; acc:  83.82; ppl:  1.80; xent: 0.59; lr: 1.00000; 5050/5089 tok/s;   2542 sec\n",
            "[2020-06-01 13:16:36,978 INFO] Step 19900/50000; acc:  83.44; ppl:  1.80; xent: 0.59; lr: 1.00000; 5119/5188 tok/s;   2548 sec\n",
            "[2020-06-01 13:16:43,200 INFO] Step 19950/50000; acc:  83.76; ppl:  1.77; xent: 0.57; lr: 1.00000; 5004/5348 tok/s;   2554 sec\n",
            "[2020-06-01 13:16:49,957 INFO] Step 20000/50000; acc:  82.16; ppl:  1.89; xent: 0.64; lr: 1.00000; 5422/5341 tok/s;   2560 sec\n",
            "[2020-06-01 13:16:49,957 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 13:16:49,963 INFO] number of examples: 276\n",
            "[2020-06-01 13:16:50,518 INFO] Validation perplexity: 138.882\n",
            "[2020-06-01 13:16:50,518 INFO] Validation accuracy: 42.7663\n",
            "[2020-06-01 13:16:50,549 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_20000.pt\n",
            "[2020-06-01 13:16:56,415 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:16:56,757 INFO] number of examples: 26142\n",
            "[2020-06-01 13:16:57,953 INFO] Step 20050/50000; acc:  81.91; ppl:  1.94; xent: 0.66; lr: 1.00000; 4004/4078 tok/s;   2568 sec\n",
            "[2020-06-01 13:17:04,278 INFO] Step 20100/50000; acc:  83.47; ppl:  1.77; xent: 0.57; lr: 1.00000; 5137/5088 tok/s;   2575 sec\n",
            "[2020-06-01 13:17:11,507 INFO] Step 20150/50000; acc:  80.71; ppl:  2.01; xent: 0.70; lr: 1.00000; 5186/5011 tok/s;   2582 sec\n",
            "[2020-06-01 13:17:17,596 INFO] Step 20200/50000; acc:  83.51; ppl:  1.78; xent: 0.58; lr: 1.00000; 4911/5325 tok/s;   2588 sec\n",
            "[2020-06-01 13:17:23,261 INFO] Step 20250/50000; acc:  83.79; ppl:  1.78; xent: 0.58; lr: 1.00000; 4944/5008 tok/s;   2594 sec\n",
            "[2020-06-01 13:17:29,505 INFO] Step 20300/50000; acc:  83.61; ppl:  1.78; xent: 0.58; lr: 1.00000; 5145/5222 tok/s;   2600 sec\n",
            "[2020-06-01 13:17:35,171 INFO] Step 20350/50000; acc:  85.31; ppl:  1.66; xent: 0.51; lr: 1.00000; 5015/5351 tok/s;   2606 sec\n",
            "[2020-06-01 13:17:42,271 INFO] Step 20400/50000; acc:  81.91; ppl:  1.88; xent: 0.63; lr: 1.00000; 5381/5324 tok/s;   2613 sec\n",
            "[2020-06-01 13:17:48,798 INFO] Step 20450/50000; acc:  81.57; ppl:  1.94; xent: 0.66; lr: 1.00000; 4969/5044 tok/s;   2619 sec\n",
            "[2020-06-01 13:17:48,799 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:17:49,139 INFO] number of examples: 26142\n",
            "[2020-06-01 13:17:55,687 INFO] Step 20500/50000; acc:  83.60; ppl:  1.78; xent: 0.57; lr: 1.00000; 4786/4728 tok/s;   2626 sec\n",
            "[2020-06-01 13:18:02,477 INFO] Step 20550/50000; acc:  82.35; ppl:  1.89; xent: 0.64; lr: 1.00000; 5114/5075 tok/s;   2633 sec\n",
            "[2020-06-01 13:18:08,706 INFO] Step 20600/50000; acc:  83.45; ppl:  1.78; xent: 0.57; lr: 1.00000; 4896/5157 tok/s;   2639 sec\n",
            "[2020-06-01 13:18:14,283 INFO] Step 20650/50000; acc:  85.45; ppl:  1.64; xent: 0.50; lr: 1.00000; 5033/5151 tok/s;   2645 sec\n",
            "[2020-06-01 13:18:20,742 INFO] Step 20700/50000; acc:  83.89; ppl:  1.78; xent: 0.57; lr: 1.00000; 5078/5178 tok/s;   2651 sec\n",
            "[2020-06-01 13:18:26,335 INFO] Step 20750/50000; acc:  85.28; ppl:  1.68; xent: 0.52; lr: 1.00000; 5099/5248 tok/s;   2657 sec\n",
            "[2020-06-01 13:18:33,355 INFO] Step 20800/50000; acc:  82.31; ppl:  1.86; xent: 0.62; lr: 1.00000; 5233/5321 tok/s;   2664 sec\n",
            "[2020-06-01 13:18:40,433 INFO] Step 20850/50000; acc:  81.57; ppl:  1.94; xent: 0.66; lr: 1.00000; 5061/5099 tok/s;   2671 sec\n",
            "[2020-06-01 13:18:41,236 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:18:41,587 INFO] number of examples: 26142\n",
            "[2020-06-01 13:18:46,854 INFO] Step 20900/50000; acc:  84.38; ppl:  1.73; xent: 0.55; lr: 1.00000; 4768/4658 tok/s;   2677 sec\n",
            "[2020-06-01 13:18:53,816 INFO] Step 20950/50000; acc:  82.79; ppl:  1.89; xent: 0.63; lr: 1.00000; 5128/5221 tok/s;   2684 sec\n",
            "[2020-06-01 13:19:00,051 INFO] Step 21000/50000; acc:  84.46; ppl:  1.70; xent: 0.53; lr: 1.00000; 4886/4970 tok/s;   2691 sec\n",
            "[2020-06-01 13:19:05,904 INFO] Step 21050/50000; acc:  84.28; ppl:  1.71; xent: 0.54; lr: 1.00000; 5014/5215 tok/s;   2696 sec\n",
            "[2020-06-01 13:19:11,926 INFO] Step 21100/50000; acc:  84.88; ppl:  1.71; xent: 0.54; lr: 1.00000; 5075/5124 tok/s;   2702 sec\n",
            "[2020-06-01 13:19:17,470 INFO] Step 21150/50000; acc:  85.51; ppl:  1.66; xent: 0.51; lr: 1.00000; 5029/5201 tok/s;   2708 sec\n",
            "[2020-06-01 13:19:24,712 INFO] Step 21200/50000; acc:  82.25; ppl:  1.87; xent: 0.62; lr: 1.00000; 5236/5406 tok/s;   2715 sec\n",
            "[2020-06-01 13:19:31,371 INFO] Step 21250/50000; acc:  82.78; ppl:  1.84; xent: 0.61; lr: 1.00000; 5122/5094 tok/s;   2722 sec\n",
            "[2020-06-01 13:19:33,673 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:19:34,016 INFO] number of examples: 26142\n",
            "[2020-06-01 13:19:38,269 INFO] Step 21300/50000; acc:  83.46; ppl:  1.79; xent: 0.58; lr: 1.00000; 4764/4684 tok/s;   2729 sec\n",
            "[2020-06-01 13:19:44,924 INFO] Step 21350/50000; acc:  83.80; ppl:  1.77; xent: 0.57; lr: 1.00000; 5142/5200 tok/s;   2735 sec\n",
            "[2020-06-01 13:19:51,513 INFO] Step 21400/50000; acc:  83.31; ppl:  1.81; xent: 0.59; lr: 1.00000; 4981/5014 tok/s;   2742 sec\n",
            "[2020-06-01 13:19:57,239 INFO] Step 21450/50000; acc:  84.87; ppl:  1.68; xent: 0.52; lr: 1.00000; 4861/5201 tok/s;   2748 sec\n",
            "[2020-06-01 13:20:03,381 INFO] Step 21500/50000; acc:  85.19; ppl:  1.68; xent: 0.52; lr: 1.00000; 5132/5126 tok/s;   2754 sec\n",
            "[2020-06-01 13:20:08,912 INFO] Step 21550/50000; acc:  85.28; ppl:  1.65; xent: 0.50; lr: 1.00000; 5064/5172 tok/s;   2759 sec\n",
            "[2020-06-01 13:20:16,082 INFO] Step 21600/50000; acc:  83.22; ppl:  1.79; xent: 0.58; lr: 1.00000; 5209/5424 tok/s;   2767 sec\n",
            "[2020-06-01 13:20:22,656 INFO] Step 21650/50000; acc:  83.01; ppl:  1.84; xent: 0.61; lr: 1.00000; 5062/5062 tok/s;   2773 sec\n",
            "[2020-06-01 13:20:26,121 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:20:26,463 INFO] number of examples: 26142\n",
            "[2020-06-01 13:20:29,479 INFO] Step 21700/50000; acc:  84.11; ppl:  1.72; xent: 0.55; lr: 1.00000; 4780/4764 tok/s;   2780 sec\n",
            "[2020-06-01 13:20:36,071 INFO] Step 21750/50000; acc:  84.78; ppl:  1.68; xent: 0.52; lr: 1.00000; 5269/5191 tok/s;   2787 sec\n",
            "[2020-06-01 13:20:42,913 INFO] Step 21800/50000; acc:  82.05; ppl:  1.90; xent: 0.64; lr: 1.00000; 4965/4987 tok/s;   2793 sec\n",
            "[2020-06-01 13:20:48,689 INFO] Step 21850/50000; acc:  85.88; ppl:  1.62; xent: 0.48; lr: 1.00000; 4774/5204 tok/s;   2799 sec\n",
            "[2020-06-01 13:20:54,524 INFO] Step 21900/50000; acc:  85.10; ppl:  1.69; xent: 0.53; lr: 1.00000; 5089/5089 tok/s;   2805 sec\n",
            "[2020-06-01 13:21:00,684 INFO] Step 21950/50000; acc:  85.46; ppl:  1.67; xent: 0.51; lr: 1.00000; 5174/5192 tok/s;   2811 sec\n",
            "[2020-06-01 13:21:07,169 INFO] Step 22000/50000; acc:  84.91; ppl:  1.69; xent: 0.53; lr: 1.00000; 5098/5371 tok/s;   2818 sec\n",
            "[2020-06-01 13:21:13,614 INFO] Step 22050/50000; acc:  84.67; ppl:  1.71; xent: 0.54; lr: 1.00000; 5327/5315 tok/s;   2824 sec\n",
            "[2020-06-01 13:21:18,581 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:21:18,938 INFO] number of examples: 26142\n",
            "[2020-06-01 13:21:20,830 INFO] Step 22100/50000; acc:  83.44; ppl:  1.80; xent: 0.59; lr: 1.00000; 4534/4589 tok/s;   2831 sec\n",
            "[2020-06-01 13:21:26,966 INFO] Step 22150/50000; acc:  85.45; ppl:  1.66; xent: 0.50; lr: 1.00000; 5150/5167 tok/s;   2837 sec\n",
            "[2020-06-01 13:21:34,224 INFO] Step 22200/50000; acc:  82.51; ppl:  1.88; xent: 0.63; lr: 1.00000; 5175/5001 tok/s;   2845 sec\n",
            "[2020-06-01 13:21:40,209 INFO] Step 22250/50000; acc:  85.36; ppl:  1.65; xent: 0.50; lr: 1.00000; 4879/5286 tok/s;   2851 sec\n",
            "[2020-06-01 13:21:46,108 INFO] Step 22300/50000; acc:  85.07; ppl:  1.68; xent: 0.52; lr: 1.00000; 5018/5020 tok/s;   2857 sec\n",
            "[2020-06-01 13:21:52,186 INFO] Step 22350/50000; acc:  85.72; ppl:  1.64; xent: 0.50; lr: 1.00000; 5065/5193 tok/s;   2863 sec\n",
            "[2020-06-01 13:21:58,055 INFO] Step 22400/50000; acc:  86.32; ppl:  1.59; xent: 0.46; lr: 1.00000; 5016/5380 tok/s;   2869 sec\n",
            "[2020-06-01 13:22:05,282 INFO] Step 22450/50000; acc:  83.79; ppl:  1.77; xent: 0.57; lr: 1.00000; 5411/5327 tok/s;   2876 sec\n",
            "[2020-06-01 13:22:11,072 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:22:11,440 INFO] number of examples: 26142\n",
            "[2020-06-01 13:22:12,204 INFO] Step 22500/50000; acc:  83.78; ppl:  1.78; xent: 0.57; lr: 1.00000; 4515/4626 tok/s;   2883 sec\n",
            "[2020-06-01 13:22:18,440 INFO] Step 22550/50000; acc:  85.91; ppl:  1.61; xent: 0.48; lr: 1.00000; 5179/5058 tok/s;   2889 sec\n",
            "[2020-06-01 13:22:25,604 INFO] Step 22600/50000; acc:  83.16; ppl:  1.83; xent: 0.61; lr: 1.00000; 5149/5037 tok/s;   2896 sec\n",
            "[2020-06-01 13:22:31,851 INFO] Step 22650/50000; acc:  85.21; ppl:  1.66; xent: 0.50; lr: 1.00000; 4935/5254 tok/s;   2902 sec\n",
            "[2020-06-01 13:22:37,582 INFO] Step 22700/50000; acc:  85.37; ppl:  1.67; xent: 0.51; lr: 1.00000; 4953/5043 tok/s;   2908 sec\n",
            "[2020-06-01 13:22:43,792 INFO] Step 22750/50000; acc:  86.23; ppl:  1.62; xent: 0.48; lr: 1.00000; 5101/5193 tok/s;   2914 sec\n",
            "[2020-06-01 13:22:49,369 INFO] Step 22800/50000; acc:  87.00; ppl:  1.56; xent: 0.45; lr: 1.00000; 5003/5316 tok/s;   2920 sec\n",
            "[2020-06-01 13:22:56,494 INFO] Step 22850/50000; acc:  84.30; ppl:  1.72; xent: 0.54; lr: 1.00000; 5327/5322 tok/s;   2927 sec\n",
            "[2020-06-01 13:23:03,182 INFO] Step 22900/50000; acc:  83.63; ppl:  1.79; xent: 0.58; lr: 1.00000; 4984/5048 tok/s;   2934 sec\n",
            "[2020-06-01 13:23:03,563 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:23:03,816 INFO] number of examples: 26142\n",
            "[2020-06-01 13:23:09,743 INFO] Step 22950/50000; acc:  85.29; ppl:  1.66; xent: 0.50; lr: 1.00000; 4841/4779 tok/s;   2940 sec\n",
            "[2020-06-01 13:23:16,828 INFO] Step 23000/50000; acc:  84.26; ppl:  1.74; xent: 0.56; lr: 1.00000; 5107/5066 tok/s;   2947 sec\n",
            "[2020-06-01 13:23:22,933 INFO] Step 23050/50000; acc:  85.65; ppl:  1.64; xent: 0.50; lr: 1.00000; 4859/5128 tok/s;   2953 sec\n",
            "[2020-06-01 13:23:28,647 INFO] Step 23100/50000; acc:  86.77; ppl:  1.57; xent: 0.45; lr: 1.00000; 5067/5170 tok/s;   2959 sec\n",
            "[2020-06-01 13:23:35,017 INFO] Step 23150/50000; acc:  85.55; ppl:  1.67; xent: 0.51; lr: 1.00000; 5030/5141 tok/s;   2966 sec\n",
            "[2020-06-01 13:23:40,526 INFO] Step 23200/50000; acc:  87.08; ppl:  1.57; xent: 0.45; lr: 1.00000; 5083/5256 tok/s;   2971 sec\n",
            "[2020-06-01 13:23:47,650 INFO] Step 23250/50000; acc:  84.12; ppl:  1.73; xent: 0.55; lr: 1.00000; 5306/5368 tok/s;   2978 sec\n",
            "[2020-06-01 13:23:54,552 INFO] Step 23300/50000; acc:  83.96; ppl:  1.74; xent: 0.56; lr: 1.00000; 5000/5039 tok/s;   2985 sec\n",
            "[2020-06-01 13:23:55,941 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:23:56,267 INFO] number of examples: 26142\n",
            "[2020-06-01 13:24:00,919 INFO] Step 23350/50000; acc:  85.34; ppl:  1.67; xent: 0.51; lr: 1.00000; 4798/4714 tok/s;   2991 sec\n",
            "[2020-06-01 13:24:07,905 INFO] Step 23400/50000; acc:  84.48; ppl:  1.73; xent: 0.55; lr: 1.00000; 5156/5244 tok/s;   2998 sec\n",
            "[2020-06-01 13:24:14,271 INFO] Step 23450/50000; acc:  85.69; ppl:  1.63; xent: 0.49; lr: 1.00000; 4957/4983 tok/s;   3005 sec\n",
            "[2020-06-01 13:24:19,989 INFO] Step 23500/50000; acc:  86.07; ppl:  1.60; xent: 0.47; lr: 1.00000; 4930/5220 tok/s;   3011 sec\n",
            "[2020-06-01 13:24:26,134 INFO] Step 23550/50000; acc:  86.84; ppl:  1.59; xent: 0.47; lr: 1.00000; 5161/5126 tok/s;   3017 sec\n",
            "[2020-06-01 13:24:31,684 INFO] Step 23600/50000; acc:  87.09; ppl:  1.56; xent: 0.45; lr: 1.00000; 5070/5234 tok/s;   3022 sec\n",
            "[2020-06-01 13:24:38,836 INFO] Step 23650/50000; acc:  84.17; ppl:  1.73; xent: 0.55; lr: 1.00000; 5213/5419 tok/s;   3029 sec\n",
            "[2020-06-01 13:24:45,377 INFO] Step 23700/50000; acc:  85.25; ppl:  1.69; xent: 0.52; lr: 1.00000; 5098/5088 tok/s;   3036 sec\n",
            "[2020-06-01 13:24:48,230 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:24:48,564 INFO] number of examples: 26142\n",
            "[2020-06-01 13:24:52,092 INFO] Step 23750/50000; acc:  85.46; ppl:  1.64; xent: 0.50; lr: 1.00000; 4772/4741 tok/s;   3043 sec\n",
            "[2020-06-01 13:24:58,722 INFO] Step 23800/50000; acc:  86.16; ppl:  1.62; xent: 0.48; lr: 1.00000; 5229/5209 tok/s;   3049 sec\n",
            "[2020-06-01 13:25:05,669 INFO] Step 23850/50000; acc:  83.85; ppl:  1.77; xent: 0.57; lr: 1.00000; 4933/4978 tok/s;   3056 sec\n",
            "[2020-06-01 13:25:11,255 INFO] Step 23900/50000; acc:  87.27; ppl:  1.55; xent: 0.44; lr: 1.00000; 4846/5177 tok/s;   3062 sec\n",
            "[2020-06-01 13:25:17,211 INFO] Step 23950/50000; acc:  86.96; ppl:  1.58; xent: 0.46; lr: 1.00000; 5107/5148 tok/s;   3068 sec\n",
            "[2020-06-01 13:25:23,131 INFO] Step 24000/50000; acc:  86.22; ppl:  1.61; xent: 0.47; lr: 1.00000; 5102/5176 tok/s;   3074 sec\n",
            "[2020-06-01 13:25:29,938 INFO] Step 24050/50000; acc:  85.50; ppl:  1.64; xent: 0.50; lr: 1.00000; 5167/5378 tok/s;   3080 sec\n",
            "[2020-06-01 13:25:36,347 INFO] Step 24100/50000; acc:  85.73; ppl:  1.64; xent: 0.49; lr: 1.00000; 5142/5143 tok/s;   3087 sec\n",
            "[2020-06-01 13:25:40,649 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:25:40,979 INFO] number of examples: 26142\n",
            "[2020-06-01 13:25:43,428 INFO] Step 24150/50000; acc:  84.89; ppl:  1.68; xent: 0.52; lr: 1.00000; 4724/4772 tok/s;   3094 sec\n",
            "[2020-06-01 13:25:49,826 INFO] Step 24200/50000; acc:  87.02; ppl:  1.55; xent: 0.44; lr: 1.00000; 5268/5188 tok/s;   3100 sec\n",
            "[2020-06-01 13:25:56,906 INFO] Step 24250/50000; acc:  84.05; ppl:  1.77; xent: 0.57; lr: 1.00000; 5069/5014 tok/s;   3107 sec\n",
            "[2020-06-01 13:26:02,831 INFO] Step 24300/50000; acc:  86.58; ppl:  1.59; xent: 0.46; lr: 1.00000; 4815/5219 tok/s;   3113 sec\n",
            "[2020-06-01 13:26:08,756 INFO] Step 24350/50000; acc:  87.02; ppl:  1.58; xent: 0.45; lr: 1.00000; 5077/5083 tok/s;   3119 sec\n",
            "[2020-06-01 13:26:14,696 INFO] Step 24400/50000; acc:  86.50; ppl:  1.59; xent: 0.46; lr: 1.00000; 5096/5199 tok/s;   3125 sec\n",
            "[2020-06-01 13:26:20,942 INFO] Step 24450/50000; acc:  87.01; ppl:  1.57; xent: 0.45; lr: 1.00000; 5047/5366 tok/s;   3131 sec\n",
            "[2020-06-01 13:26:27,620 INFO] Step 24500/50000; acc:  85.67; ppl:  1.64; xent: 0.49; lr: 1.00000; 5390/5339 tok/s;   3138 sec\n",
            "[2020-06-01 13:26:33,042 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:26:33,381 INFO] number of examples: 26142\n",
            "[2020-06-01 13:26:34,602 INFO] Step 24550/50000; acc:  84.96; ppl:  1.70; xent: 0.53; lr: 1.00000; 4568/4643 tok/s;   3145 sec\n",
            "[2020-06-01 13:26:40,998 INFO] Step 24600/50000; acc:  86.68; ppl:  1.57; xent: 0.45; lr: 1.00000; 5159/5101 tok/s;   3152 sec\n",
            "[2020-06-01 13:26:48,152 INFO] Step 24650/50000; acc:  83.99; ppl:  1.77; xent: 0.57; lr: 1.00000; 5170/5001 tok/s;   3159 sec\n",
            "[2020-06-01 13:26:54,240 INFO] Step 24700/50000; acc:  86.44; ppl:  1.58; xent: 0.46; lr: 1.00000; 4911/5325 tok/s;   3165 sec\n",
            "[2020-06-01 13:27:00,014 INFO] Step 24750/50000; acc:  86.90; ppl:  1.58; xent: 0.46; lr: 1.00000; 4940/5003 tok/s;   3171 sec\n",
            "[2020-06-01 13:27:06,201 INFO] Step 24800/50000; acc:  86.87; ppl:  1.57; xent: 0.45; lr: 1.00000; 5151/5208 tok/s;   3177 sec\n",
            "[2020-06-01 13:27:12,019 INFO] Step 24850/50000; acc:  87.65; ppl:  1.52; xent: 0.42; lr: 1.00000; 5049/5374 tok/s;   3183 sec\n",
            "[2020-06-01 13:27:19,162 INFO] Step 24900/50000; acc:  85.33; ppl:  1.65; xent: 0.50; lr: 1.00000; 5340/5318 tok/s;   3190 sec\n",
            "[2020-06-01 13:27:25,464 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:27:25,781 INFO] number of examples: 26142\n",
            "[2020-06-01 13:27:25,965 INFO] Step 24950/50000; acc:  85.63; ppl:  1.64; xent: 0.49; lr: 1.00000; 4617/4689 tok/s;   3196 sec\n",
            "[2020-06-01 13:27:32,358 INFO] Step 25000/50000; acc:  86.31; ppl:  1.58; xent: 0.46; lr: 1.00000; 5137/5057 tok/s;   3203 sec\n",
            "[2020-06-01 13:27:32,390 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_25000.pt\n",
            "[2020-06-01 13:27:39,512 INFO] Step 25050/50000; acc:  85.31; ppl:  1.68; xent: 0.52; lr: 1.00000; 4854/4817 tok/s;   3210 sec\n",
            "[2020-06-01 13:27:45,812 INFO] Step 25100/50000; acc:  86.69; ppl:  1.58; xent: 0.46; lr: 1.00000; 4891/5169 tok/s;   3216 sec\n",
            "[2020-06-01 13:27:51,431 INFO] Step 25150/50000; acc:  88.17; ppl:  1.49; xent: 0.40; lr: 1.00000; 5025/5111 tok/s;   3222 sec\n",
            "[2020-06-01 13:27:58,053 INFO] Step 25200/50000; acc:  85.39; ppl:  1.67; xent: 0.51; lr: 1.00000; 5136/5204 tok/s;   3229 sec\n",
            "[2020-06-01 13:28:03,342 INFO] Step 25250/50000; acc:  88.98; ppl:  1.45; xent: 0.37; lr: 1.00000; 5070/5275 tok/s;   3234 sec\n",
            "[2020-06-01 13:28:10,429 INFO] Step 25300/50000; acc:  85.49; ppl:  1.64; xent: 0.49; lr: 1.00000; 5246/5342 tok/s;   3241 sec\n",
            "[2020-06-01 13:28:17,428 INFO] Step 25350/50000; acc:  84.68; ppl:  1.71; xent: 0.54; lr: 1.00000; 5073/5103 tok/s;   3248 sec\n",
            "[2020-06-01 13:28:18,164 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:28:18,496 INFO] number of examples: 26142\n",
            "[2020-06-01 13:28:23,931 INFO] Step 25400/50000; acc:  87.16; ppl:  1.55; xent: 0.44; lr: 1.00000; 4815/4697 tok/s;   3254 sec\n",
            "[2020-06-01 13:28:31,012 INFO] Step 25450/50000; acc:  85.13; ppl:  1.68; xent: 0.52; lr: 1.00000; 5093/5152 tok/s;   3262 sec\n",
            "[2020-06-01 13:28:37,195 INFO] Step 25500/50000; acc:  87.43; ppl:  1.53; xent: 0.42; lr: 1.00000; 4869/5028 tok/s;   3268 sec\n",
            "[2020-06-01 13:28:42,899 INFO] Step 25550/50000; acc:  87.72; ppl:  1.51; xent: 0.41; lr: 1.00000; 5077/5222 tok/s;   3273 sec\n",
            "[2020-06-01 13:28:48,982 INFO] Step 25600/50000; acc:  87.61; ppl:  1.54; xent: 0.43; lr: 1.00000; 5056/5126 tok/s;   3280 sec\n",
            "[2020-06-01 13:28:54,558 INFO] Step 25650/50000; acc:  87.97; ppl:  1.51; xent: 0.41; lr: 1.00000; 5034/5210 tok/s;   3285 sec\n",
            "[2020-06-01 13:29:01,776 INFO] Step 25700/50000; acc:  86.02; ppl:  1.62; xent: 0.48; lr: 1.00000; 5237/5384 tok/s;   3292 sec\n",
            "[2020-06-01 13:29:08,496 INFO] Step 25750/50000; acc:  85.98; ppl:  1.62; xent: 0.49; lr: 1.00000; 5069/5080 tok/s;   3299 sec\n",
            "[2020-06-01 13:29:10,598 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:29:10,930 INFO] number of examples: 26142\n",
            "[2020-06-01 13:29:15,325 INFO] Step 25800/50000; acc:  86.27; ppl:  1.59; xent: 0.46; lr: 1.00000; 4828/4710 tok/s;   3306 sec\n",
            "[2020-06-01 13:29:21,870 INFO] Step 25850/50000; acc:  87.04; ppl:  1.57; xent: 0.45; lr: 1.00000; 5121/5200 tok/s;   3312 sec\n",
            "[2020-06-01 13:29:28,509 INFO] Step 25900/50000; acc:  86.56; ppl:  1.59; xent: 0.46; lr: 1.00000; 4981/5025 tok/s;   3319 sec\n",
            "[2020-06-01 13:29:34,312 INFO] Step 25950/50000; acc:  87.57; ppl:  1.52; xent: 0.42; lr: 1.00000; 4896/5206 tok/s;   3325 sec\n",
            "[2020-06-01 13:29:40,358 INFO] Step 26000/50000; acc:  87.80; ppl:  1.53; xent: 0.42; lr: 1.00000; 5129/5116 tok/s;   3331 sec\n",
            "[2020-06-01 13:29:45,939 INFO] Step 26050/50000; acc:  88.14; ppl:  1.49; xent: 0.40; lr: 1.00000; 5076/5206 tok/s;   3336 sec\n",
            "[2020-06-01 13:29:53,091 INFO] Step 26100/50000; acc:  86.36; ppl:  1.59; xent: 0.46; lr: 1.00000; 5177/5419 tok/s;   3344 sec\n",
            "[2020-06-01 13:29:59,671 INFO] Step 26150/50000; acc:  85.85; ppl:  1.63; xent: 0.49; lr: 1.00000; 5087/5077 tok/s;   3350 sec\n",
            "[2020-06-01 13:30:02,988 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:30:03,340 INFO] number of examples: 26142\n",
            "[2020-06-01 13:30:06,461 INFO] Step 26200/50000; acc:  87.30; ppl:  1.55; xent: 0.44; lr: 1.00000; 4767/4722 tok/s;   3357 sec\n",
            "[2020-06-01 13:30:13,052 INFO] Step 26250/50000; acc:  87.53; ppl:  1.52; xent: 0.42; lr: 1.00000; 5241/5192 tok/s;   3364 sec\n",
            "[2020-06-01 13:30:19,971 INFO] Step 26300/50000; acc:  85.24; ppl:  1.68; xent: 0.52; lr: 1.00000; 4953/4953 tok/s;   3370 sec\n",
            "[2020-06-01 13:30:25,719 INFO] Step 26350/50000; acc:  88.04; ppl:  1.48; xent: 0.39; lr: 1.00000; 4776/5202 tok/s;   3376 sec\n",
            "[2020-06-01 13:30:31,574 INFO] Step 26400/50000; acc:  87.90; ppl:  1.52; xent: 0.42; lr: 1.00000; 5129/5127 tok/s;   3382 sec\n",
            "[2020-06-01 13:30:37,639 INFO] Step 26450/50000; acc:  87.99; ppl:  1.50; xent: 0.41; lr: 1.00000; 5170/5211 tok/s;   3388 sec\n",
            "[2020-06-01 13:30:44,343 INFO] Step 26500/50000; acc:  86.84; ppl:  1.57; xent: 0.45; lr: 1.00000; 5141/5374 tok/s;   3395 sec\n",
            "[2020-06-01 13:30:50,541 INFO] Step 26550/50000; acc:  88.14; ppl:  1.49; xent: 0.40; lr: 1.00000; 5302/5323 tok/s;   3401 sec\n",
            "[2020-06-01 13:30:55,465 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:30:55,830 INFO] number of examples: 26142\n",
            "[2020-06-01 13:30:57,783 INFO] Step 26600/50000; acc:  86.23; ppl:  1.60; xent: 0.47; lr: 1.00000; 4527/4582 tok/s;   3408 sec\n",
            "[2020-06-01 13:31:04,035 INFO] Step 26650/50000; acc:  88.02; ppl:  1.49; xent: 0.40; lr: 1.00000; 5197/5169 tok/s;   3415 sec\n",
            "[2020-06-01 13:31:11,255 INFO] Step 26700/50000; acc:  85.50; ppl:  1.67; xent: 0.51; lr: 1.00000; 5122/4995 tok/s;   3422 sec\n",
            "[2020-06-01 13:31:17,184 INFO] Step 26750/50000; acc:  88.03; ppl:  1.50; xent: 0.41; lr: 1.00000; 4882/5282 tok/s;   3428 sec\n",
            "[2020-06-01 13:31:23,140 INFO] Step 26800/50000; acc:  87.61; ppl:  1.54; xent: 0.43; lr: 1.00000; 5025/5036 tok/s;   3434 sec\n",
            "[2020-06-01 13:31:29,138 INFO] Step 26850/50000; acc:  87.95; ppl:  1.51; xent: 0.41; lr: 1.00000; 5068/5177 tok/s;   3440 sec\n",
            "[2020-06-01 13:31:35,198 INFO] Step 26900/50000; acc:  88.26; ppl:  1.49; xent: 0.40; lr: 1.00000; 5038/5392 tok/s;   3446 sec\n",
            "[2020-06-01 13:31:42,277 INFO] Step 26950/50000; acc:  86.70; ppl:  1.57; xent: 0.45; lr: 1.00000; 5397/5310 tok/s;   3453 sec\n",
            "[2020-06-01 13:31:47,989 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:31:48,243 INFO] number of examples: 26142\n",
            "[2020-06-01 13:31:49,126 INFO] Step 27000/50000; acc:  86.41; ppl:  1.60; xent: 0.47; lr: 1.00000; 4591/4695 tok/s;   3460 sec\n",
            "[2020-06-01 13:31:55,379 INFO] Step 27050/50000; acc:  87.68; ppl:  1.51; xent: 0.41; lr: 1.00000; 5164/5062 tok/s;   3466 sec\n",
            "[2020-06-01 13:32:02,641 INFO] Step 27100/50000; acc:  85.87; ppl:  1.64; xent: 0.50; lr: 1.00000; 5195/5026 tok/s;   3473 sec\n",
            "[2020-06-01 13:32:08,810 INFO] Step 27150/50000; acc:  88.06; ppl:  1.50; xent: 0.40; lr: 1.00000; 4861/5274 tok/s;   3479 sec\n",
            "[2020-06-01 13:32:14,508 INFO] Step 27200/50000; acc:  87.78; ppl:  1.52; xent: 0.42; lr: 1.00000; 4938/4995 tok/s;   3485 sec\n",
            "[2020-06-01 13:32:20,837 INFO] Step 27250/50000; acc:  87.99; ppl:  1.51; xent: 0.41; lr: 1.00000; 5096/5210 tok/s;   3491 sec\n",
            "[2020-06-01 13:32:26,381 INFO] Step 27300/50000; acc:  89.48; ppl:  1.42; xent: 0.35; lr: 1.00000; 4999/5324 tok/s;   3497 sec\n",
            "[2020-06-01 13:32:33,458 INFO] Step 27350/50000; acc:  86.89; ppl:  1.57; xent: 0.45; lr: 1.00000; 5344/5292 tok/s;   3504 sec\n",
            "[2020-06-01 13:32:40,139 INFO] Step 27400/50000; acc:  86.35; ppl:  1.60; xent: 0.47; lr: 1.00000; 4970/5053 tok/s;   3511 sec\n",
            "[2020-06-01 13:32:40,419 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:32:40,741 INFO] number of examples: 26142\n",
            "[2020-06-01 13:32:46,809 INFO] Step 27450/50000; acc:  87.72; ppl:  1.50; xent: 0.41; lr: 1.00000; 4820/4768 tok/s;   3517 sec\n",
            "[2020-06-01 13:32:53,791 INFO] Step 27500/50000; acc:  86.73; ppl:  1.59; xent: 0.46; lr: 1.00000; 5073/5031 tok/s;   3524 sec\n",
            "[2020-06-01 13:32:59,894 INFO] Step 27550/50000; acc:  87.97; ppl:  1.50; xent: 0.41; lr: 1.00000; 4861/5129 tok/s;   3530 sec\n",
            "[2020-06-01 13:33:05,602 INFO] Step 27600/50000; acc:  88.69; ppl:  1.45; xent: 0.37; lr: 1.00000; 5063/5169 tok/s;   3536 sec\n",
            "[2020-06-01 13:33:12,134 INFO] Step 27650/50000; acc:  87.49; ppl:  1.54; xent: 0.43; lr: 1.00000; 5099/5171 tok/s;   3543 sec\n",
            "[2020-06-01 13:33:17,517 INFO] Step 27700/50000; acc:  89.90; ppl:  1.40; xent: 0.34; lr: 1.00000; 5024/5214 tok/s;   3548 sec\n",
            "[2020-06-01 13:33:24,661 INFO] Step 27750/50000; acc:  86.66; ppl:  1.58; xent: 0.45; lr: 1.00000; 5282/5370 tok/s;   3555 sec\n",
            "[2020-06-01 13:33:31,742 INFO] Step 27800/50000; acc:  86.44; ppl:  1.61; xent: 0.48; lr: 1.00000; 5045/5072 tok/s;   3562 sec\n",
            "[2020-06-01 13:33:32,860 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:33:33,175 INFO] number of examples: 26142\n",
            "[2020-06-01 13:33:37,999 INFO] Step 27850/50000; acc:  88.39; ppl:  1.48; xent: 0.39; lr: 1.00000; 4790/4662 tok/s;   3569 sec\n",
            "[2020-06-01 13:33:44,982 INFO] Step 27900/50000; acc:  86.92; ppl:  1.57; xent: 0.45; lr: 1.00000; 5094/5227 tok/s;   3576 sec\n",
            "[2020-06-01 13:33:51,355 INFO] Step 27950/50000; acc:  88.25; ppl:  1.49; xent: 0.40; lr: 1.00000; 4962/4974 tok/s;   3582 sec\n",
            "[2020-06-01 13:33:57,117 INFO] Step 28000/50000; acc:  88.11; ppl:  1.48; xent: 0.39; lr: 1.00000; 4970/5231 tok/s;   3588 sec\n",
            "[2020-06-01 13:34:03,303 INFO] Step 28050/50000; acc:  88.88; ppl:  1.47; xent: 0.38; lr: 1.00000; 5096/5113 tok/s;   3594 sec\n",
            "[2020-06-01 13:34:08,775 INFO] Step 28100/50000; acc:  89.27; ppl:  1.45; xent: 0.37; lr: 1.00000; 5048/5200 tok/s;   3599 sec\n",
            "[2020-06-01 13:34:16,025 INFO] Step 28150/50000; acc:  87.10; ppl:  1.54; xent: 0.43; lr: 1.00000; 5213/5399 tok/s;   3607 sec\n",
            "[2020-06-01 13:34:22,508 INFO] Step 28200/50000; acc:  87.37; ppl:  1.54; xent: 0.43; lr: 1.00000; 5064/5064 tok/s;   3613 sec\n",
            "[2020-06-01 13:34:25,303 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:34:25,619 INFO] number of examples: 26142\n",
            "[2020-06-01 13:34:29,211 INFO] Step 28250/50000; acc:  87.89; ppl:  1.52; xent: 0.42; lr: 1.00000; 4753/4740 tok/s;   3620 sec\n",
            "[2020-06-01 13:34:36,167 INFO] Step 28300/50000; acc:  87.35; ppl:  1.54; xent: 0.43; lr: 1.00000; 5245/5188 tok/s;   3627 sec\n",
            "[2020-06-01 13:34:42,828 INFO] Step 28350/50000; acc:  87.69; ppl:  1.53; xent: 0.42; lr: 1.00000; 4920/4983 tok/s;   3633 sec\n",
            "[2020-06-01 13:34:48,393 INFO] Step 28400/50000; acc:  89.29; ppl:  1.43; xent: 0.36; lr: 1.00000; 4818/5173 tok/s;   3639 sec\n",
            "[2020-06-01 13:34:54,459 INFO] Step 28450/50000; acc:  88.60; ppl:  1.47; xent: 0.39; lr: 1.00000; 5140/5177 tok/s;   3645 sec\n",
            "[2020-06-01 13:35:00,297 INFO] Step 28500/50000; acc:  88.31; ppl:  1.49; xent: 0.40; lr: 1.00000; 5064/5151 tok/s;   3651 sec\n",
            "[2020-06-01 13:35:07,159 INFO] Step 28550/50000; acc:  87.57; ppl:  1.52; xent: 0.42; lr: 1.00000; 5200/5369 tok/s;   3658 sec\n",
            "[2020-06-01 13:35:13,566 INFO] Step 28600/50000; acc:  87.99; ppl:  1.50; xent: 0.40; lr: 1.00000; 5114/5158 tok/s;   3664 sec\n",
            "[2020-06-01 13:35:17,745 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:35:18,093 INFO] number of examples: 26142\n",
            "[2020-06-01 13:35:20,797 INFO] Step 28650/50000; acc:  87.05; ppl:  1.55; xent: 0.44; lr: 1.00000; 4750/4756 tok/s;   3671 sec\n",
            "[2020-06-01 13:35:27,110 INFO] Step 28700/50000; acc:  89.50; ppl:  1.42; xent: 0.35; lr: 1.00000; 5258/5170 tok/s;   3678 sec\n",
            "[2020-06-01 13:35:34,068 INFO] Step 28750/50000; acc:  86.38; ppl:  1.61; xent: 0.48; lr: 1.00000; 5030/5013 tok/s;   3685 sec\n",
            "[2020-06-01 13:35:39,986 INFO] Step 28800/50000; acc:  88.45; ppl:  1.47; xent: 0.39; lr: 1.00000; 4821/5234 tok/s;   3691 sec\n",
            "[2020-06-01 13:35:45,937 INFO] Step 28850/50000; acc:  88.84; ppl:  1.47; xent: 0.39; lr: 1.00000; 5087/5083 tok/s;   3696 sec\n",
            "[2020-06-01 13:35:51,941 INFO] Step 28900/50000; acc:  88.89; ppl:  1.46; xent: 0.38; lr: 1.00000; 5106/5196 tok/s;   3702 sec\n",
            "[2020-06-01 13:35:58,188 INFO] Step 28950/50000; acc:  89.02; ppl:  1.45; xent: 0.37; lr: 1.00000; 5067/5369 tok/s;   3709 sec\n",
            "[2020-06-01 13:36:04,789 INFO] Step 29000/50000; acc:  87.84; ppl:  1.51; xent: 0.41; lr: 1.00000; 5375/5340 tok/s;   3715 sec\n",
            "[2020-06-01 13:36:10,142 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:36:10,479 INFO] number of examples: 26142\n",
            "[2020-06-01 13:36:11,842 INFO] Step 29050/50000; acc:  87.18; ppl:  1.55; xent: 0.44; lr: 1.00000; 4603/4669 tok/s;   3722 sec\n",
            "[2020-06-01 13:36:18,187 INFO] Step 29100/50000; acc:  89.01; ppl:  1.44; xent: 0.36; lr: 1.00000; 5131/5082 tok/s;   3729 sec\n",
            "[2020-06-01 13:36:25,427 INFO] Step 29150/50000; acc:  86.65; ppl:  1.58; xent: 0.46; lr: 1.00000; 5196/5020 tok/s;   3736 sec\n",
            "[2020-06-01 13:36:31,415 INFO] Step 29200/50000; acc:  89.07; ppl:  1.44; xent: 0.37; lr: 1.00000; 4854/5300 tok/s;   3742 sec\n",
            "[2020-06-01 13:36:37,254 INFO] Step 29250/50000; acc:  88.43; ppl:  1.48; xent: 0.39; lr: 1.00000; 4972/5021 tok/s;   3748 sec\n",
            "[2020-06-01 13:36:43,386 INFO] Step 29300/50000; acc:  88.66; ppl:  1.47; xent: 0.38; lr: 1.00000; 5155/5193 tok/s;   3754 sec\n",
            "[2020-06-01 13:36:49,266 INFO] Step 29350/50000; acc:  89.69; ppl:  1.41; xent: 0.35; lr: 1.00000; 5029/5385 tok/s;   3760 sec\n",
            "[2020-06-01 13:36:56,409 INFO] Step 29400/50000; acc:  87.54; ppl:  1.52; xent: 0.42; lr: 1.00000; 5376/5336 tok/s;   3767 sec\n",
            "[2020-06-01 13:37:02,542 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:37:02,896 INFO] number of examples: 26142\n",
            "[2020-06-01 13:37:03,195 INFO] Step 29450/50000; acc:  87.72; ppl:  1.52; xent: 0.42; lr: 1.00000; 4529/4621 tok/s;   3774 sec\n",
            "[2020-06-01 13:37:09,574 INFO] Step 29500/50000; acc:  88.55; ppl:  1.47; xent: 0.38; lr: 1.00000; 5183/5083 tok/s;   3780 sec\n",
            "[2020-06-01 13:37:16,357 INFO] Step 29550/50000; acc:  87.65; ppl:  1.54; xent: 0.43; lr: 1.00000; 5091/5080 tok/s;   3787 sec\n",
            "[2020-06-01 13:37:22,757 INFO] Step 29600/50000; acc:  88.62; ppl:  1.46; xent: 0.38; lr: 1.00000; 4915/5167 tok/s;   3793 sec\n",
            "[2020-06-01 13:37:28,357 INFO] Step 29650/50000; acc:  90.14; ppl:  1.39; xent: 0.33; lr: 1.00000; 4996/5073 tok/s;   3799 sec\n",
            "[2020-06-01 13:37:34,982 INFO] Step 29700/50000; acc:  87.86; ppl:  1.53; xent: 0.43; lr: 1.00000; 5115/5192 tok/s;   3806 sec\n",
            "[2020-06-01 13:37:40,423 INFO] Step 29750/50000; acc:  89.96; ppl:  1.39; xent: 0.33; lr: 1.00000; 5070/5291 tok/s;   3811 sec\n",
            "[2020-06-01 13:37:47,520 INFO] Step 29800/50000; acc:  88.09; ppl:  1.49; xent: 0.40; lr: 1.00000; 5248/5327 tok/s;   3818 sec\n",
            "[2020-06-01 13:37:54,375 INFO] Step 29850/50000; acc:  87.26; ppl:  1.55; xent: 0.44; lr: 1.00000; 5040/5069 tok/s;   3825 sec\n",
            "[2020-06-01 13:37:55,024 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:37:55,368 INFO] number of examples: 26142\n",
            "[2020-06-01 13:38:01,050 INFO] Step 29900/50000; acc:  88.65; ppl:  1.46; xent: 0.38; lr: 1.00000; 4816/4706 tok/s;   3832 sec\n",
            "[2020-06-01 13:38:07,937 INFO] Step 29950/50000; acc:  87.85; ppl:  1.52; xent: 0.42; lr: 1.00000; 5079/5143 tok/s;   3838 sec\n",
            "[2020-06-01 13:38:14,120 INFO] Step 30000/50000; acc:  89.34; ppl:  1.43; xent: 0.36; lr: 1.00000; 4879/5049 tok/s;   3845 sec\n",
            "[2020-06-01 13:38:14,120 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 13:38:14,125 INFO] number of examples: 276\n",
            "[2020-06-01 13:38:14,683 INFO] Validation perplexity: 237.605\n",
            "[2020-06-01 13:38:14,684 INFO] Validation accuracy: 43.4855\n",
            "[2020-06-01 13:38:14,715 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_30000.pt\n",
            "[2020-06-01 13:38:20,802 INFO] Step 30050/50000; acc:  89.62; ppl:  1.41; xent: 0.35; lr: 1.00000; 4419/4514 tok/s;   3851 sec\n",
            "[2020-06-01 13:38:26,980 INFO] Step 30100/50000; acc:  88.95; ppl:  1.46; xent: 0.38; lr: 1.00000; 5020/5130 tok/s;   3858 sec\n",
            "[2020-06-01 13:38:32,484 INFO] Step 30150/50000; acc:  89.78; ppl:  1.40; xent: 0.34; lr: 1.00000; 5065/5247 tok/s;   3863 sec\n",
            "[2020-06-01 13:38:39,647 INFO] Step 30200/50000; acc:  88.19; ppl:  1.48; xent: 0.39; lr: 1.00000; 5259/5361 tok/s;   3870 sec\n",
            "[2020-06-01 13:38:46,357 INFO] Step 30250/50000; acc:  88.20; ppl:  1.50; xent: 0.40; lr: 1.00000; 5028/5092 tok/s;   3877 sec\n",
            "[2020-06-01 13:38:48,340 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:38:48,685 INFO] number of examples: 26142\n",
            "[2020-06-01 13:38:53,182 INFO] Step 30300/50000; acc:  88.55; ppl:  1.48; xent: 0.39; lr: 1.00000; 4841/4690 tok/s;   3884 sec\n",
            "[2020-06-01 13:38:59,742 INFO] Step 30350/50000; acc:  88.63; ppl:  1.47; xent: 0.38; lr: 1.00000; 5119/5197 tok/s;   3890 sec\n",
            "[2020-06-01 13:39:06,359 INFO] Step 30400/50000; acc:  88.11; ppl:  1.50; xent: 0.41; lr: 1.00000; 4969/5022 tok/s;   3897 sec\n",
            "[2020-06-01 13:39:12,271 INFO] Step 30450/50000; acc:  89.04; ppl:  1.44; xent: 0.37; lr: 1.00000; 4914/5207 tok/s;   3903 sec\n",
            "[2020-06-01 13:39:18,316 INFO] Step 30500/50000; acc:  89.90; ppl:  1.42; xent: 0.35; lr: 1.00000; 5151/5086 tok/s;   3909 sec\n",
            "[2020-06-01 13:39:23,836 INFO] Step 30550/50000; acc:  89.69; ppl:  1.42; xent: 0.35; lr: 1.00000; 5027/5204 tok/s;   3914 sec\n",
            "[2020-06-01 13:39:31,135 INFO] Step 30600/50000; acc:  88.02; ppl:  1.50; xent: 0.41; lr: 1.00000; 5196/5415 tok/s;   3922 sec\n",
            "[2020-06-01 13:39:37,590 INFO] Step 30650/50000; acc:  88.19; ppl:  1.50; xent: 0.40; lr: 1.00000; 5066/5066 tok/s;   3928 sec\n",
            "[2020-06-01 13:39:40,787 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:39:41,153 INFO] number of examples: 26142\n",
            "[2020-06-01 13:39:44,336 INFO] Step 30700/50000; acc:  89.31; ppl:  1.43; xent: 0.36; lr: 1.00000; 4750/4734 tok/s;   3935 sec\n",
            "[2020-06-01 13:39:51,034 INFO] Step 30750/50000; acc:  89.53; ppl:  1.42; xent: 0.35; lr: 1.00000; 5271/5218 tok/s;   3942 sec\n",
            "[2020-06-01 13:39:57,844 INFO] Step 30800/50000; acc:  87.50; ppl:  1.55; xent: 0.44; lr: 1.00000; 4930/4934 tok/s;   3948 sec\n",
            "[2020-06-01 13:40:03,548 INFO] Step 30850/50000; acc:  90.02; ppl:  1.39; xent: 0.33; lr: 1.00000; 4778/5196 tok/s;   3954 sec\n",
            "[2020-06-01 13:40:09,459 INFO] Step 30900/50000; acc:  89.75; ppl:  1.43; xent: 0.35; lr: 1.00000; 5146/5133 tok/s;   3960 sec\n",
            "[2020-06-01 13:40:15,460 INFO] Step 30950/50000; acc:  89.74; ppl:  1.41; xent: 0.34; lr: 1.00000; 5140/5203 tok/s;   3966 sec\n",
            "[2020-06-01 13:40:22,226 INFO] Step 31000/50000; acc:  88.96; ppl:  1.46; xent: 0.38; lr: 1.00000; 5151/5373 tok/s;   3973 sec\n",
            "[2020-06-01 13:40:28,352 INFO] Step 31050/50000; acc:  89.82; ppl:  1.41; xent: 0.34; lr: 1.00000; 5302/5333 tok/s;   3979 sec\n",
            "[2020-06-01 13:40:33,227 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:40:33,480 INFO] number of examples: 26142\n",
            "[2020-06-01 13:40:35,676 INFO] Step 31100/50000; acc:  88.00; ppl:  1.51; xent: 0.41; lr: 1.00000; 4651/4680 tok/s;   3986 sec\n",
            "[2020-06-01 13:40:41,838 INFO] Step 31150/50000; acc:  90.14; ppl:  1.39; xent: 0.33; lr: 1.00000; 5180/5174 tok/s;   3992 sec\n",
            "[2020-06-01 13:40:48,999 INFO] Step 31200/50000; acc:  87.68; ppl:  1.53; xent: 0.43; lr: 1.00000; 5119/5012 tok/s;   4000 sec\n",
            "[2020-06-01 13:40:54,841 INFO] Step 31250/50000; acc:  89.70; ppl:  1.41; xent: 0.34; lr: 1.00000; 4922/5299 tok/s;   4005 sec\n",
            "[2020-06-01 13:41:00,782 INFO] Step 31300/50000; acc:  89.28; ppl:  1.44; xent: 0.37; lr: 1.00000; 5037/5062 tok/s;   4011 sec\n",
            "[2020-06-01 13:41:06,779 INFO] Step 31350/50000; acc:  89.75; ppl:  1.42; xent: 0.35; lr: 1.00000; 5100/5199 tok/s;   4017 sec\n",
            "[2020-06-01 13:41:12,880 INFO] Step 31400/50000; acc:  89.89; ppl:  1.40; xent: 0.34; lr: 1.00000; 5077/5445 tok/s;   4023 sec\n",
            "[2020-06-01 13:41:19,843 INFO] Step 31450/50000; acc:  88.99; ppl:  1.45; xent: 0.37; lr: 1.00000; 5404/5311 tok/s;   4030 sec\n",
            "[2020-06-01 13:41:25,480 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:41:25,806 INFO] number of examples: 26142\n",
            "[2020-06-01 13:41:26,817 INFO] Step 31500/50000; acc:  88.48; ppl:  1.48; xent: 0.39; lr: 1.00000; 4564/4630 tok/s;   4037 sec\n",
            "[2020-06-01 13:41:33,070 INFO] Step 31550/50000; acc:  89.90; ppl:  1.40; xent: 0.34; lr: 1.00000; 5144/5072 tok/s;   4044 sec\n",
            "[2020-06-01 13:41:40,324 INFO] Step 31600/50000; acc:  87.81; ppl:  1.51; xent: 0.41; lr: 1.00000; 5178/5021 tok/s;   4051 sec\n",
            "[2020-06-01 13:41:46,422 INFO] Step 31650/50000; acc:  89.94; ppl:  1.40; xent: 0.34; lr: 1.00000; 4914/5316 tok/s;   4057 sec\n",
            "[2020-06-01 13:41:52,095 INFO] Step 31700/50000; acc:  89.47; ppl:  1.44; xent: 0.36; lr: 1.00000; 4948/5017 tok/s;   4063 sec\n",
            "[2020-06-01 13:41:58,386 INFO] Step 31750/50000; acc:  89.85; ppl:  1.40; xent: 0.33; lr: 1.00000; 5127/5230 tok/s;   4069 sec\n",
            "[2020-06-01 13:42:03,983 INFO] Step 31800/50000; acc:  90.90; ppl:  1.36; xent: 0.31; lr: 1.00000; 5054/5342 tok/s;   4075 sec\n",
            "[2020-06-01 13:42:11,035 INFO] Step 31850/50000; acc:  88.87; ppl:  1.44; xent: 0.37; lr: 1.00000; 5354/5320 tok/s;   4082 sec\n",
            "[2020-06-01 13:42:17,630 INFO] Step 31900/50000; acc:  88.27; ppl:  1.50; xent: 0.40; lr: 1.00000; 4966/5041 tok/s;   4088 sec\n",
            "[2020-06-01 13:42:17,838 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:42:18,197 INFO] number of examples: 26142\n",
            "[2020-06-01 13:42:24,445 INFO] Step 31950/50000; acc:  89.40; ppl:  1.42; xent: 0.35; lr: 1.00000; 4783/4767 tok/s;   4095 sec\n",
            "[2020-06-01 13:42:31,331 INFO] Step 32000/50000; acc:  88.53; ppl:  1.48; xent: 0.39; lr: 1.00000; 5097/5039 tok/s;   4102 sec\n",
            "[2020-06-01 13:42:37,422 INFO] Step 32050/50000; acc:  89.92; ppl:  1.40; xent: 0.34; lr: 1.00000; 4859/5118 tok/s;   4108 sec\n",
            "[2020-06-01 13:42:43,158 INFO] Step 32100/50000; acc:  90.54; ppl:  1.37; xent: 0.31; lr: 1.00000; 5083/5199 tok/s;   4114 sec\n",
            "[2020-06-01 13:42:49,629 INFO] Step 32150/50000; acc:  89.20; ppl:  1.44; xent: 0.37; lr: 1.00000; 5108/5181 tok/s;   4120 sec\n",
            "[2020-06-01 13:42:55,126 INFO] Step 32200/50000; acc:  90.39; ppl:  1.38; xent: 0.32; lr: 1.00000; 5047/5257 tok/s;   4126 sec\n",
            "[2020-06-01 13:43:02,070 INFO] Step 32250/50000; acc:  89.11; ppl:  1.44; xent: 0.36; lr: 1.00000; 5277/5358 tok/s;   4133 sec\n",
            "[2020-06-01 13:43:09,145 INFO] Step 32300/50000; acc:  88.15; ppl:  1.50; xent: 0.40; lr: 1.00000; 5050/5077 tok/s;   4140 sec\n",
            "[2020-06-01 13:43:10,219 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:43:10,556 INFO] number of examples: 26142\n",
            "[2020-06-01 13:43:15,492 INFO] Step 32350/50000; acc:  89.94; ppl:  1.40; xent: 0.34; lr: 1.00000; 4782/4661 tok/s;   4146 sec\n",
            "[2020-06-01 13:43:22,597 INFO] Step 32400/50000; acc:  88.34; ppl:  1.48; xent: 0.40; lr: 1.00000; 5160/5251 tok/s;   4153 sec\n",
            "[2020-06-01 13:43:28,782 INFO] Step 32450/50000; acc:  89.91; ppl:  1.40; xent: 0.34; lr: 1.00000; 4906/4969 tok/s;   4159 sec\n",
            "[2020-06-01 13:43:34,576 INFO] Step 32500/50000; acc:  90.06; ppl:  1.38; xent: 0.32; lr: 1.00000; 5009/5235 tok/s;   4165 sec\n",
            "[2020-06-01 13:43:40,692 INFO] Step 32550/50000; acc:  90.12; ppl:  1.41; xent: 0.34; lr: 1.00000; 5091/5129 tok/s;   4171 sec\n",
            "[2020-06-01 13:43:46,186 INFO] Step 32600/50000; acc:  90.72; ppl:  1.37; xent: 0.31; lr: 1.00000; 5063/5226 tok/s;   4177 sec\n",
            "[2020-06-01 13:43:53,447 INFO] Step 32650/50000; acc:  88.80; ppl:  1.45; xent: 0.37; lr: 1.00000; 5232/5409 tok/s;   4184 sec\n",
            "[2020-06-01 13:43:59,895 INFO] Step 32700/50000; acc:  89.12; ppl:  1.45; xent: 0.37; lr: 1.00000; 5111/5064 tok/s;   4190 sec\n",
            "[2020-06-01 13:44:02,544 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:44:02,887 INFO] number of examples: 26142\n",
            "[2020-06-01 13:44:06,669 INFO] Step 32750/50000; acc:  89.49; ppl:  1.43; xent: 0.36; lr: 1.00000; 4769/4766 tok/s;   4197 sec\n",
            "[2020-06-01 13:44:13,506 INFO] Step 32800/50000; acc:  88.95; ppl:  1.44; xent: 0.37; lr: 1.00000; 5195/5190 tok/s;   4204 sec\n",
            "[2020-06-01 13:44:20,165 INFO] Step 32850/50000; acc:  89.10; ppl:  1.44; xent: 0.37; lr: 1.00000; 4932/4986 tok/s;   4211 sec\n",
            "[2020-06-01 13:44:25,696 INFO] Step 32900/50000; acc:  90.29; ppl:  1.37; xent: 0.32; lr: 1.00000; 4812/5172 tok/s;   4216 sec\n",
            "[2020-06-01 13:44:31,966 INFO] Step 32950/50000; acc:  89.85; ppl:  1.41; xent: 0.34; lr: 1.00000; 5140/5158 tok/s;   4222 sec\n",
            "[2020-06-01 13:44:37,638 INFO] Step 33000/50000; acc:  90.55; ppl:  1.37; xent: 0.32; lr: 1.00000; 5118/5191 tok/s;   4228 sec\n",
            "[2020-06-01 13:44:44,565 INFO] Step 33050/50000; acc:  89.32; ppl:  1.43; xent: 0.36; lr: 1.00000; 5198/5390 tok/s;   4235 sec\n",
            "[2020-06-01 13:44:51,141 INFO] Step 33100/50000; acc:  88.89; ppl:  1.46; xent: 0.38; lr: 1.00000; 5090/5088 tok/s;   4242 sec\n",
            "[2020-06-01 13:44:54,954 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:44:55,300 INFO] number of examples: 26142\n",
            "[2020-06-01 13:44:58,063 INFO] Step 33150/50000; acc:  89.54; ppl:  1.42; xent: 0.35; lr: 1.00000; 4759/4782 tok/s;   4249 sec\n",
            "[2020-06-01 13:45:04,470 INFO] Step 33200/50000; acc:  90.96; ppl:  1.34; xent: 0.29; lr: 1.00000; 5281/5191 tok/s;   4255 sec\n",
            "[2020-06-01 13:45:11,396 INFO] Step 33250/50000; acc:  88.07; ppl:  1.50; xent: 0.41; lr: 1.00000; 4988/4993 tok/s;   4262 sec\n",
            "[2020-06-01 13:45:17,351 INFO] Step 33300/50000; acc:  90.10; ppl:  1.39; xent: 0.33; lr: 1.00000; 4802/5213 tok/s;   4268 sec\n",
            "[2020-06-01 13:45:23,249 INFO] Step 33350/50000; acc:  90.22; ppl:  1.40; xent: 0.33; lr: 1.00000; 5078/5075 tok/s;   4274 sec\n",
            "[2020-06-01 13:45:29,299 INFO] Step 33400/50000; acc:  90.33; ppl:  1.38; xent: 0.32; lr: 1.00000; 5130/5181 tok/s;   4280 sec\n",
            "[2020-06-01 13:45:35,607 INFO] Step 33450/50000; acc:  90.98; ppl:  1.36; xent: 0.31; lr: 1.00000; 5079/5358 tok/s;   4286 sec\n",
            "[2020-06-01 13:45:42,189 INFO] Step 33500/50000; acc:  89.36; ppl:  1.43; xent: 0.36; lr: 1.00000; 5332/5326 tok/s;   4293 sec\n",
            "[2020-06-01 13:45:47,439 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:45:47,780 INFO] number of examples: 26142\n",
            "[2020-06-01 13:45:49,235 INFO] Step 33550/50000; acc:  89.41; ppl:  1.44; xent: 0.36; lr: 1.00000; 4554/4643 tok/s;   4300 sec\n",
            "[2020-06-01 13:45:55,673 INFO] Step 33600/50000; acc:  90.60; ppl:  1.37; xent: 0.31; lr: 1.00000; 5136/5101 tok/s;   4306 sec\n",
            "[2020-06-01 13:46:02,832 INFO] Step 33650/50000; acc:  87.96; ppl:  1.50; xent: 0.40; lr: 1.00000; 5166/4976 tok/s;   4313 sec\n",
            "[2020-06-01 13:46:08,888 INFO] Step 33700/50000; acc:  90.57; ppl:  1.37; xent: 0.32; lr: 1.00000; 4854/5294 tok/s;   4319 sec\n",
            "[2020-06-01 13:46:14,708 INFO] Step 33750/50000; acc:  90.11; ppl:  1.41; xent: 0.34; lr: 1.00000; 5009/5025 tok/s;   4325 sec\n",
            "[2020-06-01 13:46:20,847 INFO] Step 33800/50000; acc:  90.49; ppl:  1.37; xent: 0.32; lr: 1.00000; 5140/5219 tok/s;   4331 sec\n",
            "[2020-06-01 13:46:26,721 INFO] Step 33850/50000; acc:  91.21; ppl:  1.34; xent: 0.30; lr: 1.00000; 5023/5378 tok/s;   4337 sec\n",
            "[2020-06-01 13:46:33,910 INFO] Step 33900/50000; acc:  89.63; ppl:  1.42; xent: 0.35; lr: 1.00000; 5377/5328 tok/s;   4344 sec\n",
            "[2020-06-01 13:46:39,903 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:46:40,278 INFO] number of examples: 26142\n",
            "[2020-06-01 13:46:40,695 INFO] Step 33950/50000; acc:  89.42; ppl:  1.43; xent: 0.36; lr: 1.00000; 4531/4593 tok/s;   4351 sec\n",
            "[2020-06-01 13:46:47,082 INFO] Step 34000/50000; acc:  90.19; ppl:  1.39; xent: 0.33; lr: 1.00000; 5167/5088 tok/s;   4358 sec\n",
            "[2020-06-01 13:46:53,946 INFO] Step 34050/50000; acc:  89.11; ppl:  1.45; xent: 0.37; lr: 1.00000; 5133/5087 tok/s;   4364 sec\n",
            "[2020-06-01 13:47:00,339 INFO] Step 34100/50000; acc:  90.30; ppl:  1.38; xent: 0.32; lr: 1.00000; 4910/5160 tok/s;   4371 sec\n",
            "[2020-06-01 13:47:05,923 INFO] Step 34150/50000; acc:  91.41; ppl:  1.33; xent: 0.29; lr: 1.00000; 4965/5095 tok/s;   4376 sec\n",
            "[2020-06-01 13:47:12,461 INFO] Step 34200/50000; acc:  89.36; ppl:  1.43; xent: 0.36; lr: 1.00000; 5095/5177 tok/s;   4383 sec\n",
            "[2020-06-01 13:47:17,931 INFO] Step 34250/50000; acc:  91.15; ppl:  1.34; xent: 0.30; lr: 1.00000; 5066/5279 tok/s;   4388 sec\n",
            "[2020-06-01 13:47:25,028 INFO] Step 34300/50000; acc:  89.85; ppl:  1.40; xent: 0.34; lr: 1.00000; 5266/5324 tok/s;   4396 sec\n",
            "[2020-06-01 13:47:31,869 INFO] Step 34350/50000; acc:  89.07; ppl:  1.45; xent: 0.37; lr: 1.00000; 5003/5060 tok/s;   4402 sec\n",
            "[2020-06-01 13:47:32,432 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:47:32,806 INFO] number of examples: 26142\n",
            "[2020-06-01 13:47:38,586 INFO] Step 34400/50000; acc:  90.56; ppl:  1.37; xent: 0.32; lr: 1.00000; 4787/4688 tok/s;   4409 sec\n",
            "[2020-06-01 13:47:45,510 INFO] Step 34450/50000; acc:  89.32; ppl:  1.44; xent: 0.37; lr: 1.00000; 5098/5115 tok/s;   4416 sec\n",
            "[2020-06-01 13:47:51,796 INFO] Step 34500/50000; acc:  90.37; ppl:  1.37; xent: 0.31; lr: 1.00000; 4860/5057 tok/s;   4422 sec\n",
            "[2020-06-01 13:47:57,435 INFO] Step 34550/50000; acc:  91.04; ppl:  1.34; xent: 0.30; lr: 1.00000; 5066/5191 tok/s;   4428 sec\n",
            "[2020-06-01 13:48:03,690 INFO] Step 34600/50000; acc:  90.25; ppl:  1.40; xent: 0.33; lr: 1.00000; 5030/5128 tok/s;   4434 sec\n",
            "[2020-06-01 13:48:09,231 INFO] Step 34650/50000; acc:  91.29; ppl:  1.33; xent: 0.29; lr: 1.00000; 5065/5256 tok/s;   4440 sec\n",
            "[2020-06-01 13:48:16,434 INFO] Step 34700/50000; acc:  89.68; ppl:  1.41; xent: 0.35; lr: 1.00000; 5292/5374 tok/s;   4447 sec\n",
            "[2020-06-01 13:48:23,174 INFO] Step 34750/50000; acc:  89.60; ppl:  1.42; xent: 0.35; lr: 1.00000; 4987/5023 tok/s;   4454 sec\n",
            "[2020-06-01 13:48:24,922 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:48:25,305 INFO] number of examples: 26142\n",
            "[2020-06-01 13:48:29,864 INFO] Step 34800/50000; acc:  90.17; ppl:  1.39; xent: 0.33; lr: 1.00000; 4796/4692 tok/s;   4460 sec\n",
            "[2020-06-01 13:48:36,719 INFO] Step 34850/50000; acc:  89.66; ppl:  1.42; xent: 0.35; lr: 1.00000; 5114/5183 tok/s;   4467 sec\n",
            "[2020-06-01 13:48:43,194 INFO] Step 34900/50000; acc:  90.49; ppl:  1.37; xent: 0.32; lr: 1.00000; 4998/5039 tok/s;   4474 sec\n",
            "[2020-06-01 13:48:48,977 INFO] Step 34950/50000; acc:  90.53; ppl:  1.36; xent: 0.31; lr: 1.00000; 4868/5189 tok/s;   4480 sec\n",
            "[2020-06-01 13:48:55,096 INFO] Step 35000/50000; acc:  91.02; ppl:  1.36; xent: 0.31; lr: 1.00000; 5132/5088 tok/s;   4486 sec\n",
            "[2020-06-01 13:48:55,136 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_35000.pt\n",
            "[2020-06-01 13:49:00,982 INFO] Step 35050/50000; acc:  90.97; ppl:  1.35; xent: 0.30; lr: 1.00000; 4736/4870 tok/s;   4492 sec\n",
            "[2020-06-01 13:49:08,253 INFO] Step 35100/50000; acc:  89.95; ppl:  1.40; xent: 0.34; lr: 1.00000; 5180/5400 tok/s;   4499 sec\n",
            "[2020-06-01 13:49:14,757 INFO] Step 35150/50000; acc:  90.01; ppl:  1.40; xent: 0.34; lr: 1.00000; 5058/5078 tok/s;   4505 sec\n",
            "[2020-06-01 13:49:17,844 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:49:18,104 INFO] number of examples: 26142\n",
            "[2020-06-01 13:49:21,484 INFO] Step 35200/50000; acc:  90.49; ppl:  1.37; xent: 0.32; lr: 1.00000; 4868/4799 tok/s;   4512 sec\n",
            "[2020-06-01 13:49:28,109 INFO] Step 35250/50000; acc:  91.02; ppl:  1.35; xent: 0.30; lr: 1.00000; 5223/5193 tok/s;   4519 sec\n",
            "[2020-06-01 13:49:34,991 INFO] Step 35300/50000; acc:  88.78; ppl:  1.47; xent: 0.39; lr: 1.00000; 4934/4956 tok/s;   4526 sec\n",
            "[2020-06-01 13:49:40,662 INFO] Step 35350/50000; acc:  91.09; ppl:  1.33; xent: 0.29; lr: 1.00000; 4818/5205 tok/s;   4531 sec\n",
            "[2020-06-01 13:49:46,502 INFO] Step 35400/50000; acc:  90.95; ppl:  1.36; xent: 0.31; lr: 1.00000; 5110/5119 tok/s;   4537 sec\n",
            "[2020-06-01 13:49:52,474 INFO] Step 35450/50000; acc:  91.02; ppl:  1.35; xent: 0.30; lr: 1.00000; 5122/5196 tok/s;   4543 sec\n",
            "[2020-06-01 13:49:59,305 INFO] Step 35500/50000; acc:  90.44; ppl:  1.37; xent: 0.32; lr: 1.00000; 5149/5369 tok/s;   4550 sec\n",
            "[2020-06-01 13:50:05,758 INFO] Step 35550/50000; acc:  90.30; ppl:  1.38; xent: 0.32; lr: 1.00000; 5147/5148 tok/s;   4556 sec\n",
            "[2020-06-01 13:50:10,219 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:50:10,554 INFO] number of examples: 26142\n",
            "[2020-06-01 13:50:12,885 INFO] Step 35600/50000; acc:  90.10; ppl:  1.40; xent: 0.34; lr: 1.00000; 4702/4749 tok/s;   4563 sec\n",
            "[2020-06-01 13:50:19,135 INFO] Step 35650/50000; acc:  91.17; ppl:  1.33; xent: 0.29; lr: 1.00000; 5178/5175 tok/s;   4570 sec\n",
            "[2020-06-01 13:50:26,171 INFO] Step 35700/50000; acc:  89.02; ppl:  1.45; xent: 0.37; lr: 1.00000; 5083/4971 tok/s;   4577 sec\n",
            "[2020-06-01 13:50:32,320 INFO] Step 35750/50000; acc:  90.57; ppl:  1.37; xent: 0.31; lr: 1.00000; 4870/5211 tok/s;   4583 sec\n",
            "[2020-06-01 13:50:38,174 INFO] Step 35800/50000; acc:  90.59; ppl:  1.37; xent: 0.32; lr: 1.00000; 5018/5100 tok/s;   4589 sec\n",
            "[2020-06-01 13:50:44,054 INFO] Step 35850/50000; acc:  91.11; ppl:  1.34; xent: 0.30; lr: 1.00000; 5104/5166 tok/s;   4595 sec\n",
            "[2020-06-01 13:50:50,239 INFO] Step 35900/50000; acc:  91.39; ppl:  1.33; xent: 0.29; lr: 1.00000; 5071/5423 tok/s;   4601 sec\n",
            "[2020-06-01 13:50:57,179 INFO] Step 35950/50000; acc:  90.14; ppl:  1.38; xent: 0.32; lr: 1.00000; 5394/5299 tok/s;   4608 sec\n",
            "[2020-06-01 13:51:02,734 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:51:03,097 INFO] number of examples: 26142\n",
            "[2020-06-01 13:51:04,183 INFO] Step 36000/50000; acc:  89.64; ppl:  1.42; xent: 0.35; lr: 1.00000; 4517/4612 tok/s;   4615 sec\n",
            "[2020-06-01 13:51:10,462 INFO] Step 36050/50000; acc:  91.33; ppl:  1.33; xent: 0.29; lr: 1.00000; 5144/5062 tok/s;   4621 sec\n",
            "[2020-06-01 13:51:17,777 INFO] Step 36100/50000; acc:  89.18; ppl:  1.44; xent: 0.36; lr: 1.00000; 5169/5005 tok/s;   4628 sec\n",
            "[2020-06-01 13:51:23,833 INFO] Step 36150/50000; acc:  90.91; ppl:  1.35; xent: 0.30; lr: 1.00000; 4864/5290 tok/s;   4634 sec\n",
            "[2020-06-01 13:51:29,601 INFO] Step 36200/50000; acc:  90.71; ppl:  1.37; xent: 0.32; lr: 1.00000; 4955/5019 tok/s;   4640 sec\n",
            "[2020-06-01 13:51:35,843 INFO] Step 36250/50000; acc:  91.17; ppl:  1.35; xent: 0.30; lr: 1.00000; 5117/5215 tok/s;   4646 sec\n",
            "[2020-06-01 13:51:41,456 INFO] Step 36300/50000; acc:  91.96; ppl:  1.30; xent: 0.27; lr: 1.00000; 5017/5315 tok/s;   4652 sec\n",
            "[2020-06-01 13:51:48,617 INFO] Step 36350/50000; acc:  90.37; ppl:  1.38; xent: 0.32; lr: 1.00000; 5362/5328 tok/s;   4659 sec\n",
            "[2020-06-01 13:51:55,181 INFO] Step 36400/50000; acc:  89.64; ppl:  1.42; xent: 0.35; lr: 1.00000; 4980/5046 tok/s;   4666 sec\n",
            "[2020-06-01 13:51:55,246 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:51:55,600 INFO] number of examples: 26142\n",
            "[2020-06-01 13:52:02,040 INFO] Step 36450/50000; acc:  90.81; ppl:  1.36; xent: 0.31; lr: 1.00000; 4770/4711 tok/s;   4673 sec\n",
            "[2020-06-01 13:52:08,870 INFO] Step 36500/50000; acc:  90.15; ppl:  1.40; xent: 0.34; lr: 1.00000; 5111/5073 tok/s;   4679 sec\n",
            "[2020-06-01 13:52:15,045 INFO] Step 36550/50000; acc:  90.95; ppl:  1.36; xent: 0.31; lr: 1.00000; 4877/5151 tok/s;   4686 sec\n",
            "[2020-06-01 13:52:20,680 INFO] Step 36600/50000; acc:  91.75; ppl:  1.31; xent: 0.27; lr: 1.00000; 5038/5166 tok/s;   4691 sec\n",
            "[2020-06-01 13:52:27,140 INFO] Step 36650/50000; acc:  90.84; ppl:  1.36; xent: 0.31; lr: 1.00000; 5116/5197 tok/s;   4698 sec\n",
            "[2020-06-01 13:52:32,624 INFO] Step 36700/50000; acc:  91.69; ppl:  1.32; xent: 0.28; lr: 1.00000; 5083/5259 tok/s;   4703 sec\n",
            "[2020-06-01 13:52:39,647 INFO] Step 36750/50000; acc:  90.69; ppl:  1.36; xent: 0.31; lr: 1.00000; 5291/5356 tok/s;   4710 sec\n",
            "[2020-06-01 13:52:46,756 INFO] Step 36800/50000; acc:  89.68; ppl:  1.42; xent: 0.35; lr: 1.00000; 5025/5085 tok/s;   4717 sec\n",
            "[2020-06-01 13:52:47,639 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:52:47,991 INFO] number of examples: 26142\n",
            "[2020-06-01 13:52:53,093 INFO] Step 36850/50000; acc:  91.15; ppl:  1.34; xent: 0.29; lr: 1.00000; 4780/4645 tok/s;   4724 sec\n",
            "[2020-06-01 13:53:00,117 INFO] Step 36900/50000; acc:  90.17; ppl:  1.41; xent: 0.34; lr: 1.00000; 5127/5241 tok/s;   4731 sec\n",
            "[2020-06-01 13:53:06,296 INFO] Step 36950/50000; acc:  91.29; ppl:  1.33; xent: 0.29; lr: 1.00000; 4922/4985 tok/s;   4737 sec\n",
            "[2020-06-01 13:53:12,107 INFO] Step 37000/50000; acc:  91.33; ppl:  1.33; xent: 0.28; lr: 1.00000; 5038/5241 tok/s;   4743 sec\n",
            "[2020-06-01 13:53:18,145 INFO] Step 37050/50000; acc:  91.19; ppl:  1.35; xent: 0.30; lr: 1.00000; 5094/5132 tok/s;   4749 sec\n",
            "[2020-06-01 13:53:23,642 INFO] Step 37100/50000; acc:  91.83; ppl:  1.31; xent: 0.27; lr: 1.00000; 5072/5233 tok/s;   4754 sec\n",
            "[2020-06-01 13:53:30,868 INFO] Step 37150/50000; acc:  90.49; ppl:  1.38; xent: 0.32; lr: 1.00000; 5240/5427 tok/s;   4761 sec\n",
            "[2020-06-01 13:53:37,386 INFO] Step 37200/50000; acc:  90.52; ppl:  1.37; xent: 0.32; lr: 1.00000; 5125/5088 tok/s;   4768 sec\n",
            "[2020-06-01 13:53:39,895 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:53:40,240 INFO] number of examples: 26142\n",
            "[2020-06-01 13:53:44,160 INFO] Step 37250/50000; acc:  90.91; ppl:  1.35; xent: 0.30; lr: 1.00000; 4788/4757 tok/s;   4775 sec\n",
            "[2020-06-01 13:53:51,014 INFO] Step 37300/50000; acc:  90.58; ppl:  1.38; xent: 0.32; lr: 1.00000; 5168/5183 tok/s;   4782 sec\n",
            "[2020-06-01 13:53:57,501 INFO] Step 37350/50000; acc:  90.42; ppl:  1.38; xent: 0.32; lr: 1.00000; 4970/5024 tok/s;   4788 sec\n",
            "[2020-06-01 13:54:03,183 INFO] Step 37400/50000; acc:  91.42; ppl:  1.33; xent: 0.28; lr: 1.00000; 4853/5213 tok/s;   4794 sec\n",
            "[2020-06-01 13:54:09,303 INFO] Step 37450/50000; acc:  91.23; ppl:  1.34; xent: 0.29; lr: 1.00000; 5172/5160 tok/s;   4800 sec\n",
            "[2020-06-01 13:54:14,895 INFO] Step 37500/50000; acc:  91.64; ppl:  1.32; xent: 0.28; lr: 1.00000; 5146/5230 tok/s;   4805 sec\n",
            "[2020-06-01 13:54:21,922 INFO] Step 37550/50000; acc:  90.95; ppl:  1.35; xent: 0.30; lr: 1.00000; 5233/5432 tok/s;   4812 sec\n",
            "[2020-06-01 13:54:28,503 INFO] Step 37600/50000; acc:  90.20; ppl:  1.39; xent: 0.33; lr: 1.00000; 5086/5109 tok/s;   4819 sec\n",
            "[2020-06-01 13:54:32,089 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:54:32,444 INFO] number of examples: 26142\n",
            "[2020-06-01 13:54:35,328 INFO] Step 37650/50000; acc:  91.40; ppl:  1.33; xent: 0.29; lr: 1.00000; 4770/4784 tok/s;   4826 sec\n",
            "[2020-06-01 13:54:41,862 INFO] Step 37700/50000; acc:  91.85; ppl:  1.30; xent: 0.26; lr: 1.00000; 5296/5204 tok/s;   4832 sec\n",
            "[2020-06-01 13:54:48,751 INFO] Step 37750/50000; acc:  89.44; ppl:  1.43; xent: 0.36; lr: 1.00000; 5024/5027 tok/s;   4839 sec\n",
            "[2020-06-01 13:54:54,490 INFO] Step 37800/50000; acc:  91.78; ppl:  1.31; xent: 0.27; lr: 1.00000; 4826/5248 tok/s;   4845 sec\n",
            "[2020-06-01 13:55:00,268 INFO] Step 37850/50000; acc:  91.22; ppl:  1.34; xent: 0.29; lr: 1.00000; 5106/5107 tok/s;   4851 sec\n",
            "[2020-06-01 13:55:06,310 INFO] Step 37900/50000; acc:  91.46; ppl:  1.32; xent: 0.28; lr: 1.00000; 5180/5209 tok/s;   4857 sec\n",
            "[2020-06-01 13:55:12,656 INFO] Step 37950/50000; acc:  92.01; ppl:  1.31; xent: 0.27; lr: 1.00000; 5119/5407 tok/s;   4863 sec\n",
            "[2020-06-01 13:55:19,118 INFO] Step 38000/50000; acc:  90.68; ppl:  1.37; xent: 0.31; lr: 1.00000; 5362/5356 tok/s;   4870 sec\n",
            "[2020-06-01 13:55:24,252 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:55:24,590 INFO] number of examples: 26142\n",
            "[2020-06-01 13:55:26,350 INFO] Step 38050/50000; acc:  90.39; ppl:  1.39; xent: 0.33; lr: 1.00000; 4595/4628 tok/s;   4877 sec\n",
            "[2020-06-01 13:55:32,511 INFO] Step 38100/50000; acc:  91.66; ppl:  1.32; xent: 0.28; lr: 1.00000; 5180/5187 tok/s;   4883 sec\n",
            "[2020-06-01 13:55:39,720 INFO] Step 38150/50000; acc:  89.75; ppl:  1.41; xent: 0.35; lr: 1.00000; 5175/4996 tok/s;   4890 sec\n",
            "[2020-06-01 13:55:45,733 INFO] Step 38200/50000; acc:  91.63; ppl:  1.32; xent: 0.27; lr: 1.00000; 4845/5287 tok/s;   4896 sec\n",
            "[2020-06-01 13:55:51,631 INFO] Step 38250/50000; acc:  91.16; ppl:  1.35; xent: 0.30; lr: 1.00000; 5064/5054 tok/s;   4902 sec\n",
            "[2020-06-01 13:55:57,647 INFO] Step 38300/50000; acc:  91.80; ppl:  1.31; xent: 0.27; lr: 1.00000; 5117/5222 tok/s;   4908 sec\n",
            "[2020-06-01 13:56:03,510 INFO] Step 38350/50000; acc:  92.11; ppl:  1.30; xent: 0.26; lr: 1.00000; 5022/5411 tok/s;   4914 sec\n",
            "[2020-06-01 13:56:10,727 INFO] Step 38400/50000; acc:  91.06; ppl:  1.34; xent: 0.30; lr: 1.00000; 5453/5360 tok/s;   4921 sec\n",
            "[2020-06-01 13:56:16,531 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:56:16,882 INFO] number of examples: 26142\n",
            "[2020-06-01 13:56:17,405 INFO] Step 38450/50000; acc:  90.62; ppl:  1.37; xent: 0.32; lr: 1.00000; 4526/4618 tok/s;   4928 sec\n",
            "[2020-06-01 13:56:23,743 INFO] Step 38500/50000; acc:  90.89; ppl:  1.34; xent: 0.29; lr: 1.00000; 5177/5092 tok/s;   4934 sec\n",
            "[2020-06-01 13:56:30,727 INFO] Step 38550/50000; acc:  90.23; ppl:  1.39; xent: 0.33; lr: 1.00000; 5201/5119 tok/s;   4941 sec\n",
            "[2020-06-01 13:56:37,024 INFO] Step 38600/50000; acc:  91.36; ppl:  1.34; xent: 0.29; lr: 1.00000; 4904/5195 tok/s;   4948 sec\n",
            "[2020-06-01 13:56:42,509 INFO] Step 38650/50000; acc:  92.35; ppl:  1.29; xent: 0.25; lr: 1.00000; 4995/5116 tok/s;   4953 sec\n",
            "[2020-06-01 13:56:48,966 INFO] Step 38700/50000; acc:  90.31; ppl:  1.39; xent: 0.33; lr: 1.00000; 5109/5195 tok/s;   4959 sec\n",
            "[2020-06-01 13:56:54,481 INFO] Step 38750/50000; acc:  92.54; ppl:  1.28; xent: 0.25; lr: 1.00000; 5094/5326 tok/s;   4965 sec\n",
            "[2020-06-01 13:57:01,522 INFO] Step 38800/50000; acc:  90.74; ppl:  1.35; xent: 0.30; lr: 1.00000; 5299/5339 tok/s;   4972 sec\n",
            "[2020-06-01 13:57:08,271 INFO] Step 38850/50000; acc:  90.18; ppl:  1.38; xent: 0.33; lr: 1.00000; 5015/5082 tok/s;   4979 sec\n",
            "[2020-06-01 13:57:08,784 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:57:09,147 INFO] number of examples: 26142\n",
            "[2020-06-01 13:57:14,999 INFO] Step 38900/50000; acc:  91.75; ppl:  1.32; xent: 0.27; lr: 1.00000; 4816/4736 tok/s;   4986 sec\n",
            "[2020-06-01 13:57:21,958 INFO] Step 38950/50000; acc:  90.61; ppl:  1.37; xent: 0.32; lr: 1.00000; 5108/5084 tok/s;   4992 sec\n",
            "[2020-06-01 13:57:28,075 INFO] Step 39000/50000; acc:  91.54; ppl:  1.33; xent: 0.28; lr: 1.00000; 4902/5138 tok/s;   4999 sec\n",
            "[2020-06-01 13:57:33,731 INFO] Step 39050/50000; acc:  92.13; ppl:  1.30; xent: 0.26; lr: 1.00000; 5108/5223 tok/s;   5004 sec\n",
            "[2020-06-01 13:57:40,021 INFO] Step 39100/50000; acc:  91.62; ppl:  1.32; xent: 0.28; lr: 1.00000; 5094/5181 tok/s;   5011 sec\n",
            "[2020-06-01 13:57:45,490 INFO] Step 39150/50000; acc:  92.50; ppl:  1.28; xent: 0.24; lr: 1.00000; 5084/5289 tok/s;   5016 sec\n",
            "[2020-06-01 13:57:52,593 INFO] Step 39200/50000; acc:  90.88; ppl:  1.36; xent: 0.31; lr: 1.00000; 5285/5378 tok/s;   5023 sec\n",
            "[2020-06-01 13:57:59,464 INFO] Step 39250/50000; acc:  90.86; ppl:  1.35; xent: 0.30; lr: 1.00000; 5041/5061 tok/s;   5030 sec\n",
            "[2020-06-01 13:58:00,999 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:58:01,261 INFO] number of examples: 26142\n",
            "[2020-06-01 13:58:05,826 INFO] Step 39300/50000; acc:  91.13; ppl:  1.34; xent: 0.29; lr: 1.00000; 4872/4779 tok/s;   5036 sec\n",
            "[2020-06-01 13:58:12,738 INFO] Step 39350/50000; acc:  90.65; ppl:  1.37; xent: 0.31; lr: 1.00000; 5137/5231 tok/s;   5043 sec\n",
            "[2020-06-01 13:58:19,132 INFO] Step 39400/50000; acc:  91.60; ppl:  1.32; xent: 0.28; lr: 1.00000; 5006/5022 tok/s;   5050 sec\n",
            "[2020-06-01 13:58:24,812 INFO] Step 39450/50000; acc:  91.82; ppl:  1.31; xent: 0.27; lr: 1.00000; 4940/5263 tok/s;   5055 sec\n",
            "[2020-06-01 13:58:30,920 INFO] Step 39500/50000; acc:  92.30; ppl:  1.30; xent: 0.26; lr: 1.00000; 5172/5128 tok/s;   5061 sec\n",
            "[2020-06-01 13:58:36,429 INFO] Step 39550/50000; acc:  92.17; ppl:  1.30; xent: 0.27; lr: 1.00000; 5096/5226 tok/s;   5067 sec\n",
            "[2020-06-01 13:58:43,653 INFO] Step 39600/50000; acc:  91.14; ppl:  1.35; xent: 0.30; lr: 1.00000; 5223/5453 tok/s;   5074 sec\n",
            "[2020-06-01 13:58:50,090 INFO] Step 39650/50000; acc:  91.02; ppl:  1.35; xent: 0.30; lr: 1.00000; 5091/5101 tok/s;   5081 sec\n",
            "[2020-06-01 13:58:53,071 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:58:53,399 INFO] number of examples: 26142\n",
            "[2020-06-01 13:58:56,803 INFO] Step 39700/50000; acc:  91.42; ppl:  1.33; xent: 0.29; lr: 1.00000; 4830/4780 tok/s;   5087 sec\n",
            "[2020-06-01 13:59:03,409 INFO] Step 39750/50000; acc:  91.60; ppl:  1.32; xent: 0.28; lr: 1.00000; 5257/5218 tok/s;   5094 sec\n",
            "[2020-06-01 13:59:10,309 INFO] Step 39800/50000; acc:  90.24; ppl:  1.39; xent: 0.33; lr: 1.00000; 4976/4999 tok/s;   5101 sec\n",
            "[2020-06-01 13:59:15,936 INFO] Step 39850/50000; acc:  92.13; ppl:  1.29; xent: 0.25; lr: 1.00000; 4856/5211 tok/s;   5106 sec\n",
            "[2020-06-01 13:59:21,775 INFO] Step 39900/50000; acc:  91.95; ppl:  1.32; xent: 0.28; lr: 1.00000; 5132/5174 tok/s;   5112 sec\n",
            "[2020-06-01 13:59:27,674 INFO] Step 39950/50000; acc:  91.71; ppl:  1.32; xent: 0.28; lr: 1.00000; 5121/5196 tok/s;   5118 sec\n",
            "[2020-06-01 13:59:34,530 INFO] Step 40000/50000; acc:  91.40; ppl:  1.33; xent: 0.29; lr: 1.00000; 5195/5404 tok/s;   5125 sec\n",
            "[2020-06-01 13:59:34,530 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 13:59:34,535 INFO] number of examples: 276\n",
            "[2020-06-01 13:59:35,088 INFO] Validation perplexity: 380.539\n",
            "[2020-06-01 13:59:35,088 INFO] Validation accuracy: 43.5961\n",
            "[2020-06-01 13:59:35,119 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_40000.pt\n",
            "[2020-06-01 13:59:41,762 INFO] Step 40050/50000; acc:  91.56; ppl:  1.33; xent: 0.28; lr: 1.00000; 4496/4514 tok/s;   5132 sec\n",
            "[2020-06-01 13:59:46,188 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 13:59:46,673 INFO] number of examples: 26142\n",
            "[2020-06-01 13:59:49,067 INFO] Step 40100/50000; acc:  91.35; ppl:  1.34; xent: 0.29; lr: 1.00000; 4631/4660 tok/s;   5140 sec\n",
            "[2020-06-01 13:59:55,360 INFO] Step 40150/50000; acc:  92.20; ppl:  1.29; xent: 0.26; lr: 1.00000; 5245/5209 tok/s;   5146 sec\n",
            "[2020-06-01 14:00:02,398 INFO] Step 40200/50000; acc:  90.23; ppl:  1.39; xent: 0.33; lr: 1.00000; 5109/5013 tok/s;   5153 sec\n",
            "[2020-06-01 14:00:08,424 INFO] Step 40250/50000; acc:  91.71; ppl:  1.31; xent: 0.27; lr: 1.00000; 4852/5249 tok/s;   5159 sec\n",
            "[2020-06-01 14:00:14,211 INFO] Step 40300/50000; acc:  92.34; ppl:  1.30; xent: 0.26; lr: 1.00000; 5087/5126 tok/s;   5165 sec\n",
            "[2020-06-01 14:00:20,146 INFO] Step 40350/50000; acc:  91.71; ppl:  1.31; xent: 0.27; lr: 1.00000; 5143/5213 tok/s;   5171 sec\n",
            "[2020-06-01 14:00:26,321 INFO] Step 40400/50000; acc:  92.22; ppl:  1.30; xent: 0.26; lr: 1.00000; 5043/5389 tok/s;   5177 sec\n",
            "[2020-06-01 14:00:33,043 INFO] Step 40450/50000; acc:  91.79; ppl:  1.31; xent: 0.27; lr: 1.00000; 5450/5369 tok/s;   5184 sec\n",
            "[2020-06-01 14:00:38,512 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:00:38,843 INFO] number of examples: 26142\n",
            "[2020-06-01 14:00:40,023 INFO] Step 40500/50000; acc:  91.00; ppl:  1.35; xent: 0.30; lr: 1.00000; 4587/4672 tok/s;   5191 sec\n",
            "[2020-06-01 14:00:46,296 INFO] Step 40550/50000; acc:  91.92; ppl:  1.30; xent: 0.27; lr: 1.00000; 5179/5130 tok/s;   5197 sec\n",
            "[2020-06-01 14:00:53,501 INFO] Step 40600/50000; acc:  90.28; ppl:  1.38; xent: 0.32; lr: 1.00000; 5204/5028 tok/s;   5204 sec\n",
            "[2020-06-01 14:00:59,586 INFO] Step 40650/50000; acc:  91.91; ppl:  1.31; xent: 0.27; lr: 1.00000; 4914/5328 tok/s;   5210 sec\n",
            "[2020-06-01 14:01:05,240 INFO] Step 40700/50000; acc:  91.45; ppl:  1.33; xent: 0.29; lr: 1.00000; 4954/5019 tok/s;   5216 sec\n",
            "[2020-06-01 14:01:11,452 INFO] Step 40750/50000; acc:  92.36; ppl:  1.29; xent: 0.25; lr: 1.00000; 5172/5250 tok/s;   5222 sec\n",
            "[2020-06-01 14:01:17,088 INFO] Step 40800/50000; acc:  92.70; ppl:  1.28; xent: 0.24; lr: 1.00000; 5042/5379 tok/s;   5228 sec\n",
            "[2020-06-01 14:01:24,188 INFO] Step 40850/50000; acc:  91.49; ppl:  1.33; xent: 0.28; lr: 1.00000; 5381/5324 tok/s;   5235 sec\n",
            "[2020-06-01 14:01:30,704 INFO] Step 40900/50000; acc:  90.95; ppl:  1.36; xent: 0.31; lr: 1.00000; 4978/5053 tok/s;   5241 sec\n",
            "[2020-06-01 14:01:30,706 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:01:31,066 INFO] number of examples: 26142\n",
            "[2020-06-01 14:01:37,586 INFO] Step 40950/50000; acc:  91.69; ppl:  1.31; xent: 0.27; lr: 1.00000; 4791/4733 tok/s;   5248 sec\n",
            "[2020-06-01 14:01:44,352 INFO] Step 41000/50000; acc:  91.11; ppl:  1.35; xent: 0.30; lr: 1.00000; 5131/5092 tok/s;   5255 sec\n",
            "[2020-06-01 14:01:50,568 INFO] Step 41050/50000; acc:  91.74; ppl:  1.31; xent: 0.27; lr: 1.00000; 4906/5168 tok/s;   5261 sec\n",
            "[2020-06-01 14:01:56,126 INFO] Step 41100/50000; acc:  92.46; ppl:  1.27; xent: 0.24; lr: 1.00000; 5051/5169 tok/s;   5267 sec\n",
            "[2020-06-01 14:02:02,550 INFO] Step 41150/50000; acc:  91.91; ppl:  1.32; xent: 0.28; lr: 1.00000; 5105/5206 tok/s;   5273 sec\n",
            "[2020-06-01 14:02:08,119 INFO] Step 41200/50000; acc:  92.31; ppl:  1.29; xent: 0.25; lr: 1.00000; 5120/5269 tok/s;   5279 sec\n",
            "[2020-06-01 14:02:15,099 INFO] Step 41250/50000; acc:  91.30; ppl:  1.33; xent: 0.29; lr: 1.00000; 5263/5351 tok/s;   5286 sec\n",
            "[2020-06-01 14:02:22,150 INFO] Step 41300/50000; acc:  90.90; ppl:  1.37; xent: 0.31; lr: 1.00000; 5081/5119 tok/s;   5293 sec\n",
            "[2020-06-01 14:02:22,950 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:02:23,298 INFO] number of examples: 26142\n",
            "[2020-06-01 14:02:28,551 INFO] Step 41350/50000; acc:  92.15; ppl:  1.30; xent: 0.26; lr: 1.00000; 4782/4672 tok/s;   5299 sec\n",
            "[2020-06-01 14:02:35,478 INFO] Step 41400/50000; acc:  90.95; ppl:  1.36; xent: 0.31; lr: 1.00000; 5153/5247 tok/s;   5306 sec\n",
            "[2020-06-01 14:02:41,675 INFO] Step 41450/50000; acc:  92.41; ppl:  1.29; xent: 0.26; lr: 1.00000; 4916/5001 tok/s;   5312 sec\n",
            "[2020-06-01 14:02:47,488 INFO] Step 41500/50000; acc:  92.03; ppl:  1.30; xent: 0.26; lr: 1.00000; 5048/5251 tok/s;   5318 sec\n",
            "[2020-06-01 14:02:53,494 INFO] Step 41550/50000; acc:  92.10; ppl:  1.31; xent: 0.27; lr: 1.00000; 5089/5138 tok/s;   5324 sec\n",
            "[2020-06-01 14:02:58,997 INFO] Step 41600/50000; acc:  92.43; ppl:  1.28; xent: 0.25; lr: 1.00000; 5066/5239 tok/s;   5330 sec\n",
            "[2020-06-01 14:03:06,203 INFO] Step 41650/50000; acc:  91.55; ppl:  1.32; xent: 0.28; lr: 1.00000; 5263/5433 tok/s;   5337 sec\n",
            "[2020-06-01 14:03:12,827 INFO] Step 41700/50000; acc:  91.62; ppl:  1.33; xent: 0.28; lr: 1.00000; 5150/5122 tok/s;   5343 sec\n",
            "[2020-06-01 14:03:15,118 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:03:15,466 INFO] number of examples: 26142\n",
            "[2020-06-01 14:03:19,697 INFO] Step 41750/50000; acc:  91.54; ppl:  1.33; xent: 0.28; lr: 1.00000; 4784/4704 tok/s;   5350 sec\n",
            "[2020-06-01 14:03:26,329 INFO] Step 41800/50000; acc:  91.95; ppl:  1.31; xent: 0.27; lr: 1.00000; 5160/5218 tok/s;   5357 sec\n",
            "[2020-06-01 14:03:32,885 INFO] Step 41850/50000; acc:  91.60; ppl:  1.32; xent: 0.28; lr: 1.00000; 5005/5039 tok/s;   5363 sec\n",
            "[2020-06-01 14:03:38,601 INFO] Step 41900/50000; acc:  91.62; ppl:  1.31; xent: 0.27; lr: 1.00000; 4870/5211 tok/s;   5369 sec\n",
            "[2020-06-01 14:03:44,715 INFO] Step 41950/50000; acc:  92.15; ppl:  1.31; xent: 0.27; lr: 1.00000; 5155/5149 tok/s;   5375 sec\n",
            "[2020-06-01 14:03:50,228 INFO] Step 42000/50000; acc:  92.27; ppl:  1.30; xent: 0.26; lr: 1.00000; 5081/5190 tok/s;   5381 sec\n",
            "[2020-06-01 14:03:57,383 INFO] Step 42050/50000; acc:  91.74; ppl:  1.31; xent: 0.27; lr: 1.00000; 5220/5435 tok/s;   5388 sec\n",
            "[2020-06-01 14:04:03,935 INFO] Step 42100/50000; acc:  91.16; ppl:  1.34; xent: 0.29; lr: 1.00000; 5079/5079 tok/s;   5394 sec\n",
            "[2020-06-01 14:04:07,387 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:04:07,732 INFO] number of examples: 26142\n",
            "[2020-06-01 14:04:10,740 INFO] Step 42150/50000; acc:  92.19; ppl:  1.29; xent: 0.26; lr: 1.00000; 4793/4777 tok/s;   5401 sec\n",
            "[2020-06-01 14:04:17,355 INFO] Step 42200/50000; acc:  92.35; ppl:  1.28; xent: 0.25; lr: 1.00000; 5251/5173 tok/s;   5408 sec\n",
            "[2020-06-01 14:04:24,166 INFO] Step 42250/50000; acc:  90.44; ppl:  1.38; xent: 0.32; lr: 1.00000; 4988/5011 tok/s;   5415 sec\n",
            "[2020-06-01 14:04:29,915 INFO] Step 42300/50000; acc:  92.48; ppl:  1.28; xent: 0.24; lr: 1.00000; 4796/5228 tok/s;   5420 sec\n",
            "[2020-06-01 14:04:35,748 INFO] Step 42350/50000; acc:  92.25; ppl:  1.30; xent: 0.26; lr: 1.00000; 5091/5092 tok/s;   5426 sec\n",
            "[2020-06-01 14:04:41,865 INFO] Step 42400/50000; acc:  92.69; ppl:  1.28; xent: 0.25; lr: 1.00000; 5210/5228 tok/s;   5432 sec\n",
            "[2020-06-01 14:04:48,344 INFO] Step 42450/50000; acc:  92.52; ppl:  1.28; xent: 0.25; lr: 1.00000; 5103/5376 tok/s;   5439 sec\n",
            "[2020-06-01 14:04:54,749 INFO] Step 42500/50000; acc:  92.07; ppl:  1.30; xent: 0.26; lr: 1.00000; 5360/5347 tok/s;   5445 sec\n",
            "[2020-06-01 14:04:59,703 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:05:00,067 INFO] number of examples: 26142\n",
            "[2020-06-01 14:05:01,950 INFO] Step 42550/50000; acc:  91.55; ppl:  1.33; xent: 0.29; lr: 1.00000; 4544/4599 tok/s;   5452 sec\n",
            "[2020-06-01 14:05:08,071 INFO] Step 42600/50000; acc:  92.45; ppl:  1.28; xent: 0.25; lr: 1.00000; 5163/5180 tok/s;   5459 sec\n",
            "[2020-06-01 14:05:15,290 INFO] Step 42650/50000; acc:  90.76; ppl:  1.37; xent: 0.32; lr: 1.00000; 5203/5028 tok/s;   5466 sec\n",
            "[2020-06-01 14:05:21,243 INFO] Step 42700/50000; acc:  92.27; ppl:  1.29; xent: 0.25; lr: 1.00000; 4904/5314 tok/s;   5472 sec\n",
            "[2020-06-01 14:05:27,114 INFO] Step 42750/50000; acc:  92.04; ppl:  1.31; xent: 0.27; lr: 1.00000; 5043/5045 tok/s;   5478 sec\n",
            "[2020-06-01 14:05:33,152 INFO] Step 42800/50000; acc:  92.19; ppl:  1.29; xent: 0.26; lr: 1.00000; 5098/5227 tok/s;   5484 sec\n",
            "[2020-06-01 14:05:38,993 INFO] Step 42850/50000; acc:  92.87; ppl:  1.26; xent: 0.23; lr: 1.00000; 5040/5405 tok/s;   5490 sec\n",
            "[2020-06-01 14:05:46,181 INFO] Step 42900/50000; acc:  91.86; ppl:  1.31; xent: 0.27; lr: 1.00000; 5440/5356 tok/s;   5497 sec\n",
            "[2020-06-01 14:05:51,964 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:05:52,324 INFO] number of examples: 26142\n",
            "[2020-06-01 14:05:53,075 INFO] Step 42950/50000; acc:  91.66; ppl:  1.32; xent: 0.28; lr: 1.00000; 4533/4644 tok/s;   5504 sec\n",
            "[2020-06-01 14:05:59,289 INFO] Step 43000/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 5197/5075 tok/s;   5510 sec\n",
            "[2020-06-01 14:06:06,414 INFO] Step 43050/50000; acc:  91.16; ppl:  1.35; xent: 0.30; lr: 1.00000; 5178/5065 tok/s;   5517 sec\n",
            "[2020-06-01 14:06:12,622 INFO] Step 43100/50000; acc:  92.28; ppl:  1.29; xent: 0.25; lr: 1.00000; 4965/5287 tok/s;   5523 sec\n",
            "[2020-06-01 14:06:18,333 INFO] Step 43150/50000; acc:  91.84; ppl:  1.31; xent: 0.27; lr: 1.00000; 4971/5062 tok/s;   5529 sec\n",
            "[2020-06-01 14:06:24,506 INFO] Step 43200/50000; acc:  92.95; ppl:  1.27; xent: 0.24; lr: 1.00000; 5131/5224 tok/s;   5535 sec\n",
            "[2020-06-01 14:06:30,036 INFO] Step 43250/50000; acc:  92.85; ppl:  1.27; xent: 0.24; lr: 1.00000; 5046/5362 tok/s;   5541 sec\n",
            "[2020-06-01 14:06:37,141 INFO] Step 43300/50000; acc:  91.93; ppl:  1.31; xent: 0.27; lr: 1.00000; 5341/5337 tok/s;   5548 sec\n",
            "[2020-06-01 14:06:43,798 INFO] Step 43350/50000; acc:  91.57; ppl:  1.32; xent: 0.28; lr: 1.00000; 5007/5071 tok/s;   5554 sec\n",
            "[2020-06-01 14:06:44,178 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:06:44,436 INFO] number of examples: 26142\n",
            "[2020-06-01 14:06:50,324 INFO] Step 43400/50000; acc:  92.18; ppl:  1.30; xent: 0.26; lr: 1.00000; 4868/4805 tok/s;   5561 sec\n",
            "[2020-06-01 14:06:57,391 INFO] Step 43450/50000; acc:  91.52; ppl:  1.33; xent: 0.28; lr: 1.00000; 5120/5078 tok/s;   5568 sec\n",
            "[2020-06-01 14:07:03,488 INFO] Step 43500/50000; acc:  92.09; ppl:  1.30; xent: 0.26; lr: 1.00000; 4865/5134 tok/s;   5574 sec\n",
            "[2020-06-01 14:07:09,161 INFO] Step 43550/50000; acc:  92.93; ppl:  1.26; xent: 0.23; lr: 1.00000; 5104/5208 tok/s;   5580 sec\n",
            "[2020-06-01 14:07:15,489 INFO] Step 43600/50000; acc:  91.98; ppl:  1.31; xent: 0.27; lr: 1.00000; 5063/5175 tok/s;   5586 sec\n",
            "[2020-06-01 14:07:20,978 INFO] Step 43650/50000; acc:  92.98; ppl:  1.26; xent: 0.23; lr: 1.00000; 5101/5276 tok/s;   5592 sec\n",
            "[2020-06-01 14:07:28,085 INFO] Step 43700/50000; acc:  91.74; ppl:  1.32; xent: 0.27; lr: 1.00000; 5319/5381 tok/s;   5599 sec\n",
            "[2020-06-01 14:07:34,953 INFO] Step 43750/50000; acc:  91.65; ppl:  1.32; xent: 0.28; lr: 1.00000; 5024/5063 tok/s;   5605 sec\n",
            "[2020-06-01 14:07:36,345 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:07:36,666 INFO] number of examples: 26142\n",
            "[2020-06-01 14:07:41,306 INFO] Step 43800/50000; acc:  91.89; ppl:  1.31; xent: 0.27; lr: 1.00000; 4809/4725 tok/s;   5612 sec\n",
            "[2020-06-01 14:07:48,295 INFO] Step 43850/50000; acc:  91.76; ppl:  1.31; xent: 0.27; lr: 1.00000; 5153/5242 tok/s;   5619 sec\n",
            "[2020-06-01 14:07:54,625 INFO] Step 43900/50000; acc:  92.14; ppl:  1.30; xent: 0.26; lr: 1.00000; 4985/5011 tok/s;   5625 sec\n",
            "[2020-06-01 14:08:00,308 INFO] Step 43950/50000; acc:  92.22; ppl:  1.29; xent: 0.25; lr: 1.00000; 4961/5252 tok/s;   5631 sec\n",
            "[2020-06-01 14:08:06,457 INFO] Step 44000/50000; acc:  92.84; ppl:  1.27; xent: 0.24; lr: 1.00000; 5158/5123 tok/s;   5637 sec\n",
            "[2020-06-01 14:08:11,994 INFO] Step 44050/50000; acc:  92.67; ppl:  1.28; xent: 0.25; lr: 1.00000; 5081/5245 tok/s;   5643 sec\n",
            "[2020-06-01 14:08:19,123 INFO] Step 44100/50000; acc:  92.00; ppl:  1.30; xent: 0.26; lr: 1.00000; 5231/5437 tok/s;   5650 sec\n",
            "[2020-06-01 14:08:25,646 INFO] Step 44150/50000; acc:  92.00; ppl:  1.30; xent: 0.26; lr: 1.00000; 5111/5102 tok/s;   5656 sec\n",
            "[2020-06-01 14:08:28,488 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:08:28,852 INFO] number of examples: 26142\n",
            "[2020-06-01 14:08:32,349 INFO] Step 44200/50000; acc:  92.41; ppl:  1.29; xent: 0.25; lr: 1.00000; 4781/4750 tok/s;   5663 sec\n",
            "[2020-06-01 14:08:38,942 INFO] Step 44250/50000; acc:  93.00; ppl:  1.26; xent: 0.23; lr: 1.00000; 5258/5238 tok/s;   5669 sec\n",
            "[2020-06-01 14:08:45,859 INFO] Step 44300/50000; acc:  91.39; ppl:  1.34; xent: 0.29; lr: 1.00000; 4955/5000 tok/s;   5676 sec\n",
            "[2020-06-01 14:08:51,433 INFO] Step 44350/50000; acc:  92.75; ppl:  1.27; xent: 0.24; lr: 1.00000; 4856/5189 tok/s;   5682 sec\n",
            "[2020-06-01 14:08:57,344 INFO] Step 44400/50000; acc:  92.71; ppl:  1.28; xent: 0.25; lr: 1.00000; 5145/5187 tok/s;   5688 sec\n",
            "[2020-06-01 14:09:03,234 INFO] Step 44450/50000; acc:  92.67; ppl:  1.28; xent: 0.25; lr: 1.00000; 5128/5203 tok/s;   5694 sec\n",
            "[2020-06-01 14:09:10,011 INFO] Step 44500/50000; acc:  92.32; ppl:  1.29; xent: 0.25; lr: 1.00000; 5190/5401 tok/s;   5701 sec\n",
            "[2020-06-01 14:09:16,395 INFO] Step 44550/50000; acc:  92.25; ppl:  1.29; xent: 0.26; lr: 1.00000; 5163/5164 tok/s;   5707 sec\n",
            "[2020-06-01 14:09:20,690 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:09:21,035 INFO] number of examples: 26142\n",
            "[2020-06-01 14:09:23,481 INFO] Step 44600/50000; acc:  91.88; ppl:  1.30; xent: 0.27; lr: 1.00000; 4720/4768 tok/s;   5714 sec\n",
            "[2020-06-01 14:09:29,873 INFO] Step 44650/50000; acc:  92.77; ppl:  1.26; xent: 0.23; lr: 1.00000; 5274/5193 tok/s;   5720 sec\n",
            "[2020-06-01 14:09:36,937 INFO] Step 44700/50000; acc:  91.23; ppl:  1.34; xent: 0.29; lr: 1.00000; 5081/5025 tok/s;   5727 sec\n",
            "[2020-06-01 14:09:42,856 INFO] Step 44750/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 4821/5225 tok/s;   5733 sec\n",
            "[2020-06-01 14:09:48,748 INFO] Step 44800/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 5105/5111 tok/s;   5739 sec\n",
            "[2020-06-01 14:09:54,663 INFO] Step 44850/50000; acc:  92.67; ppl:  1.27; xent: 0.24; lr: 1.00000; 5118/5220 tok/s;   5745 sec\n",
            "[2020-06-01 14:10:00,875 INFO] Step 44900/50000; acc:  93.12; ppl:  1.26; xent: 0.23; lr: 1.00000; 5074/5396 tok/s;   5751 sec\n",
            "[2020-06-01 14:10:07,519 INFO] Step 44950/50000; acc:  92.42; ppl:  1.29; xent: 0.25; lr: 1.00000; 5418/5366 tok/s;   5758 sec\n",
            "[2020-06-01 14:10:12,922 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:10:13,252 INFO] number of examples: 26142\n",
            "[2020-06-01 14:10:14,474 INFO] Step 45000/50000; acc:  91.87; ppl:  1.31; xent: 0.27; lr: 1.00000; 4586/4662 tok/s;   5765 sec\n",
            "[2020-06-01 14:10:14,506 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_45000.pt\n",
            "[2020-06-01 14:10:21,203 INFO] Step 45050/50000; acc:  92.84; ppl:  1.27; xent: 0.24; lr: 1.00000; 4904/4849 tok/s;   5772 sec\n",
            "[2020-06-01 14:10:28,379 INFO] Step 45100/50000; acc:  91.17; ppl:  1.34; xent: 0.29; lr: 1.00000; 5153/4985 tok/s;   5779 sec\n",
            "[2020-06-01 14:10:34,456 INFO] Step 45150/50000; acc:  92.52; ppl:  1.28; xent: 0.25; lr: 1.00000; 4921/5336 tok/s;   5785 sec\n",
            "[2020-06-01 14:10:40,183 INFO] Step 45200/50000; acc:  92.47; ppl:  1.29; xent: 0.25; lr: 1.00000; 4979/5043 tok/s;   5791 sec\n",
            "[2020-06-01 14:10:46,341 INFO] Step 45250/50000; acc:  92.55; ppl:  1.27; xent: 0.24; lr: 1.00000; 5175/5233 tok/s;   5797 sec\n",
            "[2020-06-01 14:10:52,133 INFO] Step 45300/50000; acc:  93.22; ppl:  1.26; xent: 0.23; lr: 1.00000; 5072/5399 tok/s;   5803 sec\n",
            "[2020-06-01 14:10:59,239 INFO] Step 45350/50000; acc:  92.37; ppl:  1.29; xent: 0.25; lr: 1.00000; 5368/5345 tok/s;   5810 sec\n",
            "[2020-06-01 14:11:05,512 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:11:05,835 INFO] number of examples: 26142\n",
            "[2020-06-01 14:11:06,024 INFO] Step 45400/50000; acc:  92.02; ppl:  1.31; xent: 0.27; lr: 1.00000; 4629/4702 tok/s;   5817 sec\n",
            "[2020-06-01 14:11:12,387 INFO] Step 45450/50000; acc:  92.74; ppl:  1.28; xent: 0.24; lr: 1.00000; 5161/5081 tok/s;   5823 sec\n",
            "[2020-06-01 14:11:19,143 INFO] Step 45500/50000; acc:  91.96; ppl:  1.31; xent: 0.27; lr: 1.00000; 5140/5100 tok/s;   5830 sec\n",
            "[2020-06-01 14:11:25,417 INFO] Step 45550/50000; acc:  92.75; ppl:  1.28; xent: 0.24; lr: 1.00000; 4912/5190 tok/s;   5836 sec\n",
            "[2020-06-01 14:11:30,999 INFO] Step 45600/50000; acc:  93.36; ppl:  1.24; xent: 0.22; lr: 1.00000; 5058/5145 tok/s;   5842 sec\n",
            "[2020-06-01 14:11:37,599 INFO] Step 45650/50000; acc:  92.06; ppl:  1.31; xent: 0.27; lr: 1.00000; 5153/5222 tok/s;   5848 sec\n",
            "[2020-06-01 14:11:42,865 INFO] Step 45700/50000; acc:  93.94; ppl:  1.23; xent: 0.20; lr: 1.00000; 5092/5297 tok/s;   5853 sec\n",
            "[2020-06-01 14:11:49,924 INFO] Step 45750/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 5268/5364 tok/s;   5860 sec\n",
            "[2020-06-01 14:11:56,887 INFO] Step 45800/50000; acc:  91.52; ppl:  1.32; xent: 0.28; lr: 1.00000; 5100/5129 tok/s;   5867 sec\n",
            "[2020-06-01 14:11:57,622 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:11:57,972 INFO] number of examples: 26142\n",
            "[2020-06-01 14:12:03,387 INFO] Step 45850/50000; acc:  92.71; ppl:  1.27; xent: 0.24; lr: 1.00000; 4817/4699 tok/s;   5874 sec\n",
            "[2020-06-01 14:12:10,446 INFO] Step 45900/50000; acc:  91.90; ppl:  1.31; xent: 0.27; lr: 1.00000; 5110/5168 tok/s;   5881 sec\n",
            "[2020-06-01 14:12:16,588 INFO] Step 45950/50000; acc:  92.77; ppl:  1.27; xent: 0.24; lr: 1.00000; 4900/5060 tok/s;   5887 sec\n",
            "[2020-06-01 14:12:22,280 INFO] Step 46000/50000; acc:  92.98; ppl:  1.25; xent: 0.23; lr: 1.00000; 5087/5233 tok/s;   5893 sec\n",
            "[2020-06-01 14:12:28,329 INFO] Step 46050/50000; acc:  92.72; ppl:  1.27; xent: 0.24; lr: 1.00000; 5084/5154 tok/s;   5899 sec\n",
            "[2020-06-01 14:12:33,866 INFO] Step 46100/50000; acc:  92.99; ppl:  1.26; xent: 0.23; lr: 1.00000; 5070/5247 tok/s;   5904 sec\n",
            "[2020-06-01 14:12:41,047 INFO] Step 46150/50000; acc:  92.31; ppl:  1.29; xent: 0.26; lr: 1.00000; 5264/5412 tok/s;   5912 sec\n",
            "[2020-06-01 14:12:47,760 INFO] Step 46200/50000; acc:  92.41; ppl:  1.29; xent: 0.25; lr: 1.00000; 5075/5085 tok/s;   5918 sec\n",
            "[2020-06-01 14:12:49,858 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:12:50,211 INFO] number of examples: 26142\n",
            "[2020-06-01 14:12:54,588 INFO] Step 46250/50000; acc:  92.45; ppl:  1.29; xent: 0.25; lr: 1.00000; 4829/4710 tok/s;   5925 sec\n",
            "[2020-06-01 14:13:01,117 INFO] Step 46300/50000; acc:  92.42; ppl:  1.29; xent: 0.25; lr: 1.00000; 5133/5213 tok/s;   5932 sec\n",
            "[2020-06-01 14:13:07,722 INFO] Step 46350/50000; acc:  92.12; ppl:  1.30; xent: 0.26; lr: 1.00000; 5007/5051 tok/s;   5938 sec\n",
            "[2020-06-01 14:13:13,519 INFO] Step 46400/50000; acc:  92.65; ppl:  1.27; xent: 0.24; lr: 1.00000; 4901/5211 tok/s;   5944 sec\n",
            "[2020-06-01 14:13:19,567 INFO] Step 46450/50000; acc:  92.91; ppl:  1.27; xent: 0.24; lr: 1.00000; 5128/5115 tok/s;   5950 sec\n",
            "[2020-06-01 14:13:25,130 INFO] Step 46500/50000; acc:  93.10; ppl:  1.26; xent: 0.23; lr: 1.00000; 5092/5222 tok/s;   5956 sec\n",
            "[2020-06-01 14:13:32,271 INFO] Step 46550/50000; acc:  92.80; ppl:  1.27; xent: 0.24; lr: 1.00000; 5185/5428 tok/s;   5963 sec\n",
            "[2020-06-01 14:13:38,825 INFO] Step 46600/50000; acc:  92.00; ppl:  1.30; xent: 0.27; lr: 1.00000; 5106/5097 tok/s;   5969 sec\n",
            "[2020-06-01 14:13:42,143 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:13:42,505 INFO] number of examples: 26142\n",
            "[2020-06-01 14:13:45,590 INFO] Step 46650/50000; acc:  92.65; ppl:  1.27; xent: 0.24; lr: 1.00000; 4784/4739 tok/s;   5976 sec\n",
            "[2020-06-01 14:13:52,170 INFO] Step 46700/50000; acc:  93.28; ppl:  1.24; xent: 0.22; lr: 1.00000; 5250/5201 tok/s;   5983 sec\n",
            "[2020-06-01 14:13:59,073 INFO] Step 46750/50000; acc:  91.28; ppl:  1.34; xent: 0.29; lr: 1.00000; 4965/4965 tok/s;   5990 sec\n",
            "[2020-06-01 14:14:04,803 INFO] Step 46800/50000; acc:  93.14; ppl:  1.25; xent: 0.22; lr: 1.00000; 4790/5218 tok/s;   5995 sec\n",
            "[2020-06-01 14:14:10,651 INFO] Step 46850/50000; acc:  92.84; ppl:  1.27; xent: 0.24; lr: 1.00000; 5135/5133 tok/s;   6001 sec\n",
            "[2020-06-01 14:14:16,723 INFO] Step 46900/50000; acc:  92.89; ppl:  1.26; xent: 0.23; lr: 1.00000; 5164/5205 tok/s;   6007 sec\n",
            "[2020-06-01 14:14:23,433 INFO] Step 46950/50000; acc:  92.54; ppl:  1.28; xent: 0.24; lr: 1.00000; 5137/5370 tok/s;   6014 sec\n",
            "[2020-06-01 14:14:29,617 INFO] Step 47000/50000; acc:  93.12; ppl:  1.25; xent: 0.23; lr: 1.00000; 5313/5335 tok/s;   6020 sec\n",
            "[2020-06-01 14:14:34,522 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:14:34,883 INFO] number of examples: 26142\n",
            "[2020-06-01 14:14:36,825 INFO] Step 47050/50000; acc:  92.35; ppl:  1.30; xent: 0.26; lr: 1.00000; 4548/4604 tok/s;   6027 sec\n",
            "[2020-06-01 14:14:43,063 INFO] Step 47100/50000; acc:  93.34; ppl:  1.24; xent: 0.22; lr: 1.00000; 5209/5181 tok/s;   6034 sec\n",
            "[2020-06-01 14:14:50,252 INFO] Step 47150/50000; acc:  91.76; ppl:  1.31; xent: 0.27; lr: 1.00000; 5144/5016 tok/s;   6041 sec\n",
            "[2020-06-01 14:14:56,180 INFO] Step 47200/50000; acc:  93.01; ppl:  1.26; xent: 0.23; lr: 1.00000; 4882/5283 tok/s;   6047 sec\n",
            "[2020-06-01 14:15:02,134 INFO] Step 47250/50000; acc:  92.57; ppl:  1.28; xent: 0.25; lr: 1.00000; 5026/5038 tok/s;   6053 sec\n",
            "[2020-06-01 14:15:08,127 INFO] Step 47300/50000; acc:  92.97; ppl:  1.26; xent: 0.23; lr: 1.00000; 5072/5181 tok/s;   6059 sec\n",
            "[2020-06-01 14:15:14,179 INFO] Step 47350/50000; acc:  93.46; ppl:  1.24; xent: 0.21; lr: 1.00000; 5045/5400 tok/s;   6065 sec\n",
            "[2020-06-01 14:15:21,252 INFO] Step 47400/50000; acc:  92.68; ppl:  1.27; xent: 0.24; lr: 1.00000; 5401/5313 tok/s;   6072 sec\n",
            "[2020-06-01 14:15:26,953 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:15:27,222 INFO] number of examples: 26142\n",
            "[2020-06-01 14:15:28,102 INFO] Step 47450/50000; acc:  92.28; ppl:  1.29; xent: 0.25; lr: 1.00000; 4591/4695 tok/s;   6079 sec\n",
            "[2020-06-01 14:15:34,366 INFO] Step 47500/50000; acc:  93.27; ppl:  1.24; xent: 0.22; lr: 1.00000; 5156/5054 tok/s;   6085 sec\n",
            "[2020-06-01 14:15:41,635 INFO] Step 47550/50000; acc:  91.73; ppl:  1.32; xent: 0.28; lr: 1.00000; 5189/5021 tok/s;   6092 sec\n",
            "[2020-06-01 14:15:47,801 INFO] Step 47600/50000; acc:  93.00; ppl:  1.26; xent: 0.23; lr: 1.00000; 4864/5277 tok/s;   6098 sec\n",
            "[2020-06-01 14:15:53,480 INFO] Step 47650/50000; acc:  92.40; ppl:  1.28; xent: 0.25; lr: 1.00000; 4955/5012 tok/s;   6104 sec\n",
            "[2020-06-01 14:15:59,779 INFO] Step 47700/50000; acc:  93.24; ppl:  1.25; xent: 0.23; lr: 1.00000; 5120/5234 tok/s;   6110 sec\n",
            "[2020-06-01 14:16:05,295 INFO] Step 47750/50000; acc:  93.82; ppl:  1.22; xent: 0.20; lr: 1.00000; 5024/5350 tok/s;   6116 sec\n",
            "[2020-06-01 14:16:12,340 INFO] Step 47800/50000; acc:  92.59; ppl:  1.28; xent: 0.24; lr: 1.00000; 5369/5317 tok/s;   6123 sec\n",
            "[2020-06-01 14:16:19,006 INFO] Step 47850/50000; acc:  92.33; ppl:  1.29; xent: 0.26; lr: 1.00000; 4981/5065 tok/s;   6130 sec\n",
            "[2020-06-01 14:16:19,288 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:16:19,619 INFO] number of examples: 26142\n",
            "[2020-06-01 14:16:25,653 INFO] Step 47900/50000; acc:  93.02; ppl:  1.26; xent: 0.23; lr: 1.00000; 4836/4784 tok/s;   6136 sec\n",
            "[2020-06-01 14:16:32,543 INFO] Step 47950/50000; acc:  92.33; ppl:  1.30; xent: 0.26; lr: 1.00000; 5141/5098 tok/s;   6143 sec\n",
            "[2020-06-01 14:16:38,602 INFO] Step 48000/50000; acc:  93.01; ppl:  1.26; xent: 0.23; lr: 1.00000; 4896/5166 tok/s;   6149 sec\n",
            "[2020-06-01 14:16:44,275 INFO] Step 48050/50000; acc:  93.47; ppl:  1.23; xent: 0.21; lr: 1.00000; 5094/5200 tok/s;   6155 sec\n",
            "[2020-06-01 14:16:50,744 INFO] Step 48100/50000; acc:  93.06; ppl:  1.26; xent: 0.23; lr: 1.00000; 5150/5223 tok/s;   6161 sec\n",
            "[2020-06-01 14:16:56,101 INFO] Step 48150/50000; acc:  93.72; ppl:  1.23; xent: 0.21; lr: 1.00000; 5048/5239 tok/s;   6167 sec\n",
            "[2020-06-01 14:17:03,211 INFO] Step 48200/50000; acc:  92.46; ppl:  1.28; xent: 0.25; lr: 1.00000; 5307/5395 tok/s;   6174 sec\n",
            "[2020-06-01 14:17:10,263 INFO] Step 48250/50000; acc:  92.33; ppl:  1.30; xent: 0.26; lr: 1.00000; 5066/5093 tok/s;   6181 sec\n",
            "[2020-06-01 14:17:11,376 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:17:11,739 INFO] number of examples: 26142\n",
            "[2020-06-01 14:17:16,538 INFO] Step 48300/50000; acc:  92.93; ppl:  1.26; xent: 0.23; lr: 1.00000; 4776/4648 tok/s;   6187 sec\n",
            "[2020-06-01 14:17:23,484 INFO] Step 48350/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 5121/5255 tok/s;   6194 sec\n",
            "[2020-06-01 14:17:29,814 INFO] Step 48400/50000; acc:  92.93; ppl:  1.26; xent: 0.23; lr: 1.00000; 4996/5008 tok/s;   6200 sec\n",
            "[2020-06-01 14:17:35,562 INFO] Step 48450/50000; acc:  92.96; ppl:  1.25; xent: 0.23; lr: 1.00000; 4983/5244 tok/s;   6206 sec\n",
            "[2020-06-01 14:17:41,722 INFO] Step 48500/50000; acc:  93.42; ppl:  1.25; xent: 0.22; lr: 1.00000; 5117/5134 tok/s;   6212 sec\n",
            "[2020-06-01 14:17:47,183 INFO] Step 48550/50000; acc:  93.40; ppl:  1.25; xent: 0.22; lr: 1.00000; 5059/5211 tok/s;   6218 sec\n",
            "[2020-06-01 14:17:54,405 INFO] Step 48600/50000; acc:  92.88; ppl:  1.27; xent: 0.24; lr: 1.00000; 5233/5419 tok/s;   6225 sec\n",
            "[2020-06-01 14:18:00,859 INFO] Step 48650/50000; acc:  92.64; ppl:  1.28; xent: 0.24; lr: 1.00000; 5087/5087 tok/s;   6231 sec\n",
            "[2020-06-01 14:18:03,645 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:18:03,991 INFO] number of examples: 26142\n",
            "[2020-06-01 14:18:07,572 INFO] Step 48700/50000; acc:  93.00; ppl:  1.26; xent: 0.23; lr: 1.00000; 4746/4732 tok/s;   6238 sec\n",
            "[2020-06-01 14:18:14,499 INFO] Step 48750/50000; acc:  92.89; ppl:  1.27; xent: 0.24; lr: 1.00000; 5266/5209 tok/s;   6245 sec\n",
            "[2020-06-01 14:18:21,122 INFO] Step 48800/50000; acc:  92.72; ppl:  1.27; xent: 0.24; lr: 1.00000; 4949/5012 tok/s;   6252 sec\n",
            "[2020-06-01 14:18:26,650 INFO] Step 48850/50000; acc:  93.21; ppl:  1.25; xent: 0.22; lr: 1.00000; 4850/5207 tok/s;   6257 sec\n",
            "[2020-06-01 14:18:32,687 INFO] Step 48900/50000; acc:  93.32; ppl:  1.25; xent: 0.22; lr: 1.00000; 5165/5201 tok/s;   6263 sec\n",
            "[2020-06-01 14:18:38,492 INFO] Step 48950/50000; acc:  93.08; ppl:  1.25; xent: 0.23; lr: 1.00000; 5093/5180 tok/s;   6269 sec\n",
            "[2020-06-01 14:18:45,328 INFO] Step 49000/50000; acc:  93.02; ppl:  1.26; xent: 0.23; lr: 1.00000; 5220/5390 tok/s;   6276 sec\n",
            "[2020-06-01 14:18:51,709 INFO] Step 49050/50000; acc:  92.99; ppl:  1.26; xent: 0.23; lr: 1.00000; 5135/5179 tok/s;   6282 sec\n",
            "[2020-06-01 14:18:55,868 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:18:56,206 INFO] number of examples: 26142\n",
            "[2020-06-01 14:18:58,914 INFO] Step 49100/50000; acc:  92.64; ppl:  1.27; xent: 0.24; lr: 1.00000; 4767/4773 tok/s;   6289 sec\n",
            "[2020-06-01 14:19:05,197 INFO] Step 49150/50000; acc:  93.75; ppl:  1.22; xent: 0.20; lr: 1.00000; 5284/5195 tok/s;   6296 sec\n",
            "[2020-06-01 14:19:12,146 INFO] Step 49200/50000; acc:  91.98; ppl:  1.31; xent: 0.27; lr: 1.00000; 5036/5019 tok/s;   6303 sec\n",
            "[2020-06-01 14:19:18,070 INFO] Step 49250/50000; acc:  93.07; ppl:  1.25; xent: 0.23; lr: 1.00000; 4817/5230 tok/s;   6309 sec\n",
            "[2020-06-01 14:19:23,990 INFO] Step 49300/50000; acc:  93.26; ppl:  1.25; xent: 0.22; lr: 1.00000; 5114/5110 tok/s;   6315 sec\n",
            "[2020-06-01 14:19:29,970 INFO] Step 49350/50000; acc:  93.52; ppl:  1.24; xent: 0.22; lr: 1.00000; 5125/5216 tok/s;   6320 sec\n",
            "[2020-06-01 14:19:36,206 INFO] Step 49400/50000; acc:  93.57; ppl:  1.23; xent: 0.21; lr: 1.00000; 5076/5378 tok/s;   6327 sec\n",
            "[2020-06-01 14:19:42,781 INFO] Step 49450/50000; acc:  92.75; ppl:  1.27; xent: 0.24; lr: 1.00000; 5397/5362 tok/s;   6333 sec\n",
            "[2020-06-01 14:19:48,122 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:19:48,452 INFO] number of examples: 26142\n",
            "[2020-06-01 14:19:49,826 INFO] Step 49500/50000; acc:  92.80; ppl:  1.27; xent: 0.24; lr: 1.00000; 4609/4675 tok/s;   6340 sec\n",
            "[2020-06-01 14:19:56,145 INFO] Step 49550/50000; acc:  93.31; ppl:  1.24; xent: 0.22; lr: 1.00000; 5152/5103 tok/s;   6347 sec\n",
            "[2020-06-01 14:20:03,362 INFO] Step 49600/50000; acc:  91.99; ppl:  1.31; xent: 0.27; lr: 1.00000; 5213/5036 tok/s;   6354 sec\n",
            "[2020-06-01 14:20:09,344 INFO] Step 49650/50000; acc:  92.98; ppl:  1.26; xent: 0.23; lr: 1.00000; 4860/5306 tok/s;   6360 sec\n",
            "[2020-06-01 14:20:15,143 INFO] Step 49700/50000; acc:  92.85; ppl:  1.27; xent: 0.24; lr: 1.00000; 5006/5055 tok/s;   6366 sec\n",
            "[2020-06-01 14:20:21,236 INFO] Step 49750/50000; acc:  93.43; ppl:  1.24; xent: 0.22; lr: 1.00000; 5189/5226 tok/s;   6372 sec\n",
            "[2020-06-01 14:20:27,087 INFO] Step 49800/50000; acc:  93.89; ppl:  1.22; xent: 0.20; lr: 1.00000; 5053/5410 tok/s;   6378 sec\n",
            "[2020-06-01 14:20:34,206 INFO] Step 49850/50000; acc:  92.73; ppl:  1.26; xent: 0.23; lr: 1.00000; 5394/5354 tok/s;   6385 sec\n",
            "[2020-06-01 14:20:40,318 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 14:20:40,661 INFO] number of examples: 26142\n",
            "[2020-06-01 14:20:40,956 INFO] Step 49900/50000; acc:  92.72; ppl:  1.27; xent: 0.24; lr: 1.00000; 4554/4646 tok/s;   6391 sec\n",
            "[2020-06-01 14:20:47,330 INFO] Step 49950/50000; acc:  93.09; ppl:  1.25; xent: 0.22; lr: 1.00000; 5187/5087 tok/s;   6398 sec\n",
            "[2020-06-01 14:20:54,086 INFO] Step 50000/50000; acc:  92.69; ppl:  1.28; xent: 0.24; lr: 0.50000; 5111/5100 tok/s;   6405 sec\n",
            "[2020-06-01 14:20:54,086 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 14:20:54,091 INFO] number of examples: 276\n",
            "[2020-06-01 14:20:54,646 INFO] Validation perplexity: 484.835\n",
            "[2020-06-01 14:20:54,646 INFO] Validation accuracy: 44.0111\n",
            "[2020-06-01 14:20:54,679 INFO] Saving checkpoint En2Fa-Translation/rnn_model_step_50000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTVAKiloGRf1",
        "colab_type": "text"
      },
      "source": [
        "### Test and BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So3uguE_GWX2",
        "colab_type": "code",
        "outputId": "49a5aea1-2a91-40bf-d0ed-6ce2cb555a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python OpenNMT-py/translate.py -model En2Fa-Translation/rnn_model_step_50000.pt -src En2Fa-Translation/Test/test.en -output En2Fa-Translation/no_bpe_pred.txt -replace_unk -verbose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 03:47:08,369 INFO] Translating shard 0.\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "\n",
            "SENT 1: ['hello', ',', 'do', 'we', 'drive', 'together', 'to', 'Hanover', 'on', 'the', 'twenty-eighth', 'of', 'March', '?']\n",
            "PRED 1: سلام ، آیا ما میخواهیم برای سخنرانی در اول مارس ؟\n",
            "PRED SCORE: -3.5878\n",
            "\n",
            "SENT 2: ['it', 'is', 'more', 'comfortable', 'by', 'train', '.']\n",
            "PRED 2: شیئ در منزل بافی میشود .\n",
            "PRED SCORE: -2.3327\n",
            "\n",
            "SENT 3: ['do', 'you', 'go', 'by', 'car', 'and', 'I', 'go', 'by', 'train', '?']\n",
            "PRED 3: من در هتل مراقب رزرواسیون هستم و من به Hanover ؟\n",
            "PRED SCORE: -2.4283\n",
            "\n",
            "SENT 4: ['I', 'would', 'like', 'to', 'go', 'by', 'train', '.', 'and', 'what', 'would', 'you', 'like', '?']\n",
            "PRED 4: من با شما میخواهم به Hanover . و چه چیزی برای شما مناسب است ؟\n",
            "PRED SCORE: -2.8917\n",
            "\n",
            "SENT 5: ['if', 'we', 'take', 'the', '$I-$C-$E', 'train', 'at', 'six', 'past', 'seven', ',', 'we', 'will', 'arrive', 'at', 'twenty-five', 'past', 'eight', '.']\n",
            "PRED 5: اگر ما باید ساعت شش ساعت هفت و سی دقیقه ، ما در won't don't .\n",
            "PRED SCORE: -3.2849\n",
            "\n",
            "SENT 6: ['which', 'cafe', '?']\n",
            "PRED 6: کدام opera ؟\n",
            "PRED SCORE: -0.6014\n",
            "\n",
            "SENT 7: ['the', 'cafe', 'at', 'platform', 'fourteen', '.']\n",
            "PRED 7: در مورد زمانی فرق .\n",
            "PRED SCORE: -2.3448\n",
            "\n",
            "SENT 8: ['in', 'any', 'case', 'a', 'cheap', 'hotel', '.']\n",
            "PRED 8: در صورتیکه یک ساعت وقت بافی میماند .\n",
            "PRED SCORE: -2.0031\n",
            "\n",
            "SENT 9: ['what', 'did', 'you', 'say', ',', 'please', '?']\n",
            "PRED 9: نظر شما چیست ، لطفا ؟\n",
            "PRED SCORE: -0.9437\n",
            "\n",
            "SENT 10: ['and', 'how', 'much', 'is', 'a', 'single', 'room', '?']\n",
            "PRED 10: و آنجا چقدر طول‌بکشد ؟\n",
            "PRED SCORE: -2.3328\n",
            "\n",
            "SENT 11: ['we', 'can', 'take', 'a', 'taxi', 'from', 'the', 'station', 'to', 'the', 'hotel', '.']\n",
            "PRED 11: میتوانیم از ایستگاه گفت تا در استکهلم برویم .\n",
            "PRED SCORE: -2.8392\n",
            "\n",
            "SENT 12: ['at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'a', 'room', 'now', 'and', 'how', 'much', 'is', 'a', 'single', 'room', '?']\n",
            "PRED 12: پس شما بتوانید شما میتوانید یک اتاق میکنم برای ما یک اتاق دویست دقیقه ؟\n",
            "PRED SCORE: -6.1555\n",
            "\n",
            "SENT 13: ['okay', ',', 'should', 'we', 'drive', 'back', 'on', 'Friday', 'evening', '?']\n",
            "PRED 13: باشه ، ما باید جمعه بعدازظهر به خانه برسیم ؟\n",
            "PRED SCORE: -1.4519\n",
            "\n",
            "SENT 14: ['I', 'think', 'we', 'rather', 'drive', 'back', 'at', 'thirty-three', 'past', 'nine', 'then', 'we', 'will', 'arrive', 'at', 'Hamburg', 'at', 'fifty-two', 'past', 'ten', '.']\n",
            "PRED 14: فکر میکنم ما باید به دفتر نبود اما نیم ساعت ده و نیم در منزل Cologne-Bonn .\n",
            "PRED SCORE: -7.6470\n",
            "\n",
            "SENT 15: ['fine', 'and', \"don't\", 'forget', 'your', 'swimming', 'stuff', ',', 'maybe', 'we', 'can', 'go', 'swimming', 'together', '.']\n",
            "PRED 15: \n",
            "PRED SCORE: -3.5973\n",
            "\n",
            "SENT 16: ['yes', '.', 'when', 'and', 'where', 'do', 'we', 'want', 'to', 'meet', '?']\n",
            "PRED 16: بله ، یا کجا باید ملاقات داشته باشیم ؟\n",
            "PRED SCORE: -0.8137\n",
            "\n",
            "SENT 17: ['I', 'prefer', 'the', 'plane', '.']\n",
            "PRED 17: من شخص شلوغی را دارم .\n",
            "PRED SCORE: -3.2095\n",
            "\n",
            "SENT 18: ['a', 'good', 'idea', '.', 'then', 'we', 'will', 'meet', 'at', 'the', 'airport', 'tomorrow', '.']\n",
            "PRED 18: یک سوال خوبی . پس ساعت هشت یکدیگر را ملاقات خواهیم کرد .\n",
            "PRED SCORE: -3.0501\n",
            "\n",
            "SENT 19: ['no', 'idea', '.', 'we', 'will', 'see', '.', 'it', 'does', 'not', 'matter', '.']\n",
            "PRED 19: مهم نیست . ما همدیگر را حتما ببینیم .\n",
            "PRED SCORE: -3.1568\n",
            "\n",
            "SENT 20: ['good', '.', 'let', 'us', 'meet', 'at', 'nine', \"o'clock\", '.', 'hopefully', 'the', 'plane', \"won't\", 'be', 'hijacked', 'tomorrow', '.']\n",
            "PRED 20: خوب است . پس ساعت نه . ساعت نه همدیگر را ملاقات نمیکنیم .\n",
            "PRED SCORE: -5.2877\n",
            "\n",
            "SENT 21: ['I', 'have', 'already', 'booked', 'two', 'rooms', 'at', 'the', 'Gr\"unschnabel', '.']\n",
            "PRED 21: من قبلا دو دوروزه در درزن هستم .\n",
            "PRED SCORE: -2.3425\n",
            "\n",
            "SENT 22: ['what', 'did', 'you', 'say', '?']\n",
            "PRED 22: نظر شما چیست ؟\n",
            "PRED SCORE: -1.4680\n",
            "\n",
            "SENT 23: ['yes', '.', 'we', 'have', 'two', 'rooms', 'at', 'the', 'Gr\"unschnabel', '.', 'I', 'will', 'reserve', 'a', 'taxi', 'right', 'now', '.']\n",
            "PRED 23: بله . ما باید دو choices وجود دارد . من در هتل Luisenhof .\n",
            "PRED SCORE: -3.3361\n",
            "\n",
            "SENT 24: ['what', 'is', 'planned', 'for', 'the', 'evening', '?']\n",
            "PRED 24: آن روز برای شما چطور است ؟\n",
            "PRED SCORE: -1.4531\n",
            "\n",
            "SENT 25: ['a', 'good', 'idea', '.', 'I', 'have', 'heard', ',', 'Phantom', 'of', 'the', 'opera', 'is', 'supposed', 'to', 'be', 'played', '.']\n",
            "PRED 25: باعث خوشحالی است . من فکر میکنم ، برای ماشین Cristal میروم .\n",
            "PRED SCORE: -4.1502\n",
            "\n",
            "SENT 26: ['fine', '.', 'I', 'think', 'we', 'have', 'arranged', 'everything', '.', 'then', 'we', 'will', 'meet', 'tomorrow', '.']\n",
            "PRED 26: خوب است . من فکر میکنم ما باید به توافق برسیم .\n",
            "PRED SCORE: -1.1315\n",
            "\n",
            "SENT 27: ['hello', '.', 'we', 'have', 'to', 'talk', 'about', 'our', 'trip', 'to', 'Hanover', '.']\n",
            "PRED 27: سلام . ما باید درباره آن از حالا نتیجه­گیری کنیم .\n",
            "PRED SCORE: -2.7337\n",
            "\n",
            "SENT 28: ['right', '.', 'we', 'will', 'be', 'at', 'the', 'Expo', 'two', 'thousand', 'in', 'Hanover', 'on', 'the', 'fourth', 'and', 'fifth', 'of', 'September', '.']\n",
            "PRED 28: درست است . ما در هتل Luisenhof چهارم و پنجم سپتامبر در Hanover .\n",
            "PRED SCORE: -3.4192\n",
            "\n",
            "SENT 29: ['I', 'have', 'already', 'booked', 'a', 'flight', '.']\n",
            "PRED 29: من هم اکنون یک وقت ملاقات گذاشته­ام .\n",
            "PRED SCORE: -1.9200\n",
            "\n",
            "SENT 30: ['we', 'will', 'set', 'off', 'at', 'a', 'quarter', 'past', 'eight', 'and', 'arrive', 'at', 'Hanover', 'at', 'twelve', \"o'clock\", '.']\n",
            "PRED 30: ما حدود ساعت هشت و نیم و پس فردا وجود دارد .\n",
            "PRED SCORE: -5.0123\n",
            "\n",
            "SENT 31: ['we', 'will', 'have', 'to', 'meet', 'at', 'the', 'airport', 'at', 'seven', \"o'clock\", '.']\n",
            "PRED 31: من باید ساعت هفت بعدازظهر در دفتر شما ملاقات داشته باشیم .\n",
            "PRED SCORE: -1.4424\n",
            "\n",
            "SENT 32: ['we', 'arrive', 'at', 'Hanover', 'at', 'twelve', \"o'clock\", 'midday', '.']\n",
            "PRED 32: ما flew ساعت دوازده بعدازظهر .\n",
            "PRED SCORE: -2.0062\n",
            "\n",
            "SENT 33: ['fine', '.', 'which', 'hotel', 'do', 'you', 'have', 'in', 'mind', '?']\n",
            "PRED 33: خوب است . آیا شما در هتل looked ؟\n",
            "PRED SCORE: -2.1994\n",
            "\n",
            "SENT 34: ['the', 'Intercontinental', 'is', 'my', 'favourite', 'hotel', 'in', 'Hanover', '.']\n",
            "PRED 34: Marriott من در هتل پارک Hanover .\n",
            "PRED SCORE: -2.2233\n",
            "\n",
            "SENT 35: ['thank', 'you', '.', 'how', 'do', 'we', 'go', 'back', 'again', 'to', 'Hamburg', '?']\n",
            "PRED 35: متشکرم . حالتان چطور است ؟\n",
            "PRED SCORE: -3.0178\n",
            "\n",
            "SENT 36: ['we', 'will', 'go', 'back', 'by', 'train', 'on', 'the', 'fifth', 'of', 'September', '.']\n",
            "PRED 36: ما پنجم سپتامبر به زودی میرویم .\n",
            "PRED SCORE: -1.7456\n",
            "\n",
            "SENT 37: ['the', 'best', 'thing', 'is', 'we', 'meet', 'at', 'the', 'train', 'station', 'at', 'eight', \"o'clock\", '.']\n",
            "PRED 37: آیا ما باید ساعت هشت ساعت هشت همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -2.1233\n",
            "\n",
            "SENT 38: ['exactly', '.', 'the', 'train', 'leaves', 'Hanover', 'at', 'six', 'minutes', 'after', 'eight', '.']\n",
            "PRED 38: آیا Hanover . Hanover Hanover شش تا شش بعد از آن .\n",
            "PRED SCORE: -2.5170\n",
            "\n",
            "SENT 39: ['we', 'leave', 'Hanover', 'at', 'eight', \"o'clock\", 'and', 'arrive', 'at', 'Hamburg', 'at', 'half', 'past', 'nine', '.']\n",
            "PRED 39: ما هشت و نیم ساعت هشت و نیم در خانه Cologne-Bonn .\n",
            "PRED SCORE: -1.5255\n",
            "\n",
            "SENT 40: ['goodbye', '.']\n",
            "PRED 40: خداحافظ .\n",
            "PRED SCORE: -0.2111\n",
            "\n",
            "SENT 41: ['I', 'would', 'prefer', 'to', 'fly', '.']\n",
            "PRED 41: من ترجیح میدهم که\n",
            "PRED SCORE: -0.9852\n",
            "\n",
            "SENT 42: ['yes', ',', 'there', 'is', 'a', 'flight', 'at', 'a', 'quarter', 'past', 'nine', '.']\n",
            "PRED 42: بله , یک ربع بعد از نه ساعت نه .\n",
            "PRED SCORE: -2.2107\n",
            "\n",
            "SENT 43: ['the', 'plane', 'arrives', 'in', 'Hanover', 'at', 'twenty-five', 'past', 'twelve', '.']\n",
            "PRED 43: آن به کار نزدیک در فرودگاه ساعت دوازده و نیم .\n",
            "PRED SCORE: -4.5316\n",
            "\n",
            "SENT 44: ['I', 'did', 'not', 'understand', ',', 'what', 'you', 'said', 'about', 'the', 'hotel', '.']\n",
            "PRED 44: نمیدانم تا چه حد مایل هستید .\n",
            "PRED SCORE: -1.2498\n",
            "\n",
            "SENT 45: ['yes', ',', 'would', 'you', 'please', 'book', 'two', 'rooms', '.']\n",
            "PRED 45: بله ، آیا شما دو تاریخ میکنید .\n",
            "PRED SCORE: -1.9754\n",
            "\n",
            "SENT 46: ['the', 'single', 'room', 'costs', 'a', 'hundred', 'Deutsch-marks', '.', 'did', 'I', 'understand', 'you', 'right', '?']\n",
            "PRED 46: Schlosshotel یک اتاق دویست sixty-three marks . آن برای شما مناسب است ؟\n",
            "PRED SCORE: -5.1805\n",
            "\n",
            "SENT 47: ['where', 'is', 'this', 'hotel', '?']\n",
            "PRED 47: کجا این است ؟\n",
            "PRED SCORE: -0.2797\n",
            "\n",
            "SENT 48: ['when', 'do', 'we', 'meet', '?']\n",
            "PRED 48: چه زمانی میتوانیم ملاقات کنیم ؟\n",
            "PRED SCORE: -0.1518\n",
            "\n",
            "SENT 49: ['yes', ',', 'would', 'you', 'please', 'book', 'this', 'hotel', '.']\n",
            "PRED 49: بله ، آیا شما درباره آن مواظب میشوم .\n",
            "PRED SCORE: -1.1657\n",
            "\n",
            "SENT 50: ['please', 'repeat', 'this', 'once', 'again', '.']\n",
            "PRED 50: دوباره این را دوباره لطفا .\n",
            "PRED SCORE: -2.5777\n",
            "\n",
            "SENT 51: ['do', 'you', 'mean', 'you', 'always', 'stay', 'there', '?']\n",
            "PRED 51: آیا شما هنوز قبلا don't ؟\n",
            "PRED SCORE: -2.1993\n",
            "\n",
            "SENT 52: ['fine', ',', 'would', 'you', 'like', 'to', 'do', 'something', 'in', 'the', 'evening', '?']\n",
            "PRED 52: خوب است ، آیا شما میخواهید چیزی در عصر ؟\n",
            "PRED SCORE: -0.7385\n",
            "\n",
            "SENT 53: ['unfortunately', 'I', 'did', 'not', 'understand', 'you', '.', 'would', 'you', 'like', 'to', 'go', 'to', 'the', 'cinema', '?']\n",
            "PRED 53: متاسفانه نمیدانم . شما میخواهید درباره آن با من خودتان را بکنید ؟\n",
            "PRED SCORE: -4.4025\n",
            "\n",
            "SENT 54: ['would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'afterwards', '?']\n",
            "PRED 54: آیا میخواهید برای پس از آن به رستوران بروید ؟\n",
            "PRED SCORE: -2.9262\n",
            "\n",
            "SENT 55: ['we', 'still', 'have', 'to', 'plan', 'our', 'return', 'trip', '.']\n",
            "PRED 55: ما هنوز باید برای سفر تجاریمان مقدمات را تهیه کنیم .\n",
            "PRED SCORE: -0.8900\n",
            "\n",
            "SENT 56: ['when', 'do', 'we', 'want', 'to', 'travel', 'back', 'to', 'Hamburg', '?']\n",
            "PRED 56: چه‌زمانی ما باید به Hanover تا حدی ؟\n",
            "PRED SCORE: -1.2422\n",
            "\n",
            "SENT 57: ['could', 'you', 'repeat', 'that', 'once', 'again', 'please', '?']\n",
            "PRED 57: میتوانید دوباره آن را هجی کنید ؟\n",
            "PRED SCORE: -1.8805\n",
            "\n",
            "SENT 58: ['yes', ',', 'I', 'agree', '.', 'should', 'we', 'also', 'fly', 'back', 'or', 'go', 'by', 'train', '?']\n",
            "PRED 58: بله ، من گمان میکنم که ما باید آن را در Hanover . یا Hanover ؟\n",
            "PRED SCORE: -3.6626\n",
            "\n",
            "SENT 59: ['there', 'is', 'a', 'flight', 'leaving', 'Hanover', 'at', 'a', 'quarter', 'past', 'seven', '$P-$M', '.']\n",
            "PRED 59: یک آنجا Hanover چهار و ربع بعد از ظهر .\n",
            "PRED SCORE: -1.3916\n",
            "\n",
            "SENT 60: ['fine', ',', 'shall', 'I', 'book', 'this', 'flight', '?']\n",
            "PRED 60: خوب است ، من این را یادداشت میکنم ؟\n",
            "PRED SCORE: -2.6258\n",
            "\n",
            "SENT 61: ['goodbye', '.']\n",
            "PRED 61: خداحافظ .\n",
            "PRED SCORE: -0.2111\n",
            "\n",
            "SENT 62: ['no', ',', 'we', 'go', 'on', 'the', 'twenty-third', '.']\n",
            "PRED 62: نه ، ما در منییم .\n",
            "PRED SCORE: -0.2813\n",
            "\n",
            "SENT 63: ['no', ',', 'I', 'suggest', 'to', 'take', 'the', 'train', 'in', 'the', 'morning', '.']\n",
            "PRED 63: نه ، من پیشنهاد میکنم که صبح شروع کنیم .\n",
            "PRED SCORE: -0.3818\n",
            "\n",
            "SENT 64: ['six', \"o'clock\", 'is', 'too', 'early', ',', 'I', 'propose', 'to', 'take', 'the', 'train', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', '.']\n",
            "PRED 64: ساعت شش خیلی زود است ، من پیشنهاد میکنم ساعت ده صبح تا ساعت ده .\n",
            "PRED SCORE: -1.8438\n",
            "\n",
            "SENT 65: ['do', 'you', 'agree', '?']\n",
            "PRED 65: موافق هستید ؟\n",
            "PRED SCORE: -0.6268\n",
            "\n",
            "SENT 66: ['I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 66: من با آن موافقم .\n",
            "PRED SCORE: -0.9914\n",
            "\n",
            "SENT 67: ['I', 'did', 'not', 'understand', 'that', 'again', '.']\n",
            "PRED 67: دوباره من نفهمیدم .\n",
            "PRED SCORE: -2.6073\n",
            "\n",
            "SENT 68: ['I', 'still', 'have', 'not', 'understood', 'anything', '.']\n",
            "PRED 68: من به هیج غیرمنتظره مشکلی ندارم .\n",
            "PRED SCORE: -2.4578\n",
            "\n",
            "SENT 69: ['I', 'suggest', 'to', 'stay', 'at', 'the', 'hotel', 'Gr\"unschnabel', 'in', 'Hanover', '.']\n",
            "PRED 69: من پیشنهاد میکنم که در هتل در Hanover .\n",
            "PRED SCORE: -0.4681\n",
            "\n",
            "SENT 70: ['yes', 'please', '.']\n",
            "PRED 70: بله حتما .\n",
            "PRED SCORE: -0.5335\n",
            "\n",
            "SENT 71: ['so', 'shall', 'we', 'take', 'the', 'hotel', 'Gr\"unschnabel', '?']\n",
            "PRED 71: پس ما باید در هتل پارک ؟\n",
            "PRED SCORE: -1.2233\n",
            "\n",
            "SENT 72: ['well', 'once', 'again', ',', 'should', 'we', 'stay', 'at', 'the', 'hotel', 'Gr\"unschnabel', '?']\n",
            "PRED 72: خب باز خب ، ما باید در هتل آلمان ؟\n",
            "PRED SCORE: -2.9125\n",
            "\n",
            "SENT 73: ['once', 'again', ',', 'shall', 'we', 'stay', 'at', 'the', 'hotel', 'Gr\"unschnabel', '?']\n",
            "PRED 73: در صورت دنی ، آیا ما در پیتسبرگ ؟\n",
            "PRED SCORE: -2.8693\n",
            "\n",
            "SENT 74: ['yes', ',', 'that', 'is', 'a', 'good', 'idea', '.']\n",
            "PRED 74: بله ، ایده خوبی است .\n",
            "PRED SCORE: -0.0091\n",
            "\n",
            "SENT 75: ['I', 'did', 'not', 'understand', 'that', ',', 'I', 'suggest', 'to', 'go', 'back', 'to', 'Hamburg', 'on', 'the', 'twenty-fourth', 'in', 'the', 'evening', '.']\n",
            "PRED 75: من مایل هستم ، شاید من به زودی در دفترم در بعدازظهر برویم .\n",
            "PRED SCORE: -5.0460\n",
            "\n",
            "SENT 76: ['yes', 'I', 'agree', ',', 'I', 'propose', 'to', 'take', 'the', 'train', 'again', '.']\n",
            "PRED 76: بله ، من فکر میکنم از Hanover تا آن‌موقع .\n",
            "PRED SCORE: -3.6575\n",
            "\n",
            "SENT 77: ['I', 'agree', ',', 'everything', 'okay', '?']\n",
            "PRED 77: من don't don't ، don't ؟\n",
            "PRED SCORE: -1.7818\n",
            "\n",
            "SENT 78: ['hello', '.', 'should', 'we', 'plan', 'our', 'journey', 'to', 'the', 'Expo', 'on', 'October', 'the', 'ninth', '?']\n",
            "PRED 78: سلام . آیا ما باید سعی کنیم تا نگرانی را برای نهم اکتبر نگهداریم ؟\n",
            "PRED SCORE: -4.4728\n",
            "\n",
            "SENT 79: ['I', 'would', 'prefer', 'to', 'take', 'the', 'train', '.']\n",
            "PRED 79: من ترجیح میدهم که از آن .\n",
            "PRED SCORE: -1.8085\n",
            "\n",
            "SENT 80: ['we', 'could', 'leave', 'Hamburg', 'at', 'twenty-four', 'past', 'seven', 'and', 'we', 'would', 'be', 'in', 'Hanover', 'at', 'thirty-nine', 'past', 'eight', '.']\n",
            "PRED 80: ما میتوانیم بیرون ساعت هفت و نیم در دفتر branch ساعت هفت و سپس ما در Hanover .\n",
            "PRED SCORE: -6.8578\n",
            "\n",
            "SENT 81: ['fine', '.', 'and', 'where', 'at', 'the', 'station', '?']\n",
            "PRED 81: باشه . و در هتل اصلی\n",
            "PRED SCORE: -0.3370\n",
            "\n",
            "SENT 82: ['do', 'you', 'also', 'want', 'to', 'reserve', 'seats', 'for', 'us', '?']\n",
            "PRED 82: آیا شما هم میخواهم برای خودتان را هم ؟\n",
            "PRED SCORE: -2.1594\n",
            "\n",
            "SENT 83: ['are', 'the', 'single', 'rooms', 'cheap', 'there', '?']\n",
            "PRED 83: آیا cheapest منطقی هستند ؟\n",
            "PRED SCORE: -3.4397\n",
            "\n",
            "SENT 84: ['three', 'hundred', 'deutschmarks', 'is', 'a', 'bit', 'expensive', '.', \"isn't\", 'there', 'anything', 'cheaper', '?']\n",
            "PRED 84: سه یک کدام cheaper central . یک cheaper دارد ؟\n",
            "PRED SCORE: -5.0998\n",
            "\n",
            "SENT 85: ['are', 'there', 'single', 'rooms', 'for', 'eighty', 'Deutsch-marks', '?']\n",
            "PRED 85: آیا آنها باهم برای یک اتاق تنها ؟\n",
            "PRED SCORE: -2.1159\n",
            "\n",
            "SENT 86: ['fine', '.', 'but', 'at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'now', '?']\n",
            "PRED 86: بسیار خوب . ولی شما\n",
            "PRED SCORE: -2.3469\n",
            "\n",
            "SENT 87: ['where', 'is', 'our', 'hotel', 'and', 'what', 'is', 'its', 'name', '?']\n",
            "PRED 87: کجا نگاهی هستیم در اتلینگن ؟\n",
            "PRED SCORE: -3.8337\n",
            "\n",
            "SENT 88: ['at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'for', 'us', 'and', 'where', 'is', 'the', 'hotel', '?']\n",
            "PRED 88: در‌هر‌حالت آیا شما میخواهید که ما میتوانیم در هتل یا چیزی شبیه آن ؟\n",
            "PRED SCORE: -5.0888\n",
            "\n",
            "SENT 89: ['would', 'you', 'repeat', 'the', 'hotel', 'name', 'then', ',', 'please', '?']\n",
            "PRED 89: آیا شما موافقی ، لطفا ؟\n",
            "PRED SCORE: -1.7676\n",
            "\n",
            "SENT 90: ['what', 'is', 'the', 'name', 'of', 'our', 'hotel', '?']\n",
            "PRED 90: آن درباره آنچه است ؟\n",
            "PRED SCORE: -2.5070\n",
            "\n",
            "SENT 91: ['in', 'the', 'evening', 'I', 'would', 'like', 'to', 'relax', 'and', 'maybe', 'go', 'to', 'the', 'sauna', '.', 'what', 'do', 'you', 'think', '?']\n",
            "PRED 91: با قطار و شاید شما میخواهید تا اینجا را به افرادم اطلاع‌ میدهم . چه زمانی برای شما مناسب است ؟\n",
            "PRED SCORE: -5.5465\n",
            "\n",
            "SENT 92: ['okay', '.', 'the', 'program', 'of', 'the', 'evening', 'we', 'can', 'plan', 'later', 'on', '.']\n",
            "PRED 92: باشه . آیا همانی که ما میتوانیم در غروب ؟\n",
            "PRED SCORE: -2.6700\n",
            "\n",
            "SENT 93: ['I', 'would', 'like', 'to', 'take', 'the', 'train', 'at', 'eighteen', 'past', 'nine', '$P-$M', '.', 'is', 'that', 'okay', 'for', 'you', '?']\n",
            "PRED 93: من میخواهم حدود ساعت نه و سی دقیقه . آن برای شما خوب است ؟\n",
            "PRED SCORE: -3.1368\n",
            "\n",
            "SENT 94: ['fine', '.', 'see', 'you', 'later', 'then', '.']\n",
            "PRED 94: بسیار خوب . پس شما را میبینم .\n",
            "PRED SCORE: -0.7315\n",
            "\n",
            "SENT 95: ['fine', '.', 'at', 'what', 'time', 'would', 'you', 'like', 'to', 'leave', '?']\n",
            "PRED 95: خوب . اگر شما چه تاریخی را پیشنهاد میکنید ؟\n",
            "PRED SCORE: -1.2716\n",
            "\n",
            "SENT 96: ['I', 'would', 'prefer', 'the', 'train', '.']\n",
            "PRED 96: من ترجیح میدهم .\n",
            "PRED SCORE: -1.3504\n",
            "\n",
            "SENT 97: ['that', 'is', 'okay', '.', 'should', 'we', 'meet', 'at', 'the', 'station', 'at', 'eight', \"o'clock\", 'then', '?']\n",
            "PRED 97: خوب است . پس شما را ساعت هشت ملاقات کنیم ؟\n",
            "PRED SCORE: -3.8210\n",
            "\n",
            "SENT 98: ['okay', '.', 'do', 'you', 'want', 'me', 'to', 'reserve', 'a', 'hotel', 'for', 'us', '?']\n",
            "PRED 98: بسیار خوب . آیا شما برنامه شما برای یک وعده ؟\n",
            "PRED SCORE: -1.0764\n",
            "\n",
            "SENT 99: ['I', 'would', 'suggest', 'the', 'Stadthotel', ',', 'because', 'it', 'is', 'the', 'cheapest', 'one', '.']\n",
            "PRED 99: من پیشنهاد میکنم ، چون آن یک رستوران است .\n",
            "PRED SCORE: -2.7425\n",
            "\n",
            "SENT 100: ['the', 'Stadthotel', '.']\n",
            "PRED 100: البته .\n",
            "PRED SCORE: -0.8183\n",
            "\n",
            "SENT 101: ['would', 'you', 'like', 'a', 'single', 'room', 'or', 'a', 'double', 'room', '?']\n",
            "PRED 101: آیا شما تا یک و نیم را ترجیح میدهید ؟\n",
            "PRED SCORE: -1.8873\n",
            "\n",
            "SENT 102: ['okay', '.', 'should', 'we', 'go', 'to', 'the', 'hotel', 'by', 'taxi', 'immediately', '?']\n",
            "PRED 102: باشه . آیا ما باید wouldn't ماشین شرکت ؟\n",
            "PRED SCORE: -2.0257\n",
            "\n",
            "SENT 103: ['would', 'you', 'like', 'to', 'do', 'something', 'in', 'the', 'evening', '?']\n",
            "PRED 103: آیا شما میخواهید عصر باشد ؟\n",
            "PRED SCORE: -1.1846\n",
            "\n",
            "SENT 104: ['fine', '.', 'I', 'agree', 'with', 'that', '.']\n",
            "PRED 104: خوب است . من با آن موافقم .\n",
            "PRED SCORE: -0.0322\n",
            "\n",
            "SENT 105: ['could', 'you', 'find', 'out', 'a', 'train', 'connection', 'for', 'Wednesday', 'evening', '?']\n",
            "PRED 105: آیا شما میتوانی تا یک چهارشنبه عصر به بعد ؟\n",
            "PRED SCORE: -2.5101\n",
            "\n",
            "SENT 106: ['sorry', '.', 'when', 'will', 'we', 'arrive', 'at', 'Hamburg', '?']\n",
            "PRED 106: متاسفم . چه hotels Hanover ؟\n",
            "PRED SCORE: -1.6891\n",
            "\n",
            "SENT 107: ['that', 'is', 'okay', '.', 'then', 'we', 'can', 'go', 'back', 'by', 'taxi', '.']\n",
            "PRED 107: خوب است . پس ما میتوانیم به آنجا برویم .\n",
            "PRED SCORE: -0.9762\n",
            "\n",
            "SENT 108: ['okay', '.', 'goodbye', '.']\n",
            "PRED 108: خداحافظ .\n",
            "PRED SCORE: -0.5133\n",
            "\n",
            "SENT 109: ['hello', '.', 'I', 'call', 'you', 'to', 'plan', 'the', 'journey', 'to', 'Hanover', 'with', 'you', '.']\n",
            "PRED 109: سلام . میخواستم با شما تماس گرفتم تا برای بررسی عملی­مان صحبت کنم .\n",
            "PRED SCORE: -3.4515\n",
            "\n",
            "SENT 110: ['yes', ',', 'I', 'would', 'like', 'to', 'leave', 'on', 'Wednesday', 'the', 'twenty-sixth', 'of', 'January', '.']\n",
            "PRED 110: بله ، دوست دارم چهارشنبه سیزدهم ژانویه را بزنم .\n",
            "PRED SCORE: -3.5007\n",
            "\n",
            "SENT 111: ['I', 'prefer', 'the', 'plane', '.']\n",
            "PRED 111: من شخص شلوغی را دارم .\n",
            "PRED SCORE: -3.2095\n",
            "\n",
            "SENT 112: ['fine', '.', 'at', 'what', 'time', 'should', 'we', 'leave', '?']\n",
            "PRED 112: خوب است . چه ساعتی را باید ما ؟\n",
            "PRED SCORE: -0.2293\n",
            "\n",
            "SENT 113: ['I', 'propose', 'to', 'leave', 'at', 'nine', \"o'clock\", 'in', 'the', 'morning', '.']\n",
            "PRED 113: من ساعت نه صبح را پیشنهاد میکنم .\n",
            "PRED SCORE: -0.9441\n",
            "\n",
            "SENT 114: ['where', 'should', 'we', 'meet', '?']\n",
            "PRED 114: کجا باید همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -0.1529\n",
            "\n",
            "SENT 115: ['at', 'which', 'office', 'please', '?']\n",
            "PRED 115: دفتر شما چیست ؟\n",
            "PRED SCORE: -0.2323\n",
            "\n",
            "SENT 116: ['fine', '.', 'do', 'you', 'want', 'me', 'to', 'reserve', 'a', 'hotel', 'for', 'us', '?']\n",
            "PRED 116: خوب . آیا شما برنامه شما برای یک\n",
            "PRED SCORE: -3.1392\n",
            "\n",
            "SENT 117: ['the', 'hotel', 'is', 'called', 'Prinzenhof', 'and', 'it', 'is', 'in', 'the', 'city', 'center', '.']\n",
            "PRED 117: آن باعث میگوید که آن در هتل Georgengarten است .\n",
            "PRED SCORE: -4.0393\n",
            "\n",
            "SENT 118: ['do', 'you', 'agree', 'on', 'a', 'double', 'room', '?']\n",
            "PRED 118: آیا شما راجع به یک اتاق دویست صحبت میکنید ؟\n",
            "PRED SCORE: -1.9127\n",
            "\n",
            "SENT 119: ['great', '.', 'I', 'will', 'reserve', 'two', 'single', 'rooms', '.']\n",
            "PRED 119: عالی است . من دو تا دو را رزرو میکنم .\n",
            "PRED SCORE: -2.2721\n",
            "\n",
            "SENT 120: ['would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '?']\n",
            "PRED 120: میخواهیم برای یک فنجان قهوه در عصر ؟\n",
            "PRED SCORE: -1.9960\n",
            "\n",
            "SENT 121: ['fine', '.', 'I', 'will', 'choose', 'a', 'restaurant', '.']\n",
            "PRED 121: خوب است . من یک نقشه‌ی را انتخاب کنم .\n",
            "PRED SCORE: -1.4794\n",
            "\n",
            "SENT 122: ['I', 'would', 'like', 'to', 'leave', 'on', 'Thursday', 'afternoon', '.']\n",
            "PRED 122: من دارم پنجشنبه بعدازظهر .\n",
            "PRED SCORE: -1.9882\n",
            "\n",
            "SENT 123: ['yes', ',', 'I', 'agree', 'with', 'that', '.']\n",
            "PRED 123: بله ، با آن موافقم .\n",
            "PRED SCORE: -0.0040\n",
            "\n",
            "SENT 124: ['yes', ',', 'I', 'agree', 'that', 'we', 'leave', 'at', 'five', \"o'clock\", '.']\n",
            "PRED 124: بله ، فکر میکنم ساعت پنج طول میکشد .\n",
            "PRED SCORE: -1.8550\n",
            "\n",
            "SENT 125: ['I', 'think', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 125: فکر میکنم خیلی زودتر میتوانیم راجع به آن صحبت کنیم .\n",
            "PRED SCORE: -3.4526\n",
            "\n",
            "SENT 126: ['should', 'we', 'meet', 'at', 'the', 'Expo', 'in', 'Hanover', 'in', 'June', '?']\n",
            "PRED 126: آیا ما میتوانیم در Hanover در Hanover ژوئن ؟\n",
            "PRED SCORE: -2.3963\n",
            "\n",
            "SENT 127: ['yes', ',', 'I', 'thought', ',', 'we', 'would', 'go', 'to', 'Hanover', 'on', 'the', 'ninth', 'and', 'tenth', 'of', 'June', '.']\n",
            "PRED 127: بله ، من فکر میکنم ، ما به Hanover در نهم و دهم ژوئن .\n",
            "PRED SCORE: -1.3474\n",
            "\n",
            "SENT 128: ['yes', ',', 'I', 'have', 'got', 'a', 'timetable', '.', 'when', 'would', 'you', 'like', 'to', 'go', '?']\n",
            "PRED 128: بله ، من یک برنامه را دارم . چه چیزی است که شما میخواهید ؟\n",
            "PRED SCORE: -3.6200\n",
            "\n",
            "SENT 129: ['\"ahm', 'there', 'is', 'a', 'train', 'leaving', 'Hamburg', 'at', 'twenty-four', 'past', 'ten', '.', 'it', 'arrives', 'at', 'Hanover', 'at', 'thirty-nine', 'past', 'eleven', '.']\n",
            "PRED 129: اوم یک تا حد express express express ساعت ده . در دفتر branch .\n",
            "PRED SCORE: -5.6621\n",
            "\n",
            "SENT 130: ['I', 'agree', '.', 'then', 'we', 'could', 'have', 'breakfast', 'together', '.']\n",
            "PRED 130: موافقم . ما میتوانیم شنبه برای ناهار قرار بگذاریم .\n",
            "PRED SCORE: -1.5423\n",
            "\n",
            "SENT 131: ['I', 'agree', '.', 'we', 'need', 'a', 'hotel', 'in', 'Hanover', '.']\n",
            "PRED 131: من نیاز دارم . در هتل Hanover .\n",
            "PRED SCORE: -3.0985\n",
            "\n",
            "SENT 132: ['unfortunately', 'I', 'did', 'not', 'understand', 'you', '.']\n",
            "PRED 132: متاسفانه شما را نمیفهمم .\n",
            "PRED SCORE: -1.6661\n",
            "\n",
            "SENT 133: ['in', 'May', 'on', 'the', 'eighteenth', 'and', 'nineteenth', 'of', 'May', 'we', 'are', 'going', 'together', 'to', 'Hanover', '.']\n",
            "PRED 133: در می هجدهم می و برداشتیم می می به بعد .\n",
            "PRED SCORE: -3.6632\n",
            "\n",
            "SENT 134: ['I', 'would', 'like', 'to', '\"ahm', 'go', 'by', 'plane', '.', 'do', 'you', 'have', 'a', 'plan', '?']\n",
            "PRED 134: من میخواهم آن را جای بدهم . آیا شما یک هیچگونه مایل هستید ؟\n",
            "PRED SCORE: -3.0234\n",
            "\n",
            "SENT 135: ['I', 'would', 'like', 'to', 'fly', 'and', 'to', 'be', 'in', 'Hanover', 'at', 'about', 'ten', \"o'clock\", '.']\n",
            "PRED 135: من میخواهم مراقب رزرواسیون هستم که در Hanover ساعت ده .\n",
            "PRED SCORE: -2.4773\n",
            "\n",
            "SENT 136: ['where', 'should', 'we', 'meet', '?']\n",
            "PRED 136: کجا باید همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -0.1529\n",
            "\n",
            "SENT 137: ['should', 'we', 'meet', 'at', 'the', 'meeting', 'point', 'at', 'the', 'airport', '?']\n",
            "PRED 137: آیا باید در یام وک ملاقات کنیم ؟\n",
            "PRED SCORE: -2.1389\n",
            "\n",
            "SENT 138: ['would', 'you', 'please', 'repeat', 'that', 'once', 'again', '?']\n",
            "PRED 138: آیا شما دوباره موافق هستید ؟\n",
            "PRED SCORE: -0.7663\n",
            "\n",
            "SENT 139: ['I', 'agree', '.', 'how', 'can', 'I', 'recognize', 'you', '?']\n",
            "PRED 139: موافق هستم . شما را میبینم ؟\n",
            "PRED SCORE: -1.1846\n",
            "\n",
            "SENT 140: ['well', ',', 'when', 'would', 'you', 'like', 'to', 'fly', 'back', '?']\n",
            "PRED 140: خب ، آیا شما میخواهید که زود ؟\n",
            "PRED SCORE: -2.7105\n",
            "\n",
            "SENT 141: ['I', 'agree', '.', 'when', 'exactly', 'does', 'the', 'plane', 'take', 'off', '?']\n",
            "PRED 141: من نمیدانم . آیا شما هیچ نرخی ؟\n",
            "PRED SCORE: -2.0914\n",
            "\n",
            "SENT 142: ['please', 'repeat', 'that', 'once', 'again', '.']\n",
            "PRED 142: لطفا دوباره با آن تماس گرفتم .\n",
            "PRED SCORE: -1.7832\n",
            "\n",
            "SENT 143: ['that', 'sounds', 'great', '.', '\"ahm', ',', 'fine', ',', 'you', 'arrange', 'the', 'flight', '.']\n",
            "PRED 143: خوب به نظر میرسد . ام ، اوه تو زمانی را در نظر دارید .\n",
            "PRED SCORE: -3.0113\n",
            "\n",
            "SENT 144: ['do', 'you', 'want', 'me', 'to', '\"ah', 'book', 'the', 'hotel', '?', 'do', 'you', 'have', 'any', 'preferences', '?']\n",
            "PRED 144: شما میخواهید در نظر دارید علاقمندم در آن کار دارید ؟\n",
            "PRED SCORE: -4.5117\n",
            "\n",
            "SENT 145: ['a', 'single', 'room', 'and', 'it', 'is', 'important', 'for', 'you', 'to', 'have', 'a', 'bar', '.']\n",
            "PRED 145: یک sauna یک اتاق دویست و یک marks برای من مناسب است .\n",
            "PRED SCORE: -3.4918\n",
            "\n",
            "SENT 146: ['I', 'think', 'there', 'is', 'a', 'TV', 'in', 'all', 'the', 'hotels', '.']\n",
            "PRED 146: من فکر میکنم که در downtown خارج از کشور هستم .\n",
            "PRED SCORE: -2.1452\n",
            "\n",
            "SENT 147: ['there', 'is', 'a', 'hotel', 'near', 'the', 'fairground', ',', 'but', 'it', 'is', 'very', 'expensive', '.']\n",
            "PRED 147: هتل Luisenhof ، در هتل Luisenhof ، این\n",
            "PRED SCORE: -4.1953\n",
            "\n",
            "SENT 148: ['I', 'agree', '.', 'a', 'single', 'room', 'costs', 'three', 'hundred', 'Deutsch-marks', 'a', 'night', '.']\n",
            "PRED 148: من آنجا . یک اتاق دویست fifty سه قرار ملاقات داریم .\n",
            "PRED SCORE: -2.4167\n",
            "\n",
            "SENT 149: ['okay', '.', 'I', 'book', 'the', 'hotel', '.']\n",
            "PRED 149: باشه . من آنجا خواهم بود .\n",
            "PRED SCORE: -0.7625\n",
            "\n",
            "SENT 150: ['\"ahm', 'should', 'we', 'meet', 'on', 'May', 'the', 'eighteenth', 'in', 'the', 'evening', '?']\n",
            "PRED 150: آیا ما باید آن را در هجدهم می در بعدازظهر ملاقات کنیم ؟\n",
            "PRED SCORE: -2.6086\n",
            "\n",
            "SENT 151: ['okay', '.', 'should', 'we', 'meet', 'at', 'the', 'hotel', 'at', 'half', 'past', 'seven', '?']\n",
            "PRED 151: باشه . آیا ما باید ساعت هفت و نیم ملاقات داشته باشیم ؟\n",
            "PRED SCORE: -1.2754\n",
            "\n",
            "SENT 152: ['fine', '.', 'we', 'still', 'have', 'to', 'arrange', 'the', 'ride', 'from', 'the', 'airport', 'to', 'the', 'hotel', '.']\n",
            "PRED 152: خوب است . ما هنوز باید برای سخنرانی از Hanover تا Minnesota .\n",
            "PRED SCORE: -2.1013\n",
            "\n",
            "SENT 153: ['I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 153: من با آن موافقم .\n",
            "PRED SCORE: -0.9914\n",
            "\n",
            "SENT 154: ['I', 'suggest', 'we', 'take', 'the', 'subway', 'to', 'the', 'hotel', '.']\n",
            "PRED 154: من باید به دفتر شما را ببینم .\n",
            "PRED SCORE: -2.4055\n",
            "\n",
            "SENT 155: ['the', 'subway', 'takes', 'about', 'twenty', 'minutes', 'to', 'the', 'station', '.']\n",
            "PRED 155: چهل و هشتم از ایستگاه اصلی قطار .\n",
            "PRED SCORE: -4.4819\n",
            "\n",
            "SENT 156: ['I', 'agree', '.', 'then', 'we', 'have', 'to', 'have', 'dinner', 'earlier', '.']\n",
            "PRED 156: من نمیدانم . ما باید برای ناهار همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -2.5209\n",
            "\n",
            "SENT 157: ['yes', '.', 'is', 'everything', 'okay', 'so', 'far', 'then', '?']\n",
            "PRED 157: بله . پس هتل connection بود ؟\n",
            "PRED SCORE: -2.5496\n",
            "\n",
            "SENT 158: ['yes', ',', 'well', 'see', 'you', 'on', 'the', 'eighteenth', 'then', '.']\n",
            "PRED 158: بله ، خوب پس هجدهم شما را میبینم .\n",
            "PRED SCORE: -0.7738\n",
            "\n",
            "SENT 159: ['hello', '.', 'I', 'would', 'like', 'to', 'go', 'with', 'you', 'to', 'the', 'Expo', 'in', 'Hanover', '.']\n",
            "PRED 159: سلام . من مایل هستم با هم به Hanover ،\n",
            "PRED SCORE: -1.2350\n",
            "\n",
            "SENT 160: ['I', 'did', 'not', 'understand', 'that', '.', 'would', 'you', 'prefer', 'to', 'fly', 'or', 'to', 'drive', '?']\n",
            "PRED 160: من نمیدانم . آیا شما ترجیح میدهید یا شما میخواهید به یک movie ؟\n",
            "PRED SCORE: -2.2362\n",
            "\n",
            "SENT 161: ['I', 'would', 'like', 'to', 'be', 'in', 'Hanover', 'until', 'noon', ',', 'but', 'I', 'still', 'do', 'not', 'know', 'if', 'you', 'want', 'to', 'fly', 'or', 'to', 'drive', '.']\n",
            "PRED 161: من میخواهم تا ساعت شش پرواز باشم ، ولی من فکر نمیکنم میتوانم آنجا باشم .\n",
            "PRED SCORE: -4.9531\n",
            "\n",
            "SENT 162: ['that', 'sounds', 'very', 'good', '.', 'where', 'should', 'we', 'meet', '?']\n",
            "PRED 162: بنظر بدهید خوب است . کجا باید ملاقات کنیم ؟\n",
            "PRED SCORE: -1.9508\n",
            "\n",
            "SENT 163: ['yes', 'fine', '.', 'how', 'would', 'half', 'past', 'seven', 'suit', 'you', '?']\n",
            "PRED 163: بله . ساعت ده و سی دقیقه برای شما چطور است ؟\n",
            "PRED SCORE: -0.8417\n",
            "\n",
            "SENT 164: ['fine', '.', 'I', 'have', 'a', 'list', 'of', 'hotels', 'for', 'Hanover', '.']\n",
            "PRED 164: خوب است . من از قبل یک list hotels .\n",
            "PRED SCORE: -2.4892\n",
            "\n",
            "SENT 165: ['I', 'would', 'prefer', 'a', 'hotel', 'in', 'the', 'city', 'center', ',', 'then', 'we', 'can', 'do', 'something', 'in', 'the', 'evening', '.']\n",
            "PRED 165: من یک روز در آنجا را ترجیح میدهم ، پس ما میتوانیم آن را در عصر .\n",
            "PRED SCORE: -2.8508\n",
            "\n",
            "SENT 166: ['unfortunately', 'I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 166: متاسفانه من آن را مخالفتی ندارم .\n",
            "PRED SCORE: -1.0676\n",
            "\n",
            "SENT 167: ['I', 'could', 'not', 'understand', 'you', 'again', '.']\n",
            "PRED 167: دوباره نمیتوانم با شما ملاقات کنم .\n",
            "PRED SCORE: -2.5432\n",
            "\n",
            "SENT 168: ['fine', '.', 'then', 'I', 'propose', 'the', 'hotel', 'Prinzenhof', ',', 'that', 'is', 'situated', 'in', 'the', 'city', 'center', '.']\n",
            "PRED 168: خوب است . پس من پیشنهاد میکنم که ، آن shouldn't روز است .\n",
            "PRED SCORE: -4.0873\n",
            "\n",
            "SENT 169: ['did', 'you', 'understand', 'that', 'I', 'have', 'proposed', 'the', 'hotel', 'Prinzenhof', '?']\n",
            "PRED 169: درست است که شما در هتل looked ؟\n",
            "PRED SCORE: -2.6689\n",
            "\n",
            "SENT 170: ['fine', '.', 'I', 'will', 'book', 'two', 'single', 'rooms', 'for', 'two', 'hundred', 'Deutsch-marks', 'each', '.']\n",
            "PRED 170: خوب است . من دو روز برای اتاق جلسه دو روزه خواهم داشت .\n",
            "PRED SCORE: -2.8484\n",
            "\n",
            "SENT 171: ['do', 'you', 'know', 'a', 'restaurant', 'in', 'Hanover', '?', 'for', 'I', 'do', 'not', 'know', 'any', '.']\n",
            "PRED 171: آیا شما یک list express در شهر هستم که نمیدانم چه\n",
            "PRED SCORE: -5.3359\n",
            "\n",
            "SENT 172: ['I', 'would', 'really', 'like', 'to', 'have', 'Chinese', 'or', 'Japanese', 'food', ',', 'but', 'not', 'Italien', 'food', '.', 'is', 'that', 'possible', '?']\n",
            "PRED 172: من واقعا مایل هستم یا این را تا حد انجام داد ، اما نه ؟ آن ممکن نیست ؟\n",
            "PRED SCORE: -4.9043\n",
            "\n",
            "SENT 173: ['that', 'is', 'fine', '.', 'then', 'we', 'still', 'have', 'to', 'arrange', 'the', 'return', 'journey', '.', 'do', 'you', 'have', 'a', 'schedule', 'for', 'a', 'return', 'flight', '?']\n",
            "PRED 173: خوب است . برای ما مشکل است . چه زمانی را باید برای یک زمانی را برای یک ساعت ؟\n",
            "PRED SCORE: -5.5288\n",
            "\n",
            "SENT 174: ['I', 'have', 'to', 'be', 'back', 'in', 'Hamburg', 'on', 'Friday', 'at', 'three', \"o'clock\", '$P-$M', 'at', 'the', 'latest', '.']\n",
            "PRED 174: من باید ساعت سه بعد از ظهر جمعه در دفتر branch .\n",
            "PRED SCORE: -1.2750\n",
            "\n",
            "SENT 175: ['I', 'did', 'not', 'understand', 'when', 'the', 'plane', 'leaves', 'Hanover', 'and', 'when', 'it', 'is', 'supposed', 'to', 'arrive', 'at', 'Hamburg', '.']\n",
            "PRED 175: من نمیدانم شما چه زمانی وقت دارید و آن را تا ساعت شش و نیم طول میکشد .\n",
            "PRED SCORE: -6.5940\n",
            "\n",
            "SENT 176: ['I', 'did', 'not', 'understand', 'that', 'yet', '.']\n",
            "PRED 176: من هنوز نمیدانم .\n",
            "PRED SCORE: -0.6251\n",
            "\n",
            "SENT 177: ['that', 'is', 'fine', '.', 'when', 'does', 'the', 'plane', 'leave', 'Hanover', '?']\n",
            "PRED 177: خوب شد . آیا شما چه زمانی را ترک میکنید ؟\n",
            "PRED SCORE: -3.3622\n",
            "\n",
            "SENT 178: ['then', 'we', 'arrive', 'at', 'the', 'airport', 'in', 'Hamburg', 'again', '.', 'right', '?']\n",
            "PRED 178: پس ما در Zentral شاپ با هم گفتگو میکنیم . گمان میکنم ؟\n",
            "PRED SCORE: -5.5114\n",
            "\n",
            "SENT 179: ['then', 'everything', 'is', 'sorted', 'out', 'now', '.', 'then', 'we', 'will', 'see', 'each', 'other', 'on', 'August', 'the', 'seventeenth', '.']\n",
            "PRED 179: پس کاملا برنامه­ریزی شوند . پس او ما هفدهم آگوست قرار بگذاریم .\n",
            "PRED SCORE: -6.3236\n",
            "\n",
            "SENT 180: ['okay', '.', 'goodbye', '.']\n",
            "PRED 180: خداحافظ .\n",
            "PRED SCORE: -0.5133\n",
            "\n",
            "SENT 181: ['good', 'morning', '.', 'how', 'are', 'you', '?']\n",
            "PRED 181: خوب صبح . شما چطور است ؟\n",
            "PRED SCORE: -1.8045\n",
            "\n",
            "SENT 182: ['when', 'should', 'we', 'go', 'to', 'Hanover', '?']\n",
            "PRED 182: چه موقع باید به Hanover ؟\n",
            "PRED SCORE: -0.6650\n",
            "\n",
            "SENT 183: ['fine', '.', 'let', 'us', 'meet', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', '.', 'should', 'we', 'go', 'by', 'train', '?']\n",
            "PRED 183: خوب است . پس بگذاریم ساعت ده صبح همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -1.6123\n",
            "\n",
            "SENT 184: ['thanks', '.', 'then', 'we', 'meet', 'at', 'the', 'train', 'station', '.']\n",
            "PRED 184: متشکرم . پس همدیگر را در ایستگاه ملاقات کنیم .\n",
            "PRED SCORE: -1.2241\n",
            "\n",
            "SENT 185: ['when', 'will', 'we', 'arrive', 'in', 'Hanover', '?']\n",
            "PRED 185: چه موقع در Hanover ؟\n",
            "PRED SCORE: -2.0051\n",
            "\n",
            "SENT 186: ['I', 'have', 'asked', ',', 'when', 'we', 'will', 'arrive', 'in', 'Hanover', '.']\n",
            "PRED 186: من باید بگویم ، چه در Hanover Hanover .\n",
            "PRED SCORE: -1.2081\n",
            "\n",
            "SENT 187: ['fine', '.', 'I', 'have', 'already', 'reserved', 'a', 'hotel', '.']\n",
            "PRED 187: خوب است . من قبلا یک اتاق خوب دارم .\n",
            "PRED SCORE: -2.1228\n",
            "\n",
            "SENT 188: ['at', 'the', 'hotel', 'Maritim', '.', 'we', 'can', 'go', 'there', 'by', 'taxi', '.']\n",
            "PRED 188: در رستوران . میتوانیم آنجا در center همدیگر را ببینیم .\n",
            "PRED SCORE: -3.1422\n",
            "\n",
            "SENT 189: ['yes', ',', 'I', 'have', 'already', 'booked', 'the', 'hotel', '.']\n",
            "PRED 189: بله ، من قبلا در آن روز قرار گذاشته­ام .\n",
            "PRED SCORE: -0.7288\n",
            "\n",
            "SENT 190: ['I', 'have', 'booked', 'two', 'single', 'rooms', '.', 'one', 'for', 'me', 'and', 'one', 'for', 'you', '.']\n",
            "PRED 190: من دو تا دو را رزرو کردم . آیا برای شما یک زمانی را فراهم میکنید .\n",
            "PRED SCORE: -6.3505\n",
            "\n",
            "SENT 191: ['in', 'the', 'evening', 'we', 'should', 'watch', 'the', 'newest', 'movie', 'with', 'Arnold', 'Schwarzenegger', '.']\n",
            "PRED 191: در صورت هرگونه ما باید به مقدار کافی برنامه ریزی کنیم .\n",
            "PRED SCORE: -5.7707\n",
            "\n",
            "SENT 192: ['fine', '.', 'let', 'us', 'meet', 'at', 'the', 'station', 'at', 'nine', \"o'clock\", 'on', 'Thursday', 'morning', '.']\n",
            "PRED 192: خوب است . بیایید همدیگر را ساعت نه صبح پنجشنبه در ایستگاه ملاقات کنیم .\n",
            "PRED SCORE: -2.6229\n",
            "\n",
            "SENT 193: ['what', 'did', 'you', 'say', ',', 'please', '?']\n",
            "PRED 193: نظر شما چیست ، لطفا ؟\n",
            "PRED SCORE: -0.9437\n",
            "\n",
            "SENT 194: ['yes', '.', 'we', 'leave', 'at', 'nine', \"o'clock\", 'and', 'arrive', 'at', 'Hamburg', 'at', 'one', \"o'clock\", '.', 'right', '?']\n",
            "PRED 194: بله . ساعت نه و سی دقیقه در دفتر branch . ساعت یک ؟\n",
            "PRED SCORE: -3.0982\n",
            "\n",
            "SENT 195: ['yes', '.', 'is', 'everything', 'cleared', 'up', 'then', '?']\n",
            "PRED 195: بله . پس به‌این رزرواسیون هستم ؟\n",
            "PRED SCORE: -2.7970\n",
            "\n",
            "SENT 196: ['then', 'everything', 'is', 'arranged', '.', 'goodbye', '.']\n",
            "PRED 196: پس به این دلیل هم همینطور . خدا­حافظ .\n",
            "PRED SCORE: -3.2896\n",
            "\n",
            "SENT 197: ['hello', '.', 'I', 'would', 'prefer', 'the', 'Intercontinental', '.']\n",
            "PRED 197: سلام . من سیلبرن‌هبیت را ترجیح میدهم .\n",
            "PRED SCORE: -1.6668\n",
            "\n",
            "SENT 198: ['fine', '.', 'let', 'us', 'take', 'the', 'Intercontinental', '.', 'should', 'we', 'fly', '?']\n",
            "PRED 198: خوب است . اجازه دهید ما وجود دارد . ما در downtown .\n",
            "PRED SCORE: -2.5651\n",
            "\n",
            "SENT 199: ['no', 'problem', '.', 'then', 'let', 'us', 'meet', '.', 'where', 'should', 'we', 'meet', '?']\n",
            "PRED 199: نه . بنابراین میبینیم . آیا ما میتوانیم ملاقات کنیم ؟\n",
            "PRED SCORE: -3.1911\n",
            "\n",
            "SENT 200: ['yes', ',', 'we', 'take', 'the', 'Atlantic-Hotel', '.']\n",
            "PRED 200: بله ، ما return .\n",
            "PRED SCORE: -1.2757\n",
            "\n",
            "SENT 201: ['thanks', '.', 'by', 'the', 'way', ',', 'we', 'fly', 'to', 'Hanover', '.']\n",
            "PRED 201: متشکرم . آدرس ما ، ما Hanover در Hanover .\n",
            "PRED SCORE: -3.0830\n",
            "\n",
            "SENT 202: ['yes', '.', 'our', 'plane', 'will', 'take', 'off', 'at', 'a', 'quarter', 'to', 'seven', 'and', 'will', 'land', 'at', 'Hanover', 'at', 'ten', 'past', 'ten', '.']\n",
            "PRED 202: بله . ساعت یک برنامه branch ساعت هفت و نیم ساعت هفت صبح تا ساعت ده عصر .\n",
            "PRED SCORE: -4.2148\n",
            "\n",
            "SENT 203: ['fine', '.', 'by', 'taxi', 'we', 'will', 'be', 'at', 'the', 'hotel', 'within', 'ten', 'minutes', '.']\n",
            "PRED 203: خوب است . در هتل اطلاعات ما در ساعت ده .\n",
            "PRED SCORE: -0.7781\n",
            "\n",
            "SENT 204: ['yes', ',', 'let', 'us', 'take', 'two', 'single', 'rooms', '.', 'and', 'what', 'would', 'you', 'like', 'to', 'do', 'in', 'the', 'evening', '?']\n",
            "PRED 204: بله ، دو ساعت میخواهید را انتخاب کنید . آیا شما میخواهید آن را در عصر انجام دهید ؟\n",
            "PRED SCORE: -3.5489\n",
            "\n",
            "SENT 205: ['fine', '.', 'let', 'us', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '.', 'the', 'best', 'would', 'be', 'the', 'Gr\"unschnabel', '.']\n",
            "PRED 205: خوب است . بگذارید یک وقت داشته باشیم . برای ظهر هم همینطور .\n",
            "PRED SCORE: -3.9054\n",
            "\n",
            "SENT 206: ['on', 'Wednesday', 'we', 'will', 'go', 'back', 'by', 'train', 'to', 'Hamburg', '.']\n",
            "PRED 206: من چهارشنبه در شهر هستم تا Hanover .\n",
            "PRED SCORE: -2.5248\n",
            "\n",
            "SENT 207: ['we', 'will', 'leave', 'at', 'half', 'past', 'eight', 'and', 'will', 'arrive', 'at', 'Hamburg', 'at', 'ten', \"o'clock\", '.']\n",
            "PRED 207: ما ساعت چهار و نیم و ما قطار تا ساعت ده را ترک میکنم .\n",
            "PRED SCORE: -5.0874\n",
            "\n",
            "SENT 208: ['the', 'best', 'thing', 'would', 'be', 'for', 'us', 'to', 'take', 'the', 'subway', 'from', 'our', 'hotel', 'to', 'the', 'station', '.']\n",
            "PRED 208: بهترین گزینه است برای رفتن به رفتن اف از منییم .\n",
            "PRED SCORE: -5.7701\n",
            "\n",
            "SENT 209: ['fine', '.', 'let', 'us', 'go', 'for', 'a', 'little', 'walk', 'in', 'Hamburg', '.']\n",
            "PRED 209: خوب است . پس اجازه ‌بدهید یک ride flights میکنم .\n",
            "PRED SCORE: -2.4995\n",
            "\n",
            "SENT 210: ['I', 'am', 'looking', 'forward', 'to', 'that', '.', 'goodbye', '.']\n",
            "PRED 210: من منتظر آن هستم . خداحافظ .\n",
            "PRED SCORE: -0.1877\n",
            "\n",
            "SENT 211: ['hello', '.', 'should', 'we', 'go', 'by', 'car', 'to', 'Hanover', '?']\n",
            "PRED 211: سلام . آیا ما باید به Hanover Hanover ؟\n",
            "PRED SCORE: -1.5052\n",
            "\n",
            "SENT 212: ['we', 'should', 'leave', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', 'to', 'be', 'in', 'Hanover', 'at', 'twelve', \"o'clock\", '.']\n",
            "PRED 212: ما باید ساعت ده صبح در هتل همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -0.9507\n",
            "\n",
            "SENT 213: ['do', 'you', 'want', 'me', 'to', 'book', 'a', 'hotel', '?']\n",
            "PRED 213: آیا شما میخواهید تا یک میز باشد ؟\n",
            "PRED SCORE: -1.9420\n",
            "\n",
            "SENT 214: ['I', 'will', 'book', 'two', 'single', 'rooms', 'with', 'a', 'shower', 'at', 'the', 'K\"onigshotel']\n",
            "PRED 214: دو قرار دو روزه را در سفر خواهم داشت .\n",
            "PRED SCORE: -4.3319\n",
            "\n",
            "SENT 215: ['yes', ',', 'I', 'would', 'suggest', 'we', 'fly', 'back', '.']\n",
            "PRED 215: بله , من پیشنهاد میکنم که ما وجود دارد .\n",
            "PRED SCORE: -0.2900\n",
            "\n",
            "SENT 216: ['yes', ',', 'I', 'would', 'suggest', 'the', 'flight', 'at', 'a', 'quarter', 'past', 'seven', '.']\n",
            "PRED 216: بله , من حدود ساعت هفت و ربع را پیشنهاد میکنم .\n",
            "PRED SCORE: -0.0695\n",
            "\n",
            "SENT 217: ['I', 'agree', '.']\n",
            "PRED 217: موافقم .\n",
            "PRED SCORE: -0.4213\n",
            "\n",
            "SENT 218: ['we', 'will', 'be', 'back', 'in', 'Hamburg', 'at', 'five', 'past', 'ten', '.']\n",
            "PRED 218: ما در منزل ساعت ده و نیم روز .\n",
            "PRED SCORE: -1.9069\n",
            "\n",
            "SENT 219: ['yes', ',', 'we', 'will', 'be', 'back', 'at', 'Hamburg', 'at', 'five', 'past', 'ten', '.', 'would', 'you', 'like', 'to', 'go', 'to', 'the', 'Wienerwald', 'in', 'Hanover', 'in', 'the', 'evening', '?']\n",
            "PRED 219: بله ، ما باید ساعت ده در Hanover . در هتل Luisenhof ؟\n",
            "PRED SCORE: -5.0332\n",
            "\n",
            "SENT 220: ['okay', ',', 'goodbye', '.']\n",
            "PRED 220: باشد ، خداحافظ .\n",
            "PRED SCORE: -0.8950\n",
            "\n",
            "SENT 221: ['Mrs', 'Schmidt', ',', 'we', 'still', 'want', 'to', 'plan', 'the', 'journey', 'to', 'Hanover', '.']\n",
            "PRED 221: خانم ولاک ، ما باید واقعا برای Hanover از بن .\n",
            "PRED SCORE: -3.5168\n",
            "\n",
            "SENT 222: ['I', 'would', 'like', 'to', 'take', 'the', 'train', 'on', 'the', 'thirtieth', '.']\n",
            "PRED 222: من مایل هستم از سی­ام برگردم .\n",
            "PRED SCORE: -2.6457\n",
            "\n",
            "SENT 223: ['during', 'a', 'flight', 'I', 'always', 'get', 'sick', '.', 'I', 'would', 'like', 'to', 'take', 'the', 'train', '.']\n",
            "PRED 223: در هتل پارک من همیشه از . به پرواز میروم .\n",
            "PRED SCORE: -5.2753\n",
            "\n",
            "SENT 224: ['well', ',', 'I', 'would', 'like', 'to', 'take', 'the', 'train', '.', 'during', 'a', 'flight', 'I', 'get', 'sick', '.']\n",
            "PRED 224: خب ، من دوست دارم . در دفتر branch ساعت یک .\n",
            "PRED SCORE: -3.2054\n",
            "\n",
            "SENT 225: ['please', 'let', 'us', 'take', 'the', 'train', '.']\n",
            "PRED 225: لطفا اجازه ‌بدهید بگوییم .\n",
            "PRED SCORE: -0.4681\n",
            "\n",
            "SENT 226: ['let', 'us', 'take', 'the', 'train', 'at', 'nine', \"o'clock\", '.']\n",
            "PRED 226: اجازه دهید سر ساعت نه .\n",
            "PRED SCORE: -1.9880\n",
            "\n",
            "SENT 227: ['at', 'six', 'past', 'nine', 'then', '.', 'then', 'let', 'us', 'meet', 'at', 'the', 'station', 'at', 'half', 'past', 'eight', '.']\n",
            "PRED 227: ساعت شش و نیم پس . اجازه دهید بگوییم ساعت هشت و نیم همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -4.8556\n",
            "\n",
            "SENT 228: ['when', 'do', 'we', 'arrive', 'at', 'Hanover', '?']\n",
            "PRED 228: چه زمانی ما باید به Hanover ؟\n",
            "PRED SCORE: -2.4494\n",
            "\n",
            "SENT 229: ['that', 'is', 'very', 'good', '.', 'at', 'which', 'hotel', 'should', 'we', 'stay', 'then', '?', 'what', 'about', 'the', 'Gr\"unschnabel', '?']\n",
            "PRED 229: آن خیلی خوب است . اگر ما آنجا در هتل ؟\n",
            "PRED SCORE: -5.4532\n",
            "\n",
            "SENT 230: ['I', 'think', 'we', 'will', 'take', 'the', 'Metropol', 'hotel', '.', 'could', 'you', 'reserve', 'two', 'single', 'rooms', '?']\n",
            "PRED 230: فکر میکنم ماشین چهل . آیا باید در دو هفته دیگر همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -4.6199\n",
            "\n",
            "SENT 231: ['that', 'is', 'perfect', '.', 'would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '?']\n",
            "PRED 231: عالی است . شما یک زمانی را برای غروب در غروب دارید ؟\n",
            "PRED SCORE: -2.8347\n",
            "\n",
            "SENT 232: ['yes', ',', 'the', 'steaks', 'at', 'the', 'Block-House', 'are', 'always', 'very', 'succulent', '.']\n",
            "PRED 232: بله ، البته در رستوران پارک سوال دارند .\n",
            "PRED SCORE: -4.8676\n",
            "\n",
            "SENT 233: ['good', 'idea', '.', 'we', 'could', 'take', 'the', 'one', 'at', 'the', 'Maschsee', '.']\n",
            "PRED 233: خوب به نظر میرسد . ما میتوانیم اینجا در یک رستوران .\n",
            "PRED SCORE: -2.2067\n",
            "\n",
            "SENT 234: ['that', 'is', 'perfect', '.', 'then', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 234: پس عالی است . پس ما با آن تماس بگیریم .\n",
            "PRED SCORE: -3.5496\n",
            "\n",
            "SENT 235: ['hello', '.', 'we', 'still', 'have', 'to', 'plan', 'our', 'trip', 'to', 'Hanover', '.']\n",
            "PRED 235: سلام ، ما هنوز باید آن را برای سفر تجاریمان طرح‌ریزی‌ کنیم .\n",
            "PRED SCORE: -1.6019\n",
            "\n",
            "SENT 236: ['I', 'would', 'like', 'to', 'fly', '.', 'that', 'looks', 'more', 'important', '.']\n",
            "PRED 236: دوست دارم .\n",
            "PRED SCORE: -2.9373\n",
            "\n",
            "SENT 237: ['the', 'earliest', 'flight', 'leaves', 'at', 'five', 'past', 'eight', '.', 'should', 'we', 'take', 'that', 'one', '?']\n",
            "PRED 237: پس هر سر میگذارد پنج ساعت هشت . ما باید آن را برای paid ؟\n",
            "PRED SCORE: -4.7679\n",
            "\n",
            "SENT 238: ['the', 'plane', 'arrives', 'at', 'Hanover', 'at', 'a', 'quarter', 'past', 'eleven', '.']\n",
            "PRED 238: آن در حقیقت ساعت یازده و ربع طول میکشد .\n",
            "PRED SCORE: -2.2702\n",
            "\n",
            "SENT 239: ['let', 'us', 'meet', 'at', 'seven', \"o'clock\", '.', 'we', 'still', 'have', 'to', 'check', 'in', '.']\n",
            "PRED 239: بیایید ساعت هفت ملاقات داشته باشیم . هنوز باید در فرودگاه همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -2.3967\n",
            "\n",
            "SENT 240: ['what', 'do', 'you', 'think', 'about', 'the', 'hotel', 'Gewandhaus', '?']\n",
            "PRED 240: نظر شما در مورد رستوران آتزینگر چیست ؟\n",
            "PRED SCORE: -0.0972\n",
            "\n",
            "SENT 241: ['I', 'would', 'like', 'one', ',', 'I', 'would', 'like', 'to', 'have', 'one', 'single', 'room', '.']\n",
            "PRED 241: من مایلم بگویم ، ترجیح میدهم که یک اتاق کنفرانس داشته باشد .\n",
            "PRED SCORE: -4.5073\n",
            "\n",
            "SENT 242: ['you', 'would', 'like', 'to', 'have', 'a', 'room', 'with', 'TV', 'and', 'Bar', '?']\n",
            "PRED 242: شما میخواهید یک رستوران و یک opera را هم میاورید ؟\n",
            "PRED SCORE: -2.9065\n",
            "\n",
            "SENT 243: ['I', 'will', 'book', 'the', 'hotelroom', '.']\n",
            "PRED 243: من بلیطها را خواهم گرفت .\n",
            "PRED SCORE: -0.4096\n",
            "\n",
            "SENT 244: ['we', 'have', 'already', 'agreed', 'on', 'the', 'hotel', '.']\n",
            "PRED 244: ما قبلا در مورد توافق توافق کردیم .\n",
            "PRED SCORE: -1.5382\n",
            "\n",
            "SENT 245: ['unfortunately', 'I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 245: متاسفانه من آن را مخالفتی ندارم .\n",
            "PRED SCORE: -1.0676\n",
            "\n",
            "SENT 246: ['let', 'us', 'leave', 'at', 'eight', \"o'clock\", '$P-$M', '.', 'there', 'is', 'a', 'flight', 'to', 'Hamburg', 'going', 'over', 'Milan', '.', \"isn't\", 'that', 'great', '?']\n",
            "PRED 246: اجازه بدهید ساعت هشت عصر . ساعت هشت . رستوران branch بهتر است .\n",
            "PRED SCORE: -4.8065\n",
            "\n",
            "SENT 247: ['let', 'yourself', 'get', 'surprised', '!']\n",
            "PRED 247: اجازه بدهید تصور کنم .\n",
            "PRED SCORE: -2.3805\n",
            "\n",
            "SENT 248: ['I', 'could', ',', 'but', 'I', \"don't\", 'do', 'it', '.']\n",
            "PRED 248: نه ، اما من فکر میکنم آن را دوست دارم .\n",
            "PRED SCORE: -2.0300\n",
            "\n",
            "SENT 249: ['at', 'eight', \"o'clock\", '$P-$M', '.']\n",
            "PRED 249: ساعت هشت عصر .\n",
            "PRED SCORE: -0.1024\n",
            "\n",
            "SENT 250: ['yes', ',', 'that', 'is', 'in', 'the', 'evening', '.', 'now', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 250: بله ، البته . در غروب صحبت میکنم . ما البته در غروب .\n",
            "PRED SCORE: -4.5975\n",
            "PRED AVG SCORE: -0.2564, PRED PPL: 1.2923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFfzrvPLMkQq",
        "colab_type": "code",
        "outputId": "c7011e88-1f4f-488c-9d43-a8262562117d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.listdir('En2Fa-Translation/Test/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.fa2', 'test.fa1', 'test.fa3', 'test.fa0', 'test.en']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4GZZ0O2JTbg",
        "colab_type": "code",
        "outputId": "44530252-bb08-4625-ebc3-96c11df33819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "!perl  OpenNMT-py/tools/multi-bleu.perl En2Fa-Translation/Test/test.fa0 En2Fa-Translation/Test/test.fa1 En2Fa-Translation/Test/test.fa2 En2Fa-Translation/Test/test.fa3 < En2Fa-Translation/pred.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU = 20.27, 60.0/26.9/15.1/8.7 (BP=0.944, ratio=0.946, hyp_len=2412, ref_len=2551)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhZb7deqK3Wv",
        "colab_type": "text"
      },
      "source": [
        "### BLEU during epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHkqL5pdLEfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values = []\n",
        "iter_num = 5000\n",
        "while iter_num <= 50000:\n",
        "  command = \"python OpenNMT-py/translate.py -model En2Fa-Translation/rnn_model_step_{}.pt -src En2Fa-Translation/Dev/dev.en -output En2Fa-Translation/Dev/pred.txt -replace_unk -verbose\".format(iter_num)\n",
        "  _ = !eval $command\n",
        "  out = !eval \"perl OpenNMT-py/tools/multi-bleu.perl En2Fa-Translation/Dev/dev.fa < En2Fa-Translation/Dev/pred.txt\"\n",
        "  values.append(out)\n",
        "  iter_num += 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS6lrnxpQtP2",
        "colab_type": "code",
        "outputId": "c79c6eb5-cfc2-40b5-97e2-ce8d4b8a30f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['BLEU = 4.34, 39.4/9.7/2.9/0.9 (BP=0.785, ratio=0.805, hyp_len=2687, ref_len=3339)'],\n",
              " ['BLEU = 8.79, 47.0/15.7/6.2/2.8 (BP=0.829, ratio=0.842, hyp_len=2812, ref_len=3339)'],\n",
              " ['BLEU = 7.30, 46.7/14.7/5.7/1.7 (BP=0.806, ratio=0.822, hyp_len=2746, ref_len=3339)'],\n",
              " ['BLEU = 8.54, 47.0/15.6/5.9/2.1 (BP=0.877, ratio=0.884, hyp_len=2951, ref_len=3339)'],\n",
              " ['BLEU = 9.05, 48.3/16.2/6.2/2.4 (BP=0.875, ratio=0.882, hyp_len=2946, ref_len=3339)'],\n",
              " ['BLEU = 9.13, 48.1/15.6/6.1/2.3 (BP=0.909, ratio=0.913, hyp_len=3047, ref_len=3339)'],\n",
              " ['BLEU = 10.02, 49.9/17.4/7.2/3.0 (BP=0.854, ratio=0.864, hyp_len=2884, ref_len=3339)'],\n",
              " ['BLEU = 9.37, 49.0/16.8/6.7/2.4 (BP=0.871, ratio=0.879, hyp_len=2935, ref_len=3339)'],\n",
              " ['BLEU = 8.84, 49.2/15.9/6.2/2.1 (BP=0.878, ratio=0.885, hyp_len=2955, ref_len=3339)'],\n",
              " ['BLEU = 8.63, 50.7/17.2/6.2/1.9 (BP=0.853, ratio=0.863, hyp_len=2882, ref_len=3339)']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8PJIwWLTpCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values_to_plot = []\n",
        "x_to_plot = []\n",
        "iter_num = 5000\n",
        "for v in values:\n",
        "  x_to_plot.append(iter_num)\n",
        "  values_to_plot.append(float(v[0].split(' ')[2].replace(',', '')))\n",
        "  iter_num += 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_JsqhRfUJ4g",
        "colab_type": "code",
        "outputId": "4fa68a18-516f-49e2-9751-255e5d6d422b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x_to_plot, values_to_plot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6375808eb8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBn1y6KmZ3lV",
        "colab_type": "text"
      },
      "source": [
        "### Testing different parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM9nF3sGaCqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbHKiEPxZ374",
        "colab_type": "code",
        "outputId": "d77a3189-4ebc-4c35-f404-11f801161302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "st = time.time()\n",
        "!python OpenNMT-py/train.py -data En2Fa-Translation/Cleaned -world_size 1 -gpu_rank 0 --rnn_size 1024 --layers 4 --rnn_type LSTM -train_steps 10000\n",
        "en = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 19:43:38,841 INFO]  * src vocab size = 3116\n",
            "[2020-06-01 19:43:38,841 INFO]  * tgt vocab size = 5908\n",
            "[2020-06-01 19:43:38,841 INFO] Building model...\n",
            "[2020-06-01 19:43:48,322 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3116, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 1024, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5908, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1524, 1024)\n",
            "        (1): LSTMCell(1024, 1024)\n",
            "        (2): LSTMCell(1024, 1024)\n",
            "        (3): LSTMCell(1024, 1024)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "      (linear_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=5908, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-01 19:43:48,323 INFO] encoder: 32998896\n",
            "[2020-06-01 19:43:48,323 INFO] decoder: 47790628\n",
            "[2020-06-01 19:43:48,323 INFO] * number of parameters: 80789524\n",
            "[2020-06-01 19:43:48,326 INFO] Starting training on GPU: [0]\n",
            "[2020-06-01 19:43:48,327 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-01 19:43:48,327 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:43:49,382 INFO] number of examples: 26142\n",
            "[2020-06-01 19:44:06,535 INFO] Step 50/10000; acc:   5.87; ppl: 6478249.63; xent: 15.68; lr: 1.00000; 1803/1823 tok/s;     18 sec\n",
            "[2020-06-01 19:44:22,750 INFO] Step 100/10000; acc:   6.59; ppl: 775908.07; xent: 13.56; lr: 1.00000; 1936/1980 tok/s;     34 sec\n",
            "[2020-06-01 19:44:38,582 INFO] Step 150/10000; acc:   7.11; ppl: 13671.53; xent: 9.52; lr: 1.00000; 1956/1974 tok/s;     50 sec\n",
            "[2020-06-01 19:44:55,737 INFO] Step 200/10000; acc:   6.33; ppl: 6312.73; xent: 8.75; lr: 1.00000; 1881/1938 tok/s;     67 sec\n",
            "[2020-06-01 19:45:14,982 INFO] Step 250/10000; acc:   6.18; ppl: 2659.24; xent: 7.89; lr: 1.00000; 1943/1978 tok/s;     87 sec\n",
            "[2020-06-01 19:45:32,423 INFO] Step 300/10000; acc:   6.30; ppl: 12499.68; xent: 9.43; lr: 1.00000; 1885/1937 tok/s;    104 sec\n",
            "[2020-06-01 19:45:49,336 INFO] Step 350/10000; acc:   7.15; ppl: 3271.65; xent: 8.09; lr: 1.00000; 1800/1826 tok/s;    121 sec\n",
            "[2020-06-01 19:46:05,619 INFO] Step 400/10000; acc:   7.32; ppl: 1776.73; xent: 7.48; lr: 1.00000; 1915/1906 tok/s;    137 sec\n",
            "[2020-06-01 19:46:07,976 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:46:08,343 INFO] number of examples: 26142\n",
            "[2020-06-01 19:46:22,182 INFO] Step 450/10000; acc:   8.22; ppl: 1075.78; xent: 6.98; lr: 1.00000; 1936/1926 tok/s;    154 sec\n",
            "[2020-06-01 19:46:38,641 INFO] Step 500/10000; acc:   7.53; ppl: 851.38; xent: 6.75; lr: 1.00000; 1954/2015 tok/s;    170 sec\n",
            "[2020-06-01 19:46:53,037 INFO] Step 550/10000; acc:   9.33; ppl: 576.15; xent: 6.36; lr: 1.00000; 1934/1960 tok/s;    185 sec\n",
            "[2020-06-01 19:47:11,170 INFO] Step 600/10000; acc:   8.50; ppl: 786.03; xent: 6.67; lr: 1.00000; 1935/1946 tok/s;    203 sec\n",
            "[2020-06-01 19:47:29,954 INFO] Step 650/10000; acc:   8.49; ppl: 517.46; xent: 6.25; lr: 1.00000; 1947/2011 tok/s;    222 sec\n",
            "[2020-06-01 19:47:47,660 INFO] Step 700/10000; acc:   9.42; ppl: 342.00; xent: 5.83; lr: 1.00000; 1888/1945 tok/s;    239 sec\n",
            "[2020-06-01 19:48:03,920 INFO] Step 750/10000; acc:  12.72; ppl: 252.90; xent: 5.53; lr: 1.00000; 1849/1850 tok/s;    256 sec\n",
            "[2020-06-01 19:48:20,221 INFO] Step 800/10000; acc:  15.92; ppl: 180.62; xent: 5.20; lr: 1.00000; 1891/1904 tok/s;    272 sec\n",
            "[2020-06-01 19:48:25,754 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:48:25,987 INFO] number of examples: 26142\n",
            "[2020-06-01 19:48:36,477 INFO] Step 850/10000; acc:  16.82; ppl: 172.61; xent: 5.15; lr: 1.00000; 1923/1928 tok/s;    288 sec\n",
            "[2020-06-01 19:48:53,726 INFO] Step 900/10000; acc:  14.58; ppl: 245.31; xent: 5.50; lr: 1.00000; 1979/2029 tok/s;    305 sec\n",
            "[2020-06-01 19:49:08,475 INFO] Step 950/10000; acc:  19.28; ppl: 125.28; xent: 4.83; lr: 1.00000; 1952/1989 tok/s;    320 sec\n",
            "[2020-06-01 19:49:25,978 INFO] Step 1000/10000; acc:  18.09; ppl: 141.16; xent: 4.95; lr: 1.00000; 1957/1948 tok/s;    338 sec\n",
            "[2020-06-01 19:49:43,829 INFO] Step 1050/10000; acc:  16.90; ppl: 137.65; xent: 4.92; lr: 1.00000; 1931/2014 tok/s;    356 sec\n",
            "[2020-06-01 19:50:01,875 INFO] Step 1100/10000; acc:  18.23; ppl: 125.94; xent: 4.84; lr: 1.00000; 1928/1984 tok/s;    374 sec\n",
            "[2020-06-01 19:50:18,713 INFO] Step 1150/10000; acc:  21.83; ppl: 98.01; xent: 4.59; lr: 1.00000; 1872/1845 tok/s;    390 sec\n",
            "[2020-06-01 19:50:34,477 INFO] Step 1200/10000; acc:  24.72; ppl: 78.69; xent: 4.37; lr: 1.00000; 1867/1948 tok/s;    406 sec\n",
            "[2020-06-01 19:50:42,740 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:50:42,983 INFO] number of examples: 26142\n",
            "[2020-06-01 19:50:50,747 INFO] Step 1250/10000; acc:  24.01; ppl: 85.79; xent: 4.45; lr: 1.00000; 1947/1925 tok/s;    422 sec\n",
            "[2020-06-01 19:51:07,739 INFO] Step 1300/10000; acc:  23.00; ppl: 85.63; xent: 4.45; lr: 1.00000; 1996/2016 tok/s;    439 sec\n",
            "[2020-06-01 19:51:22,151 INFO] Step 1350/10000; acc:  28.97; ppl: 58.51; xent: 4.07; lr: 1.00000; 1945/2000 tok/s;    454 sec\n",
            "[2020-06-01 19:51:39,146 INFO] Step 1400/10000; acc:  24.93; ppl: 75.44; xent: 4.32; lr: 1.00000; 1975/1969 tok/s;    471 sec\n",
            "[2020-06-01 19:51:56,548 INFO] Step 1450/10000; acc:  25.41; ppl: 70.57; xent: 4.26; lr: 1.00000; 1902/1977 tok/s;    488 sec\n",
            "[2020-06-01 19:52:14,549 INFO] Step 1500/10000; acc:  25.77; ppl: 71.67; xent: 4.27; lr: 1.00000; 1965/2026 tok/s;    506 sec\n",
            "[2020-06-01 19:52:33,442 INFO] Step 1550/10000; acc:  26.82; ppl: 69.36; xent: 4.24; lr: 1.00000; 1858/1838 tok/s;    525 sec\n",
            "[2020-06-01 19:52:48,623 INFO] Step 1600/10000; acc:  32.52; ppl: 45.07; xent: 3.81; lr: 1.00000; 1850/1942 tok/s;    540 sec\n",
            "[2020-06-01 19:52:59,518 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:52:59,838 INFO] number of examples: 26142\n",
            "[2020-06-01 19:53:05,338 INFO] Step 1650/10000; acc:  31.54; ppl: 49.17; xent: 3.90; lr: 1.00000; 1953/1916 tok/s;    557 sec\n",
            "[2020-06-01 19:53:21,251 INFO] Step 1700/10000; acc:  31.39; ppl: 46.06; xent: 3.83; lr: 1.00000; 1974/2010 tok/s;    573 sec\n",
            "[2020-06-01 19:53:36,029 INFO] Step 1750/10000; acc:  34.56; ppl: 38.43; xent: 3.65; lr: 1.00000; 1966/2002 tok/s;    588 sec\n",
            "[2020-06-01 19:53:53,051 INFO] Step 1800/10000; acc:  32.15; ppl: 43.27; xent: 3.77; lr: 1.00000; 1992/1996 tok/s;    605 sec\n",
            "[2020-06-01 19:54:09,813 INFO] Step 1850/10000; acc:  32.95; ppl: 42.30; xent: 3.74; lr: 1.00000; 1883/1965 tok/s;    621 sec\n",
            "[2020-06-01 19:54:28,598 INFO] Step 1900/10000; acc:  31.81; ppl: 47.30; xent: 3.86; lr: 1.00000; 1980/2006 tok/s;    640 sec\n",
            "[2020-06-01 19:54:47,324 INFO] Step 1950/10000; acc:  33.92; ppl: 40.95; xent: 3.71; lr: 1.00000; 1847/1873 tok/s;    659 sec\n",
            "[2020-06-01 19:55:02,736 INFO] Step 2000/10000; acc:  40.10; ppl: 27.13; xent: 3.30; lr: 1.00000; 1855/1928 tok/s;    674 sec\n",
            "[2020-06-01 19:55:16,430 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:55:16,744 INFO] number of examples: 26142\n",
            "[2020-06-01 19:55:18,976 INFO] Step 2050/10000; acc:  40.04; ppl: 26.31; xent: 3.27; lr: 1.00000; 1915/1875 tok/s;    691 sec\n",
            "[2020-06-01 19:55:34,475 INFO] Step 2100/10000; acc:  41.33; ppl: 24.35; xent: 3.19; lr: 1.00000; 1963/2026 tok/s;    706 sec\n",
            "[2020-06-01 19:55:50,641 INFO] Step 2150/10000; acc:  41.44; ppl: 23.62; xent: 3.16; lr: 1.00000; 1993/1990 tok/s;    722 sec\n",
            "[2020-06-01 19:56:06,743 INFO] Step 2200/10000; acc:  42.94; ppl: 21.34; xent: 3.06; lr: 1.00000; 1964/2016 tok/s;    738 sec\n",
            "[2020-06-01 19:56:23,944 INFO] Step 2250/10000; acc:  42.23; ppl: 22.48; xent: 3.11; lr: 1.00000; 1899/1943 tok/s;    756 sec\n",
            "[2020-06-01 19:56:42,489 INFO] Step 2300/10000; acc:  40.95; ppl: 23.94; xent: 3.18; lr: 1.00000; 1956/2008 tok/s;    774 sec\n",
            "[2020-06-01 19:57:00,959 INFO] Step 2350/10000; acc:  43.17; ppl: 21.07; xent: 3.05; lr: 1.00000; 1886/1897 tok/s;    793 sec\n",
            "[2020-06-01 19:57:16,656 INFO] Step 2400/10000; acc:  48.21; ppl: 15.79; xent: 2.76; lr: 1.00000; 1851/1900 tok/s;    808 sec\n",
            "[2020-06-01 19:57:32,422 INFO] Step 2450/10000; acc:  49.43; ppl: 14.29; xent: 2.66; lr: 1.00000; 1929/1925 tok/s;    824 sec\n",
            "[2020-06-01 19:57:33,546 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:57:33,861 INFO] number of examples: 26142\n",
            "[2020-06-01 19:57:49,135 INFO] Step 2500/10000; acc:  49.02; ppl: 14.62; xent: 2.68; lr: 1.00000; 1938/1947 tok/s;    841 sec\n",
            "[2020-06-01 19:58:05,344 INFO] Step 2550/10000; acc:  50.74; ppl: 13.06; xent: 2.57; lr: 1.00000; 1965/2020 tok/s;    857 sec\n",
            "[2020-06-01 19:58:20,475 INFO] Step 2600/10000; acc:  52.50; ppl: 11.71; xent: 2.46; lr: 1.00000; 1979/1982 tok/s;    872 sec\n",
            "[2020-06-01 19:58:37,962 INFO] Step 2650/10000; acc:  50.00; ppl: 13.83; xent: 2.63; lr: 1.00000; 1918/1952 tok/s;    890 sec\n",
            "[2020-06-01 19:58:57,292 INFO] Step 2700/10000; acc:  48.58; ppl: 14.44; xent: 2.67; lr: 1.00000; 1938/1988 tok/s;    909 sec\n",
            "[2020-06-01 19:59:14,143 INFO] Step 2750/10000; acc:  52.41; ppl: 11.78; xent: 2.47; lr: 1.00000; 1890/1952 tok/s;    926 sec\n",
            "[2020-06-01 19:59:30,395 INFO] Step 2800/10000; acc:  52.97; ppl: 11.61; xent: 2.45; lr: 1.00000; 1830/1855 tok/s;    942 sec\n",
            "[2020-06-01 19:59:47,346 INFO] Step 2850/10000; acc:  54.56; ppl: 10.23; xent: 2.33; lr: 1.00000; 1892/1893 tok/s;    959 sec\n",
            "[2020-06-01 19:59:51,067 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 19:59:51,358 INFO] number of examples: 26142\n",
            "[2020-06-01 20:00:03,541 INFO] Step 2900/10000; acc:  55.34; ppl:  9.76; xent: 2.28; lr: 1.00000; 1968/1940 tok/s;    975 sec\n",
            "[2020-06-01 20:00:20,452 INFO] Step 2950/10000; acc:  54.46; ppl:  9.94; xent: 2.30; lr: 1.00000; 1981/2034 tok/s;    992 sec\n",
            "[2020-06-01 20:00:34,889 INFO] Step 3000/10000; acc:  58.55; ppl:  7.77; xent: 2.05; lr: 1.00000; 1946/1979 tok/s;   1007 sec\n",
            "[2020-06-01 20:00:52,861 INFO] Step 3050/10000; acc:  53.38; ppl: 10.96; xent: 2.39; lr: 1.00000; 1952/1957 tok/s;   1025 sec\n",
            "[2020-06-01 20:01:11,216 INFO] Step 3100/10000; acc:  54.16; ppl: 10.03; xent: 2.31; lr: 1.00000; 1940/2007 tok/s;   1043 sec\n",
            "[2020-06-01 20:01:28,905 INFO] Step 3150/10000; acc:  55.07; ppl:  9.70; xent: 2.27; lr: 1.00000; 1876/1949 tok/s;   1061 sec\n",
            "[2020-06-01 20:01:45,417 INFO] Step 3200/10000; acc:  56.91; ppl:  8.87; xent: 2.18; lr: 1.00000; 1863/1859 tok/s;   1077 sec\n",
            "[2020-06-01 20:02:01,820 INFO] Step 3250/10000; acc:  58.88; ppl:  7.51; xent: 2.02; lr: 1.00000; 1891/1908 tok/s;   1093 sec\n",
            "[2020-06-01 20:02:08,292 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:02:08,616 INFO] number of examples: 26142\n",
            "[2020-06-01 20:02:17,881 INFO] Step 3300/10000; acc:  59.35; ppl:  7.53; xent: 2.02; lr: 1.00000; 1953/1930 tok/s;   1110 sec\n",
            "[2020-06-01 20:02:34,884 INFO] Step 3350/10000; acc:  57.72; ppl:  8.10; xent: 2.09; lr: 1.00000; 1961/2020 tok/s;   1127 sec\n",
            "[2020-06-01 20:02:49,378 INFO] Step 3400/10000; acc:  62.08; ppl:  6.22; xent: 1.83; lr: 1.00000; 1925/1995 tok/s;   1141 sec\n",
            "[2020-06-01 20:03:07,032 INFO] Step 3450/10000; acc:  56.61; ppl:  8.58; xent: 2.15; lr: 1.00000; 1982/1948 tok/s;   1159 sec\n",
            "[2020-06-01 20:03:24,595 INFO] Step 3500/10000; acc:  57.71; ppl:  7.83; xent: 2.06; lr: 1.00000; 1895/1994 tok/s;   1176 sec\n",
            "[2020-06-01 20:03:43,055 INFO] Step 3550/10000; acc:  57.40; ppl:  8.18; xent: 2.10; lr: 1.00000; 1929/1983 tok/s;   1195 sec\n",
            "[2020-06-01 20:04:00,658 INFO] Step 3600/10000; acc:  58.58; ppl:  7.77; xent: 2.05; lr: 1.00000; 1878/1843 tok/s;   1212 sec\n",
            "[2020-06-01 20:04:16,079 INFO] Step 3650/10000; acc:  61.96; ppl:  6.07; xent: 1.80; lr: 1.00000; 1842/1937 tok/s;   1228 sec\n",
            "[2020-06-01 20:04:25,621 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:04:25,956 INFO] number of examples: 26142\n",
            "[2020-06-01 20:04:32,472 INFO] Step 3700/10000; acc:  61.53; ppl:  6.31; xent: 1.84; lr: 1.00000; 1929/1914 tok/s;   1244 sec\n",
            "[2020-06-01 20:04:49,031 INFO] Step 3750/10000; acc:  59.96; ppl:  6.82; xent: 1.92; lr: 1.00000; 1986/2003 tok/s;   1261 sec\n",
            "[2020-06-01 20:05:03,806 INFO] Step 3800/10000; acc:  63.54; ppl:  5.51; xent: 1.71; lr: 1.00000; 1962/1991 tok/s;   1275 sec\n",
            "[2020-06-01 20:05:20,106 INFO] Step 3850/10000; acc:  61.44; ppl:  6.32; xent: 1.84; lr: 1.00000; 1967/1980 tok/s;   1292 sec\n",
            "[2020-06-01 20:05:37,611 INFO] Step 3900/10000; acc:  59.64; ppl:  6.83; xent: 1.92; lr: 1.00000; 1911/1952 tok/s;   1309 sec\n",
            "[2020-06-01 20:05:56,662 INFO] Step 3950/10000; acc:  59.31; ppl:  7.05; xent: 1.95; lr: 1.00000; 1947/2019 tok/s;   1328 sec\n",
            "[2020-06-01 20:06:15,121 INFO] Step 4000/10000; acc:  59.24; ppl:  7.09; xent: 1.96; lr: 1.00000; 1839/1836 tok/s;   1347 sec\n",
            "[2020-06-01 20:06:30,831 INFO] Step 4050/10000; acc:  63.52; ppl:  5.47; xent: 1.70; lr: 1.00000; 1865/1932 tok/s;   1363 sec\n",
            "[2020-06-01 20:06:42,897 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:06:43,231 INFO] number of examples: 26142\n",
            "[2020-06-01 20:06:47,665 INFO] Step 4100/10000; acc:  63.13; ppl:  5.57; xent: 1.72; lr: 1.00000; 1943/1908 tok/s;   1379 sec\n",
            "[2020-06-01 20:07:02,469 INFO] Step 4150/10000; acc:  64.39; ppl:  5.19; xent: 1.65; lr: 1.00000; 1943/2014 tok/s;   1394 sec\n",
            "[2020-06-01 20:07:18,410 INFO] Step 4200/10000; acc:  64.08; ppl:  5.31; xent: 1.67; lr: 1.00000; 1977/1984 tok/s;   1410 sec\n",
            "[2020-06-01 20:07:35,559 INFO] Step 4250/10000; acc:  62.85; ppl:  5.73; xent: 1.75; lr: 1.00000; 1955/1992 tok/s;   1427 sec\n",
            "[2020-06-01 20:07:52,241 INFO] Step 4300/10000; acc:  62.15; ppl:  5.78; xent: 1.76; lr: 1.00000; 1900/1948 tok/s;   1444 sec\n",
            "[2020-06-01 20:08:10,642 INFO] Step 4350/10000; acc:  61.63; ppl:  5.94; xent: 1.78; lr: 1.00000; 1976/2013 tok/s;   1462 sec\n",
            "[2020-06-01 20:08:30,020 INFO] Step 4400/10000; acc:  60.42; ppl:  6.37; xent: 1.85; lr: 1.00000; 1838/1868 tok/s;   1482 sec\n",
            "[2020-06-01 20:08:44,750 INFO] Step 4450/10000; acc:  66.08; ppl:  4.70; xent: 1.55; lr: 1.00000; 1872/1935 tok/s;   1496 sec\n",
            "[2020-06-01 20:09:00,344 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:09:00,685 INFO] number of examples: 26142\n",
            "[2020-06-01 20:09:01,222 INFO] Step 4500/10000; acc:  65.54; ppl:  4.77; xent: 1.56; lr: 1.00000; 1897/1862 tok/s;   1513 sec\n",
            "[2020-06-01 20:09:17,717 INFO] Step 4550/10000; acc:  64.14; ppl:  5.11; xent: 1.63; lr: 1.00000; 1967/2001 tok/s;   1529 sec\n",
            "[2020-06-01 20:09:33,585 INFO] Step 4600/10000; acc:  65.65; ppl:  4.68; xent: 1.54; lr: 1.00000; 1975/2012 tok/s;   1545 sec\n",
            "[2020-06-01 20:09:49,665 INFO] Step 4650/10000; acc:  65.27; ppl:  4.78; xent: 1.56; lr: 1.00000; 1954/1988 tok/s;   1561 sec\n",
            "[2020-06-01 20:10:06,217 INFO] Step 4700/10000; acc:  64.15; ppl:  5.00; xent: 1.61; lr: 1.00000; 1907/1958 tok/s;   1578 sec\n",
            "[2020-06-01 20:10:25,352 INFO] Step 4750/10000; acc:  62.31; ppl:  5.59; xent: 1.72; lr: 1.00000; 1950/1989 tok/s;   1597 sec\n",
            "[2020-06-01 20:10:42,737 INFO] Step 4800/10000; acc:  63.88; ppl:  5.13; xent: 1.63; lr: 1.00000; 1902/1946 tok/s;   1614 sec\n",
            "[2020-06-01 20:10:59,502 INFO] Step 4850/10000; acc:  64.40; ppl:  5.04; xent: 1.62; lr: 1.00000; 1812/1842 tok/s;   1631 sec\n",
            "[2020-06-01 20:11:15,543 INFO] Step 4900/10000; acc:  66.94; ppl:  4.21; xent: 1.44; lr: 1.00000; 1924/1915 tok/s;   1647 sec\n",
            "[2020-06-01 20:11:17,776 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:11:18,119 INFO] number of examples: 26142\n",
            "[2020-06-01 20:11:32,013 INFO] Step 4950/10000; acc:  66.71; ppl:  4.35; xent: 1.47; lr: 1.00000; 1947/1940 tok/s;   1664 sec\n",
            "[2020-06-01 20:11:48,462 INFO] Step 5000/10000; acc:  66.40; ppl:  4.38; xent: 1.48; lr: 1.00000; 1971/2032 tok/s;   1680 sec\n",
            "[2020-06-01 20:11:48,492 INFO] Saving checkpoint model_step_5000.pt\n",
            "[2020-06-01 20:12:04,251 INFO] Step 5050/10000; acc:  68.25; ppl:  3.94; xent: 1.37; lr: 1.00000; 1816/1840 tok/s;   1696 sec\n",
            "[2020-06-01 20:12:22,071 INFO] Step 5100/10000; acc:  64.35; ppl:  4.93; xent: 1.60; lr: 1.00000; 1951/1954 tok/s;   1714 sec\n",
            "[2020-06-01 20:12:40,541 INFO] Step 5150/10000; acc:  64.73; ppl:  4.72; xent: 1.55; lr: 1.00000; 1946/2011 tok/s;   1732 sec\n",
            "[2020-06-01 20:12:58,311 INFO] Step 5200/10000; acc:  65.34; ppl:  4.62; xent: 1.53; lr: 1.00000; 1885/1949 tok/s;   1750 sec\n",
            "[2020-06-01 20:13:14,500 INFO] Step 5250/10000; acc:  66.05; ppl:  4.47; xent: 1.50; lr: 1.00000; 1849/1850 tok/s;   1766 sec\n",
            "[2020-06-01 20:13:31,059 INFO] Step 5300/10000; acc:  68.63; ppl:  3.82; xent: 1.34; lr: 1.00000; 1889/1903 tok/s;   1783 sec\n",
            "[2020-06-01 20:13:36,261 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:13:36,617 INFO] number of examples: 26142\n",
            "[2020-06-01 20:13:47,327 INFO] Step 5350/10000; acc:  68.72; ppl:  3.85; xent: 1.35; lr: 1.00000; 1922/1916 tok/s;   1799 sec\n",
            "[2020-06-01 20:14:04,573 INFO] Step 5400/10000; acc:  66.64; ppl:  4.23; xent: 1.44; lr: 1.00000; 1980/2029 tok/s;   1816 sec\n",
            "[2020-06-01 20:14:19,135 INFO] Step 5450/10000; acc:  70.30; ppl:  3.43; xent: 1.23; lr: 1.00000; 1942/1983 tok/s;   1831 sec\n",
            "[2020-06-01 20:14:36,840 INFO] Step 5500/10000; acc:  65.50; ppl:  4.56; xent: 1.52; lr: 1.00000; 1953/1944 tok/s;   1849 sec\n",
            "[2020-06-01 20:14:54,810 INFO] Step 5550/10000; acc:  66.57; ppl:  4.20; xent: 1.44; lr: 1.00000; 1925/2004 tok/s;   1866 sec\n",
            "[2020-06-01 20:15:12,842 INFO] Step 5600/10000; acc:  66.12; ppl:  4.33; xent: 1.47; lr: 1.00000; 1915/1975 tok/s;   1885 sec\n",
            "[2020-06-01 20:15:29,960 INFO] Step 5650/10000; acc:  67.03; ppl:  4.20; xent: 1.44; lr: 1.00000; 1860/1846 tok/s;   1902 sec\n",
            "[2020-06-01 20:15:46,021 INFO] Step 5700/10000; acc:  70.34; ppl:  3.45; xent: 1.24; lr: 1.00000; 1860/1906 tok/s;   1918 sec\n",
            "[2020-06-01 20:15:53,696 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:15:53,948 INFO] number of examples: 26142\n",
            "[2020-06-01 20:16:02,063 INFO] Step 5750/10000; acc:  70.05; ppl:  3.48; xent: 1.25; lr: 1.00000; 1951/1937 tok/s;   1934 sec\n",
            "[2020-06-01 20:16:19,046 INFO] Step 5800/10000; acc:  68.34; ppl:  3.87; xent: 1.35; lr: 1.00000; 1986/2013 tok/s;   1951 sec\n",
            "[2020-06-01 20:16:33,575 INFO] Step 5850/10000; acc:  71.82; ppl:  3.09; xent: 1.13; lr: 1.00000; 1938/1997 tok/s;   1965 sec\n",
            "[2020-06-01 20:16:50,578 INFO] Step 5900/10000; acc:  67.93; ppl:  3.97; xent: 1.38; lr: 1.00000; 1966/1957 tok/s;   1982 sec\n",
            "[2020-06-01 20:17:08,091 INFO] Step 5950/10000; acc:  67.99; ppl:  3.78; xent: 1.33; lr: 1.00000; 1890/1972 tok/s;   2000 sec\n",
            "[2020-06-01 20:17:26,224 INFO] Step 6000/10000; acc:  67.94; ppl:  3.83; xent: 1.34; lr: 1.00000; 1941/2000 tok/s;   2018 sec\n",
            "[2020-06-01 20:17:45,155 INFO] Step 6050/10000; acc:  66.50; ppl:  4.25; xent: 1.45; lr: 1.00000; 1863/1841 tok/s;   2037 sec\n",
            "[2020-06-01 20:18:00,410 INFO] Step 6100/10000; acc:  71.75; ppl:  3.14; xent: 1.15; lr: 1.00000; 1837/1924 tok/s;   2052 sec\n",
            "[2020-06-01 20:18:11,137 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:18:11,467 INFO] number of examples: 26142\n",
            "[2020-06-01 20:18:17,187 INFO] Step 6150/10000; acc:  71.30; ppl:  3.19; xent: 1.16; lr: 1.00000; 1942/1905 tok/s;   2069 sec\n",
            "[2020-06-01 20:18:33,509 INFO] Step 6200/10000; acc:  69.77; ppl:  3.52; xent: 1.26; lr: 1.00000; 1964/2003 tok/s;   2085 sec\n",
            "[2020-06-01 20:18:48,427 INFO] Step 6250/10000; acc:  72.54; ppl:  2.98; xent: 1.09; lr: 1.00000; 1952/1983 tok/s;   2100 sec\n",
            "[2020-06-01 20:19:05,178 INFO] Step 6300/10000; acc:  70.43; ppl:  3.36; xent: 1.21; lr: 1.00000; 1967/1975 tok/s;   2117 sec\n",
            "[2020-06-01 20:19:22,137 INFO] Step 6350/10000; acc:  69.93; ppl:  3.49; xent: 1.25; lr: 1.00000; 1892/1961 tok/s;   2134 sec\n",
            "[2020-06-01 20:19:41,145 INFO] Step 6400/10000; acc:  68.76; ppl:  3.68; xent: 1.30; lr: 1.00000; 1960/1993 tok/s;   2153 sec\n",
            "[2020-06-01 20:19:59,782 INFO] Step 6450/10000; acc:  68.52; ppl:  3.77; xent: 1.33; lr: 1.00000; 1839/1864 tok/s;   2171 sec\n",
            "[2020-06-01 20:20:15,365 INFO] Step 6500/10000; acc:  72.05; ppl:  3.12; xent: 1.14; lr: 1.00000; 1851/1927 tok/s;   2187 sec\n",
            "[2020-06-01 20:20:28,770 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:20:29,106 INFO] number of examples: 26142\n",
            "[2020-06-01 20:20:31,915 INFO] Step 6550/10000; acc:  72.90; ppl:  2.89; xent: 1.06; lr: 1.00000; 1918/1869 tok/s;   2204 sec\n",
            "[2020-06-01 20:20:47,077 INFO] Step 6600/10000; acc:  73.39; ppl:  2.93; xent: 1.08; lr: 1.00000; 1944/2019 tok/s;   2219 sec\n",
            "[2020-06-01 20:21:03,422 INFO] Step 6650/10000; acc:  72.23; ppl:  3.04; xent: 1.11; lr: 1.00000; 1987/1976 tok/s;   2235 sec\n",
            "[2020-06-01 20:21:20,028 INFO] Step 6700/10000; acc:  71.60; ppl:  3.12; xent: 1.14; lr: 1.00000; 1962/2018 tok/s;   2252 sec\n",
            "[2020-06-01 20:21:36,703 INFO] Step 6750/10000; acc:  71.00; ppl:  3.26; xent: 1.18; lr: 1.00000; 1886/1926 tok/s;   2268 sec\n",
            "[2020-06-01 20:21:55,668 INFO] Step 6800/10000; acc:  70.33; ppl:  3.31; xent: 1.20; lr: 1.00000; 1943/1991 tok/s;   2287 sec\n",
            "[2020-06-01 20:22:14,240 INFO] Step 6850/10000; acc:  70.46; ppl:  3.38; xent: 1.22; lr: 1.00000; 1859/1884 tok/s;   2306 sec\n",
            "[2020-06-01 20:22:29,956 INFO] Step 6900/10000; acc:  72.69; ppl:  3.01; xent: 1.10; lr: 1.00000; 1841/1881 tok/s;   2322 sec\n",
            "[2020-06-01 20:22:45,700 INFO] Step 6950/10000; acc:  74.63; ppl:  2.67; xent: 0.98; lr: 1.00000; 1912/1912 tok/s;   2337 sec\n",
            "[2020-06-01 20:22:46,722 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:22:47,045 INFO] number of examples: 26142\n",
            "[2020-06-01 20:23:02,515 INFO] Step 7000/10000; acc:  73.33; ppl:  2.91; xent: 1.07; lr: 1.00000; 1937/1943 tok/s;   2354 sec\n",
            "[2020-06-01 20:23:18,931 INFO] Step 7050/10000; acc:  73.73; ppl:  2.82; xent: 1.04; lr: 1.00000; 1975/2016 tok/s;   2371 sec\n",
            "[2020-06-01 20:23:34,380 INFO] Step 7100/10000; acc:  74.25; ppl:  2.71; xent: 1.00; lr: 1.00000; 1963/1978 tok/s;   2386 sec\n",
            "[2020-06-01 20:23:51,431 INFO] Step 7150/10000; acc:  72.59; ppl:  3.01; xent: 1.10; lr: 1.00000; 1900/1941 tok/s;   2403 sec\n",
            "[2020-06-01 20:24:10,947 INFO] Step 7200/10000; acc:  71.26; ppl:  3.18; xent: 1.16; lr: 1.00000; 1939/1979 tok/s;   2423 sec\n",
            "[2020-06-01 20:24:27,923 INFO] Step 7250/10000; acc:  73.45; ppl:  2.82; xent: 1.04; lr: 1.00000; 1888/1951 tok/s;   2440 sec\n",
            "[2020-06-01 20:24:44,645 INFO] Step 7300/10000; acc:  72.27; ppl:  3.06; xent: 1.12; lr: 1.00000; 1811/1842 tok/s;   2456 sec\n",
            "[2020-06-01 20:25:01,282 INFO] Step 7350/10000; acc:  75.43; ppl:  2.56; xent: 0.94; lr: 1.00000; 1904/1891 tok/s;   2473 sec\n",
            "[2020-06-01 20:25:04,686 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:25:05,030 INFO] number of examples: 26142\n",
            "[2020-06-01 20:25:17,581 INFO] Step 7400/10000; acc:  75.56; ppl:  2.56; xent: 0.94; lr: 1.00000; 1932/1927 tok/s;   2489 sec\n",
            "[2020-06-01 20:25:34,466 INFO] Step 7450/10000; acc:  74.16; ppl:  2.76; xent: 1.01; lr: 1.00000; 1984/2023 tok/s;   2506 sec\n",
            "[2020-06-01 20:25:48,886 INFO] Step 7500/10000; acc:  77.23; ppl:  2.35; xent: 0.85; lr: 1.00000; 1926/1968 tok/s;   2521 sec\n",
            "[2020-06-01 20:26:07,106 INFO] Step 7550/10000; acc:  71.90; ppl:  3.06; xent: 1.12; lr: 1.00000; 1943/1954 tok/s;   2539 sec\n",
            "[2020-06-01 20:26:25,541 INFO] Step 7600/10000; acc:  73.43; ppl:  2.82; xent: 1.04; lr: 1.00000; 1935/1999 tok/s;   2557 sec\n",
            "[2020-06-01 20:26:43,438 INFO] Step 7650/10000; acc:  73.27; ppl:  2.83; xent: 1.04; lr: 1.00000; 1875/1944 tok/s;   2575 sec\n",
            "[2020-06-01 20:26:59,641 INFO] Step 7700/10000; acc:  74.07; ppl:  2.80; xent: 1.03; lr: 1.00000; 1851/1847 tok/s;   2591 sec\n",
            "[2020-06-01 20:27:16,115 INFO] Step 7750/10000; acc:  77.12; ppl:  2.39; xent: 0.87; lr: 1.00000; 1883/1899 tok/s;   2608 sec\n",
            "[2020-06-01 20:27:22,526 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:27:22,876 INFO] number of examples: 26142\n",
            "[2020-06-01 20:27:32,348 INFO] Step 7800/10000; acc:  77.04; ppl:  2.37; xent: 0.86; lr: 1.00000; 1940/1921 tok/s;   2624 sec\n",
            "[2020-06-01 20:27:49,733 INFO] Step 7850/10000; acc:  74.23; ppl:  2.71; xent: 1.00; lr: 1.00000; 1962/2018 tok/s;   2641 sec\n",
            "[2020-06-01 20:28:04,318 INFO] Step 7900/10000; acc:  78.76; ppl:  2.18; xent: 0.78; lr: 1.00000; 1917/1975 tok/s;   2656 sec\n",
            "[2020-06-01 20:28:21,912 INFO] Step 7950/10000; acc:  73.83; ppl:  2.80; xent: 1.03; lr: 1.00000; 1954/1929 tok/s;   2674 sec\n",
            "[2020-06-01 20:28:39,436 INFO] Step 8000/10000; acc:  75.09; ppl:  2.60; xent: 0.95; lr: 1.00000; 1901/1999 tok/s;   2691 sec\n",
            "[2020-06-01 20:28:57,894 INFO] Step 8050/10000; acc:  74.47; ppl:  2.71; xent: 1.00; lr: 1.00000; 1933/1977 tok/s;   2710 sec\n",
            "[2020-06-01 20:29:15,486 INFO] Step 8100/10000; acc:  74.93; ppl:  2.66; xent: 0.98; lr: 1.00000; 1868/1843 tok/s;   2727 sec\n",
            "[2020-06-01 20:29:30,958 INFO] Step 8150/10000; acc:  78.13; ppl:  2.27; xent: 0.82; lr: 1.00000; 1832/1931 tok/s;   2743 sec\n",
            "[2020-06-01 20:29:40,337 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:29:40,688 INFO] number of examples: 26142\n",
            "[2020-06-01 20:29:47,596 INFO] Step 8200/10000; acc:  77.96; ppl:  2.23; xent: 0.80; lr: 1.00000; 1927/1897 tok/s;   2759 sec\n",
            "[2020-06-01 20:30:04,384 INFO] Step 8250/10000; acc:  75.81; ppl:  2.55; xent: 0.94; lr: 1.00000; 1982/1998 tok/s;   2776 sec\n",
            "[2020-06-01 20:30:18,932 INFO] Step 8300/10000; acc:  79.67; ppl:  2.09; xent: 0.74; lr: 1.00000; 1931/1980 tok/s;   2791 sec\n",
            "[2020-06-01 20:30:35,818 INFO] Step 8350/10000; acc:  76.20; ppl:  2.49; xent: 0.91; lr: 1.00000; 1963/1975 tok/s;   2807 sec\n",
            "[2020-06-01 20:30:53,225 INFO] Step 8400/10000; acc:  76.17; ppl:  2.44; xent: 0.89; lr: 1.00000; 1900/1942 tok/s;   2825 sec\n",
            "[2020-06-01 20:31:12,015 INFO] Step 8450/10000; acc:  75.81; ppl:  2.51; xent: 0.92; lr: 1.00000; 1944/2012 tok/s;   2844 sec\n",
            "[2020-06-01 20:31:31,035 INFO] Step 8500/10000; acc:  74.32; ppl:  2.73; xent: 1.01; lr: 1.00000; 1849/1833 tok/s;   2863 sec\n",
            "[2020-06-01 20:31:46,302 INFO] Step 8550/10000; acc:  79.77; ppl:  2.11; xent: 0.75; lr: 1.00000; 1831/1924 tok/s;   2878 sec\n",
            "[2020-06-01 20:31:58,227 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:31:58,582 INFO] number of examples: 26142\n",
            "[2020-06-01 20:32:03,272 INFO] Step 8600/10000; acc:  79.10; ppl:  2.13; xent: 0.75; lr: 1.00000; 1935/1898 tok/s;   2895 sec\n",
            "[2020-06-01 20:32:18,325 INFO] Step 8650/10000; acc:  79.18; ppl:  2.16; xent: 0.77; lr: 1.00000; 1954/2006 tok/s;   2910 sec\n",
            "[2020-06-01 20:32:34,414 INFO] Step 8700/10000; acc:  78.56; ppl:  2.20; xent: 0.79; lr: 1.00000; 1951/1978 tok/s;   2926 sec\n",
            "[2020-06-01 20:32:51,292 INFO] Step 8750/10000; acc:  77.92; ppl:  2.29; xent: 0.83; lr: 1.00000; 1956/1981 tok/s;   2943 sec\n",
            "[2020-06-01 20:33:08,119 INFO] Step 8800/10000; acc:  77.41; ppl:  2.34; xent: 0.85; lr: 1.00000; 1899/1950 tok/s;   2960 sec\n",
            "[2020-06-01 20:33:26,636 INFO] Step 8850/10000; acc:  77.13; ppl:  2.34; xent: 0.85; lr: 1.00000; 1967/2004 tok/s;   2978 sec\n",
            "[2020-06-01 20:33:45,923 INFO] Step 8900/10000; acc:  75.81; ppl:  2.53; xent: 0.93; lr: 1.00000; 1837/1867 tok/s;   2998 sec\n",
            "[2020-06-01 20:34:00,579 INFO] Step 8950/10000; acc:  80.07; ppl:  2.09; xent: 0.74; lr: 1.00000; 1864/1923 tok/s;   3012 sec\n",
            "[2020-06-01 20:34:16,031 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:34:16,409 INFO] number of examples: 26142\n",
            "[2020-06-01 20:34:17,202 INFO] Step 9000/10000; acc:  80.43; ppl:  2.02; xent: 0.71; lr: 1.00000; 1895/1853 tok/s;   3029 sec\n",
            "[2020-06-01 20:34:33,715 INFO] Step 9050/10000; acc:  79.60; ppl:  2.12; xent: 0.75; lr: 1.00000; 1957/2006 tok/s;   3045 sec\n",
            "[2020-06-01 20:34:49,616 INFO] Step 9100/10000; acc:  79.77; ppl:  2.10; xent: 0.74; lr: 1.00000; 1970/1995 tok/s;   3061 sec\n",
            "[2020-06-01 20:35:05,809 INFO] Step 9150/10000; acc:  79.44; ppl:  2.11; xent: 0.75; lr: 1.00000; 1952/1990 tok/s;   3077 sec\n",
            "[2020-06-01 20:35:22,706 INFO] Step 9200/10000; acc:  78.49; ppl:  2.21; xent: 0.79; lr: 1.00000; 1909/1950 tok/s;   3094 sec\n",
            "[2020-06-01 20:35:41,577 INFO] Step 9250/10000; acc:  77.53; ppl:  2.31; xent: 0.84; lr: 1.00000; 1934/1979 tok/s;   3113 sec\n",
            "[2020-06-01 20:35:59,406 INFO] Step 9300/10000; acc:  78.13; ppl:  2.27; xent: 0.82; lr: 1.00000; 1898/1946 tok/s;   3131 sec\n",
            "[2020-06-01 20:36:15,957 INFO] Step 9350/10000; acc:  78.82; ppl:  2.19; xent: 0.78; lr: 1.00000; 1797/1830 tok/s;   3148 sec\n",
            "[2020-06-01 20:36:31,965 INFO] Step 9400/10000; acc:  81.58; ppl:  1.91; xent: 0.65; lr: 1.00000; 1924/1907 tok/s;   3164 sec\n",
            "[2020-06-01 20:36:33,962 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:36:34,216 INFO] number of examples: 26142\n",
            "[2020-06-01 20:36:48,415 INFO] Step 9450/10000; acc:  81.02; ppl:  1.97; xent: 0.68; lr: 1.00000; 1934/1931 tok/s;   3180 sec\n",
            "[2020-06-01 20:37:05,340 INFO] Step 9500/10000; acc:  79.99; ppl:  2.09; xent: 0.74; lr: 1.00000; 1972/2027 tok/s;   3197 sec\n",
            "[2020-06-01 20:37:20,237 INFO] Step 9550/10000; acc:  81.58; ppl:  1.94; xent: 0.66; lr: 1.00000; 1942/1960 tok/s;   3212 sec\n",
            "[2020-06-01 20:37:37,743 INFO] Step 9600/10000; acc:  79.35; ppl:  2.16; xent: 0.77; lr: 1.00000; 1924/1945 tok/s;   3229 sec\n",
            "[2020-06-01 20:37:56,522 INFO] Step 9650/10000; acc:  78.96; ppl:  2.17; xent: 0.77; lr: 1.00000; 1937/2002 tok/s;   3248 sec\n",
            "[2020-06-01 20:38:14,172 INFO] Step 9700/10000; acc:  79.45; ppl:  2.11; xent: 0.75; lr: 1.00000; 1880/1936 tok/s;   3266 sec\n",
            "[2020-06-01 20:38:30,505 INFO] Step 9750/10000; acc:  80.04; ppl:  2.11; xent: 0.75; lr: 1.00000; 1833/1846 tok/s;   3282 sec\n",
            "[2020-06-01 20:38:47,191 INFO] Step 9800/10000; acc:  82.24; ppl:  1.88; xent: 0.63; lr: 1.00000; 1880/1884 tok/s;   3299 sec\n",
            "[2020-06-01 20:38:51,956 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:38:52,220 INFO] number of examples: 26142\n",
            "[2020-06-01 20:39:03,354 INFO] Step 9850/10000; acc:  82.74; ppl:  1.83; xent: 0.60; lr: 1.00000; 1948/1940 tok/s;   3315 sec\n",
            "[2020-06-01 20:39:20,366 INFO] Step 9900/10000; acc:  80.10; ppl:  2.08; xent: 0.73; lr: 1.00000; 1965/2021 tok/s;   3332 sec\n",
            "[2020-06-01 20:39:35,073 INFO] Step 9950/10000; acc:  83.41; ppl:  1.78; xent: 0.58; lr: 1.00000; 1928/1970 tok/s;   3347 sec\n",
            "[2020-06-01 20:39:52,949 INFO] Step 10000/10000; acc:  79.27; ppl:  2.16; xent: 0.77; lr: 1.00000; 1945/1939 tok/s;   3365 sec\n",
            "[2020-06-01 20:39:52,949 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 20:39:53,416 INFO] number of examples: 276\n",
            "[2020-06-01 20:39:55,044 INFO] Validation perplexity: 47.844\n",
            "[2020-06-01 20:39:55,044 INFO] Validation accuracy: 49.6266\n",
            "[2020-06-01 20:39:55,073 INFO] Saving checkpoint model_step_10000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUZNKV1yaN1-",
        "colab_type": "code",
        "outputId": "7cd3e31a-3fd9-4c5a-9c6e-691f1ae6fcbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "en - st"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3384.543745279312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp_-dlCaa74U",
        "colab_type": "code",
        "outputId": "bb098afb-3716-49ab-f67d-bdd6563eceff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "st = time.time()\n",
        "!python OpenNMT-py/train.py -data En2Fa-Translation/Cleaned -world_size 1 -gpu_rank 0 --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 10000\n",
        "en = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 20:40:04,994 INFO]  * src vocab size = 3116\n",
            "[2020-06-01 20:40:04,994 INFO]  * tgt vocab size = 5908\n",
            "[2020-06-01 20:40:04,994 INFO] Building model...\n",
            "[2020-06-01 20:40:08,052 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3116, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5908, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=5908, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-01 20:40:08,053 INFO] encoder: 9938416\n",
            "[2020-06-01 20:40:08,053 INFO] decoder: 16200228\n",
            "[2020-06-01 20:40:08,053 INFO] * number of parameters: 26138644\n",
            "[2020-06-01 20:40:08,057 INFO] Starting training on GPU: [0]\n",
            "[2020-06-01 20:40:08,057 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-01 20:40:08,058 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:40:08,446 INFO] number of examples: 26142\n",
            "[2020-06-01 20:40:14,998 INFO] Step 50/10000; acc:   7.04; ppl: 74501.70; xent: 11.22; lr: 1.00000; 4480/4386 tok/s;      7 sec\n",
            "[2020-06-01 20:40:21,692 INFO] Step 100/10000; acc:   7.06; ppl: 3472.25; xent: 8.15; lr: 1.00000; 4881/4869 tok/s;     14 sec\n",
            "[2020-06-01 20:40:28,345 INFO] Step 150/10000; acc:   7.34; ppl: 763.11; xent: 6.64; lr: 1.00000; 4810/5099 tok/s;     20 sec\n",
            "[2020-06-01 20:40:34,821 INFO] Step 200/10000; acc:   8.03; ppl: 464.38; xent: 6.14; lr: 1.00000; 5106/5103 tok/s;     27 sec\n",
            "[2020-06-01 20:40:41,539 INFO] Step 250/10000; acc:   8.05; ppl: 335.77; xent: 5.82; lr: 1.00000; 5074/5095 tok/s;     33 sec\n",
            "[2020-06-01 20:40:48,005 INFO] Step 300/10000; acc:   8.97; ppl: 315.79; xent: 5.76; lr: 1.00000; 4930/5069 tok/s;     40 sec\n",
            "[2020-06-01 20:40:54,189 INFO] Step 350/10000; acc:  15.54; ppl: 202.30; xent: 5.31; lr: 1.00000; 4875/5072 tok/s;     46 sec\n",
            "[2020-06-01 20:41:00,872 INFO] Step 400/10000; acc:  14.91; ppl: 203.81; xent: 5.32; lr: 1.00000; 4885/4987 tok/s;     53 sec\n",
            "[2020-06-01 20:41:02,273 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:41:02,609 INFO] number of examples: 26142\n",
            "[2020-06-01 20:41:07,719 INFO] Step 450/10000; acc:  16.61; ppl: 159.77; xent: 5.07; lr: 1.00000; 4681/4569 tok/s;     60 sec\n",
            "[2020-06-01 20:41:13,903 INFO] Step 500/10000; acc:  18.25; ppl: 134.41; xent: 4.90; lr: 1.00000; 4976/4939 tok/s;     66 sec\n",
            "[2020-06-01 20:41:20,918 INFO] Step 550/10000; acc:  16.53; ppl: 148.35; xent: 5.00; lr: 1.00000; 4804/4999 tok/s;     73 sec\n",
            "[2020-06-01 20:41:27,482 INFO] Step 600/10000; acc:  18.24; ppl: 126.08; xent: 4.84; lr: 1.00000; 4989/5232 tok/s;     79 sec\n",
            "[2020-06-01 20:41:34,193 INFO] Step 650/10000; acc:  20.24; ppl: 114.32; xent: 4.74; lr: 1.00000; 5163/5112 tok/s;     86 sec\n",
            "[2020-06-01 20:41:40,419 INFO] Step 700/10000; acc:  21.64; ppl: 100.36; xent: 4.61; lr: 1.00000; 4987/5053 tok/s;     92 sec\n",
            "[2020-06-01 20:41:46,663 INFO] Step 750/10000; acc:  23.00; ppl: 90.01; xent: 4.50; lr: 1.00000; 4983/5148 tok/s;     99 sec\n",
            "[2020-06-01 20:41:53,508 INFO] Step 800/10000; acc:  21.19; ppl: 104.85; xent: 4.65; lr: 1.00000; 4890/4993 tok/s;    105 sec\n",
            "[2020-06-01 20:41:55,881 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:41:56,117 INFO] number of examples: 26142\n",
            "[2020-06-01 20:42:00,107 INFO] Step 850/10000; acc:  25.06; ppl: 80.57; xent: 4.39; lr: 1.00000; 4658/4547 tok/s;    112 sec\n",
            "[2020-06-01 20:42:06,360 INFO] Step 900/10000; acc:  25.48; ppl: 75.89; xent: 4.33; lr: 1.00000; 4974/4937 tok/s;    118 sec\n",
            "[2020-06-01 20:42:12,984 INFO] Step 950/10000; acc:  24.66; ppl: 78.55; xent: 4.36; lr: 1.00000; 4840/5065 tok/s;    125 sec\n",
            "[2020-06-01 20:42:20,108 INFO] Step 1000/10000; acc:  25.11; ppl: 74.44; xent: 4.31; lr: 1.00000; 4938/5142 tok/s;    132 sec\n",
            "[2020-06-01 20:42:26,718 INFO] Step 1050/10000; acc:  26.78; ppl: 68.07; xent: 4.22; lr: 1.00000; 5165/5117 tok/s;    139 sec\n",
            "[2020-06-01 20:42:32,881 INFO] Step 1100/10000; acc:  27.79; ppl: 61.86; xent: 4.12; lr: 1.00000; 5048/5060 tok/s;    145 sec\n",
            "[2020-06-01 20:42:39,018 INFO] Step 1150/10000; acc:  29.31; ppl: 55.98; xent: 4.02; lr: 1.00000; 4939/5181 tok/s;    151 sec\n",
            "[2020-06-01 20:42:45,826 INFO] Step 1200/10000; acc:  27.30; ppl: 65.03; xent: 4.17; lr: 1.00000; 4901/4951 tok/s;    158 sec\n",
            "[2020-06-01 20:42:49,477 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:42:49,729 INFO] number of examples: 26142\n",
            "[2020-06-01 20:42:52,474 INFO] Step 1250/10000; acc:  30.03; ppl: 54.84; xent: 4.00; lr: 1.00000; 4660/4685 tok/s;    164 sec\n",
            "[2020-06-01 20:42:58,802 INFO] Step 1300/10000; acc:  31.42; ppl: 50.79; xent: 3.93; lr: 1.00000; 4980/4898 tok/s;    171 sec\n",
            "[2020-06-01 20:43:05,450 INFO] Step 1350/10000; acc:  30.55; ppl: 51.75; xent: 3.95; lr: 1.00000; 4890/5048 tok/s;    177 sec\n",
            "[2020-06-01 20:43:12,275 INFO] Step 1400/10000; acc:  31.46; ppl: 48.90; xent: 3.89; lr: 1.00000; 4920/5119 tok/s;    184 sec\n",
            "[2020-06-01 20:43:19,236 INFO] Step 1450/10000; acc:  31.12; ppl: 48.76; xent: 3.89; lr: 1.00000; 5180/5166 tok/s;    191 sec\n",
            "[2020-06-01 20:43:25,094 INFO] Step 1500/10000; acc:  35.34; ppl: 37.94; xent: 3.64; lr: 1.00000; 4993/5049 tok/s;    197 sec\n",
            "[2020-06-01 20:43:31,426 INFO] Step 1550/10000; acc:  33.93; ppl: 41.57; xent: 3.73; lr: 1.00000; 4944/5183 tok/s;    203 sec\n",
            "[2020-06-01 20:43:37,400 INFO] Step 1600/10000; acc:  34.93; ppl: 38.79; xent: 3.66; lr: 1.00000; 4970/5003 tok/s;    209 sec\n",
            "[2020-06-01 20:43:42,955 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:43:43,294 INFO] number of examples: 26142\n",
            "[2020-06-01 20:43:44,920 INFO] Step 1650/10000; acc:  32.08; ppl: 45.74; xent: 3.82; lr: 1.00000; 4534/4611 tok/s;    217 sec\n",
            "[2020-06-01 20:43:51,329 INFO] Step 1700/10000; acc:  35.19; ppl: 37.36; xent: 3.62; lr: 1.00000; 5009/4905 tok/s;    223 sec\n",
            "[2020-06-01 20:43:57,924 INFO] Step 1750/10000; acc:  34.41; ppl: 39.00; xent: 3.66; lr: 1.00000; 4899/4993 tok/s;    230 sec\n",
            "[2020-06-01 20:44:04,637 INFO] Step 1800/10000; acc:  35.53; ppl: 35.72; xent: 3.58; lr: 1.00000; 4926/5106 tok/s;    237 sec\n",
            "[2020-06-01 20:44:11,219 INFO] Step 1850/10000; acc:  36.21; ppl: 33.81; xent: 3.52; lr: 1.00000; 5124/5222 tok/s;    243 sec\n",
            "[2020-06-01 20:44:17,589 INFO] Step 1900/10000; acc:  37.68; ppl: 32.01; xent: 3.47; lr: 1.00000; 5058/5033 tok/s;    250 sec\n",
            "[2020-06-01 20:44:23,839 INFO] Step 1950/10000; acc:  38.36; ppl: 30.41; xent: 3.41; lr: 1.00000; 4947/5150 tok/s;    256 sec\n",
            "[2020-06-01 20:44:30,148 INFO] Step 2000/10000; acc:  37.77; ppl: 31.11; xent: 3.44; lr: 1.00000; 5043/5130 tok/s;    262 sec\n",
            "[2020-06-01 20:44:36,571 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:44:36,900 INFO] number of examples: 26142\n",
            "[2020-06-01 20:44:37,537 INFO] Step 2050/10000; acc:  36.80; ppl: 33.00; xent: 3.50; lr: 1.00000; 4493/4602 tok/s;    269 sec\n",
            "[2020-06-01 20:44:43,732 INFO] Step 2100/10000; acc:  39.41; ppl: 28.21; xent: 3.34; lr: 1.00000; 4988/4885 tok/s;    276 sec\n",
            "[2020-06-01 20:44:50,630 INFO] Step 2150/10000; acc:  36.98; ppl: 32.61; xent: 3.48; lr: 1.00000; 4996/4982 tok/s;    283 sec\n",
            "[2020-06-01 20:44:57,146 INFO] Step 2200/10000; acc:  39.04; ppl: 27.42; xent: 3.31; lr: 1.00000; 4829/5083 tok/s;    289 sec\n",
            "[2020-06-01 20:45:03,639 INFO] Step 2250/10000; acc:  39.12; ppl: 27.04; xent: 3.30; lr: 1.00000; 5184/5246 tok/s;    296 sec\n",
            "[2020-06-01 20:45:09,995 INFO] Step 2300/10000; acc:  39.87; ppl: 26.38; xent: 3.27; lr: 1.00000; 5046/5076 tok/s;    302 sec\n",
            "[2020-06-01 20:45:16,429 INFO] Step 2350/10000; acc:  40.36; ppl: 26.37; xent: 3.27; lr: 1.00000; 4979/5123 tok/s;    308 sec\n",
            "[2020-06-01 20:45:22,649 INFO] Step 2400/10000; acc:  40.91; ppl: 24.29; xent: 3.19; lr: 1.00000; 4981/5133 tok/s;    315 sec\n",
            "[2020-06-01 20:45:29,468 INFO] Step 2450/10000; acc:  38.69; ppl: 27.75; xent: 3.32; lr: 1.00000; 4813/4852 tok/s;    321 sec\n",
            "[2020-06-01 20:45:30,085 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:45:30,395 INFO] number of examples: 26142\n",
            "[2020-06-01 20:45:36,041 INFO] Step 2500/10000; acc:  41.44; ppl: 23.76; xent: 3.17; lr: 1.00000; 4721/4678 tok/s;    328 sec\n",
            "[2020-06-01 20:45:42,338 INFO] Step 2550/10000; acc:  41.15; ppl: 24.17; xent: 3.19; lr: 1.00000; 5070/5019 tok/s;    334 sec\n",
            "[2020-06-01 20:45:49,404 INFO] Step 2600/10000; acc:  39.54; ppl: 25.89; xent: 3.25; lr: 1.00000; 4787/5048 tok/s;    341 sec\n",
            "[2020-06-01 20:45:55,761 INFO] Step 2650/10000; acc:  42.20; ppl: 21.77; xent: 3.08; lr: 1.00000; 5092/5203 tok/s;    348 sec\n",
            "[2020-06-01 20:46:02,385 INFO] Step 2700/10000; acc:  41.50; ppl: 23.06; xent: 3.14; lr: 1.00000; 5059/5097 tok/s;    354 sec\n",
            "[2020-06-01 20:46:08,614 INFO] Step 2750/10000; acc:  42.72; ppl: 21.68; xent: 3.08; lr: 1.00000; 5025/5081 tok/s;    361 sec\n",
            "[2020-06-01 20:46:15,091 INFO] Step 2800/10000; acc:  42.44; ppl: 21.06; xent: 3.05; lr: 1.00000; 4971/5146 tok/s;    367 sec\n",
            "[2020-06-01 20:46:21,831 INFO] Step 2850/10000; acc:  40.27; ppl: 24.22; xent: 3.19; lr: 1.00000; 4929/4992 tok/s;    374 sec\n",
            "[2020-06-01 20:46:23,548 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:46:23,867 INFO] number of examples: 26142\n",
            "[2020-06-01 20:46:28,518 INFO] Step 2900/10000; acc:  43.54; ppl: 20.36; xent: 3.01; lr: 1.00000; 4692/4609 tok/s;    380 sec\n",
            "[2020-06-01 20:46:34,658 INFO] Step 2950/10000; acc:  44.32; ppl: 19.21; xent: 2.96; lr: 1.00000; 4922/4905 tok/s;    387 sec\n",
            "[2020-06-01 20:46:41,413 INFO] Step 3000/10000; acc:  42.24; ppl: 21.41; xent: 3.06; lr: 1.00000; 4899/5120 tok/s;    393 sec\n",
            "[2020-06-01 20:46:48,289 INFO] Step 3050/10000; acc:  42.90; ppl: 20.09; xent: 3.00; lr: 1.00000; 4953/5151 tok/s;    400 sec\n",
            "[2020-06-01 20:46:54,993 INFO] Step 3100/10000; acc:  43.10; ppl: 20.07; xent: 3.00; lr: 1.00000; 5159/5118 tok/s;    407 sec\n",
            "[2020-06-01 20:47:01,136 INFO] Step 3150/10000; acc:  44.38; ppl: 18.56; xent: 2.92; lr: 1.00000; 5054/5048 tok/s;    413 sec\n",
            "[2020-06-01 20:47:07,285 INFO] Step 3200/10000; acc:  45.77; ppl: 16.73; xent: 2.82; lr: 1.00000; 4874/5134 tok/s;    419 sec\n",
            "[2020-06-01 20:47:14,056 INFO] Step 3250/10000; acc:  42.55; ppl: 20.43; xent: 3.02; lr: 1.00000; 4931/5003 tok/s;    426 sec\n",
            "[2020-06-01 20:47:17,075 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:47:17,400 INFO] number of examples: 26142\n",
            "[2020-06-01 20:47:20,595 INFO] Step 3300/10000; acc:  45.61; ppl: 17.11; xent: 2.84; lr: 1.00000; 4610/4576 tok/s;    433 sec\n",
            "[2020-06-01 20:47:27,066 INFO] Step 3350/10000; acc:  45.06; ppl: 17.64; xent: 2.87; lr: 1.00000; 4950/4909 tok/s;    439 sec\n",
            "[2020-06-01 20:47:33,636 INFO] Step 3400/10000; acc:  44.32; ppl: 17.93; xent: 2.89; lr: 1.00000; 4908/5052 tok/s;    446 sec\n",
            "[2020-06-01 20:47:40,825 INFO] Step 3450/10000; acc:  43.92; ppl: 18.27; xent: 2.91; lr: 1.00000; 4947/5136 tok/s;    453 sec\n",
            "[2020-06-01 20:47:47,478 INFO] Step 3500/10000; acc:  45.17; ppl: 16.99; xent: 2.83; lr: 1.00000; 5131/5136 tok/s;    459 sec\n",
            "[2020-06-01 20:47:53,402 INFO] Step 3550/10000; acc:  47.25; ppl: 14.86; xent: 2.70; lr: 1.00000; 5067/5054 tok/s;    465 sec\n",
            "[2020-06-01 20:47:59,607 INFO] Step 3600/10000; acc:  47.25; ppl: 15.09; xent: 2.71; lr: 1.00000; 4854/5162 tok/s;    472 sec\n",
            "[2020-06-01 20:48:06,318 INFO] Step 3650/10000; acc:  44.37; ppl: 17.73; xent: 2.88; lr: 1.00000; 4980/4982 tok/s;    478 sec\n",
            "[2020-06-01 20:48:10,659 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:48:10,988 INFO] number of examples: 26142\n",
            "[2020-06-01 20:48:13,185 INFO] Step 3700/10000; acc:  46.36; ppl: 15.32; xent: 2.73; lr: 1.00000; 4548/4637 tok/s;    485 sec\n",
            "[2020-06-01 20:48:19,641 INFO] Step 3750/10000; acc:  45.80; ppl: 15.87; xent: 2.76; lr: 1.00000; 5051/4890 tok/s;    492 sec\n",
            "[2020-06-01 20:48:26,267 INFO] Step 3800/10000; acc:  46.36; ppl: 15.26; xent: 2.73; lr: 1.00000; 4868/5033 tok/s;    498 sec\n",
            "[2020-06-01 20:48:32,922 INFO] Step 3850/10000; acc:  47.03; ppl: 14.63; xent: 2.68; lr: 1.00000; 4921/5097 tok/s;    505 sec\n",
            "[2020-06-01 20:48:39,571 INFO] Step 3900/10000; acc:  46.81; ppl: 14.58; xent: 2.68; lr: 1.00000; 5149/5224 tok/s;    512 sec\n",
            "[2020-06-01 20:48:45,851 INFO] Step 3950/10000; acc:  48.20; ppl: 13.79; xent: 2.62; lr: 1.00000; 5019/5023 tok/s;    518 sec\n",
            "[2020-06-01 20:48:52,219 INFO] Step 4000/10000; acc:  47.89; ppl: 13.86; xent: 2.63; lr: 1.00000; 4996/5175 tok/s;    524 sec\n",
            "[2020-06-01 20:48:58,352 INFO] Step 4050/10000; acc:  48.51; ppl: 13.16; xent: 2.58; lr: 1.00000; 4945/5021 tok/s;    530 sec\n",
            "[2020-06-01 20:49:04,241 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:49:04,583 INFO] number of examples: 26142\n",
            "[2020-06-01 20:49:05,736 INFO] Step 4100/10000; acc:  45.70; ppl: 15.36; xent: 2.73; lr: 1.00000; 4551/4629 tok/s;    538 sec\n",
            "[2020-06-01 20:49:11,880 INFO] Step 4150/10000; acc:  48.82; ppl: 12.93; xent: 2.56; lr: 1.00000; 4946/4878 tok/s;    544 sec\n",
            "[2020-06-01 20:49:18,761 INFO] Step 4200/10000; acc:  47.13; ppl: 14.26; xent: 2.66; lr: 1.00000; 4925/4988 tok/s;    551 sec\n",
            "[2020-06-01 20:49:25,412 INFO] Step 4250/10000; acc:  48.57; ppl: 13.00; xent: 2.57; lr: 1.00000; 4895/5087 tok/s;    557 sec\n",
            "[2020-06-01 20:49:32,078 INFO] Step 4300/10000; acc:  47.96; ppl: 13.07; xent: 2.57; lr: 1.00000; 5146/5232 tok/s;    564 sec\n",
            "[2020-06-01 20:49:38,278 INFO] Step 4350/10000; acc:  49.77; ppl: 12.18; xent: 2.50; lr: 1.00000; 5021/4969 tok/s;    570 sec\n",
            "[2020-06-01 20:49:44,652 INFO] Step 4400/10000; acc:  49.74; ppl: 12.24; xent: 2.50; lr: 1.00000; 4982/5175 tok/s;    577 sec\n",
            "[2020-06-01 20:49:50,942 INFO] Step 4450/10000; acc:  49.86; ppl: 11.79; xent: 2.47; lr: 1.00000; 4987/5107 tok/s;    583 sec\n",
            "[2020-06-01 20:49:57,905 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:49:58,256 INFO] number of examples: 26142\n",
            "[2020-06-01 20:49:58,441 INFO] Step 4500/10000; acc:  47.17; ppl: 14.03; xent: 2.64; lr: 1.00000; 4479/4599 tok/s;    590 sec\n",
            "[2020-06-01 20:50:04,624 INFO] Step 4550/10000; acc:  50.00; ppl: 11.66; xent: 2.46; lr: 1.00000; 5029/4905 tok/s;    597 sec\n",
            "[2020-06-01 20:50:11,348 INFO] Step 4600/10000; acc:  49.02; ppl: 12.55; xent: 2.53; lr: 1.00000; 4964/4965 tok/s;    603 sec\n",
            "[2020-06-01 20:50:17,807 INFO] Step 4650/10000; acc:  50.41; ppl: 11.28; xent: 2.42; lr: 1.00000; 4845/5130 tok/s;    610 sec\n",
            "[2020-06-01 20:50:24,346 INFO] Step 4700/10000; acc:  50.16; ppl: 11.11; xent: 2.41; lr: 1.00000; 5165/5156 tok/s;    616 sec\n",
            "[2020-06-01 20:50:31,015 INFO] Step 4750/10000; acc:  49.83; ppl: 11.77; xent: 2.47; lr: 1.00000; 5091/5117 tok/s;    623 sec\n",
            "[2020-06-01 20:50:37,400 INFO] Step 4800/10000; acc:  51.28; ppl: 11.01; xent: 2.40; lr: 1.00000; 4912/5064 tok/s;    629 sec\n",
            "[2020-06-01 20:50:43,521 INFO] Step 4850/10000; acc:  52.34; ppl:  9.96; xent: 2.30; lr: 1.00000; 4936/5103 tok/s;    635 sec\n",
            "[2020-06-01 20:50:50,220 INFO] Step 4900/10000; acc:  48.46; ppl: 12.55; xent: 2.53; lr: 1.00000; 4883/4990 tok/s;    642 sec\n",
            "[2020-06-01 20:50:51,529 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:50:51,882 INFO] number of examples: 26142\n",
            "[2020-06-01 20:50:57,072 INFO] Step 4950/10000; acc:  51.70; ppl: 10.43; xent: 2.34; lr: 1.00000; 4659/4580 tok/s;    649 sec\n",
            "[2020-06-01 20:51:03,299 INFO] Step 5000/10000; acc:  52.36; ppl: 10.01; xent: 2.30; lr: 1.00000; 4992/4951 tok/s;    655 sec\n",
            "[2020-06-01 20:51:03,330 INFO] Saving checkpoint model_step_5000.pt\n",
            "[2020-06-01 20:51:10,709 INFO] Step 5050/10000; acc:  49.63; ppl: 11.52; xent: 2.44; lr: 1.00000; 4565/4737 tok/s;    663 sec\n",
            "[2020-06-01 20:51:17,199 INFO] Step 5100/10000; acc:  52.22; ppl:  9.82; xent: 2.28; lr: 1.00000; 4947/5192 tok/s;    669 sec\n",
            "[2020-06-01 20:51:23,976 INFO] Step 5150/10000; acc:  51.11; ppl: 10.60; xent: 2.36; lr: 1.00000; 5180/5120 tok/s;    676 sec\n",
            "[2020-06-01 20:51:30,215 INFO] Step 5200/10000; acc:  52.94; ppl:  9.64; xent: 2.27; lr: 1.00000; 4966/5042 tok/s;    682 sec\n",
            "[2020-06-01 20:51:36,601 INFO] Step 5250/10000; acc:  53.28; ppl:  9.24; xent: 2.22; lr: 1.00000; 4962/5072 tok/s;    689 sec\n",
            "[2020-06-01 20:51:43,552 INFO] Step 5300/10000; acc:  49.96; ppl: 11.35; xent: 2.43; lr: 1.00000; 4899/5018 tok/s;    695 sec\n",
            "[2020-06-01 20:51:45,605 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:51:45,983 INFO] number of examples: 26142\n",
            "[2020-06-01 20:51:50,060 INFO] Step 5350/10000; acc:  53.70; ppl:  8.88; xent: 2.18; lr: 1.00000; 4615/4539 tok/s;    702 sec\n",
            "[2020-06-01 20:51:56,253 INFO] Step 5400/10000; acc:  54.67; ppl:  8.65; xent: 2.16; lr: 1.00000; 4960/4917 tok/s;    708 sec\n",
            "[2020-06-01 20:52:02,901 INFO] Step 5450/10000; acc:  53.01; ppl:  9.59; xent: 2.26; lr: 1.00000; 4861/5078 tok/s;    715 sec\n",
            "[2020-06-01 20:52:10,064 INFO] Step 5500/10000; acc:  52.56; ppl:  9.63; xent: 2.26; lr: 1.00000; 4946/5148 tok/s;    722 sec\n",
            "[2020-06-01 20:52:16,611 INFO] Step 5550/10000; acc:  53.68; ppl:  9.06; xent: 2.20; lr: 1.00000; 5126/5069 tok/s;    729 sec\n",
            "[2020-06-01 20:52:22,777 INFO] Step 5600/10000; acc:  55.59; ppl:  8.10; xent: 2.09; lr: 1.00000; 5005/5019 tok/s;    735 sec\n",
            "[2020-06-01 20:52:28,945 INFO] Step 5650/10000; acc:  55.90; ppl:  7.98; xent: 2.08; lr: 1.00000; 4893/5162 tok/s;    741 sec\n",
            "[2020-06-01 20:52:35,909 INFO] Step 5700/10000; acc:  52.17; ppl:  9.80; xent: 2.28; lr: 1.00000; 4938/4974 tok/s;    748 sec\n",
            "[2020-06-01 20:52:39,362 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:52:39,621 INFO] number of examples: 26142\n",
            "[2020-06-01 20:52:42,451 INFO] Step 5750/10000; acc:  56.07; ppl:  7.84; xent: 2.06; lr: 1.00000; 4608/4638 tok/s;    754 sec\n",
            "[2020-06-01 20:52:48,844 INFO] Step 5800/10000; acc:  56.04; ppl:  8.06; xent: 2.09; lr: 1.00000; 5000/4879 tok/s;    761 sec\n",
            "[2020-06-01 20:52:55,420 INFO] Step 5850/10000; acc:  55.46; ppl:  8.18; xent: 2.10; lr: 1.00000; 4846/5045 tok/s;    767 sec\n",
            "[2020-06-01 20:53:02,491 INFO] Step 5900/10000; acc:  55.06; ppl:  8.39; xent: 2.13; lr: 1.00000; 4930/5113 tok/s;    774 sec\n",
            "[2020-06-01 20:53:09,327 INFO] Step 5950/10000; acc:  55.75; ppl:  7.93; xent: 2.07; lr: 1.00000; 5125/5128 tok/s;    781 sec\n",
            "[2020-06-01 20:53:15,300 INFO] Step 6000/10000; acc:  59.57; ppl:  6.62; xent: 1.89; lr: 1.00000; 5015/5039 tok/s;    787 sec\n",
            "[2020-06-01 20:53:21,487 INFO] Step 6050/10000; acc:  58.58; ppl:  7.01; xent: 1.95; lr: 1.00000; 4905/5170 tok/s;    793 sec\n",
            "[2020-06-01 20:53:27,873 INFO] Step 6100/10000; acc:  57.41; ppl:  7.39; xent: 2.00; lr: 1.00000; 4964/4953 tok/s;    800 sec\n",
            "[2020-06-01 20:53:33,020 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:53:33,353 INFO] number of examples: 26142\n",
            "[2020-06-01 20:53:35,038 INFO] Step 6150/10000; acc:  56.78; ppl:  7.67; xent: 2.04; lr: 1.00000; 4497/4624 tok/s;    807 sec\n",
            "[2020-06-01 20:53:41,627 INFO] Step 6200/10000; acc:  58.10; ppl:  7.20; xent: 1.97; lr: 1.00000; 5057/4907 tok/s;    814 sec\n",
            "[2020-06-01 20:53:48,096 INFO] Step 6250/10000; acc:  59.55; ppl:  6.71; xent: 1.90; lr: 1.00000; 4836/4982 tok/s;    820 sec\n",
            "[2020-06-01 20:53:54,822 INFO] Step 6300/10000; acc:  58.52; ppl:  6.97; xent: 1.94; lr: 1.00000; 4907/5077 tok/s;    827 sec\n",
            "[2020-06-01 20:54:01,431 INFO] Step 6350/10000; acc:  59.69; ppl:  6.59; xent: 1.89; lr: 1.00000; 5103/5201 tok/s;    833 sec\n",
            "[2020-06-01 20:54:07,879 INFO] Step 6400/10000; acc:  60.14; ppl:  6.42; xent: 1.86; lr: 1.00000; 5037/5021 tok/s;    840 sec\n",
            "[2020-06-01 20:54:14,076 INFO] Step 6450/10000; acc:  60.87; ppl:  6.19; xent: 1.82; lr: 1.00000; 4948/5122 tok/s;    846 sec\n",
            "[2020-06-01 20:54:20,414 INFO] Step 6500/10000; acc:  60.55; ppl:  6.17; xent: 1.82; lr: 1.00000; 5009/5106 tok/s;    852 sec\n",
            "[2020-06-01 20:54:26,785 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:54:27,105 INFO] number of examples: 26142\n",
            "[2020-06-01 20:54:27,852 INFO] Step 6550/10000; acc:  57.68; ppl:  7.36; xent: 2.00; lr: 1.00000; 4499/4589 tok/s;    860 sec\n",
            "[2020-06-01 20:54:34,122 INFO] Step 6600/10000; acc:  61.92; ppl:  5.89; xent: 1.77; lr: 1.00000; 4970/4888 tok/s;    866 sec\n",
            "[2020-06-01 20:54:41,014 INFO] Step 6650/10000; acc:  59.96; ppl:  6.54; xent: 1.88; lr: 1.00000; 4936/4942 tok/s;    873 sec\n",
            "[2020-06-01 20:54:47,603 INFO] Step 6700/10000; acc:  60.79; ppl:  6.09; xent: 1.81; lr: 1.00000; 4814/5053 tok/s;    880 sec\n",
            "[2020-06-01 20:54:54,159 INFO] Step 6750/10000; acc:  61.36; ppl:  5.81; xent: 1.76; lr: 1.00000; 5164/5206 tok/s;    886 sec\n",
            "[2020-06-01 20:55:00,534 INFO] Step 6800/10000; acc:  62.50; ppl:  5.65; xent: 1.73; lr: 1.00000; 5001/5014 tok/s;    892 sec\n",
            "[2020-06-01 20:55:06,935 INFO] Step 6850/10000; acc:  62.47; ppl:  5.70; xent: 1.74; lr: 1.00000; 4924/5106 tok/s;    899 sec\n",
            "[2020-06-01 20:55:13,325 INFO] Step 6900/10000; acc:  62.63; ppl:  5.43; xent: 1.69; lr: 1.00000; 4989/5107 tok/s;    905 sec\n",
            "[2020-06-01 20:55:20,242 INFO] Step 6950/10000; acc:  59.73; ppl:  6.59; xent: 1.89; lr: 1.00000; 4791/4850 tok/s;    912 sec\n",
            "[2020-06-01 20:55:20,615 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:55:20,956 INFO] number of examples: 26142\n",
            "[2020-06-01 20:55:26,805 INFO] Step 7000/10000; acc:  63.16; ppl:  5.26; xent: 1.66; lr: 1.00000; 4660/4630 tok/s;    919 sec\n",
            "[2020-06-01 20:55:33,060 INFO] Step 7050/10000; acc:  64.08; ppl:  5.20; xent: 1.65; lr: 1.00000; 5022/4985 tok/s;    925 sec\n",
            "[2020-06-01 20:55:40,211 INFO] Step 7100/10000; acc:  60.87; ppl:  6.12; xent: 1.81; lr: 1.00000; 4757/5002 tok/s;    932 sec\n",
            "[2020-06-01 20:55:46,625 INFO] Step 7150/10000; acc:  63.82; ppl:  5.07; xent: 1.62; lr: 1.00000; 5086/5142 tok/s;    939 sec\n",
            "[2020-06-01 20:55:53,292 INFO] Step 7200/10000; acc:  63.38; ppl:  5.36; xent: 1.68; lr: 1.00000; 5045/5091 tok/s;    945 sec\n",
            "[2020-06-01 20:55:59,611 INFO] Step 7250/10000; acc:  64.49; ppl:  5.09; xent: 1.63; lr: 1.00000; 5004/5073 tok/s;    952 sec\n",
            "[2020-06-01 20:56:06,008 INFO] Step 7300/10000; acc:  64.08; ppl:  4.92; xent: 1.59; lr: 1.00000; 4883/5091 tok/s;    958 sec\n",
            "[2020-06-01 20:56:12,772 INFO] Step 7350/10000; acc:  61.03; ppl:  5.96; xent: 1.78; lr: 1.00000; 4912/4970 tok/s;    965 sec\n",
            "[2020-06-01 20:56:14,404 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:56:14,725 INFO] number of examples: 26142\n",
            "[2020-06-01 20:56:19,495 INFO] Step 7400/10000; acc:  64.40; ppl:  4.91; xent: 1.59; lr: 1.00000; 4686/4604 tok/s;    971 sec\n",
            "[2020-06-01 20:56:25,718 INFO] Step 7450/10000; acc:  65.17; ppl:  4.73; xent: 1.55; lr: 1.00000; 4939/4891 tok/s;    978 sec\n",
            "[2020-06-01 20:56:32,743 INFO] Step 7500/10000; acc:  62.58; ppl:  5.55; xent: 1.71; lr: 1.00000; 4820/5025 tok/s;    985 sec\n",
            "[2020-06-01 20:56:39,354 INFO] Step 7550/10000; acc:  64.63; ppl:  4.85; xent: 1.58; lr: 1.00000; 4939/5163 tok/s;    991 sec\n",
            "[2020-06-01 20:56:46,112 INFO] Step 7600/10000; acc:  64.55; ppl:  4.95; xent: 1.60; lr: 1.00000; 5137/5087 tok/s;    998 sec\n",
            "[2020-06-01 20:56:52,468 INFO] Step 7650/10000; acc:  65.48; ppl:  4.62; xent: 1.53; lr: 1.00000; 4986/5030 tok/s;   1004 sec\n",
            "[2020-06-01 20:56:58,509 INFO] Step 7700/10000; acc:  66.43; ppl:  4.30; xent: 1.46; lr: 1.00000; 4886/5131 tok/s;   1010 sec\n",
            "[2020-06-01 20:57:05,223 INFO] Step 7750/10000; acc:  62.64; ppl:  5.44; xent: 1.69; lr: 1.00000; 4915/4978 tok/s;   1017 sec\n",
            "[2020-06-01 20:57:08,207 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:57:08,547 INFO] number of examples: 26142\n",
            "[2020-06-01 20:57:11,843 INFO] Step 7800/10000; acc:  66.36; ppl:  4.42; xent: 1.49; lr: 1.00000; 4593/4550 tok/s;   1024 sec\n",
            "[2020-06-01 20:57:18,302 INFO] Step 7850/10000; acc:  65.19; ppl:  4.64; xent: 1.54; lr: 1.00000; 4919/4888 tok/s;   1030 sec\n",
            "[2020-06-01 20:57:24,944 INFO] Step 7900/10000; acc:  64.72; ppl:  4.81; xent: 1.57; lr: 1.00000; 4875/5017 tok/s;   1037 sec\n",
            "[2020-06-01 20:57:32,235 INFO] Step 7950/10000; acc:  64.43; ppl:  4.87; xent: 1.58; lr: 1.00000; 4948/5125 tok/s;   1044 sec\n",
            "[2020-06-01 20:57:38,822 INFO] Step 8000/10000; acc:  65.79; ppl:  4.51; xent: 1.51; lr: 1.00000; 5066/5090 tok/s;   1051 sec\n",
            "[2020-06-01 20:57:44,916 INFO] Step 8050/10000; acc:  68.13; ppl:  3.97; xent: 1.38; lr: 1.00000; 5063/5014 tok/s;   1057 sec\n",
            "[2020-06-01 20:57:51,187 INFO] Step 8100/10000; acc:  66.26; ppl:  4.31; xent: 1.46; lr: 1.00000; 4792/5144 tok/s;   1063 sec\n",
            "[2020-06-01 20:57:57,876 INFO] Step 8150/10000; acc:  64.26; ppl:  4.88; xent: 1.59; lr: 1.00000; 4968/4930 tok/s;   1070 sec\n",
            "[2020-06-01 20:58:02,117 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:58:02,446 INFO] number of examples: 26142\n",
            "[2020-06-01 20:58:04,824 INFO] Step 8200/10000; acc:  66.20; ppl:  4.37; xent: 1.47; lr: 1.00000; 4551/4627 tok/s;   1077 sec\n",
            "[2020-06-01 20:58:11,210 INFO] Step 8250/10000; acc:  66.40; ppl:  4.37; xent: 1.47; lr: 1.00000; 4987/4856 tok/s;   1083 sec\n",
            "[2020-06-01 20:58:17,956 INFO] Step 8300/10000; acc:  65.97; ppl:  4.44; xent: 1.49; lr: 1.00000; 4876/5029 tok/s;   1090 sec\n",
            "[2020-06-01 20:58:24,599 INFO] Step 8350/10000; acc:  66.55; ppl:  4.26; xent: 1.45; lr: 1.00000; 4862/5049 tok/s;   1097 sec\n",
            "[2020-06-01 20:58:31,394 INFO] Step 8400/10000; acc:  66.60; ppl:  4.24; xent: 1.45; lr: 1.00000; 5180/5200 tok/s;   1103 sec\n",
            "[2020-06-01 20:58:37,523 INFO] Step 8450/10000; acc:  68.31; ppl:  3.94; xent: 1.37; lr: 1.00000; 4924/4996 tok/s;   1109 sec\n",
            "[2020-06-01 20:58:43,957 INFO] Step 8500/10000; acc:  67.04; ppl:  4.11; xent: 1.41; lr: 1.00000; 4985/5152 tok/s;   1116 sec\n",
            "[2020-06-01 20:58:50,150 INFO] Step 8550/10000; acc:  67.96; ppl:  3.91; xent: 1.36; lr: 1.00000; 4908/4983 tok/s;   1122 sec\n",
            "[2020-06-01 20:58:55,969 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:58:56,313 INFO] number of examples: 26142\n",
            "[2020-06-01 20:58:57,589 INFO] Step 8600/10000; acc:  65.11; ppl:  4.64; xent: 1.53; lr: 1.00000; 4517/4603 tok/s;   1130 sec\n",
            "[2020-06-01 20:59:03,853 INFO] Step 8650/10000; acc:  68.35; ppl:  3.88; xent: 1.36; lr: 1.00000; 4954/4866 tok/s;   1136 sec\n",
            "[2020-06-01 20:59:10,698 INFO] Step 8700/10000; acc:  66.80; ppl:  4.23; xent: 1.44; lr: 1.00000; 4875/4939 tok/s;   1143 sec\n",
            "[2020-06-01 20:59:17,390 INFO] Step 8750/10000; acc:  67.61; ppl:  4.08; xent: 1.41; lr: 1.00000; 4874/5066 tok/s;   1149 sec\n",
            "[2020-06-01 20:59:24,099 INFO] Step 8800/10000; acc:  67.90; ppl:  3.93; xent: 1.37; lr: 1.00000; 5133/5217 tok/s;   1156 sec\n",
            "[2020-06-01 20:59:30,388 INFO] Step 8850/10000; acc:  69.05; ppl:  3.76; xent: 1.33; lr: 1.00000; 5022/4976 tok/s;   1162 sec\n",
            "[2020-06-01 20:59:36,733 INFO] Step 8900/10000; acc:  68.61; ppl:  3.83; xent: 1.34; lr: 1.00000; 4914/5124 tok/s;   1169 sec\n",
            "[2020-06-01 20:59:43,002 INFO] Step 8950/10000; acc:  68.87; ppl:  3.65; xent: 1.30; lr: 1.00000; 4973/5073 tok/s;   1175 sec\n",
            "[2020-06-01 20:59:49,901 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 20:59:50,277 INFO] number of examples: 26142\n",
            "[2020-06-01 20:59:50,594 INFO] Step 9000/10000; acc:  65.46; ppl:  4.49; xent: 1.50; lr: 1.00000; 4441/4576 tok/s;   1183 sec\n",
            "[2020-06-01 20:59:56,846 INFO] Step 9050/10000; acc:  69.10; ppl:  3.67; xent: 1.30; lr: 1.00000; 5004/4851 tok/s;   1189 sec\n",
            "[2020-06-01 21:00:03,675 INFO] Step 9100/10000; acc:  67.60; ppl:  4.02; xent: 1.39; lr: 1.00000; 4962/4957 tok/s;   1196 sec\n",
            "[2020-06-01 21:00:10,087 INFO] Step 9150/10000; acc:  69.06; ppl:  3.69; xent: 1.31; lr: 1.00000; 4781/5096 tok/s;   1202 sec\n",
            "[2020-06-01 21:00:16,607 INFO] Step 9200/10000; acc:  69.66; ppl:  3.57; xent: 1.27; lr: 1.00000; 5140/5141 tok/s;   1209 sec\n",
            "[2020-06-01 21:00:23,318 INFO] Step 9250/10000; acc:  68.74; ppl:  3.79; xent: 1.33; lr: 1.00000; 5046/5072 tok/s;   1215 sec\n",
            "[2020-06-01 21:00:29,723 INFO] Step 9300/10000; acc:  69.22; ppl:  3.67; xent: 1.30; lr: 1.00000; 4931/5082 tok/s;   1222 sec\n",
            "[2020-06-01 21:00:35,900 INFO] Step 9350/10000; acc:  70.22; ppl:  3.36; xent: 1.21; lr: 1.00000; 4933/5054 tok/s;   1228 sec\n",
            "[2020-06-01 21:00:42,618 INFO] Step 9400/10000; acc:  66.98; ppl:  4.15; xent: 1.42; lr: 1.00000; 4850/4989 tok/s;   1235 sec\n",
            "[2020-06-01 21:00:43,805 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:00:44,064 INFO] number of examples: 26142\n",
            "[2020-06-01 21:00:49,451 INFO] Step 9450/10000; acc:  70.15; ppl:  3.48; xent: 1.25; lr: 1.00000; 4597/4527 tok/s;   1241 sec\n",
            "[2020-06-01 21:00:55,931 INFO] Step 9500/10000; acc:  69.63; ppl:  3.54; xent: 1.26; lr: 1.00000; 5024/4946 tok/s;   1248 sec\n",
            "[2020-06-01 21:01:02,901 INFO] Step 9550/10000; acc:  68.20; ppl:  3.88; xent: 1.36; lr: 1.00000; 4743/4985 tok/s;   1255 sec\n",
            "[2020-06-01 21:01:09,323 INFO] Step 9600/10000; acc:  70.39; ppl:  3.41; xent: 1.23; lr: 1.00000; 5000/5192 tok/s;   1261 sec\n",
            "[2020-06-01 21:01:16,106 INFO] Step 9650/10000; acc:  69.36; ppl:  3.59; xent: 1.28; lr: 1.00000; 5109/5087 tok/s;   1268 sec\n",
            "[2020-06-01 21:01:22,365 INFO] Step 9700/10000; acc:  70.59; ppl:  3.36; xent: 1.21; lr: 1.00000; 4951/5016 tok/s;   1274 sec\n",
            "[2020-06-01 21:01:28,835 INFO] Step 9750/10000; acc:  70.21; ppl:  3.37; xent: 1.21; lr: 1.00000; 4936/5077 tok/s;   1281 sec\n",
            "[2020-06-01 21:01:35,706 INFO] Step 9800/10000; acc:  67.40; ppl:  3.98; xent: 1.38; lr: 1.00000; 4910/4991 tok/s;   1288 sec\n",
            "[2020-06-01 21:01:37,708 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:01:37,958 INFO] number of examples: 26142\n",
            "[2020-06-01 21:01:42,135 INFO] Step 9850/10000; acc:  71.33; ppl:  3.21; xent: 1.17; lr: 1.00000; 4681/4615 tok/s;   1294 sec\n",
            "[2020-06-01 21:01:48,446 INFO] Step 9900/10000; acc:  70.97; ppl:  3.28; xent: 1.19; lr: 1.00000; 4958/4907 tok/s;   1300 sec\n",
            "[2020-06-01 21:01:55,150 INFO] Step 9950/10000; acc:  69.61; ppl:  3.51; xent: 1.26; lr: 1.00000; 4848/5053 tok/s;   1307 sec\n",
            "[2020-06-01 21:02:02,321 INFO] Step 10000/10000; acc:  69.38; ppl:  3.58; xent: 1.27; lr: 1.00000; 4932/5125 tok/s;   1314 sec\n",
            "[2020-06-01 21:02:02,321 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 21:02:02,326 INFO] number of examples: 276\n",
            "[2020-06-01 21:02:02,905 INFO] Validation perplexity: 32.6941\n",
            "[2020-06-01 21:02:02,905 INFO] Validation accuracy: 47.4412\n",
            "[2020-06-01 21:02:02,938 INFO] Saving checkpoint model_step_10000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53nXNgDa83F",
        "colab_type": "code",
        "outputId": "91960bcb-b899-46dc-a101-1ed8e56d917a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "en - st"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1322.9168176651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmXNfGoCa8pd",
        "colab_type": "code",
        "outputId": "dac2ccda-273c-4662-e2f0-c291aead6992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "st = time.time()\n",
        "!python OpenNMT-py/train.py -data En2Fa-Translation/Cleaned -world_size 1 -gpu_rank 0 --learning_rate 0.1 --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 10000\n",
        "en = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 21:02:14,103 INFO]  * src vocab size = 3116\n",
            "[2020-06-01 21:02:14,104 INFO]  * tgt vocab size = 5908\n",
            "[2020-06-01 21:02:14,104 INFO] Building model...\n",
            "[2020-06-01 21:02:16,635 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3116, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5908, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=5908, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-01 21:02:16,636 INFO] encoder: 9938416\n",
            "[2020-06-01 21:02:16,636 INFO] decoder: 16200228\n",
            "[2020-06-01 21:02:16,636 INFO] * number of parameters: 26138644\n",
            "[2020-06-01 21:02:16,640 INFO] Starting training on GPU: [0]\n",
            "[2020-06-01 21:02:16,640 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-01 21:02:16,640 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:02:16,889 INFO] number of examples: 26142\n",
            "[2020-06-01 21:02:24,318 INFO] Step 50/10000; acc:   8.32; ppl: 1406.52; xent: 7.25; lr: 0.10000; 4664/4624 tok/s;      8 sec\n",
            "[2020-06-01 21:02:30,612 INFO] Step 100/10000; acc:   9.87; ppl: 397.65; xent: 5.99; lr: 0.10000; 4937/4990 tok/s;     14 sec\n",
            "[2020-06-01 21:02:36,757 INFO] Step 150/10000; acc:  10.63; ppl: 334.97; xent: 5.81; lr: 0.10000; 4988/5186 tok/s;     20 sec\n",
            "[2020-06-01 21:02:43,540 INFO] Step 200/10000; acc:   9.33; ppl: 317.19; xent: 5.76; lr: 0.10000; 4986/4934 tok/s;     27 sec\n",
            "[2020-06-01 21:02:49,848 INFO] Step 250/10000; acc:  11.46; ppl: 277.37; xent: 5.63; lr: 0.10000; 4730/4984 tok/s;     33 sec\n",
            "[2020-06-01 21:02:56,084 INFO] Step 300/10000; acc:  11.86; ppl: 246.03; xent: 5.51; lr: 0.10000; 4834/4924 tok/s;     39 sec\n",
            "[2020-06-01 21:03:02,546 INFO] Step 350/10000; acc:  11.24; ppl: 234.73; xent: 5.46; lr: 0.10000; 4971/5196 tok/s;     46 sec\n",
            "[2020-06-01 21:03:09,405 INFO] Step 400/10000; acc:  11.03; ppl: 240.28; xent: 5.48; lr: 0.10000; 4982/4899 tok/s;     53 sec\n",
            "[2020-06-01 21:03:10,663 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:03:11,016 INFO] number of examples: 26142\n",
            "[2020-06-01 21:03:17,267 INFO] Step 450/10000; acc:  10.90; ppl: 246.93; xent: 5.51; lr: 0.10000; 4725/4649 tok/s;     61 sec\n",
            "[2020-06-01 21:03:23,547 INFO] Step 500/10000; acc:  12.87; ppl: 192.81; xent: 5.26; lr: 0.10000; 4867/5009 tok/s;     67 sec\n",
            "[2020-06-01 21:03:29,418 INFO] Step 550/10000; acc:  12.61; ppl: 210.78; xent: 5.35; lr: 0.10000; 5036/5144 tok/s;     73 sec\n",
            "[2020-06-01 21:03:36,187 INFO] Step 600/10000; acc:  12.89; ppl: 200.86; xent: 5.30; lr: 0.10000; 4911/4986 tok/s;     80 sec\n",
            "[2020-06-01 21:03:42,520 INFO] Step 650/10000; acc:  12.16; ppl: 193.85; xent: 5.27; lr: 0.10000; 4897/5000 tok/s;     86 sec\n",
            "[2020-06-01 21:03:48,917 INFO] Step 700/10000; acc:  13.45; ppl: 195.68; xent: 5.28; lr: 0.10000; 4913/4968 tok/s;     92 sec\n",
            "[2020-06-01 21:03:55,537 INFO] Step 750/10000; acc:  11.74; ppl: 190.98; xent: 5.25; lr: 0.10000; 4915/5164 tok/s;     99 sec\n",
            "[2020-06-01 21:04:02,071 INFO] Step 800/10000; acc:  12.59; ppl: 178.89; xent: 5.19; lr: 0.10000; 4983/4973 tok/s;    105 sec\n",
            "[2020-06-01 21:04:04,625 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:04:04,861 INFO] number of examples: 26142\n",
            "[2020-06-01 21:04:10,183 INFO] Step 850/10000; acc:  11.15; ppl: 194.99; xent: 5.27; lr: 0.10000; 4645/4618 tok/s;    114 sec\n",
            "[2020-06-01 21:04:16,515 INFO] Step 900/10000; acc:  15.05; ppl: 160.76; xent: 5.08; lr: 0.10000; 5025/5038 tok/s;    120 sec\n",
            "[2020-06-01 21:04:22,281 INFO] Step 950/10000; acc:  16.36; ppl: 150.37; xent: 5.01; lr: 0.10000; 4978/5088 tok/s;    126 sec\n",
            "[2020-06-01 21:04:28,766 INFO] Step 1000/10000; acc:  14.55; ppl: 161.28; xent: 5.08; lr: 0.10000; 4900/5061 tok/s;    132 sec\n",
            "[2020-06-01 21:04:35,049 INFO] Step 1050/10000; acc:  14.73; ppl: 159.08; xent: 5.07; lr: 0.10000; 4950/5108 tok/s;    138 sec\n",
            "[2020-06-01 21:04:41,782 INFO] Step 1100/10000; acc:  13.90; ppl: 171.10; xent: 5.14; lr: 0.10000; 4873/4840 tok/s;    145 sec\n",
            "[2020-06-01 21:04:48,696 INFO] Step 1150/10000; acc:  13.96; ppl: 165.51; xent: 5.11; lr: 0.10000; 4929/5129 tok/s;    152 sec\n",
            "[2020-06-01 21:04:54,478 INFO] Step 1200/10000; acc:  15.86; ppl: 129.79; xent: 4.87; lr: 0.10000; 4849/4942 tok/s;    158 sec\n",
            "[2020-06-01 21:04:58,631 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:04:58,896 INFO] number of examples: 26142\n",
            "[2020-06-01 21:05:02,897 INFO] Step 1250/10000; acc:  12.22; ppl: 178.48; xent: 5.18; lr: 0.10000; 4762/4720 tok/s;    166 sec\n",
            "[2020-06-01 21:05:09,375 INFO] Step 1300/10000; acc:  15.36; ppl: 140.91; xent: 4.95; lr: 0.10000; 4980/4944 tok/s;    173 sec\n",
            "[2020-06-01 21:05:15,057 INFO] Step 1350/10000; acc:  18.09; ppl: 122.57; xent: 4.81; lr: 0.10000; 4928/5078 tok/s;    178 sec\n",
            "[2020-06-01 21:05:21,620 INFO] Step 1400/10000; acc:  15.88; ppl: 143.47; xent: 4.97; lr: 0.10000; 4974/5144 tok/s;    185 sec\n",
            "[2020-06-01 21:05:27,968 INFO] Step 1450/10000; acc:  15.46; ppl: 142.61; xent: 4.96; lr: 0.10000; 4904/5027 tok/s;    191 sec\n",
            "[2020-06-01 21:05:34,402 INFO] Step 1500/10000; acc:  16.28; ppl: 136.93; xent: 4.92; lr: 0.10000; 4845/4870 tok/s;    198 sec\n",
            "[2020-06-01 21:05:41,527 INFO] Step 1550/10000; acc:  14.94; ppl: 150.89; xent: 5.02; lr: 0.10000; 4977/5058 tok/s;    205 sec\n",
            "[2020-06-01 21:05:47,135 INFO] Step 1600/10000; acc:  18.03; ppl: 107.21; xent: 4.67; lr: 0.10000; 4763/5067 tok/s;    210 sec\n",
            "[2020-06-01 21:05:52,529 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:05:52,865 INFO] number of examples: 26142\n",
            "[2020-06-01 21:05:55,123 INFO] Step 1650/10000; acc:  14.44; ppl: 149.08; xent: 5.00; lr: 0.10000; 4835/4722 tok/s;    218 sec\n",
            "[2020-06-01 21:06:02,078 INFO] Step 1700/10000; acc:  16.51; ppl: 132.03; xent: 4.88; lr: 0.10000; 4907/4839 tok/s;    225 sec\n",
            "[2020-06-01 21:06:07,926 INFO] Step 1750/10000; acc:  19.68; ppl: 100.12; xent: 4.61; lr: 0.10000; 4813/5060 tok/s;    231 sec\n",
            "[2020-06-01 21:06:14,237 INFO] Step 1800/10000; acc:  18.25; ppl: 118.24; xent: 4.77; lr: 0.10000; 5002/5189 tok/s;    238 sec\n",
            "[2020-06-01 21:06:20,844 INFO] Step 1850/10000; acc:  17.22; ppl: 127.72; xent: 4.85; lr: 0.10000; 4942/4924 tok/s;    244 sec\n",
            "[2020-06-01 21:06:27,475 INFO] Step 1900/10000; acc:  17.32; ppl: 123.04; xent: 4.81; lr: 0.10000; 4846/4903 tok/s;    251 sec\n",
            "[2020-06-01 21:06:34,476 INFO] Step 1950/10000; acc:  16.81; ppl: 125.90; xent: 4.84; lr: 0.10000; 4956/5120 tok/s;    258 sec\n",
            "[2020-06-01 21:06:40,157 INFO] Step 2000/10000; acc:  19.70; ppl: 93.35; xent: 4.54; lr: 0.10000; 4852/5072 tok/s;    264 sec\n",
            "[2020-06-01 21:06:46,566 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:06:46,871 INFO] number of examples: 26142\n",
            "[2020-06-01 21:06:47,607 INFO] Step 2050/10000; acc:  16.38; ppl: 118.99; xent: 4.78; lr: 0.10000; 4734/4679 tok/s;    271 sec\n",
            "[2020-06-01 21:06:54,796 INFO] Step 2100/10000; acc:  17.34; ppl: 117.73; xent: 4.77; lr: 0.10000; 4972/4904 tok/s;    278 sec\n",
            "[2020-06-01 21:07:01,015 INFO] Step 2150/10000; acc:  19.74; ppl: 97.91; xent: 4.58; lr: 0.10000; 4935/5039 tok/s;    284 sec\n",
            "[2020-06-01 21:07:07,164 INFO] Step 2200/10000; acc:  20.16; ppl: 99.01; xent: 4.60; lr: 0.10000; 5028/5218 tok/s;    291 sec\n",
            "[2020-06-01 21:07:13,687 INFO] Step 2250/10000; acc:  18.45; ppl: 106.15; xent: 4.66; lr: 0.10000; 4929/4927 tok/s;    297 sec\n",
            "[2020-06-01 21:07:20,037 INFO] Step 2300/10000; acc:  19.44; ppl: 92.54; xent: 4.53; lr: 0.10000; 4829/4991 tok/s;    303 sec\n",
            "[2020-06-01 21:07:26,512 INFO] Step 2350/10000; acc:  19.77; ppl: 102.26; xent: 4.63; lr: 0.10000; 4835/4991 tok/s;    310 sec\n",
            "[2020-06-01 21:07:32,949 INFO] Step 2400/10000; acc:  19.08; ppl: 97.31; xent: 4.58; lr: 0.10000; 5020/5173 tok/s;    316 sec\n",
            "[2020-06-01 21:07:39,820 INFO] Step 2450/10000; acc:  18.74; ppl: 99.30; xent: 4.60; lr: 0.10000; 4973/4919 tok/s;    323 sec\n",
            "[2020-06-01 21:07:40,409 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:07:40,720 INFO] number of examples: 26142\n",
            "[2020-06-01 21:07:47,574 INFO] Step 2500/10000; acc:  18.02; ppl: 107.48; xent: 4.68; lr: 0.10000; 4759/4662 tok/s;    331 sec\n",
            "[2020-06-01 21:07:53,824 INFO] Step 2550/10000; acc:  21.45; ppl: 80.80; xent: 4.39; lr: 0.10000; 4849/4998 tok/s;    337 sec\n",
            "[2020-06-01 21:07:59,718 INFO] Step 2600/10000; acc:  22.60; ppl: 75.36; xent: 4.32; lr: 0.10000; 5050/5165 tok/s;    343 sec\n",
            "[2020-06-01 21:08:06,808 INFO] Step 2650/10000; acc:  18.48; ppl: 104.84; xent: 4.65; lr: 0.10000; 4959/5000 tok/s;    350 sec\n",
            "[2020-06-01 21:08:12,838 INFO] Step 2700/10000; acc:  20.93; ppl: 76.91; xent: 4.34; lr: 0.10000; 4793/4976 tok/s;    356 sec\n",
            "[2020-06-01 21:08:19,345 INFO] Step 2750/10000; acc:  20.43; ppl: 91.19; xent: 4.51; lr: 0.10000; 4874/4933 tok/s;    363 sec\n",
            "[2020-06-01 21:08:25,666 INFO] Step 2800/10000; acc:  21.08; ppl: 81.74; xent: 4.40; lr: 0.10000; 4901/5159 tok/s;    369 sec\n",
            "[2020-06-01 21:08:32,551 INFO] Step 2850/10000; acc:  19.25; ppl: 85.90; xent: 4.45; lr: 0.10000; 4987/4925 tok/s;    376 sec\n",
            "[2020-06-01 21:08:34,379 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:08:34,721 INFO] number of examples: 26142\n",
            "[2020-06-01 21:08:40,654 INFO] Step 2900/10000; acc:  17.75; ppl: 100.64; xent: 4.61; lr: 0.10000; 4730/4672 tok/s;    384 sec\n",
            "[2020-06-01 21:08:46,766 INFO] Step 2950/10000; acc:  22.84; ppl: 69.46; xent: 4.24; lr: 0.10000; 4875/4983 tok/s;    390 sec\n",
            "[2020-06-01 21:08:52,597 INFO] Step 3000/10000; acc:  23.14; ppl: 68.68; xent: 4.23; lr: 0.10000; 5049/5139 tok/s;    396 sec\n",
            "[2020-06-01 21:08:59,315 INFO] Step 3050/10000; acc:  20.75; ppl: 82.27; xent: 4.41; lr: 0.10000; 4944/5018 tok/s;    403 sec\n",
            "[2020-06-01 21:09:05,492 INFO] Step 3100/10000; acc:  20.80; ppl: 74.01; xent: 4.30; lr: 0.10000; 4957/5140 tok/s;    409 sec\n",
            "[2020-06-01 21:09:11,990 INFO] Step 3150/10000; acc:  21.27; ppl: 78.07; xent: 4.36; lr: 0.10000; 4813/4824 tok/s;    415 sec\n",
            "[2020-06-01 21:09:18,855 INFO] Step 3200/10000; acc:  20.10; ppl: 87.50; xent: 4.47; lr: 0.10000; 4936/5143 tok/s;    422 sec\n",
            "[2020-06-01 21:09:25,234 INFO] Step 3250/10000; acc:  21.55; ppl: 69.14; xent: 4.24; lr: 0.10000; 4903/4968 tok/s;    429 sec\n",
            "[2020-06-01 21:09:28,335 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:09:28,666 INFO] number of examples: 26142\n",
            "[2020-06-01 21:09:33,463 INFO] Step 3300/10000; acc:  18.27; ppl: 94.46; xent: 4.55; lr: 0.10000; 4689/4653 tok/s;    437 sec\n",
            "[2020-06-01 21:09:39,805 INFO] Step 3350/10000; acc:  23.34; ppl: 65.18; xent: 4.18; lr: 0.10000; 5046/5012 tok/s;    443 sec\n",
            "[2020-06-01 21:09:45,346 INFO] Step 3400/10000; acc:  24.97; ppl: 57.39; xent: 4.05; lr: 0.10000; 4914/5070 tok/s;    449 sec\n",
            "[2020-06-01 21:09:51,770 INFO] Step 3450/10000; acc:  22.03; ppl: 70.65; xent: 4.26; lr: 0.10000; 4943/5136 tok/s;    455 sec\n",
            "[2020-06-01 21:09:58,218 INFO] Step 3500/10000; acc:  21.26; ppl: 71.46; xent: 4.27; lr: 0.10000; 4907/5043 tok/s;    462 sec\n",
            "[2020-06-01 21:10:04,880 INFO] Step 3550/10000; acc:  21.37; ppl: 73.83; xent: 4.30; lr: 0.10000; 4867/4863 tok/s;    468 sec\n",
            "[2020-06-01 21:10:11,868 INFO] Step 3600/10000; acc:  21.05; ppl: 79.66; xent: 4.38; lr: 0.10000; 4986/5109 tok/s;    475 sec\n",
            "[2020-06-01 21:10:17,673 INFO] Step 3650/10000; acc:  24.04; ppl: 55.00; xent: 4.01; lr: 0.10000; 4877/5052 tok/s;    481 sec\n",
            "[2020-06-01 21:10:22,260 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:10:22,597 INFO] number of examples: 26142\n",
            "[2020-06-01 21:10:25,804 INFO] Step 3700/10000; acc:  19.08; ppl: 85.13; xent: 4.44; lr: 0.10000; 4738/4685 tok/s;    489 sec\n",
            "[2020-06-01 21:10:32,590 INFO] Step 3750/10000; acc:  22.62; ppl: 69.60; xent: 4.24; lr: 0.10000; 4943/4884 tok/s;    496 sec\n",
            "[2020-06-01 21:10:38,083 INFO] Step 3800/10000; acc:  26.71; ppl: 47.67; xent: 3.86; lr: 0.10000; 4864/5048 tok/s;    501 sec\n",
            "[2020-06-01 21:10:44,573 INFO] Step 3850/10000; acc:  22.59; ppl: 66.89; xent: 4.20; lr: 0.10000; 5012/5211 tok/s;    508 sec\n",
            "[2020-06-01 21:10:51,195 INFO] Step 3900/10000; acc:  22.20; ppl: 68.84; xent: 4.23; lr: 0.10000; 4940/5008 tok/s;    515 sec\n",
            "[2020-06-01 21:10:57,676 INFO] Step 3950/10000; acc:  23.12; ppl: 63.43; xent: 4.15; lr: 0.10000; 4860/4852 tok/s;    521 sec\n",
            "[2020-06-01 21:11:04,513 INFO] Step 4000/10000; acc:  22.85; ppl: 69.88; xent: 4.25; lr: 0.10000; 4933/5086 tok/s;    528 sec\n",
            "[2020-06-01 21:11:10,387 INFO] Step 4050/10000; acc:  25.88; ppl: 52.41; xent: 3.96; lr: 0.10000; 4886/5108 tok/s;    534 sec\n",
            "[2020-06-01 21:11:16,146 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:11:16,487 INFO] number of examples: 26142\n",
            "[2020-06-01 21:11:18,164 INFO] Step 4100/10000; acc:  23.37; ppl: 70.26; xent: 4.25; lr: 0.10000; 4810/4683 tok/s;    542 sec\n",
            "[2020-06-01 21:11:24,957 INFO] Step 4150/10000; acc:  27.26; ppl: 57.46; xent: 4.05; lr: 0.10000; 4895/4888 tok/s;    548 sec\n",
            "[2020-06-01 21:11:30,973 INFO] Step 4200/10000; acc:  30.18; ppl: 46.99; xent: 3.85; lr: 0.10000; 4857/5016 tok/s;    554 sec\n",
            "[2020-06-01 21:11:37,402 INFO] Step 4250/10000; acc:  28.47; ppl: 54.79; xent: 4.00; lr: 0.10000; 5039/5234 tok/s;    561 sec\n",
            "[2020-06-01 21:11:44,002 INFO] Step 4300/10000; acc:  27.80; ppl: 55.89; xent: 4.02; lr: 0.10000; 4909/4935 tok/s;    567 sec\n",
            "[2020-06-01 21:11:50,548 INFO] Step 4350/10000; acc:  29.51; ppl: 49.60; xent: 3.90; lr: 0.10000; 4890/4874 tok/s;    574 sec\n",
            "[2020-06-01 21:11:57,166 INFO] Step 4400/10000; acc:  29.18; ppl: 54.05; xent: 3.99; lr: 0.10000; 4875/5148 tok/s;    581 sec\n",
            "[2020-06-01 21:12:03,187 INFO] Step 4450/10000; acc:  31.69; ppl: 44.60; xent: 3.80; lr: 0.10000; 4962/5127 tok/s;    587 sec\n",
            "[2020-06-01 21:12:10,102 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:12:10,440 INFO] number of examples: 26142\n",
            "[2020-06-01 21:12:10,679 INFO] Step 4500/10000; acc:  28.06; ppl: 54.47; xent: 4.00; lr: 0.10000; 4681/4623 tok/s;    594 sec\n",
            "[2020-06-01 21:12:17,982 INFO] Step 4550/10000; acc:  28.08; ppl: 55.73; xent: 4.02; lr: 0.10000; 4965/4925 tok/s;    601 sec\n",
            "[2020-06-01 21:12:24,164 INFO] Step 4600/10000; acc:  31.99; ppl: 42.27; xent: 3.74; lr: 0.10000; 4902/4983 tok/s;    608 sec\n",
            "[2020-06-01 21:12:30,275 INFO] Step 4650/10000; acc:  31.58; ppl: 45.23; xent: 3.81; lr: 0.10000; 5037/5206 tok/s;    614 sec\n",
            "[2020-06-01 21:12:36,993 INFO] Step 4700/10000; acc:  29.54; ppl: 49.79; xent: 3.91; lr: 0.10000; 4986/4953 tok/s;    620 sec\n",
            "[2020-06-01 21:12:43,261 INFO] Step 4750/10000; acc:  31.34; ppl: 42.51; xent: 3.75; lr: 0.10000; 4760/5005 tok/s;    627 sec\n",
            "[2020-06-01 21:12:49,570 INFO] Step 4800/10000; acc:  31.73; ppl: 45.33; xent: 3.81; lr: 0.10000; 4850/4949 tok/s;    633 sec\n",
            "[2020-06-01 21:12:55,958 INFO] Step 4850/10000; acc:  30.95; ppl: 45.75; xent: 3.82; lr: 0.10000; 5008/5216 tok/s;    639 sec\n",
            "[2020-06-01 21:13:02,897 INFO] Step 4900/10000; acc:  29.85; ppl: 47.66; xent: 3.86; lr: 0.10000; 4990/4907 tok/s;    646 sec\n",
            "[2020-06-01 21:13:03,992 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:13:04,333 INFO] number of examples: 26142\n",
            "[2020-06-01 21:13:10,649 INFO] Step 4950/10000; acc:  28.33; ppl: 53.91; xent: 3.99; lr: 0.10000; 4718/4641 tok/s;    654 sec\n",
            "[2020-06-01 21:13:16,915 INFO] Step 5000/10000; acc:  33.87; ppl: 36.25; xent: 3.59; lr: 0.10000; 4868/5019 tok/s;    660 sec\n",
            "[2020-06-01 21:13:16,945 INFO] Saving checkpoint model_step_5000.pt\n",
            "[2020-06-01 21:13:23,187 INFO] Step 5050/10000; acc:  33.91; ppl: 36.56; xent: 3.60; lr: 0.10000; 4735/4837 tok/s;    667 sec\n",
            "[2020-06-01 21:13:30,066 INFO] Step 5100/10000; acc:  30.70; ppl: 46.51; xent: 3.84; lr: 0.10000; 4888/4943 tok/s;    673 sec\n",
            "[2020-06-01 21:13:36,397 INFO] Step 5150/10000; acc:  32.67; ppl: 38.98; xent: 3.66; lr: 0.10000; 4868/4997 tok/s;    680 sec\n",
            "[2020-06-01 21:13:42,784 INFO] Step 5200/10000; acc:  33.13; ppl: 40.04; xent: 3.69; lr: 0.10000; 4885/4938 tok/s;    686 sec\n",
            "[2020-06-01 21:13:49,309 INFO] Step 5250/10000; acc:  32.20; ppl: 42.29; xent: 3.74; lr: 0.10000; 4953/5202 tok/s;    693 sec\n",
            "[2020-06-01 21:13:55,916 INFO] Step 5300/10000; acc:  33.34; ppl: 37.65; xent: 3.63; lr: 0.10000; 4995/4975 tok/s;    699 sec\n",
            "[2020-06-01 21:13:58,357 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:13:58,714 INFO] number of examples: 26142\n",
            "[2020-06-01 21:14:04,106 INFO] Step 5350/10000; acc:  29.08; ppl: 51.12; xent: 3.93; lr: 0.10000; 4656/4622 tok/s;    707 sec\n",
            "[2020-06-01 21:14:10,360 INFO] Step 5400/10000; acc:  35.72; ppl: 32.23; xent: 3.47; lr: 0.10000; 4959/4996 tok/s;    714 sec\n",
            "[2020-06-01 21:14:16,095 INFO] Step 5450/10000; acc:  37.16; ppl: 29.87; xent: 3.40; lr: 0.10000; 5000/5107 tok/s;    719 sec\n",
            "[2020-06-01 21:14:22,880 INFO] Step 5500/10000; acc:  33.19; ppl: 39.70; xent: 3.68; lr: 0.10000; 4924/5041 tok/s;    726 sec\n",
            "[2020-06-01 21:14:28,916 INFO] Step 5550/10000; acc:  35.80; ppl: 31.09; xent: 3.44; lr: 0.10000; 4914/5120 tok/s;    732 sec\n",
            "[2020-06-01 21:14:35,660 INFO] Step 5600/10000; acc:  33.82; ppl: 37.55; xent: 3.63; lr: 0.10000; 4884/4844 tok/s;    739 sec\n",
            "[2020-06-01 21:14:42,530 INFO] Step 5650/10000; acc:  32.68; ppl: 40.34; xent: 3.70; lr: 0.10000; 4913/5133 tok/s;    746 sec\n",
            "[2020-06-01 21:14:48,396 INFO] Step 5700/10000; acc:  37.88; ppl: 27.42; xent: 3.31; lr: 0.10000; 4878/4947 tok/s;    752 sec\n",
            "[2020-06-01 21:14:52,383 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:14:52,683 INFO] number of examples: 26142\n",
            "[2020-06-01 21:14:56,742 INFO] Step 5750/10000; acc:  30.16; ppl: 46.40; xent: 3.84; lr: 0.10000; 4727/4693 tok/s;    760 sec\n",
            "[2020-06-01 21:15:03,260 INFO] Step 5800/10000; acc:  36.14; ppl: 31.39; xent: 3.45; lr: 0.10000; 4998/4963 tok/s;    767 sec\n",
            "[2020-06-01 21:15:08,906 INFO] Step 5850/10000; acc:  39.28; ppl: 25.52; xent: 3.24; lr: 0.10000; 4948/5076 tok/s;    772 sec\n",
            "[2020-06-01 21:15:15,411 INFO] Step 5900/10000; acc:  35.29; ppl: 32.84; xent: 3.49; lr: 0.10000; 4978/5170 tok/s;    779 sec\n",
            "[2020-06-01 21:15:21,795 INFO] Step 5950/10000; acc:  35.38; ppl: 31.89; xent: 3.46; lr: 0.10000; 4916/5059 tok/s;    785 sec\n",
            "[2020-06-01 21:15:28,364 INFO] Step 6000/10000; acc:  35.62; ppl: 32.29; xent: 3.47; lr: 0.10000; 4882/4903 tok/s;    792 sec\n",
            "[2020-06-01 21:15:35,339 INFO] Step 6050/10000; acc:  33.94; ppl: 36.81; xent: 3.61; lr: 0.10000; 4982/5068 tok/s;    799 sec\n",
            "[2020-06-01 21:15:41,011 INFO] Step 6100/10000; acc:  40.14; ppl: 23.48; xent: 3.16; lr: 0.10000; 4800/5056 tok/s;    804 sec\n",
            "[2020-06-01 21:15:46,215 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:15:46,539 INFO] number of examples: 26142\n",
            "[2020-06-01 21:15:48,839 INFO] Step 6150/10000; acc:  33.57; ppl: 36.20; xent: 3.59; lr: 0.10000; 4811/4718 tok/s;    812 sec\n",
            "[2020-06-01 21:15:56,007 INFO] Step 6200/10000; acc:  34.68; ppl: 35.24; xent: 3.56; lr: 0.10000; 4958/4878 tok/s;    819 sec\n",
            "[2020-06-01 21:16:01,654 INFO] Step 6250/10000; acc:  41.48; ppl: 21.66; xent: 3.08; lr: 0.10000; 4826/5048 tok/s;    825 sec\n",
            "[2020-06-01 21:16:08,059 INFO] Step 6300/10000; acc:  37.31; ppl: 29.20; xent: 3.37; lr: 0.10000; 4979/5226 tok/s;    831 sec\n",
            "[2020-06-01 21:16:14,586 INFO] Step 6350/10000; acc:  36.20; ppl: 30.69; xent: 3.42; lr: 0.10000; 5002/4959 tok/s;    838 sec\n",
            "[2020-06-01 21:16:21,135 INFO] Step 6400/10000; acc:  37.52; ppl: 28.70; xent: 3.36; lr: 0.10000; 4848/4886 tok/s;    844 sec\n",
            "[2020-06-01 21:16:28,113 INFO] Step 6450/10000; acc:  35.87; ppl: 31.92; xent: 3.46; lr: 0.10000; 4954/5127 tok/s;    851 sec\n",
            "[2020-06-01 21:16:33,797 INFO] Step 6500/10000; acc:  41.19; ppl: 22.25; xent: 3.10; lr: 0.10000; 4839/5070 tok/s;    857 sec\n",
            "[2020-06-01 21:16:40,104 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:16:40,424 INFO] number of examples: 26142\n",
            "[2020-06-01 21:16:41,412 INFO] Step 6550/10000; acc:  35.37; ppl: 32.14; xent: 3.47; lr: 0.10000; 4783/4699 tok/s;    865 sec\n",
            "[2020-06-01 21:16:48,501 INFO] Step 6600/10000; acc:  36.29; ppl: 30.75; xent: 3.43; lr: 0.10000; 4943/4880 tok/s;    872 sec\n",
            "[2020-06-01 21:16:54,658 INFO] Step 6650/10000; acc:  40.82; ppl: 23.07; xent: 3.14; lr: 0.10000; 4881/5005 tok/s;    878 sec\n",
            "[2020-06-01 21:17:00,950 INFO] Step 6700/10000; acc:  38.96; ppl: 26.03; xent: 3.26; lr: 0.10000; 5046/5242 tok/s;    884 sec\n",
            "[2020-06-01 21:17:07,369 INFO] Step 6750/10000; acc:  38.10; ppl: 27.37; xent: 3.31; lr: 0.10000; 4899/4907 tok/s;    891 sec\n",
            "[2020-06-01 21:17:13,764 INFO] Step 6800/10000; acc:  39.41; ppl: 24.39; xent: 3.19; lr: 0.10000; 4866/4977 tok/s;    897 sec\n",
            "[2020-06-01 21:17:20,241 INFO] Step 6850/10000; acc:  38.74; ppl: 26.53; xent: 3.28; lr: 0.10000; 4812/5027 tok/s;    904 sec\n",
            "[2020-06-01 21:17:26,587 INFO] Step 6900/10000; acc:  38.87; ppl: 26.24; xent: 3.27; lr: 0.10000; 5041/5167 tok/s;    910 sec\n",
            "[2020-06-01 21:17:33,623 INFO] Step 6950/10000; acc:  37.20; ppl: 27.72; xent: 3.32; lr: 0.10000; 5002/4967 tok/s;    917 sec\n",
            "[2020-06-01 21:17:33,951 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:17:34,270 INFO] number of examples: 26142\n",
            "[2020-06-01 21:17:41,267 INFO] Step 7000/10000; acc:  36.35; ppl: 30.58; xent: 3.42; lr: 0.10000; 4751/4638 tok/s;    925 sec\n",
            "[2020-06-01 21:17:47,466 INFO] Step 7050/10000; acc:  41.93; ppl: 20.84; xent: 3.04; lr: 0.10000; 4868/5010 tok/s;    931 sec\n",
            "[2020-06-01 21:17:53,285 INFO] Step 7100/10000; acc:  42.31; ppl: 20.76; xent: 3.03; lr: 0.10000; 5070/5181 tok/s;    937 sec\n",
            "[2020-06-01 21:18:00,461 INFO] Step 7150/10000; acc:  36.41; ppl: 29.98; xent: 3.40; lr: 0.10000; 4980/5021 tok/s;    944 sec\n",
            "[2020-06-01 21:18:06,443 INFO] Step 7200/10000; acc:  42.21; ppl: 20.14; xent: 3.00; lr: 0.10000; 4789/4988 tok/s;    950 sec\n",
            "[2020-06-01 21:18:13,007 INFO] Step 7250/10000; acc:  39.18; ppl: 25.41; xent: 3.24; lr: 0.10000; 4891/4979 tok/s;    956 sec\n",
            "[2020-06-01 21:18:19,210 INFO] Step 7300/10000; acc:  40.24; ppl: 23.61; xent: 3.16; lr: 0.10000; 4931/5196 tok/s;    963 sec\n",
            "[2020-06-01 21:18:26,063 INFO] Step 7350/10000; acc:  39.33; ppl: 24.42; xent: 3.20; lr: 0.10000; 5038/4914 tok/s;    969 sec\n",
            "[2020-06-01 21:18:27,737 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:18:28,074 INFO] number of examples: 26142\n",
            "[2020-06-01 21:18:34,066 INFO] Step 7400/10000; acc:  36.01; ppl: 30.64; xent: 3.42; lr: 0.10000; 4702/4678 tok/s;    977 sec\n",
            "[2020-06-01 21:18:40,228 INFO] Step 7450/10000; acc:  43.10; ppl: 19.17; xent: 2.95; lr: 0.10000; 4877/5003 tok/s;    984 sec\n",
            "[2020-06-01 21:18:46,004 INFO] Step 7500/10000; acc:  43.24; ppl: 18.99; xent: 2.94; lr: 0.10000; 5075/5145 tok/s;    989 sec\n",
            "[2020-06-01 21:18:52,717 INFO] Step 7550/10000; acc:  39.69; ppl: 24.78; xent: 3.21; lr: 0.10000; 4948/5041 tok/s;    996 sec\n",
            "[2020-06-01 21:18:58,853 INFO] Step 7600/10000; acc:  41.41; ppl: 20.89; xent: 3.04; lr: 0.10000; 5011/5143 tok/s;   1002 sec\n",
            "[2020-06-01 21:19:05,600 INFO] Step 7650/10000; acc:  40.11; ppl: 23.72; xent: 3.17; lr: 0.10000; 4807/4840 tok/s;   1009 sec\n",
            "[2020-06-01 21:19:12,174 INFO] Step 7700/10000; acc:  39.63; ppl: 24.66; xent: 3.21; lr: 0.10000; 4930/5162 tok/s;   1016 sec\n",
            "[2020-06-01 21:19:18,625 INFO] Step 7750/10000; acc:  41.87; ppl: 20.37; xent: 3.01; lr: 0.10000; 4928/4988 tok/s;   1022 sec\n",
            "[2020-06-01 21:19:21,578 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:19:21,929 INFO] number of examples: 26142\n",
            "[2020-06-01 21:19:26,857 INFO] Step 7800/10000; acc:  36.13; ppl: 29.69; xent: 3.39; lr: 0.10000; 4663/4624 tok/s;   1030 sec\n",
            "[2020-06-01 21:19:33,164 INFO] Step 7850/10000; acc:  42.93; ppl: 18.88; xent: 2.94; lr: 0.10000; 5064/5017 tok/s;   1037 sec\n",
            "[2020-06-01 21:19:38,759 INFO] Step 7900/10000; acc:  45.46; ppl: 16.48; xent: 2.80; lr: 0.10000; 4936/5067 tok/s;   1042 sec\n",
            "[2020-06-01 21:19:45,182 INFO] Step 7950/10000; acc:  41.85; ppl: 20.99; xent: 3.04; lr: 0.10000; 4933/5137 tok/s;   1049 sec\n",
            "[2020-06-01 21:19:51,566 INFO] Step 8000/10000; acc:  41.06; ppl: 21.35; xent: 3.06; lr: 0.10000; 4895/5042 tok/s;   1055 sec\n",
            "[2020-06-01 21:19:58,195 INFO] Step 8050/10000; acc:  41.41; ppl: 21.52; xent: 3.07; lr: 0.10000; 4863/4868 tok/s;   1062 sec\n",
            "[2020-06-01 21:20:05,290 INFO] Step 8100/10000; acc:  39.16; ppl: 25.01; xent: 3.22; lr: 0.10000; 5010/5131 tok/s;   1069 sec\n",
            "[2020-06-01 21:20:11,030 INFO] Step 8150/10000; acc:  45.14; ppl: 16.38; xent: 2.80; lr: 0.10000; 4888/5043 tok/s;   1074 sec\n",
            "[2020-06-01 21:20:15,499 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:20:15,836 INFO] number of examples: 26142\n",
            "[2020-06-01 21:20:19,343 INFO] Step 8200/10000; acc:  36.84; ppl: 27.81; xent: 3.33; lr: 0.10000; 4726/4653 tok/s;   1083 sec\n",
            "[2020-06-01 21:20:25,896 INFO] Step 8250/10000; acc:  42.24; ppl: 20.19; xent: 3.01; lr: 0.10000; 4965/4955 tok/s;   1089 sec\n",
            "[2020-06-01 21:20:31,490 INFO] Step 8300/10000; acc:  46.94; ppl: 14.75; xent: 2.69; lr: 0.10000; 4959/5094 tok/s;   1095 sec\n",
            "[2020-06-01 21:20:37,920 INFO] Step 8350/10000; acc:  42.47; ppl: 19.93; xent: 2.99; lr: 0.10000; 4989/5204 tok/s;   1101 sec\n",
            "[2020-06-01 21:20:44,508 INFO] Step 8400/10000; acc:  41.18; ppl: 21.45; xent: 3.07; lr: 0.10000; 4927/5005 tok/s;   1108 sec\n",
            "[2020-06-01 21:20:50,914 INFO] Step 8450/10000; acc:  43.27; ppl: 18.71; xent: 2.93; lr: 0.10000; 4857/4850 tok/s;   1114 sec\n",
            "[2020-06-01 21:20:57,867 INFO] Step 8500/10000; acc:  39.91; ppl: 23.28; xent: 3.15; lr: 0.10000; 4943/5108 tok/s;   1121 sec\n",
            "[2020-06-01 21:21:03,668 INFO] Step 8550/10000; acc:  45.80; ppl: 15.63; xent: 2.75; lr: 0.10000; 4870/5087 tok/s;   1127 sec\n",
            "[2020-06-01 21:21:09,313 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:21:09,665 INFO] number of examples: 26142\n",
            "[2020-06-01 21:21:11,474 INFO] Step 8600/10000; acc:  39.60; ppl: 22.70; xent: 3.12; lr: 0.10000; 4817/4691 tok/s;   1135 sec\n",
            "[2020-06-01 21:21:18,306 INFO] Step 8650/10000; acc:  41.41; ppl: 21.20; xent: 3.05; lr: 0.10000; 4905/4918 tok/s;   1142 sec\n",
            "[2020-06-01 21:21:24,303 INFO] Step 8700/10000; acc:  46.11; ppl: 15.47; xent: 2.74; lr: 0.10000; 4862/5011 tok/s;   1148 sec\n",
            "[2020-06-01 21:21:30,679 INFO] Step 8750/10000; acc:  43.09; ppl: 18.81; xent: 2.93; lr: 0.10000; 5060/5235 tok/s;   1154 sec\n",
            "[2020-06-01 21:21:37,163 INFO] Step 8800/10000; acc:  42.37; ppl: 19.83; xent: 2.99; lr: 0.10000; 4908/4943 tok/s;   1161 sec\n",
            "[2020-06-01 21:21:43,727 INFO] Step 8850/10000; acc:  43.71; ppl: 18.15; xent: 2.90; lr: 0.10000; 4905/4880 tok/s;   1167 sec\n",
            "[2020-06-01 21:21:50,455 INFO] Step 8900/10000; acc:  42.16; ppl: 20.18; xent: 3.00; lr: 0.10000; 4901/5174 tok/s;   1174 sec\n",
            "[2020-06-01 21:21:56,415 INFO] Step 8950/10000; acc:  45.17; ppl: 16.62; xent: 2.81; lr: 0.10000; 4914/5064 tok/s;   1180 sec\n",
            "[2020-06-01 21:22:03,181 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:22:03,545 INFO] number of examples: 26142\n",
            "[2020-06-01 21:22:03,990 INFO] Step 9000/10000; acc:  41.65; ppl: 20.05; xent: 3.00; lr: 0.10000; 4724/4678 tok/s;   1187 sec\n",
            "[2020-06-01 21:22:11,178 INFO] Step 9050/10000; acc:  40.98; ppl: 21.55; xent: 3.07; lr: 0.10000; 4964/4903 tok/s;   1195 sec\n",
            "[2020-06-01 21:22:17,445 INFO] Step 9100/10000; acc:  45.71; ppl: 15.57; xent: 2.75; lr: 0.10000; 4897/5011 tok/s;   1201 sec\n",
            "[2020-06-01 21:22:23,440 INFO] Step 9150/10000; acc:  45.24; ppl: 16.53; xent: 2.81; lr: 0.10000; 5028/5195 tok/s;   1207 sec\n",
            "[2020-06-01 21:22:30,167 INFO] Step 9200/10000; acc:  42.11; ppl: 19.87; xent: 2.99; lr: 0.10000; 4990/4965 tok/s;   1214 sec\n",
            "[2020-06-01 21:22:36,444 INFO] Step 9250/10000; acc:  44.95; ppl: 15.96; xent: 2.77; lr: 0.10000; 4783/4997 tok/s;   1220 sec\n",
            "[2020-06-01 21:22:42,751 INFO] Step 9300/10000; acc:  44.73; ppl: 17.13; xent: 2.84; lr: 0.10000; 4841/4961 tok/s;   1226 sec\n",
            "[2020-06-01 21:22:49,207 INFO] Step 9350/10000; acc:  43.35; ppl: 18.43; xent: 2.91; lr: 0.10000; 5005/5191 tok/s;   1233 sec\n",
            "[2020-06-01 21:22:56,090 INFO] Step 9400/10000; acc:  43.12; ppl: 17.85; xent: 2.88; lr: 0.10000; 4993/4928 tok/s;   1239 sec\n",
            "[2020-06-01 21:22:57,060 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:22:57,299 INFO] number of examples: 26142\n",
            "[2020-06-01 21:23:03,845 INFO] Step 9450/10000; acc:  40.30; ppl: 22.42; xent: 3.11; lr: 0.10000; 4766/4672 tok/s;   1247 sec\n",
            "[2020-06-01 21:23:10,079 INFO] Step 9500/10000; acc:  47.17; ppl: 13.97; xent: 2.64; lr: 0.10000; 4820/5019 tok/s;   1253 sec\n",
            "[2020-06-01 21:23:15,964 INFO] Step 9550/10000; acc:  47.29; ppl: 14.37; xent: 2.67; lr: 0.10000; 5090/5171 tok/s;   1259 sec\n",
            "[2020-06-01 21:23:22,828 INFO] Step 9600/10000; acc:  42.20; ppl: 19.76; xent: 2.98; lr: 0.10000; 4955/4970 tok/s;   1266 sec\n",
            "[2020-06-01 21:23:29,070 INFO] Step 9650/10000; acc:  45.72; ppl: 15.42; xent: 2.74; lr: 0.10000; 4815/5014 tok/s;   1272 sec\n",
            "[2020-06-01 21:23:35,392 INFO] Step 9700/10000; acc:  45.23; ppl: 16.25; xent: 2.79; lr: 0.10000; 4915/4945 tok/s;   1279 sec\n",
            "[2020-06-01 21:23:41,951 INFO] Step 9750/10000; acc:  43.58; ppl: 18.28; xent: 2.91; lr: 0.10000; 4947/5195 tok/s;   1285 sec\n",
            "[2020-06-01 21:23:48,568 INFO] Step 9800/10000; acc:  45.28; ppl: 15.94; xent: 2.77; lr: 0.10000; 5007/4986 tok/s;   1292 sec\n",
            "[2020-06-01 21:23:50,885 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:23:51,135 INFO] number of examples: 26142\n",
            "[2020-06-01 21:23:56,698 INFO] Step 9850/10000; acc:  39.79; ppl: 22.71; xent: 3.12; lr: 0.10000; 4761/4698 tok/s;   1300 sec\n",
            "[2020-06-01 21:24:02,931 INFO] Step 9900/10000; acc:  47.28; ppl: 13.86; xent: 2.63; lr: 0.10000; 4944/5009 tok/s;   1306 sec\n",
            "[2020-06-01 21:24:08,556 INFO] Step 9950/10000; acc:  49.03; ppl: 12.57; xent: 2.53; lr: 0.10000; 5007/5113 tok/s;   1312 sec\n",
            "[2020-06-01 21:24:15,397 INFO] Step 10000/10000; acc:  43.37; ppl: 18.37; xent: 2.91; lr: 0.10000; 4958/5057 tok/s;   1319 sec\n",
            "[2020-06-01 21:24:15,397 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 21:24:15,402 INFO] number of examples: 276\n",
            "[2020-06-01 21:24:15,983 INFO] Validation perplexity: 60.0428\n",
            "[2020-06-01 21:24:15,983 INFO] Validation accuracy: 31.6183\n",
            "[2020-06-01 21:24:16,015 INFO] Saving checkpoint model_step_10000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dujAPxzNa8a6",
        "colab_type": "code",
        "outputId": "301ef906-8db5-4a09-86a9-d72dc682b313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "en - st"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1328.0391142368317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUux3yV4a8QJ",
        "colab_type": "code",
        "outputId": "8b611c6b-1b57-4e63-e0d0-bc4388e76b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "st = time.time()\n",
        "!python OpenNMT-py/train.py -data En2Fa-Translation/Cleaned -world_size 1 -gpu_rank 0 --optim adam --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 10000\n",
        "en = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-01 21:24:26,887 INFO]  * src vocab size = 3116\n",
            "[2020-06-01 21:24:26,887 INFO]  * tgt vocab size = 5908\n",
            "[2020-06-01 21:24:26,888 INFO] Building model...\n",
            "[2020-06-01 21:24:29,371 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3116, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(5908, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=5908, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-01 21:24:29,371 INFO] encoder: 9938416\n",
            "[2020-06-01 21:24:29,371 INFO] decoder: 16200228\n",
            "[2020-06-01 21:24:29,372 INFO] * number of parameters: 26138644\n",
            "[2020-06-01 21:24:29,375 INFO] Starting training on GPU: [0]\n",
            "[2020-06-01 21:24:29,375 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-01 21:24:29,375 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:24:29,628 INFO] number of examples: 26142\n",
            "[2020-06-01 21:24:36,265 INFO] Step 50/10000; acc:   1.55; ppl: 26881171418161356094253400435962903554686976.00; xent: 2459.70; lr: 1.00000; 4145/4194 tok/s;      7 sec\n",
            "[2020-06-01 21:24:43,428 INFO] Step 100/10000; acc:   1.65; ppl: 26881171418161356094253400435962903554686976.00; xent: 4997.56; lr: 1.00000; 4433/4521 tok/s;     14 sec\n",
            "[2020-06-01 21:24:50,967 INFO] Step 150/10000; acc:   1.92; ppl: 26881171418161356094253400435962903554686976.00; xent: 5132.13; lr: 1.00000; 4752/4774 tok/s;     22 sec\n",
            "[2020-06-01 21:24:58,228 INFO] Step 200/10000; acc:   2.30; ppl: 26881171418161356094253400435962903554686976.00; xent: 4714.11; lr: 1.00000; 4492/4545 tok/s;     29 sec\n",
            "[2020-06-01 21:25:06,015 INFO] Step 250/10000; acc:   2.39; ppl: 26881171418161356094253400435962903554686976.00; xent: 4199.99; lr: 1.00000; 4534/4652 tok/s;     37 sec\n",
            "[2020-06-01 21:25:13,092 INFO] Step 300/10000; acc:   2.65; ppl: 26881171418161356094253400435962903554686976.00; xent: 3622.60; lr: 1.00000; 4801/4764 tok/s;     44 sec\n",
            "[2020-06-01 21:25:19,929 INFO] Step 350/10000; acc:   2.71; ppl: 26881171418161356094253400435962903554686976.00; xent: 3112.12; lr: 1.00000; 4480/4666 tok/s;     51 sec\n",
            "[2020-06-01 21:25:26,645 INFO] Step 400/10000; acc:   3.05; ppl: 26881171418161356094253400435962903554686976.00; xent: 2836.99; lr: 1.00000; 4524/4608 tok/s;     57 sec\n",
            "[2020-06-01 21:25:27,811 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:25:28,150 INFO] number of examples: 26142\n",
            "[2020-06-01 21:25:33,604 INFO] Step 450/10000; acc:   3.18; ppl: 26881171418161356094253400435962903554686976.00; xent: 2635.25; lr: 1.00000; 4139/4207 tok/s;     64 sec\n",
            "[2020-06-01 21:25:40,286 INFO] Step 500/10000; acc:   3.23; ppl: 26881171418161356094253400435962903554686976.00; xent: 2369.40; lr: 1.00000; 4387/4474 tok/s;     71 sec\n",
            "[2020-06-01 21:25:47,953 INFO] Step 550/10000; acc:   2.51; ppl: 26881171418161356094253400435962903554686976.00; xent: 2286.97; lr: 1.00000; 4803/4771 tok/s;     79 sec\n",
            "[2020-06-01 21:25:55,599 INFO] Step 600/10000; acc:   2.63; ppl: 26881171418161356094253400435962903554686976.00; xent: 2165.71; lr: 1.00000; 4573/4671 tok/s;     86 sec\n",
            "[2020-06-01 21:26:02,901 INFO] Step 650/10000; acc:   2.66; ppl: 26881171418161356094253400435962903554686976.00; xent: 2139.52; lr: 1.00000; 4557/4689 tok/s;     94 sec\n",
            "[2020-06-01 21:26:09,934 INFO] Step 700/10000; acc:   2.59; ppl: 26881171418161356094253400435962903554686976.00; xent: 2056.19; lr: 1.00000; 4560/4608 tok/s;    101 sec\n",
            "[2020-06-01 21:26:17,169 INFO] Step 750/10000; acc:   2.44; ppl: 26881171418161356094253400435962903554686976.00; xent: 2007.47; lr: 1.00000; 4627/4661 tok/s;    108 sec\n",
            "[2020-06-01 21:26:23,721 INFO] Step 800/10000; acc:   3.49; ppl: 26881171418161356094253400435962903554686976.00; xent: 2036.85; lr: 1.00000; 4515/4637 tok/s;    114 sec\n",
            "[2020-06-01 21:26:26,212 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:26:26,445 INFO] number of examples: 26142\n",
            "[2020-06-01 21:26:31,078 INFO] Step 850/10000; acc:   3.14; ppl: 26881171418161356094253400435962903554686976.00; xent: 2139.08; lr: 1.00000; 4181/4218 tok/s;    122 sec\n",
            "[2020-06-01 21:26:37,472 INFO] Step 900/10000; acc:   3.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 1970.02; lr: 1.00000; 4355/4489 tok/s;    128 sec\n",
            "[2020-06-01 21:26:45,074 INFO] Step 950/10000; acc:   2.46; ppl: 26881171418161356094253400435962903554686976.00; xent: 2050.64; lr: 1.00000; 4705/4703 tok/s;    136 sec\n",
            "[2020-06-01 21:26:52,687 INFO] Step 1000/10000; acc:   2.46; ppl: 26881171418161356094253400435962903554686976.00; xent: 1942.05; lr: 1.00000; 4645/4675 tok/s;    143 sec\n",
            "[2020-06-01 21:26:59,945 INFO] Step 1050/10000; acc:   2.81; ppl: 26881171418161356094253400435962903554686976.00; xent: 2156.53; lr: 1.00000; 4445/4576 tok/s;    151 sec\n",
            "[2020-06-01 21:27:07,378 INFO] Step 1100/10000; acc:   2.67; ppl: 26881171418161356094253400435962903554686976.00; xent: 2108.70; lr: 1.00000; 4537/4663 tok/s;    158 sec\n",
            "[2020-06-01 21:27:14,780 INFO] Step 1150/10000; acc:   2.76; ppl: 26881171418161356094253400435962903554686976.00; xent: 2187.40; lr: 1.00000; 4687/4683 tok/s;    165 sec\n",
            "[2020-06-01 21:27:21,198 INFO] Step 1200/10000; acc:   3.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 2065.09; lr: 1.00000; 4489/4597 tok/s;    172 sec\n",
            "[2020-06-01 21:27:24,812 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:27:25,055 INFO] number of examples: 26142\n",
            "[2020-06-01 21:27:28,305 INFO] Step 1250/10000; acc:   2.68; ppl: 26881171418161356094253400435962903554686976.00; xent: 1999.97; lr: 1.00000; 4167/4223 tok/s;    179 sec\n",
            "[2020-06-01 21:27:34,852 INFO] Step 1300/10000; acc:   3.81; ppl: 26881171418161356094253400435962903554686976.00; xent: 2003.64; lr: 1.00000; 4460/4562 tok/s;    185 sec\n",
            "[2020-06-01 21:27:42,168 INFO] Step 1350/10000; acc:   3.08; ppl: 26881171418161356094253400435962903554686976.00; xent: 2129.86; lr: 1.00000; 4578/4658 tok/s;    193 sec\n",
            "[2020-06-01 21:27:49,991 INFO] Step 1400/10000; acc:   2.56; ppl: 26881171418161356094253400435962903554686976.00; xent: 1994.53; lr: 1.00000; 4720/4651 tok/s;    201 sec\n",
            "[2020-06-01 21:27:57,317 INFO] Step 1450/10000; acc:   2.65; ppl: 26881171418161356094253400435962903554686976.00; xent: 2013.10; lr: 1.00000; 4412/4607 tok/s;    208 sec\n",
            "[2020-06-01 21:28:04,402 INFO] Step 1500/10000; acc:   3.04; ppl: 26881171418161356094253400435962903554686976.00; xent: 2086.07; lr: 1.00000; 4462/4617 tok/s;    215 sec\n",
            "[2020-06-01 21:28:11,803 INFO] Step 1550/10000; acc:   2.60; ppl: 26881171418161356094253400435962903554686976.00; xent: 2162.01; lr: 1.00000; 4790/4750 tok/s;    222 sec\n",
            "[2020-06-01 21:28:18,433 INFO] Step 1600/10000; acc:   3.43; ppl: 26881171418161356094253400435962903554686976.00; xent: 2062.36; lr: 1.00000; 4559/4601 tok/s;    229 sec\n",
            "[2020-06-01 21:28:23,278 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:28:23,586 INFO] number of examples: 26142\n",
            "[2020-06-01 21:28:25,577 INFO] Step 1650/10000; acc:   2.98; ppl: 26881171418161356094253400435962903554686976.00; xent: 2016.96; lr: 1.00000; 4123/4221 tok/s;    236 sec\n",
            "[2020-06-01 21:28:31,969 INFO] Step 1700/10000; acc:   3.45; ppl: 26881171418161356094253400435962903554686976.00; xent: 2099.81; lr: 1.00000; 4480/4592 tok/s;    243 sec\n",
            "[2020-06-01 21:28:39,511 INFO] Step 1750/10000; acc:   2.84; ppl: 26881171418161356094253400435962903554686976.00; xent: 2137.70; lr: 1.00000; 4587/4577 tok/s;    250 sec\n",
            "[2020-06-01 21:28:46,756 INFO] Step 1800/10000; acc:   2.53; ppl: 26881171418161356094253400435962903554686976.00; xent: 2152.05; lr: 1.00000; 4613/4723 tok/s;    257 sec\n",
            "[2020-06-01 21:28:54,288 INFO] Step 1850/10000; acc:   2.48; ppl: 26881171418161356094253400435962903554686976.00; xent: 2122.69; lr: 1.00000; 4462/4558 tok/s;    265 sec\n",
            "[2020-06-01 21:29:01,613 INFO] Step 1900/10000; acc:   2.66; ppl: 26881171418161356094253400435962903554686976.00; xent: 2122.91; lr: 1.00000; 4462/4571 tok/s;    272 sec\n",
            "[2020-06-01 21:29:09,057 INFO] Step 1950/10000; acc:   2.42; ppl: 26881171418161356094253400435962903554686976.00; xent: 2160.02; lr: 1.00000; 4785/4821 tok/s;    280 sec\n",
            "[2020-06-01 21:29:15,822 INFO] Step 2000/10000; acc:   2.96; ppl: 26881171418161356094253400435962903554686976.00; xent: 2188.87; lr: 1.00000; 4528/4587 tok/s;    286 sec\n",
            "[2020-06-01 21:29:21,820 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:29:22,136 INFO] number of examples: 26142\n",
            "[2020-06-01 21:29:22,878 INFO] Step 2050/10000; acc:   2.90; ppl: 26881171418161356094253400435962903554686976.00; xent: 2099.24; lr: 1.00000; 4204/4280 tok/s;    294 sec\n",
            "[2020-06-01 21:29:29,378 INFO] Step 2100/10000; acc:   3.93; ppl: 26881171418161356094253400435962903554686976.00; xent: 2187.58; lr: 1.00000; 4394/4511 tok/s;    300 sec\n",
            "[2020-06-01 21:29:36,602 INFO] Step 2150/10000; acc:   2.96; ppl: 26881171418161356094253400435962903554686976.00; xent: 2349.26; lr: 1.00000; 4461/4481 tok/s;    307 sec\n",
            "[2020-06-01 21:29:44,035 INFO] Step 2200/10000; acc:   2.61; ppl: 26881171418161356094253400435962903554686976.00; xent: 2252.23; lr: 1.00000; 4678/4779 tok/s;    315 sec\n",
            "[2020-06-01 21:29:51,519 INFO] Step 2250/10000; acc:   2.97; ppl: 26881171418161356094253400435962903554686976.00; xent: 2207.68; lr: 1.00000; 4507/4533 tok/s;    322 sec\n",
            "[2020-06-01 21:29:59,038 INFO] Step 2300/10000; acc:   2.72; ppl: 26881171418161356094253400435962903554686976.00; xent: 2164.01; lr: 1.00000; 4509/4576 tok/s;    330 sec\n",
            "[2020-06-01 21:30:06,292 INFO] Step 2350/10000; acc:   2.82; ppl: 26881171418161356094253400435962903554686976.00; xent: 2200.77; lr: 1.00000; 4796/4807 tok/s;    337 sec\n",
            "[2020-06-01 21:30:13,225 INFO] Step 2400/10000; acc:   3.10; ppl: 26881171418161356094253400435962903554686976.00; xent: 2206.63; lr: 1.00000; 4519/4634 tok/s;    344 sec\n",
            "[2020-06-01 21:30:19,869 INFO] Step 2450/10000; acc:   3.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 2199.78; lr: 1.00000; 4487/4591 tok/s;    350 sec\n",
            "[2020-06-01 21:30:20,400 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:30:20,719 INFO] number of examples: 26142\n",
            "[2020-06-01 21:30:26,750 INFO] Step 2500/10000; acc:   3.47; ppl: 26881171418161356094253400435962903554686976.00; xent: 2170.66; lr: 1.00000; 4121/4181 tok/s;    357 sec\n",
            "[2020-06-01 21:30:33,597 INFO] Step 2550/10000; acc:   3.27; ppl: 26881171418161356094253400435962903554686976.00; xent: 2166.04; lr: 1.00000; 4384/4489 tok/s;    364 sec\n",
            "[2020-06-01 21:30:41,379 INFO] Step 2600/10000; acc:   2.44; ppl: 26881171418161356094253400435962903554686976.00; xent: 2138.66; lr: 1.00000; 4760/4766 tok/s;    372 sec\n",
            "[2020-06-01 21:30:48,725 INFO] Step 2650/10000; acc:   2.81; ppl: 26881171418161356094253400435962903554686976.00; xent: 2141.96; lr: 1.00000; 4564/4629 tok/s;    379 sec\n",
            "[2020-06-01 21:30:56,314 INFO] Step 2700/10000; acc:   2.64; ppl: 26881171418161356094253400435962903554686976.00; xent: 2179.18; lr: 1.00000; 4613/4708 tok/s;    387 sec\n",
            "[2020-06-01 21:31:03,437 INFO] Step 2750/10000; acc:   3.07; ppl: 26881171418161356094253400435962903554686976.00; xent: 2183.76; lr: 1.00000; 4583/4603 tok/s;    394 sec\n",
            "[2020-06-01 21:31:10,536 INFO] Step 2800/10000; acc:   2.79; ppl: 26881171418161356094253400435962903554686976.00; xent: 2070.07; lr: 1.00000; 4535/4648 tok/s;    401 sec\n",
            "[2020-06-01 21:31:17,040 INFO] Step 2850/10000; acc:   3.46; ppl: 26881171418161356094253400435962903554686976.00; xent: 2142.03; lr: 1.00000; 4529/4609 tok/s;    408 sec\n",
            "[2020-06-01 21:31:18,908 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:31:19,228 INFO] number of examples: 26142\n",
            "[2020-06-01 21:31:24,230 INFO] Step 2900/10000; acc:   3.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 2173.74; lr: 1.00000; 4118/4194 tok/s;    415 sec\n",
            "[2020-06-01 21:31:30,985 INFO] Step 2950/10000; acc:   3.33; ppl: 26881171418161356094253400435962903554686976.00; xent: 2083.36; lr: 1.00000; 4425/4486 tok/s;    422 sec\n",
            "[2020-06-01 21:31:38,557 INFO] Step 3000/10000; acc:   2.93; ppl: 26881171418161356094253400435962903554686976.00; xent: 2157.53; lr: 1.00000; 4702/4743 tok/s;    429 sec\n",
            "[2020-06-01 21:31:46,081 INFO] Step 3050/10000; acc:   2.71; ppl: 26881171418161356094253400435962903554686976.00; xent: 2029.87; lr: 1.00000; 4596/4613 tok/s;    437 sec\n",
            "[2020-06-01 21:31:53,537 INFO] Step 3100/10000; acc:   2.77; ppl: 26881171418161356094253400435962903554686976.00; xent: 2097.87; lr: 1.00000; 4548/4698 tok/s;    444 sec\n",
            "[2020-06-01 21:32:00,564 INFO] Step 3150/10000; acc:   2.79; ppl: 26881171418161356094253400435962903554686976.00; xent: 2095.45; lr: 1.00000; 4518/4627 tok/s;    451 sec\n",
            "[2020-06-01 21:32:08,004 INFO] Step 3200/10000; acc:   2.54; ppl: 26881171418161356094253400435962903554686976.00; xent: 2176.77; lr: 1.00000; 4680/4697 tok/s;    459 sec\n",
            "[2020-06-01 21:32:14,458 INFO] Step 3250/10000; acc:   3.14; ppl: 26881171418161356094253400435962903554686976.00; xent: 2212.74; lr: 1.00000; 4504/4617 tok/s;    465 sec\n",
            "[2020-06-01 21:32:17,389 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:32:17,752 INFO] number of examples: 26142\n",
            "[2020-06-01 21:32:21,779 INFO] Step 3300/10000; acc:   3.22; ppl: 26881171418161356094253400435962903554686976.00; xent: 2274.39; lr: 1.00000; 4149/4205 tok/s;    472 sec\n",
            "[2020-06-01 21:32:27,980 INFO] Step 3350/10000; acc:   3.60; ppl: 26881171418161356094253400435962903554686976.00; xent: 2189.71; lr: 1.00000; 4389/4520 tok/s;    479 sec\n",
            "[2020-06-01 21:32:35,539 INFO] Step 3400/10000; acc:   2.62; ppl: 26881171418161356094253400435962903554686976.00; xent: 2232.28; lr: 1.00000; 4643/4666 tok/s;    486 sec\n",
            "[2020-06-01 21:32:43,297 INFO] Step 3450/10000; acc:   2.47; ppl: 26881171418161356094253400435962903554686976.00; xent: 2201.22; lr: 1.00000; 4702/4655 tok/s;    494 sec\n",
            "[2020-06-01 21:32:50,662 INFO] Step 3500/10000; acc:   2.50; ppl: 26881171418161356094253400435962903554686976.00; xent: 2195.71; lr: 1.00000; 4441/4606 tok/s;    501 sec\n",
            "[2020-06-01 21:32:57,914 INFO] Step 3550/10000; acc:   2.57; ppl: 26881171418161356094253400435962903554686976.00; xent: 2244.78; lr: 1.00000; 4501/4642 tok/s;    509 sec\n",
            "[2020-06-01 21:33:05,447 INFO] Step 3600/10000; acc:   2.39; ppl: 26881171418161356094253400435962903554686976.00; xent: 2255.38; lr: 1.00000; 4750/4735 tok/s;    516 sec\n",
            "[2020-06-01 21:33:11,841 INFO] Step 3650/10000; acc:   3.34; ppl: 26881171418161356094253400435962903554686976.00; xent: 2124.98; lr: 1.00000; 4526/4584 tok/s;    522 sec\n",
            "[2020-06-01 21:33:15,964 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:33:16,298 INFO] number of examples: 26142\n",
            "[2020-06-01 21:33:19,264 INFO] Step 3700/10000; acc:   3.11; ppl: 26881171418161356094253400435962903554686976.00; xent: 2143.47; lr: 1.00000; 4144/4220 tok/s;    530 sec\n",
            "[2020-06-01 21:33:25,347 INFO] Step 3750/10000; acc:   3.62; ppl: 26881171418161356094253400435962903554686976.00; xent: 2053.07; lr: 1.00000; 4381/4554 tok/s;    536 sec\n",
            "[2020-06-01 21:33:32,855 INFO] Step 3800/10000; acc:   2.88; ppl: 26881171418161356094253400435962903554686976.00; xent: 2151.33; lr: 1.00000; 4605/4601 tok/s;    543 sec\n",
            "[2020-06-01 21:33:40,310 INFO] Step 3850/10000; acc:   2.87; ppl: 26881171418161356094253400435962903554686976.00; xent: 2128.77; lr: 1.00000; 4636/4681 tok/s;    551 sec\n",
            "[2020-06-01 21:33:48,005 INFO] Step 3900/10000; acc:   2.61; ppl: 26881171418161356094253400435962903554686976.00; xent: 2179.28; lr: 1.00000; 4524/4598 tok/s;    559 sec\n",
            "[2020-06-01 21:33:55,149 INFO] Step 3950/10000; acc:   2.91; ppl: 26881171418161356094253400435962903554686976.00; xent: 2175.93; lr: 1.00000; 4408/4582 tok/s;    566 sec\n",
            "[2020-06-01 21:34:02,445 INFO] Step 4000/10000; acc:   2.71; ppl: 26881171418161356094253400435962903554686976.00; xent: 2228.19; lr: 1.00000; 4803/4807 tok/s;    573 sec\n",
            "[2020-06-01 21:34:09,166 INFO] Step 4050/10000; acc:   3.02; ppl: 26881171418161356094253400435962903554686976.00; xent: 2207.07; lr: 1.00000; 4539/4579 tok/s;    580 sec\n",
            "[2020-06-01 21:34:14,524 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:34:14,852 INFO] number of examples: 26142\n",
            "[2020-06-01 21:34:16,207 INFO] Step 4100/10000; acc:   3.22; ppl: 26881171418161356094253400435962903554686976.00; xent: 2091.64; lr: 1.00000; 4120/4243 tok/s;    587 sec\n",
            "[2020-06-01 21:34:22,668 INFO] Step 4150/10000; acc:   3.22; ppl: 26881171418161356094253400435962903554686976.00; xent: 2013.18; lr: 1.00000; 4412/4541 tok/s;    593 sec\n",
            "[2020-06-01 21:34:30,129 INFO] Step 4200/10000; acc:   2.83; ppl: 26881171418161356094253400435962903554686976.00; xent: 2242.51; lr: 1.00000; 4568/4563 tok/s;    601 sec\n",
            "[2020-06-01 21:34:37,348 INFO] Step 4250/10000; acc:   2.60; ppl: 26881171418161356094253400435962903554686976.00; xent: 2187.01; lr: 1.00000; 4621/4698 tok/s;    608 sec\n",
            "[2020-06-01 21:34:44,961 INFO] Step 4300/10000; acc:   2.80; ppl: 26881171418161356094253400435962903554686976.00; xent: 2122.76; lr: 1.00000; 4506/4574 tok/s;    616 sec\n",
            "[2020-06-01 21:34:52,357 INFO] Step 4350/10000; acc:   3.01; ppl: 26881171418161356094253400435962903554686976.00; xent: 2161.33; lr: 1.00000; 4471/4556 tok/s;    623 sec\n",
            "[2020-06-01 21:34:59,771 INFO] Step 4400/10000; acc:   2.49; ppl: 26881171418161356094253400435962903554686976.00; xent: 2166.23; lr: 1.00000; 4839/4832 tok/s;    630 sec\n",
            "[2020-06-01 21:35:06,439 INFO] Step 4450/10000; acc:   3.05; ppl: 26881171418161356094253400435962903554686976.00; xent: 2085.72; lr: 1.00000; 4431/4555 tok/s;    637 sec\n",
            "[2020-06-01 21:35:13,108 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:35:13,441 INFO] number of examples: 26142\n",
            "[2020-06-01 21:35:13,620 INFO] Step 4500/10000; acc:   3.14; ppl: 26881171418161356094253400435962903554686976.00; xent: 2187.05; lr: 1.00000; 4238/4313 tok/s;    644 sec\n",
            "[2020-06-01 21:35:20,085 INFO] Step 4550/10000; acc:   3.91; ppl: 26881171418161356094253400435962903554686976.00; xent: 2137.62; lr: 1.00000; 4408/4485 tok/s;    651 sec\n",
            "[2020-06-01 21:35:27,325 INFO] Step 4600/10000; acc:   2.84; ppl: 26881171418161356094253400435962903554686976.00; xent: 2297.47; lr: 1.00000; 4464/4528 tok/s;    658 sec\n",
            "[2020-06-01 21:35:34,880 INFO] Step 4650/10000; acc:   2.90; ppl: 26881171418161356094253400435962903554686976.00; xent: 2310.60; lr: 1.00000; 4717/4748 tok/s;    666 sec\n",
            "[2020-06-01 21:35:42,158 INFO] Step 4700/10000; acc:   2.79; ppl: 26881171418161356094253400435962903554686976.00; xent: 2273.64; lr: 1.00000; 4490/4562 tok/s;    673 sec\n",
            "[2020-06-01 21:35:49,917 INFO] Step 4750/10000; acc:   2.57; ppl: 26881171418161356094253400435962903554686976.00; xent: 2318.09; lr: 1.00000; 4534/4620 tok/s;    681 sec\n",
            "[2020-06-01 21:35:57,079 INFO] Step 4800/10000; acc:   2.91; ppl: 26881171418161356094253400435962903554686976.00; xent: 2266.80; lr: 1.00000; 4763/4751 tok/s;    688 sec\n",
            "[2020-06-01 21:36:03,936 INFO] Step 4850/10000; acc:   3.10; ppl: 26881171418161356094253400435962903554686976.00; xent: 2187.68; lr: 1.00000; 4466/4644 tok/s;    695 sec\n",
            "[2020-06-01 21:36:10,658 INFO] Step 4900/10000; acc:   3.25; ppl: 26881171418161356094253400435962903554686976.00; xent: 2145.85; lr: 1.00000; 4529/4603 tok/s;    701 sec\n",
            "[2020-06-01 21:36:11,675 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:36:12,014 INFO] number of examples: 26142\n",
            "[2020-06-01 21:36:17,724 INFO] Step 4950/10000; acc:   3.12; ppl: 26881171418161356094253400435962903554686976.00; xent: 2166.38; lr: 1.00000; 4131/4195 tok/s;    708 sec\n",
            "[2020-06-01 21:36:24,357 INFO] Step 5000/10000; acc:   3.52; ppl: 26881171418161356094253400435962903554686976.00; xent: 2025.36; lr: 1.00000; 4342/4423 tok/s;    715 sec\n",
            "[2020-06-01 21:36:24,395 INFO] Saving checkpoint model_step_5000.pt\n",
            "[2020-06-01 21:36:33,246 INFO] Step 5050/10000; acc:   2.57; ppl: 26881171418161356094253400435962903554686976.00; xent: 2193.02; lr: 1.00000; 4164/4144 tok/s;    724 sec\n",
            "[2020-06-01 21:36:40,951 INFO] Step 5100/10000; acc:   2.62; ppl: 26881171418161356094253400435962903554686976.00; xent: 2232.18; lr: 1.00000; 4505/4610 tok/s;    732 sec\n",
            "[2020-06-01 21:36:48,307 INFO] Step 5150/10000; acc:   2.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 2213.06; lr: 1.00000; 4576/4683 tok/s;    739 sec\n",
            "[2020-06-01 21:36:55,342 INFO] Step 5200/10000; acc:   3.03; ppl: 26881171418161356094253400435962903554686976.00; xent: 2184.00; lr: 1.00000; 4494/4589 tok/s;    746 sec\n",
            "[2020-06-01 21:37:02,527 INFO] Step 5250/10000; acc:   2.68; ppl: 26881171418161356094253400435962903554686976.00; xent: 2241.66; lr: 1.00000; 4615/4637 tok/s;    753 sec\n",
            "[2020-06-01 21:37:09,091 INFO] Step 5300/10000; acc:   2.82; ppl: 26881171418161356094253400435962903554686976.00; xent: 2162.55; lr: 1.00000; 4526/4629 tok/s;    760 sec\n",
            "[2020-06-01 21:37:11,497 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:37:11,858 INFO] number of examples: 26142\n",
            "[2020-06-01 21:37:16,505 INFO] Step 5350/10000; acc:   3.01; ppl: 26881171418161356094253400435962903554686976.00; xent: 2237.60; lr: 1.00000; 4184/4222 tok/s;    767 sec\n",
            "[2020-06-01 21:37:22,881 INFO] Step 5400/10000; acc:   3.44; ppl: 26881171418161356094253400435962903554686976.00; xent: 2051.26; lr: 1.00000; 4357/4499 tok/s;    774 sec\n",
            "[2020-06-01 21:37:30,483 INFO] Step 5450/10000; acc:   3.04; ppl: 26881171418161356094253400435962903554686976.00; xent: 2105.47; lr: 1.00000; 4689/4703 tok/s;    781 sec\n",
            "[2020-06-01 21:37:38,198 INFO] Step 5500/10000; acc:   2.47; ppl: 26881171418161356094253400435962903554686976.00; xent: 2180.07; lr: 1.00000; 4646/4653 tok/s;    789 sec\n",
            "[2020-06-01 21:37:45,405 INFO] Step 5550/10000; acc:   2.77; ppl: 26881171418161356094253400435962903554686976.00; xent: 2150.07; lr: 1.00000; 4462/4633 tok/s;    796 sec\n",
            "[2020-06-01 21:37:52,716 INFO] Step 5600/10000; acc:   2.75; ppl: 26881171418161356094253400435962903554686976.00; xent: 2194.10; lr: 1.00000; 4544/4649 tok/s;    803 sec\n",
            "[2020-06-01 21:38:00,128 INFO] Step 5650/10000; acc:   2.85; ppl: 26881171418161356094253400435962903554686976.00; xent: 2157.94; lr: 1.00000; 4689/4676 tok/s;    811 sec\n",
            "[2020-06-01 21:38:06,530 INFO] Step 5700/10000; acc:   3.62; ppl: 26881171418161356094253400435962903554686976.00; xent: 2066.42; lr: 1.00000; 4481/4600 tok/s;    817 sec\n",
            "[2020-06-01 21:38:10,046 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:38:10,288 INFO] number of examples: 26142\n",
            "[2020-06-01 21:38:13,717 INFO] Step 5750/10000; acc:   2.78; ppl: 26881171418161356094253400435962903554686976.00; xent: 2153.43; lr: 1.00000; 4209/4274 tok/s;    824 sec\n",
            "[2020-06-01 21:38:20,160 INFO] Step 5800/10000; acc:   3.42; ppl: 26881171418161356094253400435962903554686976.00; xent: 1965.79; lr: 1.00000; 4463/4555 tok/s;    831 sec\n",
            "[2020-06-01 21:38:27,507 INFO] Step 5850/10000; acc:   2.88; ppl: 26881171418161356094253400435962903554686976.00; xent: 2138.03; lr: 1.00000; 4603/4665 tok/s;    838 sec\n",
            "[2020-06-01 21:38:35,332 INFO] Step 5900/10000; acc:   2.54; ppl: 26881171418161356094253400435962903554686976.00; xent: 2134.50; lr: 1.00000; 4743/4666 tok/s;    846 sec\n",
            "[2020-06-01 21:38:42,581 INFO] Step 5950/10000; acc:   2.39; ppl: 26881171418161356094253400435962903554686976.00; xent: 2081.09; lr: 1.00000; 4388/4612 tok/s;    853 sec\n",
            "[2020-06-01 21:38:49,624 INFO] Step 6000/10000; acc:   3.10; ppl: 26881171418161356094253400435962903554686976.00; xent: 2129.28; lr: 1.00000; 4462/4608 tok/s;    860 sec\n",
            "[2020-06-01 21:38:57,113 INFO] Step 6050/10000; acc:   2.53; ppl: 26881171418161356094253400435962903554686976.00; xent: 2118.23; lr: 1.00000; 4819/4763 tok/s;    868 sec\n",
            "[2020-06-01 21:39:03,815 INFO] Step 6100/10000; acc:   3.37; ppl: 26881171418161356094253400435962903554686976.00; xent: 2107.00; lr: 1.00000; 4586/4629 tok/s;    874 sec\n",
            "[2020-06-01 21:39:08,409 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:39:08,727 INFO] number of examples: 26142\n",
            "[2020-06-01 21:39:11,150 INFO] Step 6150/10000; acc:   3.04; ppl: 26881171418161356094253400435962903554686976.00; xent: 2124.66; lr: 1.00000; 4116/4199 tok/s;    882 sec\n",
            "[2020-06-01 21:39:17,328 INFO] Step 6200/10000; acc:   3.87; ppl: 26881171418161356094253400435962903554686976.00; xent: 2101.85; lr: 1.00000; 4416/4587 tok/s;    888 sec\n",
            "[2020-06-01 21:39:24,822 INFO] Step 6250/10000; acc:   2.96; ppl: 26881171418161356094253400435962903554686976.00; xent: 2203.84; lr: 1.00000; 4606/4605 tok/s;    895 sec\n",
            "[2020-06-01 21:39:32,173 INFO] Step 6300/10000; acc:   2.65; ppl: 26881171418161356094253400435962903554686976.00; xent: 2228.44; lr: 1.00000; 4660/4743 tok/s;    903 sec\n",
            "[2020-06-01 21:39:39,741 INFO] Step 6350/10000; acc:   2.66; ppl: 26881171418161356094253400435962903554686976.00; xent: 2270.10; lr: 1.00000; 4446/4510 tok/s;    910 sec\n",
            "[2020-06-01 21:39:46,985 INFO] Step 6400/10000; acc:   2.74; ppl: 26881171418161356094253400435962903554686976.00; xent: 2184.05; lr: 1.00000; 4498/4611 tok/s;    918 sec\n",
            "[2020-06-01 21:39:54,279 INFO] Step 6450/10000; acc:   2.67; ppl: 26881171418161356094253400435962903554686976.00; xent: 2177.73; lr: 1.00000; 4769/4808 tok/s;    925 sec\n",
            "[2020-06-01 21:40:01,060 INFO] Step 6500/10000; acc:   2.96; ppl: 26881171418161356094253400435962903554686976.00; xent: 2173.15; lr: 1.00000; 4518/4603 tok/s;    932 sec\n",
            "[2020-06-01 21:40:06,910 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:40:07,218 INFO] number of examples: 26142\n",
            "[2020-06-01 21:40:08,057 INFO] Step 6550/10000; acc:   3.51; ppl: 26881171418161356094253400435962903554686976.00; xent: 2071.53; lr: 1.00000; 4212/4288 tok/s;    939 sec\n",
            "[2020-06-01 21:40:14,568 INFO] Step 6600/10000; acc:   3.53; ppl: 26881171418161356094253400435962903554686976.00; xent: 2086.19; lr: 1.00000; 4386/4522 tok/s;    945 sec\n",
            "[2020-06-01 21:40:21,819 INFO] Step 6650/10000; acc:   3.00; ppl: 26881171418161356094253400435962903554686976.00; xent: 2113.79; lr: 1.00000; 4498/4500 tok/s;    952 sec\n",
            "[2020-06-01 21:40:29,175 INFO] Step 6700/10000; acc:   2.82; ppl: 26881171418161356094253400435962903554686976.00; xent: 2099.37; lr: 1.00000; 4665/4776 tok/s;    960 sec\n",
            "[2020-06-01 21:40:36,683 INFO] Step 6750/10000; acc:   2.94; ppl: 26881171418161356094253400435962903554686976.00; xent: 2155.27; lr: 1.00000; 4527/4569 tok/s;    967 sec\n",
            "[2020-06-01 21:40:44,176 INFO] Step 6800/10000; acc:   2.67; ppl: 26881171418161356094253400435962903554686976.00; xent: 2114.41; lr: 1.00000; 4525/4583 tok/s;    975 sec\n",
            "[2020-06-01 21:40:51,321 INFO] Step 6850/10000; acc:   2.45; ppl: 26881171418161356094253400435962903554686976.00; xent: 2040.23; lr: 1.00000; 4824/4826 tok/s;    982 sec\n",
            "[2020-06-01 21:40:58,294 INFO] Step 6900/10000; acc:   3.27; ppl: 26881171418161356094253400435962903554686976.00; xent: 2197.77; lr: 1.00000; 4521/4627 tok/s;    989 sec\n",
            "[2020-06-01 21:41:04,951 INFO] Step 6950/10000; acc:   3.13; ppl: 26881171418161356094253400435962903554686976.00; xent: 2120.37; lr: 1.00000; 4466/4561 tok/s;    996 sec\n",
            "[2020-06-01 21:41:05,339 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:41:05,665 INFO] number of examples: 26142\n",
            "[2020-06-01 21:41:11,810 INFO] Step 7000/10000; acc:   3.58; ppl: 26881171418161356094253400435962903554686976.00; xent: 2103.02; lr: 1.00000; 4145/4224 tok/s;   1002 sec\n",
            "[2020-06-01 21:41:18,774 INFO] Step 7050/10000; acc:   3.26; ppl: 26881171418161356094253400435962903554686976.00; xent: 2143.04; lr: 1.00000; 4420/4500 tok/s;   1009 sec\n",
            "[2020-06-01 21:41:26,517 INFO] Step 7100/10000; acc:   2.17; ppl: 26881171418161356094253400435962903554686976.00; xent: 2158.06; lr: 1.00000; 4751/4762 tok/s;   1017 sec\n",
            "[2020-06-01 21:41:33,826 INFO] Step 7150/10000; acc:   2.98; ppl: 26881171418161356094253400435962903554686976.00; xent: 2086.82; lr: 1.00000; 4535/4595 tok/s;   1024 sec\n",
            "[2020-06-01 21:41:41,390 INFO] Step 7200/10000; acc:   2.51; ppl: 26881171418161356094253400435962903554686976.00; xent: 2125.19; lr: 1.00000; 4585/4720 tok/s;   1032 sec\n",
            "[2020-06-01 21:41:48,632 INFO] Step 7250/10000; acc:   2.96; ppl: 26881171418161356094253400435962903554686976.00; xent: 2128.84; lr: 1.00000; 4658/4620 tok/s;   1039 sec\n",
            "[2020-06-01 21:41:55,560 INFO] Step 7300/10000; acc:   2.91; ppl: 26881171418161356094253400435962903554686976.00; xent: 2069.47; lr: 1.00000; 4481/4624 tok/s;   1046 sec\n",
            "[2020-06-01 21:42:02,088 INFO] Step 7350/10000; acc:   2.86; ppl: 26881171418161356094253400435962903554686976.00; xent: 2148.61; lr: 1.00000; 4521/4627 tok/s;   1053 sec\n",
            "[2020-06-01 21:42:03,851 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:42:04,176 INFO] number of examples: 26142\n",
            "[2020-06-01 21:42:09,334 INFO] Step 7400/10000; acc:   3.07; ppl: 26881171418161356094253400435962903554686976.00; xent: 2190.42; lr: 1.00000; 4140/4206 tok/s;   1060 sec\n",
            "[2020-06-01 21:42:16,027 INFO] Step 7450/10000; acc:   3.62; ppl: 26881171418161356094253400435962903554686976.00; xent: 2121.85; lr: 1.00000; 4408/4465 tok/s;   1067 sec\n",
            "[2020-06-01 21:42:23,622 INFO] Step 7500/10000; acc:   2.74; ppl: 26881171418161356094253400435962903554686976.00; xent: 2199.59; lr: 1.00000; 4747/4756 tok/s;   1074 sec\n",
            "[2020-06-01 21:42:31,186 INFO] Step 7550/10000; acc:   2.43; ppl: 26881171418161356094253400435962903554686976.00; xent: 2201.03; lr: 1.00000; 4580/4643 tok/s;   1082 sec\n",
            "[2020-06-01 21:42:38,536 INFO] Step 7600/10000; acc:   2.90; ppl: 26881171418161356094253400435962903554686976.00; xent: 2152.20; lr: 1.00000; 4536/4671 tok/s;   1089 sec\n",
            "[2020-06-01 21:42:45,575 INFO] Step 7650/10000; acc:   2.89; ppl: 26881171418161356094253400435962903554686976.00; xent: 2041.88; lr: 1.00000; 4501/4619 tok/s;   1096 sec\n",
            "[2020-06-01 21:42:53,006 INFO] Step 7700/10000; acc:   2.40; ppl: 26881171418161356094253400435962903554686976.00; xent: 2149.43; lr: 1.00000; 4686/4695 tok/s;   1104 sec\n",
            "[2020-06-01 21:42:59,525 INFO] Step 7750/10000; acc:   3.32; ppl: 26881171418161356094253400435962903554686976.00; xent: 2115.15; lr: 1.00000; 4509/4610 tok/s;   1110 sec\n",
            "[2020-06-01 21:43:02,356 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:43:02,680 INFO] number of examples: 26142\n",
            "[2020-06-01 21:43:06,918 INFO] Step 7800/10000; acc:   2.92; ppl: 26881171418161356094253400435962903554686976.00; xent: 2188.87; lr: 1.00000; 4195/4258 tok/s;   1118 sec\n",
            "[2020-06-01 21:43:12,960 INFO] Step 7850/10000; acc:   3.71; ppl: 26881171418161356094253400435962903554686976.00; xent: 2135.96; lr: 1.00000; 4335/4481 tok/s;   1124 sec\n",
            "[2020-06-01 21:43:20,645 INFO] Step 7900/10000; acc:   2.93; ppl: 26881171418161356094253400435962903554686976.00; xent: 2161.78; lr: 1.00000; 4700/4673 tok/s;   1131 sec\n",
            "[2020-06-01 21:43:28,382 INFO] Step 7950/10000; acc:   2.52; ppl: 26881171418161356094253400435962903554686976.00; xent: 2104.87; lr: 1.00000; 4657/4651 tok/s;   1139 sec\n",
            "[2020-06-01 21:43:35,783 INFO] Step 8000/10000; acc:   3.00; ppl: 26881171418161356094253400435962903554686976.00; xent: 2195.95; lr: 1.00000; 4462/4632 tok/s;   1146 sec\n",
            "[2020-06-01 21:43:42,890 INFO] Step 8050/10000; acc:   2.74; ppl: 26881171418161356094253400435962903554686976.00; xent: 2144.96; lr: 1.00000; 4467/4615 tok/s;   1154 sec\n",
            "[2020-06-01 21:43:50,477 INFO] Step 8100/10000; acc:   2.85; ppl: 26881171418161356094253400435962903554686976.00; xent: 2270.71; lr: 1.00000; 4758/4730 tok/s;   1161 sec\n",
            "[2020-06-01 21:43:56,916 INFO] Step 8150/10000; acc:   3.20; ppl: 26881171418161356094253400435962903554686976.00; xent: 2101.17; lr: 1.00000; 4544/4606 tok/s;   1168 sec\n",
            "[2020-06-01 21:44:00,875 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:44:01,204 INFO] number of examples: 26142\n",
            "[2020-06-01 21:44:04,232 INFO] Step 8200/10000; acc:   2.86; ppl: 26881171418161356094253400435962903554686976.00; xent: 2129.09; lr: 1.00000; 4118/4204 tok/s;   1175 sec\n",
            "[2020-06-01 21:44:10,400 INFO] Step 8250/10000; acc:   3.68; ppl: 26881171418161356094253400435962903554686976.00; xent: 2113.24; lr: 1.00000; 4423/4564 tok/s;   1181 sec\n",
            "[2020-06-01 21:44:17,879 INFO] Step 8300/10000; acc:   2.80; ppl: 26881171418161356094253400435962903554686976.00; xent: 2208.87; lr: 1.00000; 4572/4605 tok/s;   1189 sec\n",
            "[2020-06-01 21:44:25,359 INFO] Step 8350/10000; acc:   2.85; ppl: 26881171418161356094253400435962903554686976.00; xent: 2067.57; lr: 1.00000; 4647/4689 tok/s;   1196 sec\n",
            "[2020-06-01 21:44:32,994 INFO] Step 8400/10000; acc:   2.75; ppl: 26881171418161356094253400435962903554686976.00; xent: 2197.93; lr: 1.00000; 4526/4601 tok/s;   1204 sec\n",
            "[2020-06-01 21:44:40,196 INFO] Step 8450/10000; acc:   3.13; ppl: 26881171418161356094253400435962903554686976.00; xent: 2093.45; lr: 1.00000; 4426/4598 tok/s;   1211 sec\n",
            "[2020-06-01 21:44:47,409 INFO] Step 8500/10000; acc:   2.48; ppl: 26881171418161356094253400435962903554686976.00; xent: 2089.48; lr: 1.00000; 4788/4783 tok/s;   1218 sec\n",
            "[2020-06-01 21:44:54,208 INFO] Step 8550/10000; acc:   3.06; ppl: 26881171418161356094253400435962903554686976.00; xent: 2069.19; lr: 1.00000; 4553/4583 tok/s;   1225 sec\n",
            "[2020-06-01 21:44:59,420 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:44:59,767 INFO] number of examples: 26142\n",
            "[2020-06-01 21:45:01,229 INFO] Step 8600/10000; acc:   2.81; ppl: 26881171418161356094253400435962903554686976.00; xent: 1974.15; lr: 1.00000; 4087/4228 tok/s;   1232 sec\n",
            "[2020-06-01 21:45:07,684 INFO] Step 8650/10000; acc:   3.61; ppl: 26881171418161356094253400435962903554686976.00; xent: 2054.80; lr: 1.00000; 4445/4536 tok/s;   1238 sec\n",
            "[2020-06-01 21:45:15,169 INFO] Step 8700/10000; acc:   3.16; ppl: 26881171418161356094253400435962903554686976.00; xent: 2170.08; lr: 1.00000; 4554/4573 tok/s;   1246 sec\n",
            "[2020-06-01 21:45:22,441 INFO] Step 8750/10000; acc:   2.44; ppl: 26881171418161356094253400435962903554686976.00; xent: 2133.56; lr: 1.00000; 4675/4722 tok/s;   1253 sec\n",
            "[2020-06-01 21:45:30,008 INFO] Step 8800/10000; acc:   2.59; ppl: 26881171418161356094253400435962903554686976.00; xent: 2157.31; lr: 1.00000; 4483/4560 tok/s;   1261 sec\n",
            "[2020-06-01 21:45:37,344 INFO] Step 8850/10000; acc:   2.52; ppl: 26881171418161356094253400435962903554686976.00; xent: 2204.48; lr: 1.00000; 4464/4569 tok/s;   1268 sec\n",
            "[2020-06-01 21:45:44,766 INFO] Step 8900/10000; acc:   2.39; ppl: 26881171418161356094253400435962903554686976.00; xent: 2211.11; lr: 1.00000; 4825/4839 tok/s;   1275 sec\n",
            "[2020-06-01 21:45:51,403 INFO] Step 8950/10000; acc:   3.47; ppl: 26881171418161356094253400435962903554686976.00; xent: 2198.44; lr: 1.00000; 4461/4553 tok/s;   1282 sec\n",
            "[2020-06-01 21:45:57,967 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:45:58,326 INFO] number of examples: 26142\n",
            "[2020-06-01 21:45:58,694 INFO] Step 9000/10000; acc:   2.89; ppl: 26881171418161356094253400435962903554686976.00; xent: 2102.95; lr: 1.00000; 4235/4310 tok/s;   1289 sec\n",
            "[2020-06-01 21:46:05,089 INFO] Step 9050/10000; acc:   3.64; ppl: 26881171418161356094253400435962903554686976.00; xent: 2110.98; lr: 1.00000; 4396/4503 tok/s;   1296 sec\n",
            "[2020-06-01 21:46:12,239 INFO] Step 9100/10000; acc:   3.49; ppl: 26881171418161356094253400435962903554686976.00; xent: 2138.12; lr: 1.00000; 4468/4522 tok/s;   1303 sec\n",
            "[2020-06-01 21:46:19,818 INFO] Step 9150/10000; acc:   2.43; ppl: 26881171418161356094253400435962903554686976.00; xent: 2197.81; lr: 1.00000; 4735/4767 tok/s;   1310 sec\n",
            "[2020-06-01 21:46:27,119 INFO] Step 9200/10000; acc:   3.23; ppl: 26881171418161356094253400435962903554686976.00; xent: 2084.98; lr: 1.00000; 4486/4550 tok/s;   1318 sec\n",
            "[2020-06-01 21:46:34,807 INFO] Step 9250/10000; acc:   2.42; ppl: 26881171418161356094253400435962903554686976.00; xent: 2070.76; lr: 1.00000; 4534/4619 tok/s;   1325 sec\n",
            "[2020-06-01 21:46:41,983 INFO] Step 9300/10000; acc:   2.81; ppl: 26881171418161356094253400435962903554686976.00; xent: 2158.53; lr: 1.00000; 4798/4768 tok/s;   1333 sec\n",
            "[2020-06-01 21:46:48,894 INFO] Step 9350/10000; acc:   3.02; ppl: 26881171418161356094253400435962903554686976.00; xent: 2086.82; lr: 1.00000; 4450/4640 tok/s;   1340 sec\n",
            "[2020-06-01 21:46:55,607 INFO] Step 9400/10000; acc:   2.92; ppl: 26881171418161356094253400435962903554686976.00; xent: 2112.72; lr: 1.00000; 4536/4587 tok/s;   1346 sec\n",
            "[2020-06-01 21:46:56,506 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:46:56,893 INFO] number of examples: 26142\n",
            "[2020-06-01 21:47:02,652 INFO] Step 9450/10000; acc:   3.26; ppl: 26881171418161356094253400435962903554686976.00; xent: 2080.29; lr: 1.00000; 4098/4180 tok/s;   1353 sec\n",
            "[2020-06-01 21:47:09,279 INFO] Step 9500/10000; acc:   3.33; ppl: 26881171418161356094253400435962903554686976.00; xent: 2094.35; lr: 1.00000; 4327/4418 tok/s;   1360 sec\n",
            "[2020-06-01 21:47:17,088 INFO] Step 9550/10000; acc:   2.79; ppl: 26881171418161356094253400435962903554686976.00; xent: 2267.30; lr: 1.00000; 4805/4782 tok/s;   1368 sec\n",
            "[2020-06-01 21:47:24,686 INFO] Step 9600/10000; acc:   2.78; ppl: 26881171418161356094253400435962903554686976.00; xent: 2234.21; lr: 1.00000; 4534/4641 tok/s;   1375 sec\n",
            "[2020-06-01 21:47:32,150 INFO] Step 9650/10000; acc:   2.77; ppl: 26881171418161356094253400435962903554686976.00; xent: 2178.55; lr: 1.00000; 4604/4703 tok/s;   1383 sec\n",
            "[2020-06-01 21:47:39,125 INFO] Step 9700/10000; acc:   2.69; ppl: 26881171418161356094253400435962903554686976.00; xent: 2109.24; lr: 1.00000; 4524/4575 tok/s;   1390 sec\n",
            "[2020-06-01 21:47:46,235 INFO] Step 9750/10000; acc:   2.56; ppl: 26881171418161356094253400435962903554686976.00; xent: 2073.68; lr: 1.00000; 4591/4654 tok/s;   1397 sec\n",
            "[2020-06-01 21:47:52,817 INFO] Step 9800/10000; acc:   3.32; ppl: 26881171418161356094253400435962903554686976.00; xent: 2040.64; lr: 1.00000; 4514/4641 tok/s;   1403 sec\n",
            "[2020-06-01 21:47:55,080 INFO] Loading dataset from En2Fa-Translation/Cleaned.train.0.pt\n",
            "[2020-06-01 21:47:55,325 INFO] number of examples: 26142\n",
            "[2020-06-01 21:48:00,082 INFO] Step 9850/10000; acc:   3.52; ppl: 26881171418161356094253400435962903554686976.00; xent: 2135.58; lr: 1.00000; 4252/4274 tok/s;   1411 sec\n",
            "[2020-06-01 21:48:06,686 INFO] Step 9900/10000; acc:   3.41; ppl: 26881171418161356094253400435962903554686976.00; xent: 1955.06; lr: 1.00000; 4380/4462 tok/s;   1417 sec\n",
            "[2020-06-01 21:48:13,989 INFO] Step 9950/10000; acc:   2.91; ppl: 26881171418161356094253400435962903554686976.00; xent: 2055.23; lr: 1.00000; 4689/4757 tok/s;   1425 sec\n",
            "[2020-06-01 21:48:21,735 INFO] Step 10000/10000; acc:   2.63; ppl: 26881171418161356094253400435962903554686976.00; xent: 2088.44; lr: 1.00000; 4644/4659 tok/s;   1432 sec\n",
            "[2020-06-01 21:48:21,736 INFO] Loading dataset from En2Fa-Translation/Cleaned.valid.0.pt\n",
            "[2020-06-01 21:48:21,741 INFO] number of examples: 276\n",
            "[2020-06-01 21:48:22,318 INFO] Validation perplexity: 2.68812e+43\n",
            "[2020-06-01 21:48:22,318 INFO] Validation accuracy: 2.76625\n",
            "[2020-06-01 21:48:22,356 INFO] Saving checkpoint model_step_10000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVzf_AyVcn0t",
        "colab_type": "code",
        "outputId": "fa52a314-fd45-4fc3-e735-12e4ed6678ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "en - st"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1442.0429320335388"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0lq3JqU7vJZ",
        "colab_type": "text"
      },
      "source": [
        "# Q2: RNN + bpe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeipYqg777OZ",
        "colab_type": "text"
      },
      "source": [
        "### BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bF2JuOP79lv",
        "colab_type": "code",
        "outputId": "d23cedd1-f872-4781-87e7-78b595248cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i En2Fa-Translation/Train/train.en -o En2Fa-Translation/Train/BPEtrain.en -s 10000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no pair has frequency >= 2. Stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYeXNlZD7-Di",
        "colab_type": "code",
        "outputId": "2877b088-8ed7-4132-d3ad-55b029783624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!python OpenNMT-py/tools/learn_bpe.py -i En2Fa-Translation/Train/train.fa -o En2Fa-Translation/Train/BPEtrain.fa -s 10000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no pair has frequency >= 2. Stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVtbIO6k7-bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c En2Fa-Translation/Train/BPEtrain.fa -i En2Fa-Translation/Train/train.fa -o En2Fa-Translation/Train/Q2train.fa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sim8_kf9Nr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c En2Fa-Translation/Train/BPEtrain.en -i En2Fa-Translation/Train/train.en -o En2Fa-Translation/Train/Q2train.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkxd6Nyo7-lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c En2Fa-Translation/Train/BPEtrain.fa -i En2Fa-Translation/Dev/dev.fa -o En2Fa-Translation/Dev/Q2dev.fa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSb_Py_C9PDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c En2Fa-Translation/Train/BPEtrain.en -i En2Fa-Translation/Dev/dev.en -o En2Fa-Translation/Dev/Q2dev.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qci0h7q19OtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python OpenNMT-py/tools/apply_bpe.py -c En2Fa-Translation/Train/BPEtrain.en -i En2Fa-Translation/Test/test.en -o En2Fa-Translation/Test/Q2test.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eJDIHfN9P9O",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSYdZdD17-vt",
        "colab_type": "code",
        "outputId": "4d231eff-d0fe-4300-c9b9-6d512ca7ec08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "!python OpenNMT-py/preprocess.py -train_src En2Fa-Translation/Train/Q2train.en -train_tgt En2Fa-Translation/Train/Q2train.fa -valid_src En2Fa-Translation/Dev/Q2dev.en -valid_tgt En2Fa-Translation/Dev/Q2dev.fa -save_data En2Fa-Translation/BPE_Cleaned"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 03:01:35,536 INFO] Extracting features...\n",
            "[2020-06-02 03:01:35,538 INFO]  * number of source features: 0.\n",
            "[2020-06-02 03:01:35,538 INFO]  * number of target features: 0.\n",
            "[2020-06-02 03:01:35,538 INFO] Building `Fields` object...\n",
            "[2020-06-02 03:01:35,538 INFO] Building & saving training data...\n",
            "[2020-06-02 03:01:35,582 INFO] Building shard 0.\n",
            "[2020-06-02 03:01:36,306 INFO]  * saving 0th train data shard to En2Fa-Translation/BPE_Cleaned.train.0.pt.\n",
            "[2020-06-02 03:01:36,957 INFO]  * tgt vocab size: 4885.\n",
            "[2020-06-02 03:01:36,961 INFO]  * src vocab size: 3041.\n",
            "[2020-06-02 03:01:37,030 INFO] Building & saving validation data...\n",
            "[2020-06-02 03:01:37,056 INFO] Building shard 0.\n",
            "[2020-06-02 03:01:37,061 INFO]  * saving 0th valid data shard to En2Fa-Translation/BPE_Cleaned.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHzMhsPk-Z6T",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZejtLg99O_J",
        "colab_type": "code",
        "outputId": "411cf2d1-7722-4319-9525-df41697ecd9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python OpenNMT-py/train.py -data En2Fa-Translation/BPE_Cleaned -save_model En2Fa-Translation/with_bpe_rnn_model -world_size 1 -gpu_rank 0 --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 50000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 03:02:03,953 INFO]  * src vocab size = 3041\n",
            "[2020-06-02 03:02:03,953 INFO]  * tgt vocab size = 4885\n",
            "[2020-06-02 03:02:03,953 INFO] Building model...\n",
            "[2020-06-02 03:02:13,668 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3041, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(4885, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=4885, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-02 03:02:13,668 INFO] encoder: 9900916\n",
            "[2020-06-02 03:02:13,668 INFO] decoder: 15163929\n",
            "[2020-06-02 03:02:13,668 INFO] * number of parameters: 25064845\n",
            "[2020-06-02 03:02:13,671 INFO] Starting training on GPU: [0]\n",
            "[2020-06-02 03:02:13,672 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-02 03:02:13,672 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:02:13,898 INFO] number of examples: 26141\n",
            "[2020-06-02 03:02:16,834 INFO] Step 50/50000; acc:   5.42; ppl: 543444.90; xent: 13.21; lr: 1.00000; 11299/11662 tok/s;      3 sec\n",
            "[2020-06-02 03:02:19,115 INFO] Step 100/50000; acc:   6.21; ppl: 11629.08; xent: 9.36; lr: 1.00000; 14817/14883 tok/s;      5 sec\n",
            "[2020-06-02 03:02:21,298 INFO] Step 150/50000; acc:   7.56; ppl: 2050.93; xent: 7.63; lr: 1.00000; 14532/14774 tok/s;      8 sec\n",
            "[2020-06-02 03:02:23,690 INFO] Step 200/50000; acc:   7.88; ppl: 448.75; xent: 6.11; lr: 1.00000; 14958/15233 tok/s;     10 sec\n",
            "[2020-06-02 03:02:25,656 INFO] Step 250/50000; acc:  11.25; ppl: 269.55; xent: 5.60; lr: 1.00000; 14379/14608 tok/s;     12 sec\n",
            "[2020-06-02 03:02:27,928 INFO] Step 300/50000; acc:  11.92; ppl: 244.33; xent: 5.50; lr: 1.00000; 14862/14806 tok/s;     14 sec\n",
            "[2020-06-02 03:02:30,162 INFO] Step 350/50000; acc:  15.66; ppl: 192.76; xent: 5.26; lr: 1.00000; 14423/15075 tok/s;     16 sec\n",
            "[2020-06-02 03:02:32,288 INFO] Step 400/50000; acc:  16.32; ppl: 161.60; xent: 5.09; lr: 1.00000; 14111/14797 tok/s;     19 sec\n",
            "[2020-06-02 03:02:32,622 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:02:32,928 INFO] number of examples: 26141\n",
            "[2020-06-02 03:02:35,091 INFO] Step 450/50000; acc:  15.55; ppl: 170.81; xent: 5.14; lr: 1.00000; 12043/12453 tok/s;     21 sec\n",
            "[2020-06-02 03:02:37,403 INFO] Step 500/50000; acc:  15.57; ppl: 174.05; xent: 5.16; lr: 1.00000; 15007/15138 tok/s;     24 sec\n",
            "[2020-06-02 03:02:39,599 INFO] Step 550/50000; acc:  18.17; ppl: 136.90; xent: 4.92; lr: 1.00000; 14850/15142 tok/s;     26 sec\n",
            "[2020-06-02 03:02:41,878 INFO] Step 600/50000; acc:  17.53; ppl: 137.30; xent: 4.92; lr: 1.00000; 14937/15232 tok/s;     28 sec\n",
            "[2020-06-02 03:02:43,908 INFO] Step 650/50000; acc:  20.30; ppl: 114.58; xent: 4.74; lr: 1.00000; 14638/14961 tok/s;     30 sec\n",
            "[2020-06-02 03:02:46,185 INFO] Step 700/50000; acc:  19.58; ppl: 119.46; xent: 4.78; lr: 1.00000; 14447/14576 tok/s;     33 sec\n",
            "[2020-06-02 03:02:48,472 INFO] Step 750/50000; acc:  20.38; ppl: 112.03; xent: 4.72; lr: 1.00000; 14650/14960 tok/s;     35 sec\n",
            "[2020-06-02 03:02:50,535 INFO] Step 800/50000; acc:  22.37; ppl: 89.08; xent: 4.49; lr: 1.00000; 14282/14752 tok/s;     37 sec\n",
            "[2020-06-02 03:02:51,275 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:02:51,482 INFO] number of examples: 26141\n",
            "[2020-06-02 03:02:53,252 INFO] Step 850/50000; acc:  21.22; ppl: 105.74; xent: 4.66; lr: 1.00000; 11527/12373 tok/s;     40 sec\n",
            "[2020-06-02 03:02:55,617 INFO] Step 900/50000; acc:  21.39; ppl: 102.19; xent: 4.63; lr: 1.00000; 15225/15103 tok/s;     42 sec\n",
            "[2020-06-02 03:02:57,913 INFO] Step 950/50000; acc:  23.68; ppl: 88.02; xent: 4.48; lr: 1.00000; 14787/14878 tok/s;     44 sec\n",
            "[2020-06-02 03:03:00,080 INFO] Step 1000/50000; acc:  25.64; ppl: 75.23; xent: 4.32; lr: 1.00000; 15058/15477 tok/s;     46 sec\n",
            "[2020-06-02 03:03:02,317 INFO] Step 1050/50000; acc:  26.03; ppl: 74.23; xent: 4.31; lr: 1.00000; 14546/15064 tok/s;     49 sec\n",
            "[2020-06-02 03:03:04,437 INFO] Step 1100/50000; acc:  27.14; ppl: 67.27; xent: 4.21; lr: 1.00000; 14634/14371 tok/s;     51 sec\n",
            "[2020-06-02 03:03:06,597 INFO] Step 1150/50000; acc:  28.29; ppl: 63.89; xent: 4.16; lr: 1.00000; 14566/14811 tok/s;     53 sec\n",
            "[2020-06-02 03:03:08,896 INFO] Step 1200/50000; acc:  27.48; ppl: 64.90; xent: 4.17; lr: 1.00000; 14404/15044 tok/s;     55 sec\n",
            "[2020-06-02 03:03:09,930 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:03:10,147 INFO] number of examples: 26141\n",
            "[2020-06-02 03:03:11,366 INFO] Step 1250/50000; acc:  29.51; ppl: 56.93; xent: 4.04; lr: 1.00000; 11748/12631 tok/s;     58 sec\n",
            "[2020-06-02 03:03:13,651 INFO] Step 1300/50000; acc:  27.89; ppl: 60.47; xent: 4.10; lr: 1.00000; 14977/15102 tok/s;     60 sec\n",
            "[2020-06-02 03:03:16,060 INFO] Step 1350/50000; acc:  28.45; ppl: 60.68; xent: 4.11; lr: 1.00000; 14835/14699 tok/s;     62 sec\n",
            "[2020-06-02 03:03:18,284 INFO] Step 1400/50000; acc:  30.86; ppl: 50.69; xent: 3.93; lr: 1.00000; 14817/15492 tok/s;     65 sec\n",
            "[2020-06-02 03:03:20,558 INFO] Step 1450/50000; acc:  31.01; ppl: 49.17; xent: 3.90; lr: 1.00000; 14444/15123 tok/s;     67 sec\n",
            "[2020-06-02 03:03:22,629 INFO] Step 1500/50000; acc:  32.21; ppl: 45.48; xent: 3.82; lr: 1.00000; 14958/14291 tok/s;     69 sec\n",
            "[2020-06-02 03:03:24,668 INFO] Step 1550/50000; acc:  34.24; ppl: 40.10; xent: 3.69; lr: 1.00000; 14706/15114 tok/s;     71 sec\n",
            "[2020-06-02 03:03:27,026 INFO] Step 1600/50000; acc:  32.32; ppl: 46.11; xent: 3.83; lr: 1.00000; 14319/14934 tok/s;     73 sec\n",
            "[2020-06-02 03:03:28,485 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:03:28,756 INFO] number of examples: 26141\n",
            "[2020-06-02 03:03:29,521 INFO] Step 1650/50000; acc:  34.79; ppl: 39.56; xent: 3.68; lr: 1.00000; 12133/12892 tok/s;     76 sec\n",
            "[2020-06-02 03:03:31,861 INFO] Step 1700/50000; acc:  33.07; ppl: 43.44; xent: 3.77; lr: 1.00000; 14084/14578 tok/s;     78 sec\n",
            "[2020-06-02 03:03:34,260 INFO] Step 1750/50000; acc:  33.08; ppl: 44.16; xent: 3.79; lr: 1.00000; 15281/14913 tok/s;     81 sec\n",
            "[2020-06-02 03:03:36,440 INFO] Step 1800/50000; acc:  36.16; ppl: 36.80; xent: 3.61; lr: 1.00000; 14759/15501 tok/s;     83 sec\n",
            "[2020-06-02 03:03:38,797 INFO] Step 1850/50000; acc:  35.26; ppl: 37.60; xent: 3.63; lr: 1.00000; 14530/14958 tok/s;     85 sec\n",
            "[2020-06-02 03:03:40,778 INFO] Step 1900/50000; acc:  38.19; ppl: 31.74; xent: 3.46; lr: 1.00000; 14862/14201 tok/s;     87 sec\n",
            "[2020-06-02 03:03:42,873 INFO] Step 1950/50000; acc:  37.78; ppl: 31.26; xent: 3.44; lr: 1.00000; 14848/15137 tok/s;     89 sec\n",
            "[2020-06-02 03:03:45,310 INFO] Step 2000/50000; acc:  35.88; ppl: 35.69; xent: 3.57; lr: 1.00000; 14075/14727 tok/s;     92 sec\n",
            "[2020-06-02 03:03:47,116 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:03:47,407 INFO] number of examples: 26141\n",
            "[2020-06-02 03:03:47,747 INFO] Step 2050/50000; acc:  39.23; ppl: 28.18; xent: 3.34; lr: 1.00000; 11843/12549 tok/s;     94 sec\n",
            "[2020-06-02 03:03:50,194 INFO] Step 2100/50000; acc:  35.83; ppl: 35.22; xent: 3.56; lr: 1.00000; 14379/14833 tok/s;     97 sec\n",
            "[2020-06-02 03:03:52,587 INFO] Step 2150/50000; acc:  36.22; ppl: 34.92; xent: 3.55; lr: 1.00000; 15009/14873 tok/s;     99 sec\n",
            "[2020-06-02 03:03:54,720 INFO] Step 2200/50000; acc:  39.46; ppl: 28.86; xent: 3.36; lr: 1.00000; 14686/15266 tok/s;    101 sec\n",
            "[2020-06-02 03:03:57,045 INFO] Step 2250/50000; acc:  37.83; ppl: 30.23; xent: 3.41; lr: 1.00000; 14614/14991 tok/s;    103 sec\n",
            "[2020-06-02 03:03:58,954 INFO] Step 2300/50000; acc:  41.51; ppl: 24.36; xent: 3.19; lr: 1.00000; 14951/14796 tok/s;    105 sec\n",
            "[2020-06-02 03:04:01,240 INFO] Step 2350/50000; acc:  38.05; ppl: 29.28; xent: 3.38; lr: 1.00000; 14936/14965 tok/s;    108 sec\n",
            "[2020-06-02 03:04:03,494 INFO] Step 2400/50000; acc:  39.92; ppl: 26.28; xent: 3.27; lr: 1.00000; 14183/14917 tok/s;    110 sec\n",
            "[2020-06-02 03:04:05,608 INFO] Step 2450/50000; acc:  41.26; ppl: 24.12; xent: 3.18; lr: 1.00000; 14099/14788 tok/s;    112 sec\n",
            "[2020-06-02 03:04:05,757 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:04:06,035 INFO] number of examples: 26141\n",
            "[2020-06-02 03:04:08,482 INFO] Step 2500/50000; acc:  37.79; ppl: 29.78; xent: 3.39; lr: 1.00000; 12433/12733 tok/s;    115 sec\n",
            "[2020-06-02 03:04:10,694 INFO] Step 2550/50000; acc:  39.82; ppl: 26.50; xent: 3.28; lr: 1.00000; 14819/15073 tok/s;    117 sec\n",
            "[2020-06-02 03:04:12,915 INFO] Step 2600/50000; acc:  40.03; ppl: 25.86; xent: 3.25; lr: 1.00000; 14861/15086 tok/s;    119 sec\n",
            "[2020-06-02 03:04:15,223 INFO] Step 2650/50000; acc:  40.26; ppl: 25.15; xent: 3.22; lr: 1.00000; 14805/15075 tok/s;    122 sec\n",
            "[2020-06-02 03:04:17,222 INFO] Step 2700/50000; acc:  42.94; ppl: 21.37; xent: 3.06; lr: 1.00000; 14395/14792 tok/s;    124 sec\n",
            "[2020-06-02 03:04:19,487 INFO] Step 2750/50000; acc:  40.93; ppl: 23.77; xent: 3.17; lr: 1.00000; 14793/14776 tok/s;    126 sec\n",
            "[2020-06-02 03:04:21,735 INFO] Step 2800/50000; acc:  40.99; ppl: 23.47; xent: 3.16; lr: 1.00000; 14536/15057 tok/s;    128 sec\n",
            "[2020-06-02 03:04:23,768 INFO] Step 2850/50000; acc:  43.92; ppl: 19.49; xent: 2.97; lr: 1.00000; 14363/14966 tok/s;    130 sec\n",
            "[2020-06-02 03:04:24,358 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:04:24,639 INFO] number of examples: 26141\n",
            "[2020-06-02 03:04:26,598 INFO] Step 2900/50000; acc:  40.58; ppl: 24.45; xent: 3.20; lr: 1.00000; 11993/12589 tok/s;    133 sec\n",
            "[2020-06-02 03:04:29,018 INFO] Step 2950/50000; acc:  39.48; ppl: 25.39; xent: 3.23; lr: 1.00000; 15068/14804 tok/s;    135 sec\n",
            "[2020-06-02 03:04:31,155 INFO] Step 3000/50000; acc:  42.80; ppl: 20.80; xent: 3.04; lr: 1.00000; 14602/15140 tok/s;    137 sec\n",
            "[2020-06-02 03:04:33,407 INFO] Step 3050/50000; acc:  42.44; ppl: 21.02; xent: 3.05; lr: 1.00000; 14944/15199 tok/s;    140 sec\n",
            "[2020-06-02 03:04:35,557 INFO] Step 3100/50000; acc:  43.01; ppl: 20.24; xent: 3.01; lr: 1.00000; 14681/15022 tok/s;    142 sec\n",
            "[2020-06-02 03:04:37,774 INFO] Step 3150/50000; acc:  42.66; ppl: 20.37; xent: 3.01; lr: 1.00000; 14609/14668 tok/s;    144 sec\n",
            "[2020-06-02 03:04:39,996 INFO] Step 3200/50000; acc:  43.28; ppl: 19.94; xent: 2.99; lr: 1.00000; 14566/14807 tok/s;    146 sec\n",
            "[2020-06-02 03:04:42,145 INFO] Step 3250/50000; acc:  44.49; ppl: 18.10; xent: 2.90; lr: 1.00000; 14424/15018 tok/s;    148 sec\n",
            "[2020-06-02 03:04:43,006 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:04:43,289 INFO] number of examples: 26141\n",
            "[2020-06-02 03:04:44,792 INFO] Step 3300/50000; acc:  43.48; ppl: 19.91; xent: 2.99; lr: 1.00000; 11465/12289 tok/s;    151 sec\n",
            "[2020-06-02 03:04:47,049 INFO] Step 3350/50000; acc:  43.43; ppl: 18.70; xent: 2.93; lr: 1.00000; 15278/15319 tok/s;    153 sec\n",
            "[2020-06-02 03:04:49,448 INFO] Step 3400/50000; acc:  41.83; ppl: 21.34; xent: 3.06; lr: 1.00000; 15031/14870 tok/s;    156 sec\n",
            "[2020-06-02 03:04:51,647 INFO] Step 3450/50000; acc:  44.84; ppl: 17.38; xent: 2.86; lr: 1.00000; 14756/15434 tok/s;    158 sec\n",
            "[2020-06-02 03:04:53,891 INFO] Step 3500/50000; acc:  44.10; ppl: 18.23; xent: 2.90; lr: 1.00000; 14435/15071 tok/s;    160 sec\n",
            "[2020-06-02 03:04:55,964 INFO] Step 3550/50000; acc:  44.72; ppl: 17.00; xent: 2.83; lr: 1.00000; 14976/14366 tok/s;    162 sec\n",
            "[2020-06-02 03:04:58,137 INFO] Step 3600/50000; acc:  45.18; ppl: 17.01; xent: 2.83; lr: 1.00000; 14565/14805 tok/s;    164 sec\n",
            "[2020-06-02 03:05:00,445 INFO] Step 3650/50000; acc:  45.21; ppl: 16.87; xent: 2.83; lr: 1.00000; 13846/14782 tok/s;    167 sec\n",
            "[2020-06-02 03:05:01,679 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:05:01,969 INFO] number of examples: 26141\n",
            "[2020-06-02 03:05:03,026 INFO] Step 3700/50000; acc:  46.57; ppl: 15.91; xent: 2.77; lr: 1.00000; 11614/12197 tok/s;    169 sec\n",
            "[2020-06-02 03:05:05,359 INFO] Step 3750/50000; acc:  44.94; ppl: 16.87; xent: 2.83; lr: 1.00000; 14505/15019 tok/s;    172 sec\n",
            "[2020-06-02 03:05:07,708 INFO] Step 3800/50000; acc:  43.52; ppl: 18.46; xent: 2.92; lr: 1.00000; 15230/14748 tok/s;    174 sec\n",
            "[2020-06-02 03:05:09,943 INFO] Step 3850/50000; acc:  46.05; ppl: 15.92; xent: 2.77; lr: 1.00000; 14705/15632 tok/s;    176 sec\n",
            "[2020-06-02 03:05:12,282 INFO] Step 3900/50000; acc:  45.41; ppl: 16.09; xent: 2.78; lr: 1.00000; 14396/14870 tok/s;    179 sec\n",
            "[2020-06-02 03:05:14,241 INFO] Step 3950/50000; acc:  47.53; ppl: 14.06; xent: 2.64; lr: 1.00000; 14991/14231 tok/s;    181 sec\n",
            "[2020-06-02 03:05:16,287 INFO] Step 4000/50000; acc:  47.84; ppl: 13.78; xent: 2.62; lr: 1.00000; 14992/15461 tok/s;    183 sec\n",
            "[2020-06-02 03:05:18,696 INFO] Step 4050/50000; acc:  45.57; ppl: 16.34; xent: 2.79; lr: 1.00000; 14209/14722 tok/s;    185 sec\n",
            "[2020-06-02 03:05:20,324 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:05:20,621 INFO] number of examples: 26141\n",
            "[2020-06-02 03:05:21,170 INFO] Step 4100/50000; acc:  48.32; ppl: 13.57; xent: 2.61; lr: 1.00000; 12030/12701 tok/s;    187 sec\n",
            "[2020-06-02 03:05:23,609 INFO] Step 4150/50000; acc:  45.71; ppl: 15.80; xent: 2.76; lr: 1.00000; 14242/14759 tok/s;    190 sec\n",
            "[2020-06-02 03:05:25,985 INFO] Step 4200/50000; acc:  44.75; ppl: 16.69; xent: 2.81; lr: 1.00000; 15194/14995 tok/s;    192 sec\n",
            "[2020-06-02 03:05:28,090 INFO] Step 4250/50000; acc:  48.08; ppl: 13.67; xent: 2.61; lr: 1.00000; 14736/15381 tok/s;    194 sec\n",
            "[2020-06-02 03:05:30,473 INFO] Step 4300/50000; acc:  46.64; ppl: 14.53; xent: 2.68; lr: 1.00000; 14369/14858 tok/s;    197 sec\n",
            "[2020-06-02 03:05:32,390 INFO] Step 4350/50000; acc:  49.84; ppl: 11.71; xent: 2.46; lr: 1.00000; 15145/14502 tok/s;    199 sec\n",
            "[2020-06-02 03:05:34,569 INFO] Step 4400/50000; acc:  47.76; ppl: 13.68; xent: 2.62; lr: 1.00000; 14851/15096 tok/s;    201 sec\n",
            "[2020-06-02 03:05:36,813 INFO] Step 4450/50000; acc:  48.60; ppl: 13.22; xent: 2.58; lr: 1.00000; 14187/14973 tok/s;    203 sec\n",
            "[2020-06-02 03:05:38,946 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:05:39,243 INFO] number of examples: 26141\n",
            "[2020-06-02 03:05:39,406 INFO] Step 4500/50000; acc:  49.03; ppl: 12.61; xent: 2.53; lr: 1.00000; 12092/12717 tok/s;    206 sec\n",
            "[2020-06-02 03:05:41,898 INFO] Step 4550/50000; acc:  46.11; ppl: 14.94; xent: 2.70; lr: 1.00000; 14236/14601 tok/s;    208 sec\n",
            "[2020-06-02 03:05:44,179 INFO] Step 4600/50000; acc:  47.16; ppl: 14.09; xent: 2.65; lr: 1.00000; 15068/15103 tok/s;    211 sec\n",
            "[2020-06-02 03:05:46,316 INFO] Step 4650/50000; acc:  49.28; ppl: 12.23; xent: 2.50; lr: 1.00000; 14637/15081 tok/s;    213 sec\n",
            "[2020-06-02 03:05:48,668 INFO] Step 4700/50000; acc:  48.07; ppl: 12.98; xent: 2.56; lr: 1.00000; 15021/15287 tok/s;    215 sec\n",
            "[2020-06-02 03:05:50,606 INFO] Step 4750/50000; acc:  51.21; ppl: 10.66; xent: 2.37; lr: 1.00000; 14518/14684 tok/s;    217 sec\n",
            "[2020-06-02 03:05:52,862 INFO] Step 4800/50000; acc:  48.49; ppl: 12.71; xent: 2.54; lr: 1.00000; 14882/14854 tok/s;    219 sec\n",
            "[2020-06-02 03:05:55,125 INFO] Step 4850/50000; acc:  49.45; ppl: 12.16; xent: 2.50; lr: 1.00000; 14409/14974 tok/s;    221 sec\n",
            "[2020-06-02 03:05:57,238 INFO] Step 4900/50000; acc:  51.01; ppl: 10.92; xent: 2.39; lr: 1.00000; 14111/14886 tok/s;    224 sec\n",
            "[2020-06-02 03:05:57,542 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:05:57,849 INFO] number of examples: 26141\n",
            "[2020-06-02 03:06:00,073 INFO] Step 4950/50000; acc:  48.42; ppl: 12.81; xent: 2.55; lr: 1.00000; 12107/12407 tok/s;    226 sec\n",
            "[2020-06-02 03:06:02,399 INFO] Step 5000/50000; acc:  48.09; ppl: 12.96; xent: 2.56; lr: 1.00000; 14944/15175 tok/s;    229 sec\n",
            "[2020-06-02 03:06:02,422 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_5000.pt\n",
            "[2020-06-02 03:06:04,851 INFO] Step 5050/50000; acc:  50.25; ppl: 11.23; xent: 2.42; lr: 1.00000; 13040/13275 tok/s;    231 sec\n",
            "[2020-06-02 03:06:07,169 INFO] Step 5100/50000; acc:  49.40; ppl: 11.69; xent: 2.46; lr: 1.00000; 14769/15019 tok/s;    233 sec\n",
            "[2020-06-02 03:06:09,176 INFO] Step 5150/50000; acc:  52.22; ppl:  9.92; xent: 2.29; lr: 1.00000; 14581/14988 tok/s;    236 sec\n",
            "[2020-06-02 03:06:11,500 INFO] Step 5200/50000; acc:  49.77; ppl: 11.48; xent: 2.44; lr: 1.00000; 14378/14477 tok/s;    238 sec\n",
            "[2020-06-02 03:06:13,912 INFO] Step 5250/50000; acc:  50.26; ppl: 11.33; xent: 2.43; lr: 1.00000; 13780/14070 tok/s;    240 sec\n",
            "[2020-06-02 03:06:15,956 INFO] Step 5300/50000; acc:  53.11; ppl:  9.46; xent: 2.25; lr: 1.00000; 14352/14881 tok/s;    242 sec\n",
            "[2020-06-02 03:06:16,682 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:06:16,998 INFO] number of examples: 26141\n",
            "[2020-06-02 03:06:18,744 INFO] Step 5350/50000; acc:  49.84; ppl: 11.67; xent: 2.46; lr: 1.00000; 11601/12330 tok/s;    245 sec\n",
            "[2020-06-02 03:06:21,159 INFO] Step 5400/50000; acc:  49.26; ppl: 11.88; xent: 2.47; lr: 1.00000; 15110/14984 tok/s;    247 sec\n",
            "[2020-06-02 03:06:23,421 INFO] Step 5450/50000; acc:  50.98; ppl: 10.58; xent: 2.36; lr: 1.00000; 14628/14826 tok/s;    250 sec\n",
            "[2020-06-02 03:06:25,612 INFO] Step 5500/50000; acc:  52.08; ppl:  9.78; xent: 2.28; lr: 1.00000; 14752/15167 tok/s;    252 sec\n",
            "[2020-06-02 03:06:27,898 INFO] Step 5550/50000; acc:  51.00; ppl: 10.45; xent: 2.35; lr: 1.00000; 14311/14682 tok/s;    254 sec\n",
            "[2020-06-02 03:06:30,029 INFO] Step 5600/50000; acc:  52.35; ppl:  9.52; xent: 2.25; lr: 1.00000; 14443/14297 tok/s;    256 sec\n",
            "[2020-06-02 03:06:32,235 INFO] Step 5650/50000; acc:  51.94; ppl: 10.17; xent: 2.32; lr: 1.00000; 14492/14684 tok/s;    259 sec\n",
            "[2020-06-02 03:06:34,538 INFO] Step 5700/50000; acc:  52.11; ppl:  9.81; xent: 2.28; lr: 1.00000; 14241/14898 tok/s;    261 sec\n",
            "[2020-06-02 03:06:35,542 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:06:35,771 INFO] number of examples: 26141\n",
            "[2020-06-02 03:06:37,049 INFO] Step 5750/50000; acc:  53.45; ppl:  9.37; xent: 2.24; lr: 1.00000; 11454/12374 tok/s;    263 sec\n",
            "[2020-06-02 03:06:39,364 INFO] Step 5800/50000; acc:  51.26; ppl: 10.10; xent: 2.31; lr: 1.00000; 15059/15127 tok/s;    266 sec\n",
            "[2020-06-02 03:06:41,744 INFO] Step 5850/50000; acc:  50.27; ppl: 10.93; xent: 2.39; lr: 1.00000; 14885/14748 tok/s;    268 sec\n",
            "[2020-06-02 03:06:43,990 INFO] Step 5900/50000; acc:  52.83; ppl:  9.42; xent: 2.24; lr: 1.00000; 14811/15510 tok/s;    270 sec\n",
            "[2020-06-02 03:06:46,251 INFO] Step 5950/50000; acc:  53.04; ppl:  9.22; xent: 2.22; lr: 1.00000; 14388/14983 tok/s;    273 sec\n",
            "[2020-06-02 03:06:48,301 INFO] Step 6000/50000; acc:  53.05; ppl:  8.98; xent: 2.20; lr: 1.00000; 14796/14247 tok/s;    275 sec\n",
            "[2020-06-02 03:06:50,380 INFO] Step 6050/50000; acc:  54.56; ppl:  8.26; xent: 2.11; lr: 1.00000; 14702/15102 tok/s;    277 sec\n",
            "[2020-06-02 03:06:52,735 INFO] Step 6100/50000; acc:  52.15; ppl:  9.75; xent: 2.28; lr: 1.00000; 14309/14980 tok/s;    279 sec\n",
            "[2020-06-02 03:06:54,152 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:06:54,429 INFO] number of examples: 26141\n",
            "[2020-06-02 03:06:55,221 INFO] Step 6150/50000; acc:  54.58; ppl:  8.48; xent: 2.14; lr: 1.00000; 11972/12682 tok/s;    282 sec\n",
            "[2020-06-02 03:06:57,610 INFO] Step 6200/50000; acc:  52.56; ppl:  9.37; xent: 2.24; lr: 1.00000; 14088/14518 tok/s;    284 sec\n",
            "[2020-06-02 03:07:00,000 INFO] Step 6250/50000; acc:  51.20; ppl: 10.19; xent: 2.32; lr: 1.00000; 15237/14867 tok/s;    286 sec\n",
            "[2020-06-02 03:07:02,187 INFO] Step 6300/50000; acc:  54.26; ppl:  8.52; xent: 2.14; lr: 1.00000; 14529/15346 tok/s;    289 sec\n",
            "[2020-06-02 03:07:04,579 INFO] Step 6350/50000; acc:  53.19; ppl:  8.84; xent: 2.18; lr: 1.00000; 14373/14749 tok/s;    291 sec\n",
            "[2020-06-02 03:07:06,602 INFO] Step 6400/50000; acc:  54.55; ppl:  8.10; xent: 2.09; lr: 1.00000; 14967/14359 tok/s;    293 sec\n",
            "[2020-06-02 03:07:08,656 INFO] Step 6450/50000; acc:  55.36; ppl:  7.82; xent: 2.06; lr: 1.00000; 14862/15180 tok/s;    295 sec\n",
            "[2020-06-02 03:07:11,079 INFO] Step 6500/50000; acc:  52.93; ppl:  9.29; xent: 2.23; lr: 1.00000; 14181/14810 tok/s;    297 sec\n",
            "[2020-06-02 03:07:12,838 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:07:13,115 INFO] number of examples: 26141\n",
            "[2020-06-02 03:07:13,484 INFO] Step 6550/50000; acc:  56.98; ppl:  7.28; xent: 1.99; lr: 1.00000; 11871/12586 tok/s;    300 sec\n",
            "[2020-06-02 03:07:15,962 INFO] Step 6600/50000; acc:  52.46; ppl:  9.38; xent: 2.24; lr: 1.00000; 14429/14878 tok/s;    302 sec\n",
            "[2020-06-02 03:07:18,308 INFO] Step 6650/50000; acc:  52.51; ppl:  9.29; xent: 2.23; lr: 1.00000; 15115/14922 tok/s;    305 sec\n",
            "[2020-06-02 03:07:20,424 INFO] Step 6700/50000; acc:  55.85; ppl:  7.81; xent: 2.06; lr: 1.00000; 14663/15309 tok/s;    307 sec\n",
            "[2020-06-02 03:07:22,802 INFO] Step 6750/50000; acc:  53.93; ppl:  8.36; xent: 2.12; lr: 1.00000; 14501/14945 tok/s;    309 sec\n",
            "[2020-06-02 03:07:24,695 INFO] Step 6800/50000; acc:  57.66; ppl:  6.68; xent: 1.90; lr: 1.00000; 15071/14752 tok/s;    311 sec\n",
            "[2020-06-02 03:07:26,976 INFO] Step 6850/50000; acc:  54.13; ppl:  8.20; xent: 2.10; lr: 1.00000; 14748/14833 tok/s;    313 sec\n",
            "[2020-06-02 03:07:29,226 INFO] Step 6900/50000; acc:  55.51; ppl:  7.90; xent: 2.07; lr: 1.00000; 14206/14941 tok/s;    316 sec\n",
            "[2020-06-02 03:07:31,342 INFO] Step 6950/50000; acc:  57.00; ppl:  7.14; xent: 1.97; lr: 1.00000; 14214/14903 tok/s;    318 sec\n",
            "[2020-06-02 03:07:31,459 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:07:31,747 INFO] number of examples: 26141\n",
            "[2020-06-02 03:07:34,261 INFO] Step 7000/50000; acc:  53.25; ppl:  8.77; xent: 2.17; lr: 1.00000; 12263/12603 tok/s;    321 sec\n",
            "[2020-06-02 03:07:36,510 INFO] Step 7050/50000; acc:  54.85; ppl:  8.13; xent: 2.10; lr: 1.00000; 14766/15015 tok/s;    323 sec\n",
            "[2020-06-02 03:07:38,711 INFO] Step 7100/50000; acc:  55.80; ppl:  7.55; xent: 2.02; lr: 1.00000; 14879/14990 tok/s;    325 sec\n",
            "[2020-06-02 03:07:41,065 INFO] Step 7150/50000; acc:  55.48; ppl:  7.62; xent: 2.03; lr: 1.00000; 14762/15027 tok/s;    327 sec\n",
            "[2020-06-02 03:07:43,067 INFO] Step 7200/50000; acc:  58.44; ppl:  6.39; xent: 1.85; lr: 1.00000; 14184/14644 tok/s;    329 sec\n",
            "[2020-06-02 03:07:45,340 INFO] Step 7250/50000; acc:  55.91; ppl:  7.45; xent: 2.01; lr: 1.00000; 14800/14784 tok/s;    332 sec\n",
            "[2020-06-02 03:07:47,595 INFO] Step 7300/50000; acc:  56.33; ppl:  7.44; xent: 2.01; lr: 1.00000; 14286/14806 tok/s;    334 sec\n",
            "[2020-06-02 03:07:49,663 INFO] Step 7350/50000; acc:  58.70; ppl:  6.44; xent: 1.86; lr: 1.00000; 14342/14975 tok/s;    336 sec\n",
            "[2020-06-02 03:07:50,199 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:07:50,504 INFO] number of examples: 26141\n",
            "[2020-06-02 03:07:52,554 INFO] Step 7400/50000; acc:  55.22; ppl:  7.91; xent: 2.07; lr: 1.00000; 11774/12288 tok/s;    339 sec\n",
            "[2020-06-02 03:07:54,958 INFO] Step 7450/50000; acc:  55.35; ppl:  7.90; xent: 2.07; lr: 1.00000; 15071/14888 tok/s;    341 sec\n",
            "[2020-06-02 03:07:57,090 INFO] Step 7500/50000; acc:  58.45; ppl:  6.56; xent: 1.88; lr: 1.00000; 14424/14987 tok/s;    343 sec\n",
            "[2020-06-02 03:07:59,373 INFO] Step 7550/50000; acc:  57.15; ppl:  6.84; xent: 1.92; lr: 1.00000; 14860/15056 tok/s;    346 sec\n",
            "[2020-06-02 03:08:01,539 INFO] Step 7600/50000; acc:  58.14; ppl:  6.45; xent: 1.86; lr: 1.00000; 14599/14913 tok/s;    348 sec\n",
            "[2020-06-02 03:08:03,742 INFO] Step 7650/50000; acc:  57.75; ppl:  6.81; xent: 1.92; lr: 1.00000; 14497/14611 tok/s;    350 sec\n",
            "[2020-06-02 03:08:05,978 INFO] Step 7700/50000; acc:  57.79; ppl:  6.83; xent: 1.92; lr: 1.00000; 14645/14856 tok/s;    352 sec\n",
            "[2020-06-02 03:08:08,117 INFO] Step 7750/50000; acc:  59.18; ppl:  6.14; xent: 1.82; lr: 1.00000; 14520/15028 tok/s;    354 sec\n",
            "[2020-06-02 03:08:08,939 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:08:09,231 INFO] number of examples: 26141\n",
            "[2020-06-02 03:08:10,805 INFO] Step 7800/50000; acc:  57.15; ppl:  7.24; xent: 1.98; lr: 1.00000; 11433/12288 tok/s;    357 sec\n",
            "[2020-06-02 03:08:13,071 INFO] Step 7850/50000; acc:  58.32; ppl:  6.37; xent: 1.85; lr: 1.00000; 15333/15318 tok/s;    359 sec\n",
            "[2020-06-02 03:08:15,467 INFO] Step 7900/50000; acc:  56.38; ppl:  7.40; xent: 2.00; lr: 1.00000; 14783/14790 tok/s;    362 sec\n",
            "[2020-06-02 03:08:17,641 INFO] Step 7950/50000; acc:  60.04; ppl:  5.86; xent: 1.77; lr: 1.00000; 14925/15416 tok/s;    364 sec\n",
            "[2020-06-02 03:08:19,896 INFO] Step 8000/50000; acc:  58.96; ppl:  6.29; xent: 1.84; lr: 1.00000; 14307/15009 tok/s;    366 sec\n",
            "[2020-06-02 03:08:21,987 INFO] Step 8050/50000; acc:  59.21; ppl:  6.08; xent: 1.80; lr: 1.00000; 14782/14297 tok/s;    368 sec\n",
            "[2020-06-02 03:08:24,161 INFO] Step 8100/50000; acc:  59.58; ppl:  6.12; xent: 1.81; lr: 1.00000; 14706/14872 tok/s;    370 sec\n",
            "[2020-06-02 03:08:26,427 INFO] Step 8150/50000; acc:  59.76; ppl:  6.09; xent: 1.81; lr: 1.00000; 14279/15138 tok/s;    373 sec\n",
            "[2020-06-02 03:08:27,592 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:08:27,883 INFO] number of examples: 26141\n",
            "[2020-06-02 03:08:28,973 INFO] Step 8200/50000; acc:  60.32; ppl:  5.87; xent: 1.77; lr: 1.00000; 11671/12275 tok/s;    375 sec\n",
            "[2020-06-02 03:08:31,282 INFO] Step 8250/50000; acc:  59.63; ppl:  6.11; xent: 1.81; lr: 1.00000; 14320/14905 tok/s;    378 sec\n",
            "[2020-06-02 03:08:33,690 INFO] Step 8300/50000; acc:  57.56; ppl:  6.94; xent: 1.94; lr: 1.00000; 15216/14696 tok/s;    380 sec\n",
            "[2020-06-02 03:08:35,907 INFO] Step 8350/50000; acc:  60.77; ppl:  5.67; xent: 1.73; lr: 1.00000; 14759/15647 tok/s;    382 sec\n",
            "[2020-06-02 03:08:38,243 INFO] Step 8400/50000; acc:  60.22; ppl:  5.86; xent: 1.77; lr: 1.00000; 14217/14787 tok/s;    385 sec\n",
            "[2020-06-02 03:08:40,227 INFO] Step 8450/50000; acc:  62.04; ppl:  5.28; xent: 1.66; lr: 1.00000; 14940/14157 tok/s;    387 sec\n",
            "[2020-06-02 03:08:42,285 INFO] Step 8500/50000; acc:  62.18; ppl:  5.23; xent: 1.65; lr: 1.00000; 14867/15364 tok/s;    389 sec\n",
            "[2020-06-02 03:08:44,680 INFO] Step 8550/50000; acc:  59.25; ppl:  6.34; xent: 1.85; lr: 1.00000; 14316/14779 tok/s;    391 sec\n",
            "[2020-06-02 03:08:46,265 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:08:46,572 INFO] number of examples: 26141\n",
            "[2020-06-02 03:08:47,154 INFO] Step 8600/50000; acc:  62.68; ppl:  5.21; xent: 1.65; lr: 1.00000; 11905/12678 tok/s;    393 sec\n",
            "[2020-06-02 03:08:49,595 INFO] Step 8650/50000; acc:  59.63; ppl:  6.14; xent: 1.82; lr: 1.00000; 14175/14682 tok/s;    396 sec\n",
            "[2020-06-02 03:08:52,016 INFO] Step 8700/50000; acc:  59.03; ppl:  6.33; xent: 1.84; lr: 1.00000; 15097/14835 tok/s;    398 sec\n",
            "[2020-06-02 03:08:54,158 INFO] Step 8750/50000; acc:  62.36; ppl:  5.27; xent: 1.66; lr: 1.00000; 14630/15311 tok/s;    400 sec\n",
            "[2020-06-02 03:08:56,533 INFO] Step 8800/50000; acc:  61.60; ppl:  5.37; xent: 1.68; lr: 1.00000; 14311/14759 tok/s;    403 sec\n",
            "[2020-06-02 03:08:58,425 INFO] Step 8850/50000; acc:  64.93; ppl:  4.54; xent: 1.51; lr: 1.00000; 15104/14487 tok/s;    405 sec\n",
            "[2020-06-02 03:09:00,622 INFO] Step 8900/50000; acc:  61.68; ppl:  5.40; xent: 1.69; lr: 1.00000; 14846/15061 tok/s;    407 sec\n",
            "[2020-06-02 03:09:02,920 INFO] Step 8950/50000; acc:  61.71; ppl:  5.48; xent: 1.70; lr: 1.00000; 13858/14745 tok/s;    409 sec\n",
            "[2020-06-02 03:09:05,012 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:09:05,319 INFO] number of examples: 26141\n",
            "[2020-06-02 03:09:05,528 INFO] Step 9000/50000; acc:  62.81; ppl:  5.11; xent: 1.63; lr: 1.00000; 11943/12449 tok/s;    412 sec\n",
            "[2020-06-02 03:09:08,057 INFO] Step 9050/50000; acc:  60.00; ppl:  6.00; xent: 1.79; lr: 1.00000; 14105/14500 tok/s;    414 sec\n",
            "[2020-06-02 03:09:10,346 INFO] Step 9100/50000; acc:  60.89; ppl:  5.70; xent: 1.74; lr: 1.00000; 14964/14999 tok/s;    417 sec\n",
            "[2020-06-02 03:09:12,517 INFO] Step 9150/50000; acc:  63.38; ppl:  4.97; xent: 1.60; lr: 1.00000; 14583/15020 tok/s;    419 sec\n",
            "[2020-06-02 03:09:14,881 INFO] Step 9200/50000; acc:  62.72; ppl:  5.12; xent: 1.63; lr: 1.00000; 14856/15186 tok/s;    421 sec\n",
            "[2020-06-02 03:09:16,820 INFO] Step 9250/50000; acc:  65.77; ppl:  4.26; xent: 1.45; lr: 1.00000; 14481/14534 tok/s;    423 sec\n",
            "[2020-06-02 03:09:19,108 INFO] Step 9300/50000; acc:  62.39; ppl:  5.14; xent: 1.64; lr: 1.00000; 14844/14755 tok/s;    425 sec\n",
            "[2020-06-02 03:09:21,354 INFO] Step 9350/50000; acc:  62.62; ppl:  5.09; xent: 1.63; lr: 1.00000; 14346/15007 tok/s;    428 sec\n",
            "[2020-06-02 03:09:23,470 INFO] Step 9400/50000; acc:  64.37; ppl:  4.68; xent: 1.54; lr: 1.00000; 14184/14898 tok/s;    430 sec\n",
            "[2020-06-02 03:09:23,726 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:09:23,944 INFO] number of examples: 26141\n",
            "[2020-06-02 03:09:26,347 INFO] Step 9450/50000; acc:  61.46; ppl:  5.47; xent: 1.70; lr: 1.00000; 12129/12443 tok/s;    433 sec\n",
            "[2020-06-02 03:09:28,641 INFO] Step 9500/50000; acc:  62.53; ppl:  5.30; xent: 1.67; lr: 1.00000; 14846/15086 tok/s;    435 sec\n",
            "[2020-06-02 03:09:30,860 INFO] Step 9550/50000; acc:  63.71; ppl:  4.88; xent: 1.59; lr: 1.00000; 14787/15012 tok/s;    437 sec\n",
            "[2020-06-02 03:09:33,124 INFO] Step 9600/50000; acc:  64.05; ppl:  4.71; xent: 1.55; lr: 1.00000; 14837/15070 tok/s;    439 sec\n",
            "[2020-06-02 03:09:35,144 INFO] Step 9650/50000; acc:  66.32; ppl:  4.14; xent: 1.42; lr: 1.00000; 14513/14948 tok/s;    441 sec\n",
            "[2020-06-02 03:09:37,424 INFO] Step 9700/50000; acc:  63.93; ppl:  4.81; xent: 1.57; lr: 1.00000; 14488/14561 tok/s;    444 sec\n",
            "[2020-06-02 03:09:39,686 INFO] Step 9750/50000; acc:  63.77; ppl:  4.88; xent: 1.59; lr: 1.00000; 14586/14979 tok/s;    446 sec\n",
            "[2020-06-02 03:09:41,777 INFO] Step 9800/50000; acc:  66.14; ppl:  4.14; xent: 1.42; lr: 1.00000; 14429/14965 tok/s;    448 sec\n",
            "[2020-06-02 03:09:42,428 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:09:42,655 INFO] number of examples: 26141\n",
            "[2020-06-02 03:09:44,447 INFO] Step 9850/50000; acc:  62.80; ppl:  5.17; xent: 1.64; lr: 1.00000; 12014/12736 tok/s;    451 sec\n",
            "[2020-06-02 03:09:46,881 INFO] Step 9900/50000; acc:  62.54; ppl:  5.17; xent: 1.64; lr: 1.00000; 14953/14854 tok/s;    453 sec\n",
            "[2020-06-02 03:09:49,085 INFO] Step 9950/50000; acc:  65.25; ppl:  4.47; xent: 1.50; lr: 1.00000; 14883/15057 tok/s;    455 sec\n",
            "[2020-06-02 03:09:51,252 INFO] Step 10000/50000; acc:  66.36; ppl:  4.13; xent: 1.42; lr: 1.00000; 14802/15272 tok/s;    458 sec\n",
            "[2020-06-02 03:09:51,252 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.valid.0.pt\n",
            "[2020-06-02 03:09:51,256 INFO] number of examples: 276\n",
            "[2020-06-02 03:09:51,514 INFO] Validation perplexity: 54.4795\n",
            "[2020-06-02 03:09:51,514 INFO] Validation accuracy: 39.8446\n",
            "[2020-06-02 03:09:51,541 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_10000.pt\n",
            "[2020-06-02 03:09:54,051 INFO] Step 10050/50000; acc:  64.95; ppl:  4.44; xent: 1.49; lr: 1.00000; 11869/12086 tok/s;    460 sec\n",
            "[2020-06-02 03:09:56,215 INFO] Step 10100/50000; acc:  64.65; ppl:  4.52; xent: 1.51; lr: 1.00000; 14464/14482 tok/s;    463 sec\n",
            "[2020-06-02 03:09:58,402 INFO] Step 10150/50000; acc:  65.09; ppl:  4.45; xent: 1.49; lr: 1.00000; 14701/14812 tok/s;    465 sec\n",
            "[2020-06-02 03:10:00,757 INFO] Step 10200/50000; acc:  66.11; ppl:  4.19; xent: 1.43; lr: 1.00000; 13627/14251 tok/s;    467 sec\n",
            "[2020-06-02 03:10:01,739 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:10:02,033 INFO] number of examples: 26141\n",
            "[2020-06-02 03:10:03,397 INFO] Step 10250/50000; acc:  65.25; ppl:  4.49; xent: 1.50; lr: 1.00000; 11211/12072 tok/s;    470 sec\n",
            "[2020-06-02 03:10:05,687 INFO] Step 10300/50000; acc:  65.64; ppl:  4.30; xent: 1.46; lr: 1.00000; 14943/15018 tok/s;    472 sec\n",
            "[2020-06-02 03:10:08,066 INFO] Step 10350/50000; acc:  64.07; ppl:  4.83; xent: 1.58; lr: 1.00000; 14644/14544 tok/s;    474 sec\n",
            "[2020-06-02 03:10:10,339 INFO] Step 10400/50000; acc:  65.91; ppl:  4.25; xent: 1.45; lr: 1.00000; 14749/15390 tok/s;    477 sec\n",
            "[2020-06-02 03:10:12,592 INFO] Step 10450/50000; acc:  66.40; ppl:  4.09; xent: 1.41; lr: 1.00000; 14271/14914 tok/s;    479 sec\n",
            "[2020-06-02 03:10:14,676 INFO] Step 10500/50000; acc:  66.66; ppl:  4.09; xent: 1.41; lr: 1.00000; 14893/14338 tok/s;    481 sec\n",
            "[2020-06-02 03:10:16,758 INFO] Step 10550/50000; acc:  67.73; ppl:  3.83; xent: 1.34; lr: 1.00000; 14891/15241 tok/s;    483 sec\n",
            "[2020-06-02 03:10:19,085 INFO] Step 10600/50000; acc:  65.71; ppl:  4.35; xent: 1.47; lr: 1.00000; 14096/14767 tok/s;    485 sec\n",
            "[2020-06-02 03:10:20,475 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:10:20,755 INFO] number of examples: 26141\n",
            "[2020-06-02 03:10:21,576 INFO] Step 10650/50000; acc:  66.77; ppl:  4.05; xent: 1.40; lr: 1.00000; 12000/12723 tok/s;    488 sec\n",
            "[2020-06-02 03:10:23,981 INFO] Step 10700/50000; acc:  65.73; ppl:  4.30; xent: 1.46; lr: 1.00000; 13971/14424 tok/s;    490 sec\n",
            "[2020-06-02 03:10:26,368 INFO] Step 10750/50000; acc:  64.85; ppl:  4.59; xent: 1.52; lr: 1.00000; 15196/14806 tok/s;    493 sec\n",
            "[2020-06-02 03:10:28,574 INFO] Step 10800/50000; acc:  66.87; ppl:  3.97; xent: 1.38; lr: 1.00000; 14554/15429 tok/s;    495 sec\n",
            "[2020-06-02 03:10:30,966 INFO] Step 10850/50000; acc:  66.67; ppl:  4.03; xent: 1.39; lr: 1.00000; 14478/14788 tok/s;    497 sec\n",
            "[2020-06-02 03:10:32,988 INFO] Step 10900/50000; acc:  68.14; ppl:  3.80; xent: 1.34; lr: 1.00000; 14752/14127 tok/s;    499 sec\n",
            "[2020-06-02 03:10:35,039 INFO] Step 10950/50000; acc:  68.74; ppl:  3.59; xent: 1.28; lr: 1.00000; 14823/15219 tok/s;    501 sec\n",
            "[2020-06-02 03:10:37,491 INFO] Step 11000/50000; acc:  65.32; ppl:  4.44; xent: 1.49; lr: 1.00000; 14172/14686 tok/s;    504 sec\n",
            "[2020-06-02 03:10:39,221 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:10:39,503 INFO] number of examples: 26141\n",
            "[2020-06-02 03:10:39,953 INFO] Step 11050/50000; acc:  68.66; ppl:  3.66; xent: 1.30; lr: 1.00000; 11908/12619 tok/s;    506 sec\n",
            "[2020-06-02 03:10:42,404 INFO] Step 11100/50000; acc:  65.43; ppl:  4.35; xent: 1.47; lr: 1.00000; 14149/14672 tok/s;    509 sec\n",
            "[2020-06-02 03:10:44,752 INFO] Step 11150/50000; acc:  66.16; ppl:  4.25; xent: 1.45; lr: 1.00000; 15047/14909 tok/s;    511 sec\n",
            "[2020-06-02 03:10:46,872 INFO] Step 11200/50000; acc:  68.10; ppl:  3.74; xent: 1.32; lr: 1.00000; 14597/15210 tok/s;    513 sec\n",
            "[2020-06-02 03:10:49,277 INFO] Step 11250/50000; acc:  67.37; ppl:  3.89; xent: 1.36; lr: 1.00000; 14552/14938 tok/s;    516 sec\n",
            "[2020-06-02 03:10:51,239 INFO] Step 11300/50000; acc:  70.57; ppl:  3.30; xent: 1.20; lr: 1.00000; 14966/14517 tok/s;    518 sec\n",
            "[2020-06-02 03:10:53,434 INFO] Step 11350/50000; acc:  67.98; ppl:  3.78; xent: 1.33; lr: 1.00000; 14831/15104 tok/s;    520 sec\n",
            "[2020-06-02 03:10:55,659 INFO] Step 11400/50000; acc:  67.59; ppl:  3.88; xent: 1.36; lr: 1.00000; 14222/14964 tok/s;    522 sec\n",
            "[2020-06-02 03:10:57,778 INFO] Step 11450/50000; acc:  69.24; ppl:  3.57; xent: 1.27; lr: 1.00000; 14196/14913 tok/s;    524 sec\n",
            "[2020-06-02 03:10:57,877 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:10:58,168 INFO] number of examples: 26141\n",
            "[2020-06-02 03:11:00,675 INFO] Step 11500/50000; acc:  65.36; ppl:  4.27; xent: 1.45; lr: 1.00000; 12377/12675 tok/s;    527 sec\n",
            "[2020-06-02 03:11:02,950 INFO] Step 11550/50000; acc:  67.38; ppl:  3.95; xent: 1.37; lr: 1.00000; 14717/14964 tok/s;    529 sec\n",
            "[2020-06-02 03:11:05,140 INFO] Step 11600/50000; acc:  68.43; ppl:  3.70; xent: 1.31; lr: 1.00000; 14863/14974 tok/s;    531 sec\n",
            "[2020-06-02 03:11:07,507 INFO] Step 11650/50000; acc:  68.50; ppl:  3.68; xent: 1.30; lr: 1.00000; 14790/15053 tok/s;    534 sec\n",
            "[2020-06-02 03:11:09,512 INFO] Step 11700/50000; acc:  71.12; ppl:  3.21; xent: 1.17; lr: 1.00000; 14222/14650 tok/s;    536 sec\n",
            "[2020-06-02 03:11:11,801 INFO] Step 11750/50000; acc:  68.06; ppl:  3.76; xent: 1.32; lr: 1.00000; 14948/14869 tok/s;    538 sec\n",
            "[2020-06-02 03:11:14,057 INFO] Step 11800/50000; acc:  68.16; ppl:  3.76; xent: 1.32; lr: 1.00000; 14314/14819 tok/s;    540 sec\n",
            "[2020-06-02 03:11:16,078 INFO] Step 11850/50000; acc:  71.09; ppl:  3.22; xent: 1.17; lr: 1.00000; 14131/14928 tok/s;    542 sec\n",
            "[2020-06-02 03:11:16,596 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:11:16,881 INFO] number of examples: 26141\n",
            "[2020-06-02 03:11:18,976 INFO] Step 11900/50000; acc:  66.80; ppl:  4.03; xent: 1.39; lr: 1.00000; 12034/12502 tok/s;    545 sec\n",
            "[2020-06-02 03:11:21,318 INFO] Step 11950/50000; acc:  67.54; ppl:  3.94; xent: 1.37; lr: 1.00000; 15083/14978 tok/s;    548 sec\n",
            "[2020-06-02 03:11:23,487 INFO] Step 12000/50000; acc:  69.67; ppl:  3.42; xent: 1.23; lr: 1.00000; 14538/15031 tok/s;    550 sec\n",
            "[2020-06-02 03:11:25,813 INFO] Step 12050/50000; acc:  68.58; ppl:  3.66; xent: 1.30; lr: 1.00000; 14831/15091 tok/s;    552 sec\n",
            "[2020-06-02 03:11:27,885 INFO] Step 12100/50000; acc:  71.84; ppl:  3.05; xent: 1.12; lr: 1.00000; 14711/14993 tok/s;    554 sec\n",
            "[2020-06-02 03:11:30,131 INFO] Step 12150/50000; acc:  68.67; ppl:  3.62; xent: 1.29; lr: 1.00000; 14418/14590 tok/s;    556 sec\n",
            "[2020-06-02 03:11:32,354 INFO] Step 12200/50000; acc:  69.85; ppl:  3.48; xent: 1.25; lr: 1.00000; 14699/14850 tok/s;    559 sec\n",
            "[2020-06-02 03:11:34,502 INFO] Step 12250/50000; acc:  70.88; ppl:  3.21; xent: 1.17; lr: 1.00000; 14461/14967 tok/s;    561 sec\n",
            "[2020-06-02 03:11:35,278 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:11:35,566 INFO] number of examples: 26141\n",
            "[2020-06-02 03:11:37,188 INFO] Step 12300/50000; acc:  67.64; ppl:  3.84; xent: 1.34; lr: 1.00000; 11466/12321 tok/s;    564 sec\n",
            "[2020-06-02 03:11:39,486 INFO] Step 12350/50000; acc:  70.46; ppl:  3.30; xent: 1.19; lr: 1.00000; 14982/14939 tok/s;    566 sec\n",
            "[2020-06-02 03:11:41,923 INFO] Step 12400/50000; acc:  67.78; ppl:  3.85; xent: 1.35; lr: 1.00000; 14484/14518 tok/s;    568 sec\n",
            "[2020-06-02 03:11:44,162 INFO] Step 12450/50000; acc:  71.16; ppl:  3.18; xent: 1.16; lr: 1.00000; 14714/15076 tok/s;    570 sec\n",
            "[2020-06-02 03:11:46,446 INFO] Step 12500/50000; acc:  70.44; ppl:  3.32; xent: 1.20; lr: 1.00000; 14018/14740 tok/s;    573 sec\n",
            "[2020-06-02 03:11:48,571 INFO] Step 12550/50000; acc:  71.07; ppl:  3.24; xent: 1.18; lr: 1.00000; 14572/14185 tok/s;    575 sec\n",
            "[2020-06-02 03:11:50,786 INFO] Step 12600/50000; acc:  70.05; ppl:  3.39; xent: 1.22; lr: 1.00000; 14464/14685 tok/s;    577 sec\n",
            "[2020-06-02 03:11:53,032 INFO] Step 12650/50000; acc:  70.77; ppl:  3.23; xent: 1.17; lr: 1.00000; 14288/15068 tok/s;    579 sec\n",
            "[2020-06-02 03:11:54,171 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:11:54,465 INFO] number of examples: 26141\n",
            "[2020-06-02 03:11:55,571 INFO] Step 12700/50000; acc:  70.20; ppl:  3.31; xent: 1.20; lr: 1.00000; 11576/12208 tok/s;    582 sec\n",
            "[2020-06-02 03:11:57,893 INFO] Step 12750/50000; acc:  69.80; ppl:  3.37; xent: 1.21; lr: 1.00000; 14718/15144 tok/s;    584 sec\n",
            "[2020-06-02 03:12:00,260 INFO] Step 12800/50000; acc:  68.50; ppl:  3.67; xent: 1.30; lr: 1.00000; 15070/14668 tok/s;    587 sec\n",
            "[2020-06-02 03:12:02,473 INFO] Step 12850/50000; acc:  71.29; ppl:  3.15; xent: 1.15; lr: 1.00000; 14720/15639 tok/s;    589 sec\n",
            "[2020-06-02 03:12:04,832 INFO] Step 12900/50000; acc:  71.11; ppl:  3.20; xent: 1.16; lr: 1.00000; 14250/14787 tok/s;    591 sec\n",
            "[2020-06-02 03:12:06,814 INFO] Step 12950/50000; acc:  72.98; ppl:  2.94; xent: 1.08; lr: 1.00000; 14853/14102 tok/s;    593 sec\n",
            "[2020-06-02 03:12:08,872 INFO] Step 13000/50000; acc:  72.58; ppl:  2.91; xent: 1.07; lr: 1.00000; 14807/15273 tok/s;    595 sec\n",
            "[2020-06-02 03:12:11,300 INFO] Step 13050/50000; acc:  69.30; ppl:  3.53; xent: 1.26; lr: 1.00000; 14279/14762 tok/s;    598 sec\n",
            "[2020-06-02 03:12:12,863 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:12:13,161 INFO] number of examples: 26141\n",
            "[2020-06-02 03:12:13,785 INFO] Step 13100/50000; acc:  72.34; ppl:  3.03; xent: 1.11; lr: 1.00000; 11825/12569 tok/s;    600 sec\n",
            "[2020-06-02 03:12:16,234 INFO] Step 13150/50000; acc:  69.63; ppl:  3.45; xent: 1.24; lr: 1.00000; 14183/14688 tok/s;    603 sec\n",
            "[2020-06-02 03:12:18,626 INFO] Step 13200/50000; acc:  69.47; ppl:  3.53; xent: 1.26; lr: 1.00000; 15065/14826 tok/s;    605 sec\n",
            "[2020-06-02 03:12:20,788 INFO] Step 13250/50000; acc:  71.89; ppl:  3.06; xent: 1.12; lr: 1.00000; 14646/15350 tok/s;    607 sec\n",
            "[2020-06-02 03:12:23,166 INFO] Step 13300/50000; acc:  72.02; ppl:  3.01; xent: 1.10; lr: 1.00000; 14318/14738 tok/s;    609 sec\n",
            "[2020-06-02 03:12:25,139 INFO] Step 13350/50000; acc:  73.52; ppl:  2.88; xent: 1.06; lr: 1.00000; 15036/14419 tok/s;    611 sec\n",
            "[2020-06-02 03:12:27,257 INFO] Step 13400/50000; acc:  72.88; ppl:  2.88; xent: 1.06; lr: 1.00000; 14798/15013 tok/s;    614 sec\n",
            "[2020-06-02 03:12:29,534 INFO] Step 13450/50000; acc:  71.14; ppl:  3.19; xent: 1.16; lr: 1.00000; 14178/15032 tok/s;    616 sec\n",
            "[2020-06-02 03:12:31,563 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:12:31,882 INFO] number of examples: 26141\n",
            "[2020-06-02 03:12:32,144 INFO] Step 13500/50000; acc:  72.28; ppl:  3.06; xent: 1.12; lr: 1.00000; 11934/12451 tok/s;    618 sec\n",
            "[2020-06-02 03:12:34,635 INFO] Step 13550/50000; acc:  69.35; ppl:  3.47; xent: 1.24; lr: 1.00000; 14145/14575 tok/s;    621 sec\n",
            "[2020-06-02 03:12:36,937 INFO] Step 13600/50000; acc:  70.85; ppl:  3.26; xent: 1.18; lr: 1.00000; 15071/15129 tok/s;    623 sec\n",
            "[2020-06-02 03:12:39,111 INFO] Step 13650/50000; acc:  72.62; ppl:  2.97; xent: 1.09; lr: 1.00000; 14531/14970 tok/s;    625 sec\n",
            "[2020-06-02 03:12:41,471 INFO] Step 13700/50000; acc:  72.04; ppl:  3.01; xent: 1.10; lr: 1.00000; 14750/15128 tok/s;    628 sec\n",
            "[2020-06-02 03:12:43,436 INFO] Step 13750/50000; acc:  74.80; ppl:  2.58; xent: 0.95; lr: 1.00000; 14646/14492 tok/s;    630 sec\n",
            "[2020-06-02 03:12:45,732 INFO] Step 13800/50000; acc:  71.74; ppl:  3.03; xent: 1.11; lr: 1.00000; 14790/14763 tok/s;    632 sec\n",
            "[2020-06-02 03:12:47,953 INFO] Step 13850/50000; acc:  72.27; ppl:  3.05; xent: 1.11; lr: 1.00000; 14224/14945 tok/s;    634 sec\n",
            "[2020-06-02 03:12:50,073 INFO] Step 13900/50000; acc:  73.26; ppl:  2.89; xent: 1.06; lr: 1.00000; 14123/14864 tok/s;    636 sec\n",
            "[2020-06-02 03:12:50,302 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:12:50,615 INFO] number of examples: 26141\n",
            "[2020-06-02 03:12:52,991 INFO] Step 13950/50000; acc:  70.29; ppl:  3.28; xent: 1.19; lr: 1.00000; 12201/12414 tok/s;    639 sec\n",
            "[2020-06-02 03:12:55,253 INFO] Step 14000/50000; acc:  71.46; ppl:  3.15; xent: 1.15; lr: 1.00000; 14630/14985 tok/s;    642 sec\n",
            "[2020-06-02 03:12:57,546 INFO] Step 14050/50000; acc:  72.36; ppl:  2.99; xent: 1.10; lr: 1.00000; 14616/14806 tok/s;    644 sec\n",
            "[2020-06-02 03:12:59,816 INFO] Step 14100/50000; acc:  73.36; ppl:  2.86; xent: 1.05; lr: 1.00000; 14601/14939 tok/s;    646 sec\n",
            "[2020-06-02 03:13:01,836 INFO] Step 14150/50000; acc:  75.25; ppl:  2.55; xent: 0.94; lr: 1.00000; 14390/14738 tok/s;    648 sec\n",
            "[2020-06-02 03:13:04,137 INFO] Step 14200/50000; acc:  72.54; ppl:  2.96; xent: 1.08; lr: 1.00000; 14601/14619 tok/s;    650 sec\n",
            "[2020-06-02 03:13:06,426 INFO] Step 14250/50000; acc:  71.84; ppl:  3.06; xent: 1.12; lr: 1.00000; 14441/14924 tok/s;    653 sec\n",
            "[2020-06-02 03:13:08,493 INFO] Step 14300/50000; acc:  75.02; ppl:  2.59; xent: 0.95; lr: 1.00000; 14286/14787 tok/s;    655 sec\n",
            "[2020-06-02 03:13:09,131 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:13:09,448 INFO] number of examples: 26141\n",
            "[2020-06-02 03:13:11,299 INFO] Step 14350/50000; acc:  71.33; ppl:  3.15; xent: 1.15; lr: 1.00000; 11574/12264 tok/s;    658 sec\n",
            "[2020-06-02 03:13:13,725 INFO] Step 14400/50000; acc:  71.66; ppl:  3.14; xent: 1.15; lr: 1.00000; 14999/14843 tok/s;    660 sec\n",
            "[2020-06-02 03:13:15,947 INFO] Step 14450/50000; acc:  73.52; ppl:  2.82; xent: 1.04; lr: 1.00000; 14767/15055 tok/s;    662 sec\n",
            "[2020-06-02 03:13:18,090 INFO] Step 14500/50000; acc:  74.74; ppl:  2.61; xent: 0.96; lr: 1.00000; 14783/15229 tok/s;    664 sec\n",
            "[2020-06-02 03:13:20,363 INFO] Step 14550/50000; acc:  73.86; ppl:  2.77; xent: 1.02; lr: 1.00000; 14757/14940 tok/s;    667 sec\n",
            "[2020-06-02 03:13:22,558 INFO] Step 14600/50000; acc:  72.90; ppl:  2.91; xent: 1.07; lr: 1.00000; 14517/14548 tok/s;    669 sec\n",
            "[2020-06-02 03:13:24,754 INFO] Step 14650/50000; acc:  73.12; ppl:  2.88; xent: 1.06; lr: 1.00000; 14528/14771 tok/s;    671 sec\n",
            "[2020-06-02 03:13:26,934 INFO] Step 14700/50000; acc:  75.46; ppl:  2.58; xent: 0.95; lr: 1.00000; 14517/15104 tok/s;    673 sec\n",
            "[2020-06-02 03:13:27,851 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:13:28,084 INFO] number of examples: 26141\n",
            "[2020-06-02 03:13:29,543 INFO] Step 14750/50000; acc:  71.97; ppl:  3.07; xent: 1.12; lr: 1.00000; 11764/12640 tok/s;    676 sec\n",
            "[2020-06-02 03:13:31,793 INFO] Step 14800/50000; acc:  74.49; ppl:  2.67; xent: 0.98; lr: 1.00000; 15174/15197 tok/s;    678 sec\n",
            "[2020-06-02 03:13:34,124 INFO] Step 14850/50000; acc:  72.30; ppl:  3.02; xent: 1.11; lr: 1.00000; 14676/14661 tok/s;    680 sec\n",
            "[2020-06-02 03:13:36,369 INFO] Step 14900/50000; acc:  74.41; ppl:  2.70; xent: 0.99; lr: 1.00000; 14761/15366 tok/s;    683 sec\n",
            "[2020-06-02 03:13:38,611 INFO] Step 14950/50000; acc:  74.91; ppl:  2.61; xent: 0.96; lr: 1.00000; 14336/14925 tok/s;    685 sec\n",
            "[2020-06-02 03:13:40,737 INFO] Step 15000/50000; acc:  74.09; ppl:  2.72; xent: 1.00; lr: 1.00000; 14754/14300 tok/s;    687 sec\n",
            "[2020-06-02 03:13:40,758 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_15000.pt\n",
            "[2020-06-02 03:13:43,063 INFO] Step 15050/50000; acc:  75.46; ppl:  2.54; xent: 0.93; lr: 1.00000; 13168/13426 tok/s;    689 sec\n",
            "[2020-06-02 03:13:45,396 INFO] Step 15100/50000; acc:  73.62; ppl:  2.82; xent: 1.04; lr: 1.00000; 14110/14778 tok/s;    692 sec\n",
            "[2020-06-02 03:13:46,764 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:13:47,058 INFO] number of examples: 26141\n",
            "[2020-06-02 03:13:47,908 INFO] Step 15150/50000; acc:  74.59; ppl:  2.68; xent: 0.99; lr: 1.00000; 11974/12640 tok/s;    694 sec\n",
            "[2020-06-02 03:13:50,311 INFO] Step 15200/50000; acc:  73.24; ppl:  2.84; xent: 1.04; lr: 1.00000; 13986/14533 tok/s;    697 sec\n",
            "[2020-06-02 03:13:52,859 INFO] Step 15250/50000; acc:  72.76; ppl:  2.96; xent: 1.09; lr: 1.00000; 14262/13804 tok/s;    699 sec\n",
            "[2020-06-02 03:13:55,104 INFO] Step 15300/50000; acc:  74.77; ppl:  2.63; xent: 0.97; lr: 1.00000; 14505/15456 tok/s;    701 sec\n",
            "[2020-06-02 03:13:57,491 INFO] Step 15350/50000; acc:  74.97; ppl:  2.60; xent: 0.96; lr: 1.00000; 14476/14760 tok/s;    704 sec\n",
            "[2020-06-02 03:13:59,469 INFO] Step 15400/50000; acc:  76.15; ppl:  2.51; xent: 0.92; lr: 1.00000; 14727/14089 tok/s;    706 sec\n",
            "[2020-06-02 03:14:01,505 INFO] Step 15450/50000; acc:  76.16; ppl:  2.42; xent: 0.88; lr: 1.00000; 14936/15335 tok/s;    708 sec\n",
            "[2020-06-02 03:14:03,973 INFO] Step 15500/50000; acc:  73.14; ppl:  2.91; xent: 1.07; lr: 1.00000; 14124/14685 tok/s;    710 sec\n",
            "[2020-06-02 03:14:05,671 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:14:05,967 INFO] number of examples: 26141\n",
            "[2020-06-02 03:14:06,467 INFO] Step 15550/50000; acc:  75.49; ppl:  2.54; xent: 0.93; lr: 1.00000; 11933/12625 tok/s;    713 sec\n",
            "[2020-06-02 03:14:08,879 INFO] Step 15600/50000; acc:  73.21; ppl:  2.86; xent: 1.05; lr: 1.00000; 14192/14682 tok/s;    715 sec\n",
            "[2020-06-02 03:14:11,260 INFO] Step 15650/50000; acc:  72.71; ppl:  2.91; xent: 1.07; lr: 1.00000; 15084/15027 tok/s;    718 sec\n",
            "[2020-06-02 03:14:13,353 INFO] Step 15700/50000; acc:  76.10; ppl:  2.48; xent: 0.91; lr: 1.00000; 14603/15196 tok/s;    720 sec\n",
            "[2020-06-02 03:14:15,751 INFO] Step 15750/50000; acc:  75.42; ppl:  2.55; xent: 0.94; lr: 1.00000; 14541/14928 tok/s;    722 sec\n",
            "[2020-06-02 03:14:17,729 INFO] Step 15800/50000; acc:  77.47; ppl:  2.30; xent: 0.83; lr: 1.00000; 15039/14432 tok/s;    724 sec\n",
            "[2020-06-02 03:14:19,899 INFO] Step 15850/50000; acc:  75.39; ppl:  2.57; xent: 0.94; lr: 1.00000; 14768/15103 tok/s;    726 sec\n",
            "[2020-06-02 03:14:22,121 INFO] Step 15900/50000; acc:  75.06; ppl:  2.64; xent: 0.97; lr: 1.00000; 14123/14924 tok/s;    728 sec\n",
            "[2020-06-02 03:14:24,304 INFO] Step 15950/50000; acc:  76.19; ppl:  2.50; xent: 0.92; lr: 1.00000; 14162/14845 tok/s;    731 sec\n",
            "[2020-06-02 03:14:24,344 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:14:24,638 INFO] number of examples: 26141\n",
            "[2020-06-02 03:14:27,205 INFO] Step 16000/50000; acc:  73.06; ppl:  2.87; xent: 1.06; lr: 1.00000; 12161/12470 tok/s;    734 sec\n",
            "[2020-06-02 03:14:29,485 INFO] Step 16050/50000; acc:  74.89; ppl:  2.65; xent: 0.98; lr: 1.00000; 14629/14847 tok/s;    736 sec\n",
            "[2020-06-02 03:14:31,724 INFO] Step 16100/50000; acc:  75.49; ppl:  2.52; xent: 0.92; lr: 1.00000; 14736/14845 tok/s;    738 sec\n",
            "[2020-06-02 03:14:34,083 INFO] Step 16150/50000; acc:  76.04; ppl:  2.48; xent: 0.91; lr: 1.00000; 14784/15051 tok/s;    740 sec\n",
            "[2020-06-02 03:14:36,081 INFO] Step 16200/50000; acc:  78.06; ppl:  2.25; xent: 0.81; lr: 1.00000; 14214/14636 tok/s;    742 sec\n",
            "[2020-06-02 03:14:38,391 INFO] Step 16250/50000; acc:  75.57; ppl:  2.54; xent: 0.93; lr: 1.00000; 14892/14763 tok/s;    745 sec\n",
            "[2020-06-02 03:14:40,631 INFO] Step 16300/50000; acc:  75.20; ppl:  2.61; xent: 0.96; lr: 1.00000; 14357/14922 tok/s;    747 sec\n",
            "[2020-06-02 03:14:42,718 INFO] Step 16350/50000; acc:  77.05; ppl:  2.38; xent: 0.87; lr: 1.00000; 14040/14799 tok/s;    749 sec\n",
            "[2020-06-02 03:14:43,132 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:14:43,417 INFO] number of examples: 26141\n",
            "[2020-06-02 03:14:45,549 INFO] Step 16400/50000; acc:  74.38; ppl:  2.68; xent: 0.99; lr: 1.00000; 11990/12501 tok/s;    752 sec\n",
            "[2020-06-02 03:14:47,894 INFO] Step 16450/50000; acc:  74.79; ppl:  2.67; xent: 0.98; lr: 1.00000; 15069/15018 tok/s;    754 sec\n",
            "[2020-06-02 03:14:50,061 INFO] Step 16500/50000; acc:  76.60; ppl:  2.42; xent: 0.88; lr: 1.00000; 14520/15018 tok/s;    756 sec\n",
            "[2020-06-02 03:14:52,371 INFO] Step 16550/50000; acc:  75.70; ppl:  2.52; xent: 0.92; lr: 1.00000; 14957/15161 tok/s;    759 sec\n",
            "[2020-06-02 03:14:54,448 INFO] Step 16600/50000; acc:  78.86; ppl:  2.15; xent: 0.77; lr: 1.00000; 14642/14923 tok/s;    761 sec\n",
            "[2020-06-02 03:14:56,698 INFO] Step 16650/50000; acc:  75.49; ppl:  2.52; xent: 0.93; lr: 1.00000; 14539/14653 tok/s;    763 sec\n",
            "[2020-06-02 03:14:58,923 INFO] Step 16700/50000; acc:  76.09; ppl:  2.49; xent: 0.91; lr: 1.00000; 14656/14893 tok/s;    765 sec\n",
            "[2020-06-02 03:15:01,045 INFO] Step 16750/50000; acc:  77.94; ppl:  2.27; xent: 0.82; lr: 1.00000; 14455/14966 tok/s;    767 sec\n",
            "[2020-06-02 03:15:01,813 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:15:02,105 INFO] number of examples: 26141\n",
            "[2020-06-02 03:15:03,759 INFO] Step 16800/50000; acc:  74.46; ppl:  2.68; xent: 0.98; lr: 1.00000; 11420/12267 tok/s;    770 sec\n",
            "[2020-06-02 03:15:06,130 INFO] Step 16850/50000; acc:  75.83; ppl:  2.53; xent: 0.93; lr: 1.00000; 15219/15069 tok/s;    772 sec\n",
            "[2020-06-02 03:15:08,430 INFO] Step 16900/50000; acc:  75.31; ppl:  2.56; xent: 0.94; lr: 1.00000; 14682/14856 tok/s;    775 sec\n",
            "[2020-06-02 03:15:10,627 INFO] Step 16950/50000; acc:  77.91; ppl:  2.23; xent: 0.80; lr: 1.00000; 14996/15350 tok/s;    777 sec\n",
            "[2020-06-02 03:15:12,855 INFO] Step 17000/50000; acc:  77.14; ppl:  2.36; xent: 0.86; lr: 1.00000; 14343/15011 tok/s;    779 sec\n",
            "[2020-06-02 03:15:14,964 INFO] Step 17050/50000; acc:  77.59; ppl:  2.32; xent: 0.84; lr: 1.00000; 14683/14354 tok/s;    781 sec\n",
            "[2020-06-02 03:15:17,153 INFO] Step 17100/50000; acc:  76.60; ppl:  2.44; xent: 0.89; lr: 1.00000; 14611/14823 tok/s;    783 sec\n",
            "[2020-06-02 03:15:19,434 INFO] Step 17150/50000; acc:  77.49; ppl:  2.32; xent: 0.84; lr: 1.00000; 14459/15121 tok/s;    786 sec\n",
            "[2020-06-02 03:15:20,504 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:15:20,794 INFO] number of examples: 26141\n",
            "[2020-06-02 03:15:21,983 INFO] Step 17200/50000; acc:  76.62; ppl:  2.40; xent: 0.88; lr: 1.00000; 11408/12173 tok/s;    788 sec\n",
            "[2020-06-02 03:15:24,277 INFO] Step 17250/50000; acc:  76.83; ppl:  2.38; xent: 0.87; lr: 1.00000; 14891/15127 tok/s;    791 sec\n",
            "[2020-06-02 03:15:26,656 INFO] Step 17300/50000; acc:  75.11; ppl:  2.63; xent: 0.97; lr: 1.00000; 14995/14751 tok/s;    793 sec\n",
            "[2020-06-02 03:15:28,834 INFO] Step 17350/50000; acc:  78.09; ppl:  2.25; xent: 0.81; lr: 1.00000; 14755/15600 tok/s;    795 sec\n",
            "[2020-06-02 03:15:31,206 INFO] Step 17400/50000; acc:  77.42; ppl:  2.30; xent: 0.83; lr: 1.00000; 14381/14915 tok/s;    798 sec\n",
            "[2020-06-02 03:15:33,218 INFO] Step 17450/50000; acc:  78.04; ppl:  2.26; xent: 0.82; lr: 1.00000; 14854/14173 tok/s;    800 sec\n",
            "[2020-06-02 03:15:35,220 INFO] Step 17500/50000; acc:  79.53; ppl:  2.07; xent: 0.73; lr: 1.00000; 14747/15231 tok/s;    802 sec\n",
            "[2020-06-02 03:15:37,687 INFO] Step 17550/50000; acc:  75.62; ppl:  2.57; xent: 0.94; lr: 1.00000; 14157/14659 tok/s;    804 sec\n",
            "[2020-06-02 03:15:39,189 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:15:39,502 INFO] number of examples: 26141\n",
            "[2020-06-02 03:15:40,215 INFO] Step 17600/50000; acc:  77.94; ppl:  2.28; xent: 0.82; lr: 1.00000; 11850/12564 tok/s;    807 sec\n",
            "[2020-06-02 03:15:42,608 INFO] Step 17650/50000; acc:  76.12; ppl:  2.47; xent: 0.91; lr: 1.00000; 14018/14531 tok/s;    809 sec\n",
            "[2020-06-02 03:15:45,007 INFO] Step 17700/50000; acc:  76.07; ppl:  2.53; xent: 0.93; lr: 1.00000; 15096/14831 tok/s;    811 sec\n",
            "[2020-06-02 03:15:47,204 INFO] Step 17750/50000; acc:  78.33; ppl:  2.23; xent: 0.80; lr: 1.00000; 14669/15327 tok/s;    814 sec\n",
            "[2020-06-02 03:15:49,564 INFO] Step 17800/50000; acc:  78.22; ppl:  2.22; xent: 0.80; lr: 1.00000; 14297/14766 tok/s;    816 sec\n",
            "[2020-06-02 03:15:51,573 INFO] Step 17850/50000; acc:  78.82; ppl:  2.20; xent: 0.79; lr: 1.00000; 14944/14305 tok/s;    818 sec\n",
            "[2020-06-02 03:15:53,662 INFO] Step 17900/50000; acc:  79.35; ppl:  2.12; xent: 0.75; lr: 1.00000; 14793/15053 tok/s;    820 sec\n",
            "[2020-06-02 03:15:56,035 INFO] Step 17950/50000; acc:  76.48; ppl:  2.45; xent: 0.89; lr: 1.00000; 14085/14814 tok/s;    822 sec\n",
            "[2020-06-02 03:15:57,966 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:15:58,279 INFO] number of examples: 26141\n",
            "[2020-06-02 03:15:58,565 INFO] Step 18000/50000; acc:  79.00; ppl:  2.17; xent: 0.77; lr: 1.00000; 11868/12487 tok/s;    825 sec\n",
            "[2020-06-02 03:16:01,046 INFO] Step 18050/50000; acc:  75.74; ppl:  2.51; xent: 0.92; lr: 1.00000; 14172/14600 tok/s;    827 sec\n",
            "[2020-06-02 03:16:03,380 INFO] Step 18100/50000; acc:  76.80; ppl:  2.40; xent: 0.88; lr: 1.00000; 15032/15064 tok/s;    830 sec\n",
            "[2020-06-02 03:16:05,557 INFO] Step 18150/50000; acc:  78.53; ppl:  2.22; xent: 0.80; lr: 1.00000; 14597/15005 tok/s;    832 sec\n",
            "[2020-06-02 03:16:07,935 INFO] Step 18200/50000; acc:  78.30; ppl:  2.24; xent: 0.80; lr: 1.00000; 14482/14828 tok/s;    834 sec\n",
            "[2020-06-02 03:16:09,857 INFO] Step 18250/50000; acc:  80.92; ppl:  1.97; xent: 0.68; lr: 1.00000; 14838/14750 tok/s;    836 sec\n",
            "[2020-06-02 03:16:12,137 INFO] Step 18300/50000; acc:  77.93; ppl:  2.28; xent: 0.82; lr: 1.00000; 14923/14924 tok/s;    838 sec\n",
            "[2020-06-02 03:16:14,389 INFO] Step 18350/50000; acc:  77.79; ppl:  2.30; xent: 0.83; lr: 1.00000; 14283/14961 tok/s;    841 sec\n",
            "[2020-06-02 03:16:16,500 INFO] Step 18400/50000; acc:  79.29; ppl:  2.15; xent: 0.77; lr: 1.00000; 14121/14872 tok/s;    843 sec\n",
            "[2020-06-02 03:16:16,675 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:16:16,992 INFO] number of examples: 26141\n",
            "[2020-06-02 03:16:19,439 INFO] Step 18450/50000; acc:  76.35; ppl:  2.46; xent: 0.90; lr: 1.00000; 12243/12515 tok/s;    846 sec\n",
            "[2020-06-02 03:16:21,619 INFO] Step 18500/50000; acc:  77.89; ppl:  2.28; xent: 0.82; lr: 1.00000; 14681/14997 tok/s;    848 sec\n",
            "[2020-06-02 03:16:23,884 INFO] Step 18550/50000; acc:  78.07; ppl:  2.24; xent: 0.81; lr: 1.00000; 14909/15074 tok/s;    850 sec\n",
            "[2020-06-02 03:16:26,173 INFO] Step 18600/50000; acc:  79.16; ppl:  2.16; xent: 0.77; lr: 1.00000; 14652/14980 tok/s;    853 sec\n",
            "[2020-06-02 03:16:28,134 INFO] Step 18650/50000; acc:  81.01; ppl:  1.96; xent: 0.67; lr: 1.00000; 14498/14898 tok/s;    854 sec\n",
            "[2020-06-02 03:16:30,437 INFO] Step 18700/50000; acc:  78.35; ppl:  2.23; xent: 0.80; lr: 1.00000; 14590/14608 tok/s;    857 sec\n",
            "[2020-06-02 03:16:32,725 INFO] Step 18750/50000; acc:  77.76; ppl:  2.32; xent: 0.84; lr: 1.00000; 14506/14988 tok/s;    859 sec\n",
            "[2020-06-02 03:16:34,770 INFO] Step 18800/50000; acc:  80.78; ppl:  2.00; xent: 0.69; lr: 1.00000; 14469/15007 tok/s;    861 sec\n",
            "[2020-06-02 03:16:35,377 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:16:35,595 INFO] number of examples: 26141\n",
            "[2020-06-02 03:16:37,490 INFO] Step 18850/50000; acc:  77.36; ppl:  2.35; xent: 0.85; lr: 1.00000; 12123/12813 tok/s;    864 sec\n",
            "[2020-06-02 03:16:39,902 INFO] Step 18900/50000; acc:  77.26; ppl:  2.35; xent: 0.85; lr: 1.00000; 15167/14902 tok/s;    866 sec\n",
            "[2020-06-02 03:16:42,091 INFO] Step 18950/50000; acc:  79.10; ppl:  2.15; xent: 0.77; lr: 1.00000; 14578/15016 tok/s;    868 sec\n",
            "[2020-06-02 03:16:44,343 INFO] Step 19000/50000; acc:  79.68; ppl:  2.09; xent: 0.74; lr: 1.00000; 14835/15147 tok/s;    871 sec\n",
            "[2020-06-02 03:16:46,490 INFO] Step 19050/50000; acc:  80.74; ppl:  1.99; xent: 0.69; lr: 1.00000; 14850/15132 tok/s;    873 sec\n",
            "[2020-06-02 03:16:48,738 INFO] Step 19100/50000; acc:  78.66; ppl:  2.19; xent: 0.78; lr: 1.00000; 14293/14352 tok/s;    875 sec\n",
            "[2020-06-02 03:16:50,949 INFO] Step 19150/50000; acc:  78.72; ppl:  2.22; xent: 0.80; lr: 1.00000; 14463/14706 tok/s;    877 sec\n",
            "[2020-06-02 03:16:53,149 INFO] Step 19200/50000; acc:  80.49; ppl:  2.03; xent: 0.71; lr: 1.00000; 14322/14873 tok/s;    879 sec\n",
            "[2020-06-02 03:16:54,052 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:16:54,353 INFO] number of examples: 26141\n",
            "[2020-06-02 03:16:55,869 INFO] Step 19250/50000; acc:  77.34; ppl:  2.33; xent: 0.84; lr: 1.00000; 11229/12054 tok/s;    882 sec\n",
            "[2020-06-02 03:16:58,148 INFO] Step 19300/50000; acc:  80.01; ppl:  2.05; xent: 0.72; lr: 1.00000; 15134/15175 tok/s;    884 sec\n",
            "[2020-06-02 03:17:00,500 INFO] Step 19350/50000; acc:  77.57; ppl:  2.32; xent: 0.84; lr: 1.00000; 14702/14660 tok/s;    887 sec\n",
            "[2020-06-02 03:17:02,738 INFO] Step 19400/50000; acc:  79.85; ppl:  2.07; xent: 0.73; lr: 1.00000; 14754/15303 tok/s;    889 sec\n",
            "[2020-06-02 03:17:04,981 INFO] Step 19450/50000; acc:  80.60; ppl:  2.02; xent: 0.70; lr: 1.00000; 14215/14860 tok/s;    891 sec\n",
            "[2020-06-02 03:17:07,133 INFO] Step 19500/50000; acc:  79.43; ppl:  2.11; xent: 0.75; lr: 1.00000; 14932/14380 tok/s;    893 sec\n",
            "[2020-06-02 03:17:09,210 INFO] Step 19550/50000; acc:  81.47; ppl:  1.94; xent: 0.66; lr: 1.00000; 14408/14711 tok/s;    896 sec\n",
            "[2020-06-02 03:17:11,528 INFO] Step 19600/50000; acc:  79.25; ppl:  2.16; xent: 0.77; lr: 1.00000; 14173/14929 tok/s;    898 sec\n",
            "[2020-06-02 03:17:12,867 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:17:13,158 INFO] number of examples: 26141\n",
            "[2020-06-02 03:17:14,155 INFO] Step 19650/50000; acc:  79.10; ppl:  2.17; xent: 0.77; lr: 1.00000; 11676/12264 tok/s;    900 sec\n",
            "[2020-06-02 03:17:16,465 INFO] Step 19700/50000; acc:  79.51; ppl:  2.12; xent: 0.75; lr: 1.00000; 14540/15087 tok/s;    903 sec\n",
            "[2020-06-02 03:17:18,784 INFO] Step 19750/50000; acc:  77.91; ppl:  2.30; xent: 0.83; lr: 1.00000; 15262/14838 tok/s;    905 sec\n",
            "[2020-06-02 03:17:21,038 INFO] Step 19800/50000; acc:  79.78; ppl:  2.05; xent: 0.72; lr: 1.00000; 14698/15699 tok/s;    907 sec\n",
            "[2020-06-02 03:17:23,413 INFO] Step 19850/50000; acc:  80.57; ppl:  2.03; xent: 0.71; lr: 1.00000; 14470/14824 tok/s;    910 sec\n",
            "[2020-06-02 03:17:25,384 INFO] Step 19900/50000; acc:  81.40; ppl:  1.96; xent: 0.67; lr: 1.00000; 14836/14049 tok/s;    912 sec\n",
            "[2020-06-02 03:17:27,429 INFO] Step 19950/50000; acc:  81.55; ppl:  1.92; xent: 0.65; lr: 1.00000; 14842/15312 tok/s;    914 sec\n",
            "[2020-06-02 03:17:29,855 INFO] Step 20000/50000; acc:  78.23; ppl:  2.27; xent: 0.82; lr: 1.00000; 14160/14696 tok/s;    916 sec\n",
            "[2020-06-02 03:17:29,856 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.valid.0.pt\n",
            "[2020-06-02 03:17:29,860 INFO] number of examples: 276\n",
            "[2020-06-02 03:17:30,120 INFO] Validation perplexity: 108.858\n",
            "[2020-06-02 03:17:30,120 INFO] Validation accuracy: 42.3316\n",
            "[2020-06-02 03:17:30,142 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_20000.pt\n",
            "[2020-06-02 03:17:32,073 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:17:32,378 INFO] number of examples: 26141\n",
            "[2020-06-02 03:17:32,901 INFO] Step 20050/50000; acc:  80.73; ppl:  1.99; xent: 0.69; lr: 1.00000; 9814/10381 tok/s;    919 sec\n",
            "[2020-06-02 03:17:35,345 INFO] Step 20100/50000; acc:  78.62; ppl:  2.20; xent: 0.79; lr: 1.00000; 14136/14653 tok/s;    922 sec\n",
            "[2020-06-02 03:17:37,744 INFO] Step 20150/50000; acc:  78.26; ppl:  2.26; xent: 0.82; lr: 1.00000; 14834/14743 tok/s;    924 sec\n",
            "[2020-06-02 03:17:39,855 INFO] Step 20200/50000; acc:  81.33; ppl:  1.96; xent: 0.67; lr: 1.00000; 14695/15246 tok/s;    926 sec\n",
            "[2020-06-02 03:17:42,431 INFO] Step 20250/50000; acc:  80.39; ppl:  2.03; xent: 0.71; lr: 1.00000; 13612/13976 tok/s;    929 sec\n",
            "[2020-06-02 03:17:44,385 INFO] Step 20300/50000; acc:  82.93; ppl:  1.83; xent: 0.60; lr: 1.00000; 14957/14378 tok/s;    931 sec\n",
            "[2020-06-02 03:17:46,560 INFO] Step 20350/50000; acc:  80.28; ppl:  2.04; xent: 0.71; lr: 1.00000; 14611/14946 tok/s;    933 sec\n",
            "[2020-06-02 03:17:48,808 INFO] Step 20400/50000; acc:  79.68; ppl:  2.12; xent: 0.75; lr: 1.00000; 14256/14956 tok/s;    935 sec\n",
            "[2020-06-02 03:17:50,971 INFO] Step 20450/50000; acc:  81.21; ppl:  1.99; xent: 0.69; lr: 1.00000; 14224/14950 tok/s;    937 sec\n",
            "[2020-06-02 03:17:50,973 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:17:51,277 INFO] number of examples: 26141\n",
            "[2020-06-02 03:17:53,882 INFO] Step 20500/50000; acc:  78.06; ppl:  2.25; xent: 0.81; lr: 1.00000; 12274/12669 tok/s;    940 sec\n",
            "[2020-06-02 03:17:56,143 INFO] Step 20550/50000; acc:  79.46; ppl:  2.12; xent: 0.75; lr: 1.00000; 14947/15014 tok/s;    942 sec\n",
            "[2020-06-02 03:17:58,302 INFO] Step 20600/50000; acc:  81.01; ppl:  1.97; xent: 0.68; lr: 1.00000; 14693/14938 tok/s;    945 sec\n",
            "[2020-06-02 03:18:00,704 INFO] Step 20650/50000; acc:  80.67; ppl:  2.03; xent: 0.71; lr: 1.00000; 14896/15170 tok/s;    947 sec\n",
            "[2020-06-02 03:18:02,694 INFO] Step 20700/50000; acc:  83.48; ppl:  1.79; xent: 0.58; lr: 1.00000; 14205/14431 tok/s;    949 sec\n",
            "[2020-06-02 03:18:04,988 INFO] Step 20750/50000; acc:  80.44; ppl:  2.03; xent: 0.71; lr: 1.00000; 14718/14662 tok/s;    951 sec\n",
            "[2020-06-02 03:18:07,260 INFO] Step 20800/50000; acc:  80.04; ppl:  2.09; xent: 0.74; lr: 1.00000; 14185/14826 tok/s;    954 sec\n",
            "[2020-06-02 03:18:09,390 INFO] Step 20850/50000; acc:  81.79; ppl:  1.94; xent: 0.66; lr: 1.00000; 14090/14775 tok/s;    956 sec\n",
            "[2020-06-02 03:18:09,730 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:18:10,016 INFO] number of examples: 26141\n",
            "[2020-06-02 03:18:12,184 INFO] Step 20900/50000; acc:  79.77; ppl:  2.09; xent: 0.74; lr: 1.00000; 12077/12489 tok/s;    959 sec\n",
            "[2020-06-02 03:18:14,497 INFO] Step 20950/50000; acc:  79.49; ppl:  2.15; xent: 0.77; lr: 1.00000; 14999/15130 tok/s;    961 sec\n",
            "[2020-06-02 03:18:16,695 INFO] Step 21000/50000; acc:  80.93; ppl:  1.97; xent: 0.68; lr: 1.00000; 14838/15130 tok/s;    963 sec\n",
            "[2020-06-02 03:18:18,984 INFO] Step 21050/50000; acc:  81.08; ppl:  1.98; xent: 0.68; lr: 1.00000; 14876/15170 tok/s;    965 sec\n",
            "[2020-06-02 03:18:21,018 INFO] Step 21100/50000; acc:  83.51; ppl:  1.77; xent: 0.57; lr: 1.00000; 14604/14927 tok/s;    967 sec\n",
            "[2020-06-02 03:18:23,282 INFO] Step 21150/50000; acc:  80.64; ppl:  2.01; xent: 0.70; lr: 1.00000; 14534/14664 tok/s;    970 sec\n",
            "[2020-06-02 03:18:25,581 INFO] Step 21200/50000; acc:  80.02; ppl:  2.08; xent: 0.73; lr: 1.00000; 14572/14880 tok/s;    972 sec\n",
            "[2020-06-02 03:18:27,624 INFO] Step 21250/50000; acc:  83.30; ppl:  1.81; xent: 0.59; lr: 1.00000; 14421/14895 tok/s;    974 sec\n",
            "[2020-06-02 03:18:28,375 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:18:28,682 INFO] number of examples: 26141\n",
            "[2020-06-02 03:18:30,369 INFO] Step 21300/50000; acc:  79.18; ppl:  2.15; xent: 0.76; lr: 1.00000; 11407/12244 tok/s;    977 sec\n",
            "[2020-06-02 03:18:32,745 INFO] Step 21350/50000; acc:  80.81; ppl:  2.02; xent: 0.70; lr: 1.00000; 15158/15036 tok/s;    979 sec\n",
            "[2020-06-02 03:18:35,056 INFO] Step 21400/50000; acc:  80.50; ppl:  2.02; xent: 0.71; lr: 1.00000; 14691/14781 tok/s;    981 sec\n",
            "[2020-06-02 03:18:37,247 INFO] Step 21450/50000; acc:  82.78; ppl:  1.83; xent: 0.60; lr: 1.00000; 14893/15307 tok/s;    984 sec\n",
            "[2020-06-02 03:18:39,487 INFO] Step 21500/50000; acc:  81.87; ppl:  1.93; xent: 0.66; lr: 1.00000; 14524/15041 tok/s;    986 sec\n",
            "[2020-06-02 03:18:41,603 INFO] Step 21550/50000; acc:  81.69; ppl:  1.91; xent: 0.65; lr: 1.00000; 14670/14406 tok/s;    988 sec\n",
            "[2020-06-02 03:18:43,760 INFO] Step 21600/50000; acc:  80.94; ppl:  2.00; xent: 0.69; lr: 1.00000; 14584/14829 tok/s;    990 sec\n",
            "[2020-06-02 03:18:46,057 INFO] Step 21650/50000; acc:  82.00; ppl:  1.91; xent: 0.65; lr: 1.00000; 14414/15054 tok/s;    992 sec\n",
            "[2020-06-02 03:18:47,100 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:18:47,420 INFO] number of examples: 26141\n",
            "[2020-06-02 03:18:48,648 INFO] Step 21700/50000; acc:  81.60; ppl:  1.93; xent: 0.66; lr: 1.00000; 11202/12044 tok/s;    995 sec\n",
            "[2020-06-02 03:18:50,944 INFO] Step 21750/50000; acc:  81.69; ppl:  1.94; xent: 0.66; lr: 1.00000; 14903/15027 tok/s;    997 sec\n",
            "[2020-06-02 03:18:53,335 INFO] Step 21800/50000; acc:  79.73; ppl:  2.12; xent: 0.75; lr: 1.00000; 14947/14810 tok/s;   1000 sec\n",
            "[2020-06-02 03:18:55,580 INFO] Step 21850/50000; acc:  82.16; ppl:  1.87; xent: 0.63; lr: 1.00000; 14677/15345 tok/s;   1002 sec\n",
            "[2020-06-02 03:18:57,858 INFO] Step 21900/50000; acc:  82.79; ppl:  1.84; xent: 0.61; lr: 1.00000; 14420/15097 tok/s;   1004 sec\n",
            "[2020-06-02 03:18:59,947 INFO] Step 21950/50000; acc:  82.17; ppl:  1.92; xent: 0.65; lr: 1.00000; 14831/14170 tok/s;   1006 sec\n",
            "[2020-06-02 03:19:01,987 INFO] Step 22000/50000; acc:  83.35; ppl:  1.79; xent: 0.58; lr: 1.00000; 14694/15101 tok/s;   1008 sec\n",
            "[2020-06-02 03:19:04,357 INFO] Step 22050/50000; acc:  81.03; ppl:  2.00; xent: 0.69; lr: 1.00000; 14247/14859 tok/s;   1011 sec\n",
            "[2020-06-02 03:19:05,823 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:19:06,136 INFO] number of examples: 26141\n",
            "[2020-06-02 03:19:06,901 INFO] Step 22100/50000; acc:  81.91; ppl:  1.91; xent: 0.65; lr: 1.00000; 11902/12646 tok/s;   1013 sec\n",
            "[2020-06-02 03:19:09,268 INFO] Step 22150/50000; acc:  81.12; ppl:  1.99; xent: 0.69; lr: 1.00000; 13926/14414 tok/s;   1016 sec\n",
            "[2020-06-02 03:19:11,684 INFO] Step 22200/50000; acc:  80.32; ppl:  2.07; xent: 0.73; lr: 1.00000; 15173/14807 tok/s;   1018 sec\n",
            "[2020-06-02 03:19:13,860 INFO] Step 22250/50000; acc:  82.69; ppl:  1.84; xent: 0.61; lr: 1.00000; 14784/15527 tok/s;   1020 sec\n",
            "[2020-06-02 03:19:16,241 INFO] Step 22300/50000; acc:  83.11; ppl:  1.83; xent: 0.60; lr: 1.00000; 14383/14806 tok/s;   1023 sec\n",
            "[2020-06-02 03:19:18,221 INFO] Step 22350/50000; acc:  83.09; ppl:  1.82; xent: 0.60; lr: 1.00000; 14872/14210 tok/s;   1025 sec\n",
            "[2020-06-02 03:19:20,317 INFO] Step 22400/50000; acc:  83.63; ppl:  1.78; xent: 0.58; lr: 1.00000; 14840/15129 tok/s;   1027 sec\n",
            "[2020-06-02 03:19:22,737 INFO] Step 22450/50000; acc:  80.34; ppl:  2.06; xent: 0.72; lr: 1.00000; 14169/14825 tok/s;   1029 sec\n",
            "[2020-06-02 03:19:24,541 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:19:24,855 INFO] number of examples: 26141\n",
            "[2020-06-02 03:19:25,196 INFO] Step 22500/50000; acc:  83.84; ppl:  1.76; xent: 0.57; lr: 1.00000; 11738/12438 tok/s;   1032 sec\n",
            "[2020-06-02 03:19:27,667 INFO] Step 22550/50000; acc:  79.99; ppl:  2.06; xent: 0.72; lr: 1.00000; 14243/14693 tok/s;   1034 sec\n",
            "[2020-06-02 03:19:30,056 INFO] Step 22600/50000; acc:  80.79; ppl:  2.00; xent: 0.69; lr: 1.00000; 15029/14893 tok/s;   1036 sec\n",
            "[2020-06-02 03:19:32,197 INFO] Step 22650/50000; acc:  83.04; ppl:  1.82; xent: 0.60; lr: 1.00000; 14637/15215 tok/s;   1039 sec\n",
            "[2020-06-02 03:19:34,557 INFO] Step 22700/50000; acc:  83.04; ppl:  1.83; xent: 0.60; lr: 1.00000; 14397/14769 tok/s;   1041 sec\n",
            "[2020-06-02 03:19:36,480 INFO] Step 22750/50000; acc:  84.68; ppl:  1.69; xent: 0.52; lr: 1.00000; 14842/14688 tok/s;   1043 sec\n",
            "[2020-06-02 03:19:38,792 INFO] Step 22800/50000; acc:  81.77; ppl:  1.90; xent: 0.64; lr: 1.00000; 14763/14792 tok/s;   1045 sec\n",
            "[2020-06-02 03:19:41,048 INFO] Step 22850/50000; acc:  81.74; ppl:  1.95; xent: 0.67; lr: 1.00000; 14173/14906 tok/s;   1047 sec\n",
            "[2020-06-02 03:19:43,147 INFO] Step 22900/50000; acc:  82.97; ppl:  1.83; xent: 0.61; lr: 1.00000; 14203/14896 tok/s;   1049 sec\n",
            "[2020-06-02 03:19:43,295 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:19:43,530 INFO] number of examples: 26141\n",
            "[2020-06-02 03:19:45,992 INFO] Step 22950/50000; acc:  80.26; ppl:  2.04; xent: 0.71; lr: 1.00000; 12561/12865 tok/s;   1052 sec\n",
            "[2020-06-02 03:19:48,225 INFO] Step 23000/50000; acc:  81.71; ppl:  1.94; xent: 0.66; lr: 1.00000; 14675/14926 tok/s;   1055 sec\n",
            "[2020-06-02 03:19:50,466 INFO] Step 23050/50000; acc:  82.15; ppl:  1.88; xent: 0.63; lr: 1.00000; 14726/14949 tok/s;   1057 sec\n",
            "[2020-06-02 03:19:52,784 INFO] Step 23100/50000; acc:  83.18; ppl:  1.80; xent: 0.59; lr: 1.00000; 14746/15015 tok/s;   1059 sec\n",
            "[2020-06-02 03:19:54,800 INFO] Step 23150/50000; acc:  84.89; ppl:  1.70; xent: 0.53; lr: 1.00000; 14275/14669 tok/s;   1061 sec\n",
            "[2020-06-02 03:19:57,054 INFO] Step 23200/50000; acc:  82.57; ppl:  1.85; xent: 0.61; lr: 1.00000; 14864/14847 tok/s;   1063 sec\n",
            "[2020-06-02 03:19:59,307 INFO] Step 23250/50000; acc:  81.77; ppl:  1.94; xent: 0.66; lr: 1.00000; 14501/15021 tok/s;   1066 sec\n",
            "[2020-06-02 03:20:01,346 INFO] Step 23300/50000; acc:  84.63; ppl:  1.72; xent: 0.54; lr: 1.00000; 14328/14930 tok/s;   1068 sec\n",
            "[2020-06-02 03:20:01,943 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:20:02,228 INFO] number of examples: 26141\n",
            "[2020-06-02 03:20:04,194 INFO] Step 23350/50000; acc:  80.94; ppl:  1.97; xent: 0.68; lr: 1.00000; 11916/12508 tok/s;   1071 sec\n",
            "[2020-06-02 03:20:06,605 INFO] Step 23400/50000; acc:  81.42; ppl:  1.97; xent: 0.68; lr: 1.00000; 15119/14854 tok/s;   1073 sec\n",
            "[2020-06-02 03:20:08,758 INFO] Step 23450/50000; acc:  83.15; ppl:  1.80; xent: 0.59; lr: 1.00000; 14493/15027 tok/s;   1075 sec\n",
            "[2020-06-02 03:20:11,033 INFO] Step 23500/50000; acc:  83.73; ppl:  1.77; xent: 0.57; lr: 1.00000; 14798/15051 tok/s;   1077 sec\n",
            "[2020-06-02 03:20:13,179 INFO] Step 23550/50000; acc:  84.28; ppl:  1.72; xent: 0.55; lr: 1.00000; 14705/15047 tok/s;   1080 sec\n",
            "[2020-06-02 03:20:15,410 INFO] Step 23600/50000; acc:  82.51; ppl:  1.86; xent: 0.62; lr: 1.00000; 14518/14577 tok/s;   1082 sec\n",
            "[2020-06-02 03:20:17,622 INFO] Step 23650/50000; acc:  82.54; ppl:  1.89; xent: 0.63; lr: 1.00000; 14627/14869 tok/s;   1084 sec\n",
            "[2020-06-02 03:20:19,788 INFO] Step 23700/50000; acc:  84.40; ppl:  1.74; xent: 0.55; lr: 1.00000; 14315/14905 tok/s;   1086 sec\n",
            "[2020-06-02 03:20:20,656 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:20:20,939 INFO] number of examples: 26141\n",
            "[2020-06-02 03:20:22,443 INFO] Step 23750/50000; acc:  81.29; ppl:  1.95; xent: 0.67; lr: 1.00000; 11434/12255 tok/s;   1089 sec\n",
            "[2020-06-02 03:20:24,711 INFO] Step 23800/50000; acc:  84.03; ppl:  1.74; xent: 0.55; lr: 1.00000; 15203/15244 tok/s;   1091 sec\n",
            "[2020-06-02 03:20:27,127 INFO] Step 23850/50000; acc:  81.22; ppl:  1.96; xent: 0.67; lr: 1.00000; 14922/14762 tok/s;   1093 sec\n",
            "[2020-06-02 03:20:29,320 INFO] Step 23900/50000; acc:  84.34; ppl:  1.70; xent: 0.53; lr: 1.00000; 14795/15474 tok/s;   1096 sec\n",
            "[2020-06-02 03:20:31,574 INFO] Step 23950/50000; acc:  83.75; ppl:  1.78; xent: 0.57; lr: 1.00000; 14374/15007 tok/s;   1098 sec\n",
            "[2020-06-02 03:20:33,646 INFO] Step 24000/50000; acc:  83.83; ppl:  1.77; xent: 0.57; lr: 1.00000; 14984/14374 tok/s;   1100 sec\n",
            "[2020-06-02 03:20:35,812 INFO] Step 24050/50000; acc:  83.02; ppl:  1.85; xent: 0.62; lr: 1.00000; 14608/14848 tok/s;   1102 sec\n",
            "[2020-06-02 03:20:38,064 INFO] Step 24100/50000; acc:  83.94; ppl:  1.77; xent: 0.57; lr: 1.00000; 14196/15155 tok/s;   1104 sec\n",
            "[2020-06-02 03:20:39,299 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:20:39,587 INFO] number of examples: 26141\n",
            "[2020-06-02 03:20:40,636 INFO] Step 24150/50000; acc:  83.54; ppl:  1.78; xent: 0.58; lr: 1.00000; 11652/12236 tok/s;   1107 sec\n",
            "[2020-06-02 03:20:42,962 INFO] Step 24200/50000; acc:  83.25; ppl:  1.83; xent: 0.60; lr: 1.00000; 14553/15069 tok/s;   1109 sec\n",
            "[2020-06-02 03:20:45,315 INFO] Step 24250/50000; acc:  81.62; ppl:  1.93; xent: 0.66; lr: 1.00000; 15200/14719 tok/s;   1112 sec\n",
            "[2020-06-02 03:20:47,576 INFO] Step 24300/50000; acc:  84.47; ppl:  1.72; xent: 0.54; lr: 1.00000; 14536/15452 tok/s;   1114 sec\n",
            "[2020-06-02 03:20:49,914 INFO] Step 24350/50000; acc:  84.28; ppl:  1.74; xent: 0.55; lr: 1.00000; 14402/14876 tok/s;   1116 sec\n",
            "[2020-06-02 03:20:51,884 INFO] Step 24400/50000; acc:  84.55; ppl:  1.71; xent: 0.53; lr: 1.00000; 14912/14157 tok/s;   1118 sec\n",
            "[2020-06-02 03:20:53,943 INFO] Step 24450/50000; acc:  85.05; ppl:  1.68; xent: 0.52; lr: 1.00000; 14891/15357 tok/s;   1120 sec\n",
            "[2020-06-02 03:20:56,337 INFO] Step 24500/50000; acc:  82.06; ppl:  1.92; xent: 0.65; lr: 1.00000; 14301/14818 tok/s;   1123 sec\n",
            "[2020-06-02 03:20:57,967 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:20:58,258 INFO] number of examples: 26141\n",
            "[2020-06-02 03:20:58,810 INFO] Step 24550/50000; acc:  84.22; ppl:  1.74; xent: 0.56; lr: 1.00000; 12035/12707 tok/s;   1125 sec\n",
            "[2020-06-02 03:21:01,267 INFO] Step 24600/50000; acc:  82.35; ppl:  1.87; xent: 0.63; lr: 1.00000; 14141/14653 tok/s;   1128 sec\n",
            "[2020-06-02 03:21:03,647 INFO] Step 24650/50000; acc:  81.72; ppl:  1.91; xent: 0.65; lr: 1.00000; 15164/14966 tok/s;   1130 sec\n",
            "[2020-06-02 03:21:05,763 INFO] Step 24700/50000; acc:  85.03; ppl:  1.69; xent: 0.52; lr: 1.00000; 14658/15299 tok/s;   1132 sec\n",
            "[2020-06-02 03:21:08,144 INFO] Step 24750/50000; acc:  84.69; ppl:  1.71; xent: 0.53; lr: 1.00000; 14385/14875 tok/s;   1134 sec\n",
            "[2020-06-02 03:21:10,074 INFO] Step 24800/50000; acc:  86.11; ppl:  1.62; xent: 0.48; lr: 1.00000; 15036/14397 tok/s;   1136 sec\n",
            "[2020-06-02 03:21:12,287 INFO] Step 24850/50000; acc:  84.02; ppl:  1.76; xent: 0.56; lr: 1.00000; 14621/14863 tok/s;   1139 sec\n",
            "[2020-06-02 03:21:14,536 INFO] Step 24900/50000; acc:  83.25; ppl:  1.82; xent: 0.60; lr: 1.00000; 14159/14944 tok/s;   1141 sec\n",
            "[2020-06-02 03:21:16,656 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:21:16,945 INFO] number of examples: 26141\n",
            "[2020-06-02 03:21:17,108 INFO] Step 24950/50000; acc:  83.93; ppl:  1.77; xent: 0.57; lr: 1.00000; 12191/12821 tok/s;   1143 sec\n",
            "[2020-06-02 03:21:19,608 INFO] Step 25000/50000; acc:  82.24; ppl:  1.88; xent: 0.63; lr: 1.00000; 14190/14553 tok/s;   1146 sec\n",
            "[2020-06-02 03:21:19,630 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_25000.pt\n",
            "[2020-06-02 03:21:22,189 INFO] Step 25050/50000; acc:  82.80; ppl:  1.84; xent: 0.61; lr: 1.00000; 13319/13350 tok/s;   1149 sec\n",
            "[2020-06-02 03:21:24,342 INFO] Step 25100/50000; acc:  84.17; ppl:  1.72; xent: 0.54; lr: 1.00000; 14525/14965 tok/s;   1151 sec\n",
            "[2020-06-02 03:21:26,743 INFO] Step 25150/50000; acc:  84.69; ppl:  1.70; xent: 0.53; lr: 1.00000; 14709/14969 tok/s;   1153 sec\n",
            "[2020-06-02 03:21:28,703 INFO] Step 25200/50000; acc:  86.52; ppl:  1.58; xent: 0.46; lr: 1.00000; 14361/14525 tok/s;   1155 sec\n",
            "[2020-06-02 03:21:31,089 INFO] Step 25250/50000; acc:  83.92; ppl:  1.76; xent: 0.56; lr: 1.00000; 14071/14045 tok/s;   1157 sec\n",
            "[2020-06-02 03:21:33,357 INFO] Step 25300/50000; acc:  83.64; ppl:  1.80; xent: 0.59; lr: 1.00000; 14373/14937 tok/s;   1160 sec\n",
            "[2020-06-02 03:21:35,467 INFO] Step 25350/50000; acc:  84.82; ppl:  1.70; xent: 0.53; lr: 1.00000; 14130/14907 tok/s;   1162 sec\n",
            "[2020-06-02 03:21:35,776 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:21:36,082 INFO] number of examples: 26141\n",
            "[2020-06-02 03:21:38,303 INFO] Step 25400/50000; acc:  83.36; ppl:  1.80; xent: 0.59; lr: 1.00000; 12104/12405 tok/s;   1165 sec\n",
            "[2020-06-02 03:21:40,647 INFO] Step 25450/50000; acc:  83.03; ppl:  1.83; xent: 0.61; lr: 1.00000; 14827/15056 tok/s;   1167 sec\n",
            "[2020-06-02 03:21:42,821 INFO] Step 25500/50000; acc:  84.84; ppl:  1.70; xent: 0.53; lr: 1.00000; 14710/14975 tok/s;   1169 sec\n",
            "[2020-06-02 03:21:45,133 INFO] Step 25550/50000; acc:  84.61; ppl:  1.72; xent: 0.54; lr: 1.00000; 14808/15058 tok/s;   1171 sec\n",
            "[2020-06-02 03:21:47,147 INFO] Step 25600/50000; acc:  86.49; ppl:  1.56; xent: 0.45; lr: 1.00000; 14528/14933 tok/s;   1173 sec\n",
            "[2020-06-02 03:21:49,427 INFO] Step 25650/50000; acc:  84.31; ppl:  1.74; xent: 0.55; lr: 1.00000; 14655/14756 tok/s;   1176 sec\n",
            "[2020-06-02 03:21:51,713 INFO] Step 25700/50000; acc:  83.23; ppl:  1.80; xent: 0.59; lr: 1.00000; 14542/14849 tok/s;   1178 sec\n",
            "[2020-06-02 03:21:53,766 INFO] Step 25750/50000; acc:  86.37; ppl:  1.60; xent: 0.47; lr: 1.00000; 14291/14818 tok/s;   1180 sec\n",
            "[2020-06-02 03:21:54,495 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:21:54,800 INFO] number of examples: 26141\n",
            "[2020-06-02 03:21:56,551 INFO] Step 25800/50000; acc:  82.48; ppl:  1.85; xent: 0.61; lr: 1.00000; 11609/12339 tok/s;   1183 sec\n",
            "[2020-06-02 03:21:58,970 INFO] Step 25850/50000; acc:  83.56; ppl:  1.80; xent: 0.59; lr: 1.00000; 15090/14965 tok/s;   1185 sec\n",
            "[2020-06-02 03:22:01,233 INFO] Step 25900/50000; acc:  85.04; ppl:  1.67; xent: 0.51; lr: 1.00000; 14621/14818 tok/s;   1188 sec\n",
            "[2020-06-02 03:22:03,415 INFO] Step 25950/50000; acc:  86.65; ppl:  1.58; xent: 0.45; lr: 1.00000; 14811/15227 tok/s;   1190 sec\n",
            "[2020-06-02 03:22:05,687 INFO] Step 26000/50000; acc:  85.12; ppl:  1.68; xent: 0.52; lr: 1.00000; 14399/14772 tok/s;   1192 sec\n",
            "[2020-06-02 03:22:07,816 INFO] Step 26050/50000; acc:  85.05; ppl:  1.67; xent: 0.51; lr: 1.00000; 14458/14312 tok/s;   1194 sec\n",
            "[2020-06-02 03:22:10,006 INFO] Step 26100/50000; acc:  83.91; ppl:  1.78; xent: 0.57; lr: 1.00000; 14596/14789 tok/s;   1196 sec\n",
            "[2020-06-02 03:22:12,301 INFO] Step 26150/50000; acc:  84.91; ppl:  1.69; xent: 0.52; lr: 1.00000; 14292/14951 tok/s;   1199 sec\n",
            "[2020-06-02 03:22:13,295 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:22:13,615 INFO] number of examples: 26141\n",
            "[2020-06-02 03:22:14,876 INFO] Step 26200/50000; acc:  84.48; ppl:  1.70; xent: 0.53; lr: 1.00000; 11168/12065 tok/s;   1201 sec\n",
            "[2020-06-02 03:22:17,194 INFO] Step 26250/50000; acc:  84.50; ppl:  1.71; xent: 0.54; lr: 1.00000; 15042/15110 tok/s;   1204 sec\n",
            "[2020-06-02 03:22:19,564 INFO] Step 26300/50000; acc:  83.18; ppl:  1.81; xent: 0.59; lr: 1.00000; 14944/14806 tok/s;   1206 sec\n",
            "[2020-06-02 03:22:21,815 INFO] Step 26350/50000; acc:  85.39; ppl:  1.65; xent: 0.50; lr: 1.00000; 14784/15481 tok/s;   1208 sec\n",
            "[2020-06-02 03:22:24,087 INFO] Step 26400/50000; acc:  85.84; ppl:  1.63; xent: 0.49; lr: 1.00000; 14315/14907 tok/s;   1210 sec\n",
            "[2020-06-02 03:22:26,146 INFO] Step 26450/50000; acc:  84.75; ppl:  1.70; xent: 0.53; lr: 1.00000; 14730/14183 tok/s;   1212 sec\n",
            "[2020-06-02 03:22:28,213 INFO] Step 26500/50000; acc:  86.45; ppl:  1.59; xent: 0.47; lr: 1.00000; 14792/15194 tok/s;   1215 sec\n",
            "[2020-06-02 03:22:30,588 INFO] Step 26550/50000; acc:  84.01; ppl:  1.76; xent: 0.56; lr: 1.00000; 14184/14849 tok/s;   1217 sec\n",
            "[2020-06-02 03:22:32,013 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:22:32,335 INFO] number of examples: 26141\n",
            "[2020-06-02 03:22:33,126 INFO] Step 26600/50000; acc:  84.51; ppl:  1.71; xent: 0.54; lr: 1.00000; 11729/12425 tok/s;   1219 sec\n",
            "[2020-06-02 03:22:35,520 INFO] Step 26650/50000; acc:  84.01; ppl:  1.74; xent: 0.56; lr: 1.00000; 14061/14490 tok/s;   1222 sec\n",
            "[2020-06-02 03:22:37,895 INFO] Step 26700/50000; acc:  83.30; ppl:  1.81; xent: 0.60; lr: 1.00000; 15327/14955 tok/s;   1224 sec\n",
            "[2020-06-02 03:22:40,084 INFO] Step 26750/50000; acc:  85.85; ppl:  1.62; xent: 0.48; lr: 1.00000; 14524/15341 tok/s;   1226 sec\n",
            "[2020-06-02 03:22:42,473 INFO] Step 26800/50000; acc:  85.47; ppl:  1.66; xent: 0.50; lr: 1.00000; 14386/14762 tok/s;   1229 sec\n",
            "[2020-06-02 03:22:44,490 INFO] Step 26850/50000; acc:  85.50; ppl:  1.66; xent: 0.51; lr: 1.00000; 15009/14400 tok/s;   1231 sec\n",
            "[2020-06-02 03:22:46,550 INFO] Step 26900/50000; acc:  86.45; ppl:  1.58; xent: 0.46; lr: 1.00000; 14825/15142 tok/s;   1233 sec\n",
            "[2020-06-02 03:22:49,001 INFO] Step 26950/50000; acc:  83.24; ppl:  1.83; xent: 0.60; lr: 1.00000; 14014/14636 tok/s;   1235 sec\n",
            "[2020-06-02 03:22:50,770 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:22:50,994 INFO] number of examples: 26141\n",
            "[2020-06-02 03:22:51,368 INFO] Step 27000/50000; acc:  86.77; ppl:  1.58; xent: 0.45; lr: 1.00000; 12062/12789 tok/s;   1238 sec\n",
            "[2020-06-02 03:22:53,864 INFO] Step 27050/50000; acc:  83.51; ppl:  1.79; xent: 0.58; lr: 1.00000; 14331/14777 tok/s;   1240 sec\n",
            "[2020-06-02 03:22:56,242 INFO] Step 27100/50000; acc:  83.70; ppl:  1.78; xent: 0.57; lr: 1.00000; 14906/14716 tok/s;   1243 sec\n",
            "[2020-06-02 03:22:58,366 INFO] Step 27150/50000; acc:  85.93; ppl:  1.62; xent: 0.48; lr: 1.00000; 14604/15247 tok/s;   1245 sec\n",
            "[2020-06-02 03:23:00,750 INFO] Step 27200/50000; acc:  85.82; ppl:  1.63; xent: 0.49; lr: 1.00000; 14470/14913 tok/s;   1247 sec\n",
            "[2020-06-02 03:23:02,654 INFO] Step 27250/50000; acc:  88.01; ppl:  1.50; xent: 0.41; lr: 1.00000; 14981/14664 tok/s;   1249 sec\n",
            "[2020-06-02 03:23:04,934 INFO] Step 27300/50000; acc:  84.85; ppl:  1.68; xent: 0.52; lr: 1.00000; 14755/14840 tok/s;   1251 sec\n",
            "[2020-06-02 03:23:07,207 INFO] Step 27350/50000; acc:  85.07; ppl:  1.71; xent: 0.54; lr: 1.00000; 14063/14791 tok/s;   1254 sec\n",
            "[2020-06-02 03:23:09,339 INFO] Step 27400/50000; acc:  86.03; ppl:  1.61; xent: 0.48; lr: 1.00000; 14106/14789 tok/s;   1256 sec\n",
            "[2020-06-02 03:23:09,457 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:23:09,753 INFO] number of examples: 26141\n",
            "[2020-06-02 03:23:12,276 INFO] Step 27450/50000; acc:  83.68; ppl:  1.77; xent: 0.57; lr: 1.00000; 12186/12524 tok/s;   1259 sec\n",
            "[2020-06-02 03:23:14,532 INFO] Step 27500/50000; acc:  84.49; ppl:  1.72; xent: 0.54; lr: 1.00000; 14726/14974 tok/s;   1261 sec\n",
            "[2020-06-02 03:23:16,725 INFO] Step 27550/50000; acc:  85.65; ppl:  1.63; xent: 0.49; lr: 1.00000; 14934/15045 tok/s;   1263 sec\n",
            "[2020-06-02 03:23:19,060 INFO] Step 27600/50000; acc:  85.93; ppl:  1.63; xent: 0.49; lr: 1.00000; 14881/15147 tok/s;   1265 sec\n",
            "[2020-06-02 03:23:21,065 INFO] Step 27650/50000; acc:  87.15; ppl:  1.54; xent: 0.43; lr: 1.00000; 14164/14623 tok/s;   1267 sec\n",
            "[2020-06-02 03:23:23,324 INFO] Step 27700/50000; acc:  85.29; ppl:  1.67; xent: 0.51; lr: 1.00000; 14891/14874 tok/s;   1270 sec\n",
            "[2020-06-02 03:23:25,557 INFO] Step 27750/50000; acc:  84.84; ppl:  1.72; xent: 0.54; lr: 1.00000; 14433/14958 tok/s;   1272 sec\n",
            "[2020-06-02 03:23:27,620 INFO] Step 27800/50000; acc:  86.38; ppl:  1.59; xent: 0.46; lr: 1.00000; 14370/15004 tok/s;   1274 sec\n",
            "[2020-06-02 03:23:28,144 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:23:28,433 INFO] number of examples: 26141\n",
            "[2020-06-02 03:23:30,471 INFO] Step 27850/50000; acc:  84.07; ppl:  1.75; xent: 0.56; lr: 1.00000; 11942/12463 tok/s;   1277 sec\n",
            "[2020-06-02 03:23:32,856 INFO] Step 27900/50000; acc:  84.68; ppl:  1.71; xent: 0.54; lr: 1.00000; 15185/15000 tok/s;   1279 sec\n",
            "[2020-06-02 03:23:34,993 INFO] Step 27950/50000; acc:  86.25; ppl:  1.61; xent: 0.47; lr: 1.00000; 14397/14958 tok/s;   1281 sec\n",
            "[2020-06-02 03:23:37,263 INFO] Step 28000/50000; acc:  86.36; ppl:  1.61; xent: 0.48; lr: 1.00000; 14942/15139 tok/s;   1284 sec\n",
            "[2020-06-02 03:23:39,415 INFO] Step 28050/50000; acc:  86.98; ppl:  1.56; xent: 0.45; lr: 1.00000; 14698/15013 tok/s;   1286 sec\n",
            "[2020-06-02 03:23:41,622 INFO] Step 28100/50000; acc:  85.17; ppl:  1.67; xent: 0.51; lr: 1.00000; 14468/14582 tok/s;   1288 sec\n",
            "[2020-06-02 03:23:43,859 INFO] Step 28150/50000; acc:  85.55; ppl:  1.68; xent: 0.52; lr: 1.00000; 14636/14847 tok/s;   1290 sec\n",
            "[2020-06-02 03:23:46,015 INFO] Step 28200/50000; acc:  87.17; ppl:  1.56; xent: 0.45; lr: 1.00000; 14405/14908 tok/s;   1292 sec\n",
            "[2020-06-02 03:23:46,851 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:23:47,150 INFO] number of examples: 26141\n",
            "[2020-06-02 03:23:48,733 INFO] Step 28250/50000; acc:  84.01; ppl:  1.74; xent: 0.55; lr: 1.00000; 11312/12158 tok/s;   1295 sec\n",
            "[2020-06-02 03:23:51,023 INFO] Step 28300/50000; acc:  86.71; ppl:  1.57; xent: 0.45; lr: 1.00000; 15169/15154 tok/s;   1297 sec\n",
            "[2020-06-02 03:23:53,440 INFO] Step 28350/50000; acc:  84.31; ppl:  1.74; xent: 0.55; lr: 1.00000; 14656/14664 tok/s;   1300 sec\n",
            "[2020-06-02 03:23:55,650 INFO] Step 28400/50000; acc:  87.70; ppl:  1.52; xent: 0.42; lr: 1.00000; 14674/15157 tok/s;   1302 sec\n",
            "[2020-06-02 03:23:57,905 INFO] Step 28450/50000; acc:  86.39; ppl:  1.60; xent: 0.47; lr: 1.00000; 14310/15012 tok/s;   1304 sec\n",
            "[2020-06-02 03:23:59,987 INFO] Step 28500/50000; acc:  86.38; ppl:  1.59; xent: 0.46; lr: 1.00000; 14853/14365 tok/s;   1306 sec\n",
            "[2020-06-02 03:24:02,172 INFO] Step 28550/50000; acc:  85.84; ppl:  1.64; xent: 0.50; lr: 1.00000; 14631/14796 tok/s;   1308 sec\n",
            "[2020-06-02 03:24:04,423 INFO] Step 28600/50000; acc:  86.26; ppl:  1.61; xent: 0.48; lr: 1.00000; 14366/15230 tok/s;   1311 sec\n",
            "[2020-06-02 03:24:05,586 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:24:05,882 INFO] number of examples: 26141\n",
            "[2020-06-02 03:24:06,971 INFO] Step 28650/50000; acc:  85.79; ppl:  1.62; xent: 0.48; lr: 1.00000; 11664/12268 tok/s;   1313 sec\n",
            "[2020-06-02 03:24:09,245 INFO] Step 28700/50000; acc:  86.18; ppl:  1.61; xent: 0.48; lr: 1.00000; 14542/15137 tok/s;   1316 sec\n",
            "[2020-06-02 03:24:11,646 INFO] Step 28750/50000; acc:  84.62; ppl:  1.72; xent: 0.54; lr: 1.00000; 15263/14742 tok/s;   1318 sec\n",
            "[2020-06-02 03:24:13,883 INFO] Step 28800/50000; acc:  87.17; ppl:  1.54; xent: 0.43; lr: 1.00000; 14619/15499 tok/s;   1320 sec\n",
            "[2020-06-02 03:24:16,219 INFO] Step 28850/50000; acc:  86.53; ppl:  1.58; xent: 0.46; lr: 1.00000; 14224/14794 tok/s;   1323 sec\n",
            "[2020-06-02 03:24:18,211 INFO] Step 28900/50000; acc:  87.38; ppl:  1.56; xent: 0.44; lr: 1.00000; 14875/14096 tok/s;   1325 sec\n",
            "[2020-06-02 03:24:20,273 INFO] Step 28950/50000; acc:  87.47; ppl:  1.52; xent: 0.42; lr: 1.00000; 14838/15335 tok/s;   1327 sec\n",
            "[2020-06-02 03:24:22,664 INFO] Step 29000/50000; acc:  84.77; ppl:  1.71; xent: 0.54; lr: 1.00000; 14343/14807 tok/s;   1329 sec\n",
            "[2020-06-02 03:24:24,264 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:24:24,561 INFO] number of examples: 26141\n",
            "[2020-06-02 03:24:25,152 INFO] Step 29050/50000; acc:  86.63; ppl:  1.57; xent: 0.45; lr: 1.00000; 11831/12600 tok/s;   1331 sec\n",
            "[2020-06-02 03:24:27,581 INFO] Step 29100/50000; acc:  85.22; ppl:  1.66; xent: 0.51; lr: 1.00000; 14252/14761 tok/s;   1334 sec\n",
            "[2020-06-02 03:24:29,994 INFO] Step 29150/50000; acc:  84.96; ppl:  1.69; xent: 0.53; lr: 1.00000; 15144/14881 tok/s;   1336 sec\n",
            "[2020-06-02 03:24:32,128 INFO] Step 29200/50000; acc:  87.11; ppl:  1.54; xent: 0.43; lr: 1.00000; 14689/15373 tok/s;   1338 sec\n",
            "[2020-06-02 03:24:34,497 INFO] Step 29250/50000; acc:  87.10; ppl:  1.56; xent: 0.45; lr: 1.00000; 14349/14798 tok/s;   1341 sec\n",
            "[2020-06-02 03:24:36,407 INFO] Step 29300/50000; acc:  88.15; ppl:  1.50; xent: 0.41; lr: 1.00000; 14959/14348 tok/s;   1343 sec\n",
            "[2020-06-02 03:24:38,606 INFO] Step 29350/50000; acc:  86.48; ppl:  1.59; xent: 0.46; lr: 1.00000; 14833/15048 tok/s;   1345 sec\n",
            "[2020-06-02 03:24:40,861 INFO] Step 29400/50000; acc:  85.71; ppl:  1.64; xent: 0.50; lr: 1.00000; 14122/15025 tok/s;   1347 sec\n",
            "[2020-06-02 03:24:42,929 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:24:43,235 INFO] number of examples: 26141\n",
            "[2020-06-02 03:24:43,437 INFO] Step 29450/50000; acc:  86.40; ppl:  1.61; xent: 0.48; lr: 1.00000; 12088/12601 tok/s;   1350 sec\n",
            "[2020-06-02 03:24:45,925 INFO] Step 29500/50000; acc:  85.03; ppl:  1.69; xent: 0.52; lr: 1.00000; 14342/14744 tok/s;   1352 sec\n",
            "[2020-06-02 03:24:48,206 INFO] Step 29550/50000; acc:  85.58; ppl:  1.67; xent: 0.51; lr: 1.00000; 15012/15048 tok/s;   1355 sec\n",
            "[2020-06-02 03:24:50,376 INFO] Step 29600/50000; acc:  87.13; ppl:  1.56; xent: 0.44; lr: 1.00000; 14587/15024 tok/s;   1357 sec\n",
            "[2020-06-02 03:24:52,748 INFO] Step 29650/50000; acc:  87.15; ppl:  1.55; xent: 0.44; lr: 1.00000; 14811/15140 tok/s;   1359 sec\n",
            "[2020-06-02 03:24:54,682 INFO] Step 29700/50000; acc:  88.68; ppl:  1.46; xent: 0.38; lr: 1.00000; 14522/14575 tok/s;   1361 sec\n",
            "[2020-06-02 03:24:56,952 INFO] Step 29750/50000; acc:  86.52; ppl:  1.58; xent: 0.46; lr: 1.00000; 14958/14869 tok/s;   1363 sec\n",
            "[2020-06-02 03:24:59,207 INFO] Step 29800/50000; acc:  85.93; ppl:  1.63; xent: 0.49; lr: 1.00000; 14288/14946 tok/s;   1366 sec\n",
            "[2020-06-02 03:25:01,327 INFO] Step 29850/50000; acc:  87.20; ppl:  1.55; xent: 0.44; lr: 1.00000; 14156/14869 tok/s;   1368 sec\n",
            "[2020-06-02 03:25:01,590 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:25:01,900 INFO] number of examples: 26141\n",
            "[2020-06-02 03:25:04,195 INFO] Step 29900/50000; acc:  85.52; ppl:  1.65; xent: 0.50; lr: 1.00000; 12170/12484 tok/s;   1371 sec\n",
            "[2020-06-02 03:25:06,514 INFO] Step 29950/50000; acc:  85.97; ppl:  1.64; xent: 0.49; lr: 1.00000; 14686/14923 tok/s;   1373 sec\n",
            "[2020-06-02 03:25:08,746 INFO] Step 30000/50000; acc:  86.62; ppl:  1.56; xent: 0.45; lr: 1.00000; 14697/14921 tok/s;   1375 sec\n",
            "[2020-06-02 03:25:08,746 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.valid.0.pt\n",
            "[2020-06-02 03:25:08,751 INFO] number of examples: 276\n",
            "[2020-06-02 03:25:09,013 INFO] Validation perplexity: 205.741\n",
            "[2020-06-02 03:25:09,013 INFO] Validation accuracy: 43.1865\n",
            "[2020-06-02 03:25:09,042 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_30000.pt\n",
            "[2020-06-02 03:25:11,573 INFO] Step 30050/50000; acc:  87.54; ppl:  1.54; xent: 0.43; lr: 1.00000; 11885/12071 tok/s;   1378 sec\n",
            "[2020-06-02 03:25:13,612 INFO] Step 30100/50000; acc:  88.99; ppl:  1.44; xent: 0.37; lr: 1.00000; 14381/14812 tok/s;   1380 sec\n",
            "[2020-06-02 03:25:15,899 INFO] Step 30150/50000; acc:  86.49; ppl:  1.60; xent: 0.47; lr: 1.00000; 14439/14513 tok/s;   1382 sec\n",
            "[2020-06-02 03:25:18,165 INFO] Step 30200/50000; acc:  85.90; ppl:  1.63; xent: 0.49; lr: 1.00000; 14563/14956 tok/s;   1384 sec\n",
            "[2020-06-02 03:25:20,388 INFO] Step 30250/50000; acc:  88.20; ppl:  1.49; xent: 0.40; lr: 1.00000; 13566/14071 tok/s;   1387 sec\n",
            "[2020-06-02 03:25:21,046 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:25:21,362 INFO] number of examples: 26141\n",
            "[2020-06-02 03:25:23,173 INFO] Step 30300/50000; acc:  85.26; ppl:  1.65; xent: 0.50; lr: 1.00000; 11522/12214 tok/s;   1390 sec\n",
            "[2020-06-02 03:25:25,604 INFO] Step 30350/50000; acc:  85.53; ppl:  1.64; xent: 0.50; lr: 1.00000; 14971/14872 tok/s;   1392 sec\n",
            "[2020-06-02 03:25:27,825 INFO] Step 30400/50000; acc:  87.23; ppl:  1.55; xent: 0.44; lr: 1.00000; 14773/14946 tok/s;   1394 sec\n",
            "[2020-06-02 03:25:30,012 INFO] Step 30450/50000; acc:  88.70; ppl:  1.46; xent: 0.38; lr: 1.00000; 14658/15124 tok/s;   1396 sec\n",
            "[2020-06-02 03:25:32,272 INFO] Step 30500/50000; acc:  87.43; ppl:  1.54; xent: 0.43; lr: 1.00000; 14702/14970 tok/s;   1399 sec\n",
            "[2020-06-02 03:25:34,434 INFO] Step 30550/50000; acc:  86.64; ppl:  1.58; xent: 0.46; lr: 1.00000; 14480/14498 tok/s;   1401 sec\n",
            "[2020-06-02 03:25:36,605 INFO] Step 30600/50000; acc:  86.66; ppl:  1.59; xent: 0.47; lr: 1.00000; 14808/14920 tok/s;   1403 sec\n",
            "[2020-06-02 03:25:38,827 INFO] Step 30650/50000; acc:  87.65; ppl:  1.52; xent: 0.42; lr: 1.00000; 14443/15105 tok/s;   1405 sec\n",
            "[2020-06-02 03:25:39,782 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:25:40,105 INFO] number of examples: 26141\n",
            "[2020-06-02 03:25:41,451 INFO] Step 30700/50000; acc:  86.08; ppl:  1.61; xent: 0.47; lr: 1.00000; 11278/12144 tok/s;   1408 sec\n",
            "[2020-06-02 03:25:43,744 INFO] Step 30750/50000; acc:  87.37; ppl:  1.54; xent: 0.43; lr: 1.00000; 14923/14998 tok/s;   1410 sec\n",
            "[2020-06-02 03:25:46,098 INFO] Step 30800/50000; acc:  85.40; ppl:  1.65; xent: 0.50; lr: 1.00000; 14801/14699 tok/s;   1412 sec\n",
            "[2020-06-02 03:25:48,355 INFO] Step 30850/50000; acc:  87.72; ppl:  1.51; xent: 0.41; lr: 1.00000; 14861/15507 tok/s;   1415 sec\n",
            "[2020-06-02 03:25:50,583 INFO] Step 30900/50000; acc:  87.77; ppl:  1.52; xent: 0.42; lr: 1.00000; 14422/15072 tok/s;   1417 sec\n",
            "[2020-06-02 03:25:52,680 INFO] Step 30950/50000; acc:  86.59; ppl:  1.58; xent: 0.46; lr: 1.00000; 14804/14252 tok/s;   1419 sec\n",
            "[2020-06-02 03:25:54,766 INFO] Step 31000/50000; acc:  88.09; ppl:  1.49; xent: 0.40; lr: 1.00000; 14869/15219 tok/s;   1421 sec\n",
            "[2020-06-02 03:25:57,094 INFO] Step 31050/50000; acc:  86.65; ppl:  1.60; xent: 0.47; lr: 1.00000; 14084/14754 tok/s;   1423 sec\n",
            "[2020-06-02 03:25:58,476 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:25:58,693 INFO] number of examples: 26141\n",
            "[2020-06-02 03:25:59,504 INFO] Step 31100/50000; acc:  86.73; ppl:  1.56; xent: 0.44; lr: 1.00000; 12402/13150 tok/s;   1426 sec\n",
            "[2020-06-02 03:26:01,891 INFO] Step 31150/50000; acc:  86.83; ppl:  1.57; xent: 0.45; lr: 1.00000; 14080/14537 tok/s;   1428 sec\n",
            "[2020-06-02 03:26:04,270 INFO] Step 31200/50000; acc:  85.88; ppl:  1.63; xent: 0.49; lr: 1.00000; 15247/14856 tok/s;   1431 sec\n",
            "[2020-06-02 03:26:06,480 INFO] Step 31250/50000; acc:  88.37; ppl:  1.49; xent: 0.40; lr: 1.00000; 14530/15403 tok/s;   1433 sec\n",
            "[2020-06-02 03:26:08,856 INFO] Step 31300/50000; acc:  87.74; ppl:  1.51; xent: 0.41; lr: 1.00000; 14576/14888 tok/s;   1435 sec\n",
            "[2020-06-02 03:26:10,877 INFO] Step 31350/50000; acc:  87.63; ppl:  1.51; xent: 0.41; lr: 1.00000; 14753/14129 tok/s;   1437 sec\n",
            "[2020-06-02 03:26:12,918 INFO] Step 31400/50000; acc:  88.61; ppl:  1.47; xent: 0.39; lr: 1.00000; 14899/15297 tok/s;   1439 sec\n",
            "[2020-06-02 03:26:15,367 INFO] Step 31450/50000; acc:  85.34; ppl:  1.66; xent: 0.51; lr: 1.00000; 14186/14701 tok/s;   1442 sec\n",
            "[2020-06-02 03:26:17,094 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:26:17,383 INFO] number of examples: 26141\n",
            "[2020-06-02 03:26:17,828 INFO] Step 31500/50000; acc:  87.85; ppl:  1.51; xent: 0.41; lr: 1.00000; 11911/12622 tok/s;   1444 sec\n",
            "[2020-06-02 03:26:20,285 INFO] Step 31550/50000; acc:  86.28; ppl:  1.59; xent: 0.46; lr: 1.00000; 14117/14639 tok/s;   1447 sec\n",
            "[2020-06-02 03:26:22,649 INFO] Step 31600/50000; acc:  86.29; ppl:  1.61; xent: 0.47; lr: 1.00000; 14946/14808 tok/s;   1449 sec\n",
            "[2020-06-02 03:26:24,748 INFO] Step 31650/50000; acc:  88.11; ppl:  1.49; xent: 0.40; lr: 1.00000; 14743/15363 tok/s;   1451 sec\n",
            "[2020-06-02 03:26:27,141 INFO] Step 31700/50000; acc:  88.07; ppl:  1.50; xent: 0.41; lr: 1.00000; 14627/15015 tok/s;   1453 sec\n",
            "[2020-06-02 03:26:29,131 INFO] Step 31750/50000; acc:  89.11; ppl:  1.45; xent: 0.37; lr: 1.00000; 14753/14311 tok/s;   1455 sec\n",
            "[2020-06-02 03:26:31,341 INFO] Step 31800/50000; acc:  87.65; ppl:  1.52; xent: 0.42; lr: 1.00000; 14727/14998 tok/s;   1458 sec\n",
            "[2020-06-02 03:26:33,585 INFO] Step 31850/50000; acc:  86.58; ppl:  1.60; xent: 0.47; lr: 1.00000; 14106/14843 tok/s;   1460 sec\n",
            "[2020-06-02 03:26:35,728 INFO] Step 31900/50000; acc:  87.82; ppl:  1.50; xent: 0.41; lr: 1.00000; 14033/14742 tok/s;   1462 sec\n",
            "[2020-06-02 03:26:35,833 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:26:36,121 INFO] number of examples: 26141\n",
            "[2020-06-02 03:26:38,628 INFO] Step 31950/50000; acc:  86.29; ppl:  1.61; xent: 0.48; lr: 1.00000; 12365/12663 tok/s;   1465 sec\n",
            "[2020-06-02 03:26:40,893 INFO] Step 32000/50000; acc:  86.82; ppl:  1.57; xent: 0.45; lr: 1.00000; 14782/15030 tok/s;   1467 sec\n",
            "[2020-06-02 03:26:43,086 INFO] Step 32050/50000; acc:  87.70; ppl:  1.52; xent: 0.42; lr: 1.00000; 14845/14956 tok/s;   1469 sec\n",
            "[2020-06-02 03:26:45,429 INFO] Step 32100/50000; acc:  87.82; ppl:  1.50; xent: 0.41; lr: 1.00000; 14937/15203 tok/s;   1472 sec\n",
            "[2020-06-02 03:26:47,425 INFO] Step 32150/50000; acc:  89.42; ppl:  1.42; xent: 0.35; lr: 1.00000; 14294/14724 tok/s;   1474 sec\n",
            "[2020-06-02 03:26:49,712 INFO] Step 32200/50000; acc:  87.40; ppl:  1.54; xent: 0.43; lr: 1.00000; 14961/14883 tok/s;   1476 sec\n",
            "[2020-06-02 03:26:51,953 INFO] Step 32250/50000; acc:  86.84; ppl:  1.58; xent: 0.46; lr: 1.00000; 14409/14917 tok/s;   1478 sec\n",
            "[2020-06-02 03:26:53,969 INFO] Step 32300/50000; acc:  88.64; ppl:  1.48; xent: 0.39; lr: 1.00000; 14169/14968 tok/s;   1480 sec\n",
            "[2020-06-02 03:26:54,482 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:26:54,776 INFO] number of examples: 26141\n",
            "[2020-06-02 03:26:56,863 INFO] Step 32350/50000; acc:  86.48; ppl:  1.59; xent: 0.46; lr: 1.00000; 12047/12516 tok/s;   1483 sec\n",
            "[2020-06-02 03:26:59,197 INFO] Step 32400/50000; acc:  87.05; ppl:  1.58; xent: 0.46; lr: 1.00000; 15137/15031 tok/s;   1486 sec\n",
            "[2020-06-02 03:27:01,369 INFO] Step 32450/50000; acc:  87.94; ppl:  1.49; xent: 0.40; lr: 1.00000; 14517/15011 tok/s;   1488 sec\n",
            "[2020-06-02 03:27:03,694 INFO] Step 32500/50000; acc:  87.79; ppl:  1.52; xent: 0.42; lr: 1.00000; 14836/15096 tok/s;   1490 sec\n",
            "[2020-06-02 03:27:05,761 INFO] Step 32550/50000; acc:  89.89; ppl:  1.41; xent: 0.34; lr: 1.00000; 14742/15024 tok/s;   1492 sec\n",
            "[2020-06-02 03:27:08,009 INFO] Step 32600/50000; acc:  87.11; ppl:  1.54; xent: 0.43; lr: 1.00000; 14408/14580 tok/s;   1494 sec\n",
            "[2020-06-02 03:27:10,257 INFO] Step 32650/50000; acc:  87.48; ppl:  1.55; xent: 0.44; lr: 1.00000; 14536/14685 tok/s;   1497 sec\n",
            "[2020-06-02 03:27:12,415 INFO] Step 32700/50000; acc:  88.58; ppl:  1.47; xent: 0.38; lr: 1.00000; 14399/14902 tok/s;   1499 sec\n",
            "[2020-06-02 03:27:13,196 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:27:13,486 INFO] number of examples: 26141\n",
            "[2020-06-02 03:27:15,135 INFO] Step 32750/50000; acc:  86.49; ppl:  1.59; xent: 0.46; lr: 1.00000; 11322/12167 tok/s;   1501 sec\n",
            "[2020-06-02 03:27:17,410 INFO] Step 32800/50000; acc:  88.46; ppl:  1.46; xent: 0.38; lr: 1.00000; 15127/15084 tok/s;   1504 sec\n",
            "[2020-06-02 03:27:19,844 INFO] Step 32850/50000; acc:  86.43; ppl:  1.60; xent: 0.47; lr: 1.00000; 14502/14535 tok/s;   1506 sec\n",
            "[2020-06-02 03:27:22,037 INFO] Step 32900/50000; acc:  89.27; ppl:  1.43; xent: 0.36; lr: 1.00000; 15023/15393 tok/s;   1508 sec\n",
            "[2020-06-02 03:27:24,272 INFO] Step 32950/50000; acc:  87.81; ppl:  1.51; xent: 0.41; lr: 1.00000; 14326/15063 tok/s;   1511 sec\n",
            "[2020-06-02 03:27:26,375 INFO] Step 33000/50000; acc:  87.83; ppl:  1.50; xent: 0.41; lr: 1.00000; 14727/14336 tok/s;   1513 sec\n",
            "[2020-06-02 03:27:28,570 INFO] Step 33050/50000; acc:  87.40; ppl:  1.54; xent: 0.43; lr: 1.00000; 14600/14823 tok/s;   1515 sec\n",
            "[2020-06-02 03:27:30,800 INFO] Step 33100/50000; acc:  88.28; ppl:  1.48; xent: 0.39; lr: 1.00000; 14388/15174 tok/s;   1517 sec\n",
            "[2020-06-02 03:27:31,933 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:27:32,232 INFO] number of examples: 26141\n",
            "[2020-06-02 03:27:33,341 INFO] Step 33150/50000; acc:  88.09; ppl:  1.50; xent: 0.41; lr: 1.00000; 11567/12198 tok/s;   1520 sec\n",
            "[2020-06-02 03:27:35,658 INFO] Step 33200/50000; acc:  87.70; ppl:  1.51; xent: 0.41; lr: 1.00000; 14744/15170 tok/s;   1522 sec\n",
            "[2020-06-02 03:27:38,025 INFO] Step 33250/50000; acc:  86.22; ppl:  1.60; xent: 0.47; lr: 1.00000; 15073/14672 tok/s;   1524 sec\n",
            "[2020-06-02 03:27:40,245 INFO] Step 33300/50000; acc:  89.10; ppl:  1.44; xent: 0.36; lr: 1.00000; 14679/15595 tok/s;   1527 sec\n",
            "[2020-06-02 03:27:42,594 INFO] Step 33350/50000; acc:  88.48; ppl:  1.48; xent: 0.39; lr: 1.00000; 14303/14843 tok/s;   1529 sec\n",
            "[2020-06-02 03:27:44,569 INFO] Step 33400/50000; acc:  88.68; ppl:  1.47; xent: 0.39; lr: 1.00000; 14907/14153 tok/s;   1531 sec\n",
            "[2020-06-02 03:27:46,608 INFO] Step 33450/50000; acc:  89.21; ppl:  1.44; xent: 0.36; lr: 1.00000; 14943/15413 tok/s;   1533 sec\n",
            "[2020-06-02 03:27:49,042 INFO] Step 33500/50000; acc:  86.57; ppl:  1.59; xent: 0.46; lr: 1.00000; 14249/14731 tok/s;   1535 sec\n",
            "[2020-06-02 03:27:50,618 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:27:50,923 INFO] number of examples: 26141\n",
            "[2020-06-02 03:27:51,555 INFO] Step 33550/50000; acc:  88.52; ppl:  1.46; xent: 0.38; lr: 1.00000; 11693/12428 tok/s;   1538 sec\n",
            "[2020-06-02 03:27:54,010 INFO] Step 33600/50000; acc:  87.01; ppl:  1.55; xent: 0.44; lr: 1.00000; 14152/14655 tok/s;   1540 sec\n",
            "[2020-06-02 03:27:56,406 INFO] Step 33650/50000; acc:  86.90; ppl:  1.57; xent: 0.45; lr: 1.00000; 15037/14799 tok/s;   1543 sec\n",
            "[2020-06-02 03:27:58,578 INFO] Step 33700/50000; acc:  89.26; ppl:  1.43; xent: 0.36; lr: 1.00000; 14577/15278 tok/s;   1545 sec\n",
            "[2020-06-02 03:28:00,939 INFO] Step 33750/50000; acc:  88.91; ppl:  1.47; xent: 0.38; lr: 1.00000; 14422/14845 tok/s;   1547 sec\n",
            "[2020-06-02 03:28:02,913 INFO] Step 33800/50000; acc:  88.88; ppl:  1.45; xent: 0.37; lr: 1.00000; 15028/14411 tok/s;   1549 sec\n",
            "[2020-06-02 03:28:05,021 INFO] Step 33850/50000; acc:  89.11; ppl:  1.43; xent: 0.36; lr: 1.00000; 14867/15083 tok/s;   1551 sec\n",
            "[2020-06-02 03:28:07,306 INFO] Step 33900/50000; acc:  87.92; ppl:  1.53; xent: 0.43; lr: 1.00000; 14128/14978 tok/s;   1554 sec\n",
            "[2020-06-02 03:28:09,336 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:28:09,645 INFO] number of examples: 26141\n",
            "[2020-06-02 03:28:09,904 INFO] Step 33950/50000; acc:  88.35; ppl:  1.49; xent: 0.40; lr: 1.00000; 11993/12513 tok/s;   1556 sec\n",
            "[2020-06-02 03:28:12,406 INFO] Step 34000/50000; acc:  87.07; ppl:  1.55; xent: 0.44; lr: 1.00000; 14079/14506 tok/s;   1559 sec\n",
            "[2020-06-02 03:28:14,731 INFO] Step 34050/50000; acc:  87.78; ppl:  1.53; xent: 0.42; lr: 1.00000; 14921/14978 tok/s;   1561 sec\n",
            "[2020-06-02 03:28:16,901 INFO] Step 34100/50000; acc:  88.80; ppl:  1.46; xent: 0.38; lr: 1.00000; 14558/14998 tok/s;   1563 sec\n",
            "[2020-06-02 03:28:19,274 INFO] Step 34150/50000; acc:  88.83; ppl:  1.46; xent: 0.38; lr: 1.00000; 14675/15051 tok/s;   1566 sec\n",
            "[2020-06-02 03:28:21,224 INFO] Step 34200/50000; acc:  90.30; ppl:  1.38; xent: 0.33; lr: 1.00000; 14756/14602 tok/s;   1568 sec\n",
            "[2020-06-02 03:28:23,506 INFO] Step 34250/50000; acc:  88.16; ppl:  1.49; xent: 0.40; lr: 1.00000; 14880/14853 tok/s;   1570 sec\n",
            "[2020-06-02 03:28:25,732 INFO] Step 34300/50000; acc:  87.76; ppl:  1.53; xent: 0.43; lr: 1.00000; 14191/14910 tok/s;   1572 sec\n",
            "[2020-06-02 03:28:27,842 INFO] Step 34350/50000; acc:  89.03; ppl:  1.46; xent: 0.38; lr: 1.00000; 14188/14933 tok/s;   1574 sec\n",
            "[2020-06-02 03:28:28,071 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:28:28,390 INFO] number of examples: 26141\n",
            "[2020-06-02 03:28:30,733 INFO] Step 34400/50000; acc:  87.19; ppl:  1.54; xent: 0.43; lr: 1.00000; 12315/12529 tok/s;   1577 sec\n",
            "[2020-06-02 03:28:33,015 INFO] Step 34450/50000; acc:  87.75; ppl:  1.52; xent: 0.42; lr: 1.00000; 14501/14853 tok/s;   1579 sec\n",
            "[2020-06-02 03:28:35,264 INFO] Step 34500/50000; acc:  88.57; ppl:  1.48; xent: 0.39; lr: 1.00000; 14906/15100 tok/s;   1582 sec\n",
            "[2020-06-02 03:28:37,506 INFO] Step 34550/50000; acc:  89.02; ppl:  1.45; xent: 0.37; lr: 1.00000; 14784/15127 tok/s;   1584 sec\n",
            "[2020-06-02 03:28:39,494 INFO] Step 34600/50000; acc:  90.24; ppl:  1.39; xent: 0.33; lr: 1.00000; 14619/14972 tok/s;   1586 sec\n",
            "[2020-06-02 03:28:41,798 INFO] Step 34650/50000; acc:  88.20; ppl:  1.49; xent: 0.40; lr: 1.00000; 14589/14606 tok/s;   1588 sec\n",
            "[2020-06-02 03:28:44,069 INFO] Step 34700/50000; acc:  87.28; ppl:  1.55; xent: 0.44; lr: 1.00000; 14554/15040 tok/s;   1590 sec\n",
            "[2020-06-02 03:28:46,104 INFO] Step 34750/50000; acc:  89.52; ppl:  1.42; xent: 0.35; lr: 1.00000; 14506/15015 tok/s;   1592 sec\n",
            "[2020-06-02 03:28:46,737 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:28:47,048 INFO] number of examples: 26141\n",
            "[2020-06-02 03:28:48,882 INFO] Step 34800/50000; acc:  87.38; ppl:  1.53; xent: 0.43; lr: 1.00000; 11687/12384 tok/s;   1595 sec\n",
            "[2020-06-02 03:28:51,288 INFO] Step 34850/50000; acc:  87.84; ppl:  1.53; xent: 0.42; lr: 1.00000; 15129/14971 tok/s;   1598 sec\n",
            "[2020-06-02 03:28:53,502 INFO] Step 34900/50000; acc:  88.71; ppl:  1.46; xent: 0.38; lr: 1.00000; 14816/15105 tok/s;   1600 sec\n",
            "[2020-06-02 03:28:55,646 INFO] Step 34950/50000; acc:  89.84; ppl:  1.40; xent: 0.34; lr: 1.00000; 14778/15224 tok/s;   1602 sec\n",
            "[2020-06-02 03:28:57,910 INFO] Step 35000/50000; acc:  89.01; ppl:  1.46; xent: 0.38; lr: 1.00000; 14814/14997 tok/s;   1604 sec\n",
            "[2020-06-02 03:28:57,932 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_35000.pt\n",
            "[2020-06-02 03:29:00,382 INFO] Step 35050/50000; acc:  88.39; ppl:  1.49; xent: 0.40; lr: 1.00000; 12897/12924 tok/s;   1607 sec\n",
            "[2020-06-02 03:29:02,563 INFO] Step 35100/50000; acc:  88.04; ppl:  1.51; xent: 0.41; lr: 1.00000; 14628/14873 tok/s;   1609 sec\n",
            "[2020-06-02 03:29:04,757 INFO] Step 35150/50000; acc:  89.49; ppl:  1.42; xent: 0.35; lr: 1.00000; 14423/15006 tok/s;   1611 sec\n",
            "[2020-06-02 03:29:05,697 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:29:05,941 INFO] number of examples: 26141\n",
            "[2020-06-02 03:29:07,413 INFO] Step 35200/50000; acc:  87.50; ppl:  1.53; xent: 0.42; lr: 1.00000; 11554/12414 tok/s;   1614 sec\n",
            "[2020-06-02 03:29:09,833 INFO] Step 35250/50000; acc:  89.43; ppl:  1.42; xent: 0.35; lr: 1.00000; 14113/14135 tok/s;   1616 sec\n",
            "[2020-06-02 03:29:12,181 INFO] Step 35300/50000; acc:  87.45; ppl:  1.53; xent: 0.42; lr: 1.00000; 14564/14549 tok/s;   1619 sec\n",
            "[2020-06-02 03:29:14,431 INFO] Step 35350/50000; acc:  89.47; ppl:  1.43; xent: 0.36; lr: 1.00000; 14733/15336 tok/s;   1621 sec\n",
            "[2020-06-02 03:29:16,690 INFO] Step 35400/50000; acc:  89.36; ppl:  1.43; xent: 0.35; lr: 1.00000; 14227/14811 tok/s;   1623 sec\n",
            "[2020-06-02 03:29:18,810 INFO] Step 35450/50000; acc:  88.60; ppl:  1.47; xent: 0.38; lr: 1.00000; 14792/14337 tok/s;   1625 sec\n",
            "[2020-06-02 03:29:20,864 INFO] Step 35500/50000; acc:  89.46; ppl:  1.42; xent: 0.35; lr: 1.00000; 14911/15203 tok/s;   1627 sec\n",
            "[2020-06-02 03:29:23,178 INFO] Step 35550/50000; acc:  88.37; ppl:  1.50; xent: 0.40; lr: 1.00000; 14229/14903 tok/s;   1630 sec\n",
            "[2020-06-02 03:29:24,538 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:29:24,831 INFO] number of examples: 26141\n",
            "[2020-06-02 03:29:25,674 INFO] Step 35600/50000; acc:  88.65; ppl:  1.46; xent: 0.38; lr: 1.00000; 12054/12724 tok/s;   1632 sec\n",
            "[2020-06-02 03:29:28,059 INFO] Step 35650/50000; acc:  88.56; ppl:  1.48; xent: 0.39; lr: 1.00000; 14087/14638 tok/s;   1634 sec\n",
            "[2020-06-02 03:29:30,419 INFO] Step 35700/50000; acc:  87.60; ppl:  1.53; xent: 0.43; lr: 1.00000; 15402/14907 tok/s;   1637 sec\n",
            "[2020-06-02 03:29:32,647 INFO] Step 35750/50000; acc:  89.37; ppl:  1.43; xent: 0.35; lr: 1.00000; 14610/15568 tok/s;   1639 sec\n",
            "[2020-06-02 03:29:35,014 INFO] Step 35800/50000; acc:  89.51; ppl:  1.43; xent: 0.35; lr: 1.00000; 14601/14888 tok/s;   1641 sec\n",
            "[2020-06-02 03:29:37,002 INFO] Step 35850/50000; acc:  89.72; ppl:  1.42; xent: 0.35; lr: 1.00000; 14648/14013 tok/s;   1643 sec\n",
            "[2020-06-02 03:29:39,044 INFO] Step 35900/50000; acc:  90.37; ppl:  1.37; xent: 0.32; lr: 1.00000; 14897/15295 tok/s;   1645 sec\n",
            "[2020-06-02 03:29:41,495 INFO] Step 35950/50000; acc:  87.66; ppl:  1.54; xent: 0.43; lr: 1.00000; 14222/14787 tok/s;   1648 sec\n",
            "[2020-06-02 03:29:43,178 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:29:43,468 INFO] number of examples: 26141\n",
            "[2020-06-02 03:29:43,971 INFO] Step 36000/50000; acc:  89.66; ppl:  1.41; xent: 0.34; lr: 1.00000; 12023/12720 tok/s;   1650 sec\n",
            "[2020-06-02 03:29:46,381 INFO] Step 36050/50000; acc:  88.34; ppl:  1.47; xent: 0.39; lr: 1.00000; 14202/14693 tok/s;   1653 sec\n",
            "[2020-06-02 03:29:48,786 INFO] Step 36100/50000; acc:  87.91; ppl:  1.51; xent: 0.41; lr: 1.00000; 14929/14872 tok/s;   1655 sec\n",
            "[2020-06-02 03:29:50,880 INFO] Step 36150/50000; acc:  90.03; ppl:  1.39; xent: 0.33; lr: 1.00000; 14601/15194 tok/s;   1657 sec\n",
            "[2020-06-02 03:29:53,267 INFO] Step 36200/50000; acc:  89.52; ppl:  1.42; xent: 0.35; lr: 1.00000; 14611/15000 tok/s;   1660 sec\n",
            "[2020-06-02 03:29:55,264 INFO] Step 36250/50000; acc:  90.39; ppl:  1.38; xent: 0.32; lr: 1.00000; 14890/14290 tok/s;   1662 sec\n",
            "[2020-06-02 03:29:57,445 INFO] Step 36300/50000; acc:  89.21; ppl:  1.43; xent: 0.36; lr: 1.00000; 14690/15023 tok/s;   1664 sec\n",
            "[2020-06-02 03:29:59,662 INFO] Step 36350/50000; acc:  88.71; ppl:  1.48; xent: 0.39; lr: 1.00000; 14159/14962 tok/s;   1666 sec\n",
            "[2020-06-02 03:30:01,815 INFO] Step 36400/50000; acc:  89.52; ppl:  1.42; xent: 0.35; lr: 1.00000; 14354/15046 tok/s;   1668 sec\n",
            "[2020-06-02 03:30:01,855 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:30:02,153 INFO] number of examples: 26141\n",
            "[2020-06-02 03:30:04,693 INFO] Step 36450/50000; acc:  88.05; ppl:  1.50; xent: 0.40; lr: 1.00000; 12261/12572 tok/s;   1671 sec\n",
            "[2020-06-02 03:30:06,951 INFO] Step 36500/50000; acc:  88.69; ppl:  1.47; xent: 0.38; lr: 1.00000; 14772/14992 tok/s;   1673 sec\n",
            "[2020-06-02 03:30:09,171 INFO] Step 36550/50000; acc:  89.25; ppl:  1.43; xent: 0.36; lr: 1.00000; 14861/14971 tok/s;   1675 sec\n",
            "[2020-06-02 03:30:11,513 INFO] Step 36600/50000; acc:  89.55; ppl:  1.42; xent: 0.35; lr: 1.00000; 14896/15165 tok/s;   1678 sec\n",
            "[2020-06-02 03:30:13,500 INFO] Step 36650/50000; acc:  90.53; ppl:  1.37; xent: 0.31; lr: 1.00000; 14289/14714 tok/s;   1680 sec\n",
            "[2020-06-02 03:30:15,797 INFO] Step 36700/50000; acc:  89.08; ppl:  1.44; xent: 0.37; lr: 1.00000; 14976/14846 tok/s;   1682 sec\n",
            "[2020-06-02 03:30:18,036 INFO] Step 36750/50000; acc:  88.42; ppl:  1.48; xent: 0.39; lr: 1.00000; 14362/14927 tok/s;   1684 sec\n",
            "[2020-06-02 03:30:20,139 INFO] Step 36800/50000; acc:  89.80; ppl:  1.41; xent: 0.35; lr: 1.00000; 13933/14687 tok/s;   1686 sec\n",
            "[2020-06-02 03:30:20,545 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:30:20,832 INFO] number of examples: 26141\n",
            "[2020-06-02 03:30:22,961 INFO] Step 36850/50000; acc:  88.24; ppl:  1.48; xent: 0.40; lr: 1.00000; 12028/12541 tok/s;   1689 sec\n",
            "[2020-06-02 03:30:25,319 INFO] Step 36900/50000; acc:  88.50; ppl:  1.48; xent: 0.40; lr: 1.00000; 14986/14936 tok/s;   1692 sec\n",
            "[2020-06-02 03:30:27,475 INFO] Step 36950/50000; acc:  89.39; ppl:  1.42; xent: 0.35; lr: 1.00000; 14596/15096 tok/s;   1694 sec\n",
            "[2020-06-02 03:30:29,799 INFO] Step 37000/50000; acc:  89.06; ppl:  1.44; xent: 0.37; lr: 1.00000; 14867/15070 tok/s;   1696 sec\n",
            "[2020-06-02 03:30:31,881 INFO] Step 37050/50000; acc:  91.27; ppl:  1.34; xent: 0.29; lr: 1.00000; 14603/14884 tok/s;   1698 sec\n",
            "[2020-06-02 03:30:34,140 INFO] Step 37100/50000; acc:  88.97; ppl:  1.45; xent: 0.37; lr: 1.00000; 14479/14593 tok/s;   1700 sec\n",
            "[2020-06-02 03:30:36,389 INFO] Step 37150/50000; acc:  89.26; ppl:  1.44; xent: 0.37; lr: 1.00000; 14502/14737 tok/s;   1703 sec\n",
            "[2020-06-02 03:30:38,512 INFO] Step 37200/50000; acc:  89.95; ppl:  1.41; xent: 0.34; lr: 1.00000; 14451/14962 tok/s;   1705 sec\n",
            "[2020-06-02 03:30:39,268 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:30:39,567 INFO] number of examples: 26141\n",
            "[2020-06-02 03:30:41,233 INFO] Step 37250/50000; acc:  87.63; ppl:  1.51; xent: 0.41; lr: 1.00000; 11390/12235 tok/s;   1708 sec\n",
            "[2020-06-02 03:30:43,601 INFO] Step 37300/50000; acc:  89.27; ppl:  1.44; xent: 0.36; lr: 1.00000; 15234/15085 tok/s;   1710 sec\n",
            "[2020-06-02 03:30:45,898 INFO] Step 37350/50000; acc:  88.94; ppl:  1.44; xent: 0.36; lr: 1.00000; 14698/14873 tok/s;   1712 sec\n",
            "[2020-06-02 03:30:48,088 INFO] Step 37400/50000; acc:  90.84; ppl:  1.35; xent: 0.30; lr: 1.00000; 15046/15401 tok/s;   1714 sec\n",
            "[2020-06-02 03:30:50,301 INFO] Step 37450/50000; acc:  89.60; ppl:  1.42; xent: 0.35; lr: 1.00000; 14441/15113 tok/s;   1717 sec\n",
            "[2020-06-02 03:30:52,406 INFO] Step 37500/50000; acc:  89.43; ppl:  1.43; xent: 0.36; lr: 1.00000; 14716/14386 tok/s;   1719 sec\n",
            "[2020-06-02 03:30:54,586 INFO] Step 37550/50000; acc:  89.21; ppl:  1.44; xent: 0.37; lr: 1.00000; 14667/14880 tok/s;   1721 sec\n",
            "[2020-06-02 03:30:56,858 INFO] Step 37600/50000; acc:  89.65; ppl:  1.41; xent: 0.34; lr: 1.00000; 14518/15183 tok/s;   1723 sec\n",
            "[2020-06-02 03:30:57,917 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:30:58,226 INFO] number of examples: 26141\n",
            "[2020-06-02 03:30:59,411 INFO] Step 37650/50000; acc:  89.11; ppl:  1.44; xent: 0.37; lr: 1.00000; 11389/12153 tok/s;   1726 sec\n",
            "[2020-06-02 03:31:01,694 INFO] Step 37700/50000; acc:  89.76; ppl:  1.41; xent: 0.34; lr: 1.00000; 14961/15198 tok/s;   1728 sec\n",
            "[2020-06-02 03:31:04,075 INFO] Step 37750/50000; acc:  88.34; ppl:  1.48; xent: 0.39; lr: 1.00000; 14983/14738 tok/s;   1730 sec\n",
            "[2020-06-02 03:31:06,251 INFO] Step 37800/50000; acc:  90.40; ppl:  1.37; xent: 0.32; lr: 1.00000; 14773/15619 tok/s;   1733 sec\n",
            "[2020-06-02 03:31:08,634 INFO] Step 37850/50000; acc:  89.88; ppl:  1.40; xent: 0.34; lr: 1.00000; 14313/14845 tok/s;   1735 sec\n",
            "[2020-06-02 03:31:10,655 INFO] Step 37900/50000; acc:  89.69; ppl:  1.41; xent: 0.35; lr: 1.00000; 14791/14113 tok/s;   1737 sec\n",
            "[2020-06-02 03:31:12,643 INFO] Step 37950/50000; acc:  90.95; ppl:  1.35; xent: 0.30; lr: 1.00000; 14841/15328 tok/s;   1739 sec\n",
            "[2020-06-02 03:31:15,097 INFO] Step 38000/50000; acc:  88.21; ppl:  1.50; xent: 0.41; lr: 1.00000; 14238/14743 tok/s;   1741 sec\n",
            "[2020-06-02 03:31:16,605 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:31:16,908 INFO] number of examples: 26141\n",
            "[2020-06-02 03:31:17,610 INFO] Step 38050/50000; acc:  89.54; ppl:  1.42; xent: 0.35; lr: 1.00000; 11920/12638 tok/s;   1744 sec\n",
            "[2020-06-02 03:31:19,993 INFO] Step 38100/50000; acc:  89.07; ppl:  1.45; xent: 0.37; lr: 1.00000; 14073/14589 tok/s;   1746 sec\n",
            "[2020-06-02 03:31:22,378 INFO] Step 38150/50000; acc:  88.46; ppl:  1.48; xent: 0.39; lr: 1.00000; 15187/14920 tok/s;   1749 sec\n",
            "[2020-06-02 03:31:24,574 INFO] Step 38200/50000; acc:  90.50; ppl:  1.37; xent: 0.32; lr: 1.00000; 14674/15333 tok/s;   1751 sec\n",
            "[2020-06-02 03:31:26,924 INFO] Step 38250/50000; acc:  90.19; ppl:  1.39; xent: 0.33; lr: 1.00000; 14357/14828 tok/s;   1753 sec\n",
            "[2020-06-02 03:31:28,911 INFO] Step 38300/50000; acc:  89.85; ppl:  1.41; xent: 0.34; lr: 1.00000; 15105/14459 tok/s;   1755 sec\n",
            "[2020-06-02 03:31:30,989 INFO] Step 38350/50000; acc:  90.37; ppl:  1.38; xent: 0.32; lr: 1.00000; 14879/15140 tok/s;   1757 sec\n",
            "[2020-06-02 03:31:33,360 INFO] Step 38400/50000; acc:  88.93; ppl:  1.46; xent: 0.38; lr: 1.00000; 14095/14824 tok/s;   1760 sec\n",
            "[2020-06-02 03:31:35,289 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:31:35,599 INFO] number of examples: 26141\n",
            "[2020-06-02 03:31:35,901 INFO] Step 38450/50000; acc:  90.22; ppl:  1.38; xent: 0.32; lr: 1.00000; 11814/12430 tok/s;   1762 sec\n",
            "[2020-06-02 03:31:38,383 INFO] Step 38500/50000; acc:  88.64; ppl:  1.47; xent: 0.38; lr: 1.00000; 14169/14597 tok/s;   1765 sec\n",
            "[2020-06-02 03:31:40,702 INFO] Step 38550/50000; acc:  89.01; ppl:  1.45; xent: 0.37; lr: 1.00000; 15126/15158 tok/s;   1767 sec\n",
            "[2020-06-02 03:31:42,881 INFO] Step 38600/50000; acc:  90.37; ppl:  1.37; xent: 0.32; lr: 1.00000; 14586/14995 tok/s;   1769 sec\n",
            "[2020-06-02 03:31:45,233 INFO] Step 38650/50000; acc:  90.09; ppl:  1.39; xent: 0.33; lr: 1.00000; 14636/14987 tok/s;   1772 sec\n",
            "[2020-06-02 03:31:47,161 INFO] Step 38700/50000; acc:  91.45; ppl:  1.33; xent: 0.28; lr: 1.00000; 14800/14712 tok/s;   1773 sec\n",
            "[2020-06-02 03:31:49,451 INFO] Step 38750/50000; acc:  89.34; ppl:  1.43; xent: 0.36; lr: 1.00000; 14855/14856 tok/s;   1776 sec\n",
            "[2020-06-02 03:31:51,707 INFO] Step 38800/50000; acc:  89.01; ppl:  1.45; xent: 0.37; lr: 1.00000; 14256/14932 tok/s;   1778 sec\n",
            "[2020-06-02 03:31:53,826 INFO] Step 38850/50000; acc:  90.23; ppl:  1.38; xent: 0.33; lr: 1.00000; 14069/14817 tok/s;   1780 sec\n",
            "[2020-06-02 03:31:54,000 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:31:54,330 INFO] number of examples: 26141\n",
            "[2020-06-02 03:31:56,765 INFO] Step 38900/50000; acc:  88.79; ppl:  1.45; xent: 0.37; lr: 1.00000; 12246/12518 tok/s;   1783 sec\n",
            "[2020-06-02 03:31:58,972 INFO] Step 38950/50000; acc:  89.54; ppl:  1.43; xent: 0.36; lr: 1.00000; 14500/14812 tok/s;   1785 sec\n",
            "[2020-06-02 03:32:01,222 INFO] Step 39000/50000; acc:  89.64; ppl:  1.41; xent: 0.34; lr: 1.00000; 15011/15176 tok/s;   1788 sec\n",
            "[2020-06-02 03:32:03,499 INFO] Step 39050/50000; acc:  90.26; ppl:  1.39; xent: 0.33; lr: 1.00000; 14725/15054 tok/s;   1790 sec\n",
            "[2020-06-02 03:32:05,443 INFO] Step 39100/50000; acc:  91.32; ppl:  1.33; xent: 0.28; lr: 1.00000; 14622/15026 tok/s;   1792 sec\n",
            "[2020-06-02 03:32:07,736 INFO] Step 39150/50000; acc:  89.85; ppl:  1.41; xent: 0.34; lr: 1.00000; 14655/14673 tok/s;   1794 sec\n",
            "[2020-06-02 03:32:10,025 INFO] Step 39200/50000; acc:  89.28; ppl:  1.44; xent: 0.36; lr: 1.00000; 14499/14981 tok/s;   1796 sec\n",
            "[2020-06-02 03:32:12,080 INFO] Step 39250/50000; acc:  90.61; ppl:  1.37; xent: 0.31; lr: 1.00000; 14399/14933 tok/s;   1798 sec\n",
            "[2020-06-02 03:32:12,699 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:32:12,920 INFO] number of examples: 26141\n",
            "[2020-06-02 03:32:14,815 INFO] Step 39300/50000; acc:  89.01; ppl:  1.44; xent: 0.37; lr: 1.00000; 12058/12744 tok/s;   1801 sec\n",
            "[2020-06-02 03:32:17,218 INFO] Step 39350/50000; acc:  89.20; ppl:  1.45; xent: 0.37; lr: 1.00000; 15227/14961 tok/s;   1804 sec\n",
            "[2020-06-02 03:32:19,408 INFO] Step 39400/50000; acc:  90.26; ppl:  1.39; xent: 0.33; lr: 1.00000; 14571/15009 tok/s;   1806 sec\n",
            "[2020-06-02 03:32:21,684 INFO] Step 39450/50000; acc:  90.25; ppl:  1.38; xent: 0.33; lr: 1.00000; 14681/14990 tok/s;   1808 sec\n",
            "[2020-06-02 03:32:23,867 INFO] Step 39500/50000; acc:  91.10; ppl:  1.36; xent: 0.30; lr: 1.00000; 14604/14882 tok/s;   1810 sec\n",
            "[2020-06-02 03:32:26,099 INFO] Step 39550/50000; acc:  89.57; ppl:  1.42; xent: 0.35; lr: 1.00000; 14394/14453 tok/s;   1812 sec\n",
            "[2020-06-02 03:32:28,307 INFO] Step 39600/50000; acc:  89.79; ppl:  1.41; xent: 0.35; lr: 1.00000; 14481/14724 tok/s;   1815 sec\n",
            "[2020-06-02 03:32:30,497 INFO] Step 39650/50000; acc:  90.85; ppl:  1.36; xent: 0.30; lr: 1.00000; 14389/14943 tok/s;   1817 sec\n",
            "[2020-06-02 03:32:31,391 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:32:31,678 INFO] number of examples: 26141\n",
            "[2020-06-02 03:32:33,170 INFO] Step 39700/50000; acc:  88.91; ppl:  1.45; xent: 0.37; lr: 1.00000; 11427/12267 tok/s;   1819 sec\n",
            "[2020-06-02 03:32:35,437 INFO] Step 39750/50000; acc:  90.72; ppl:  1.36; xent: 0.31; lr: 1.00000; 15211/15252 tok/s;   1822 sec\n",
            "[2020-06-02 03:32:37,751 INFO] Step 39800/50000; acc:  88.71; ppl:  1.47; xent: 0.38; lr: 1.00000; 14945/14902 tok/s;   1824 sec\n",
            "[2020-06-02 03:32:39,972 INFO] Step 39850/50000; acc:  90.82; ppl:  1.35; xent: 0.30; lr: 1.00000; 14865/15419 tok/s;   1826 sec\n",
            "[2020-06-02 03:32:42,209 INFO] Step 39900/50000; acc:  90.77; ppl:  1.36; xent: 0.31; lr: 1.00000; 14256/14904 tok/s;   1829 sec\n",
            "[2020-06-02 03:32:44,353 INFO] Step 39950/50000; acc:  89.75; ppl:  1.41; xent: 0.34; lr: 1.00000; 14987/14434 tok/s;   1831 sec\n",
            "[2020-06-02 03:32:46,408 INFO] Step 40000/50000; acc:  91.07; ppl:  1.34; xent: 0.30; lr: 1.00000; 14556/14863 tok/s;   1833 sec\n",
            "[2020-06-02 03:32:46,408 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.valid.0.pt\n",
            "[2020-06-02 03:32:46,413 INFO] number of examples: 276\n",
            "[2020-06-02 03:32:46,664 INFO] Validation perplexity: 290.641\n",
            "[2020-06-02 03:32:46,665 INFO] Validation accuracy: 43.601\n",
            "[2020-06-02 03:32:46,689 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_40000.pt\n",
            "[2020-06-02 03:32:49,270 INFO] Step 40050/50000; acc:  89.86; ppl:  1.41; xent: 0.34; lr: 1.00000; 11484/12096 tok/s;   1836 sec\n",
            "[2020-06-02 03:32:50,600 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:32:50,890 INFO] number of examples: 26141\n",
            "[2020-06-02 03:32:51,901 INFO] Step 40100/50000; acc:  89.48; ppl:  1.42; xent: 0.35; lr: 1.00000; 11659/12246 tok/s;   1838 sec\n",
            "[2020-06-02 03:32:54,228 INFO] Step 40150/50000; acc:  90.45; ppl:  1.37; xent: 0.31; lr: 1.00000; 14429/14972 tok/s;   1841 sec\n",
            "[2020-06-02 03:32:56,555 INFO] Step 40200/50000; acc:  89.06; ppl:  1.45; xent: 0.37; lr: 1.00000; 15210/14787 tok/s;   1843 sec\n",
            "[2020-06-02 03:32:58,937 INFO] Step 40250/50000; acc:  91.19; ppl:  1.35; xent: 0.30; lr: 1.00000; 13905/14852 tok/s;   1845 sec\n",
            "[2020-06-02 03:33:01,303 INFO] Step 40300/50000; acc:  90.49; ppl:  1.38; xent: 0.32; lr: 1.00000; 14531/14886 tok/s;   1848 sec\n",
            "[2020-06-02 03:33:03,278 INFO] Step 40350/50000; acc:  90.61; ppl:  1.37; xent: 0.32; lr: 1.00000; 14809/14023 tok/s;   1850 sec\n",
            "[2020-06-02 03:33:05,312 INFO] Step 40400/50000; acc:  91.02; ppl:  1.34; xent: 0.29; lr: 1.00000; 14917/15389 tok/s;   1852 sec\n",
            "[2020-06-02 03:33:07,716 INFO] Step 40450/50000; acc:  89.10; ppl:  1.46; xent: 0.38; lr: 1.00000; 14294/14835 tok/s;   1854 sec\n",
            "[2020-06-02 03:33:09,392 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:33:09,682 INFO] number of examples: 26141\n",
            "[2020-06-02 03:33:10,215 INFO] Step 40500/50000; acc:  90.94; ppl:  1.36; xent: 0.31; lr: 1.00000; 11962/12653 tok/s;   1857 sec\n",
            "[2020-06-02 03:33:12,674 INFO] Step 40550/50000; acc:  89.81; ppl:  1.41; xent: 0.34; lr: 1.00000; 14045/14559 tok/s;   1859 sec\n",
            "[2020-06-02 03:33:15,058 INFO] Step 40600/50000; acc:  89.33; ppl:  1.43; xent: 0.36; lr: 1.00000; 14927/14836 tok/s;   1861 sec\n",
            "[2020-06-02 03:33:17,199 INFO] Step 40650/50000; acc:  91.31; ppl:  1.33; xent: 0.29; lr: 1.00000; 14493/15037 tok/s;   1864 sec\n",
            "[2020-06-02 03:33:19,635 INFO] Step 40700/50000; acc:  90.79; ppl:  1.36; xent: 0.31; lr: 1.00000; 14391/14776 tok/s;   1866 sec\n",
            "[2020-06-02 03:33:21,601 INFO] Step 40750/50000; acc:  91.12; ppl:  1.34; xent: 0.29; lr: 1.00000; 14868/14292 tok/s;   1868 sec\n",
            "[2020-06-02 03:33:23,775 INFO] Step 40800/50000; acc:  90.30; ppl:  1.39; xent: 0.33; lr: 1.00000; 14620/14954 tok/s;   1870 sec\n",
            "[2020-06-02 03:33:26,025 INFO] Step 40850/50000; acc:  89.63; ppl:  1.42; xent: 0.35; lr: 1.00000; 14236/14935 tok/s;   1872 sec\n",
            "[2020-06-02 03:33:28,187 INFO] Step 40900/50000; acc:  90.80; ppl:  1.36; xent: 0.31; lr: 1.00000; 14236/14962 tok/s;   1875 sec\n",
            "[2020-06-02 03:33:28,188 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:33:28,488 INFO] number of examples: 26141\n",
            "[2020-06-02 03:33:31,089 INFO] Step 40950/50000; acc:  89.18; ppl:  1.44; xent: 0.36; lr: 1.00000; 12313/12709 tok/s;   1877 sec\n",
            "[2020-06-02 03:33:33,353 INFO] Step 41000/50000; acc:  89.98; ppl:  1.41; xent: 0.34; lr: 1.00000; 14927/14994 tok/s;   1880 sec\n",
            "[2020-06-02 03:33:35,517 INFO] Step 41050/50000; acc:  90.95; ppl:  1.36; xent: 0.30; lr: 1.00000; 14661/14905 tok/s;   1882 sec\n",
            "[2020-06-02 03:33:37,913 INFO] Step 41100/50000; acc:  90.64; ppl:  1.37; xent: 0.31; lr: 1.00000; 14926/15201 tok/s;   1884 sec\n",
            "[2020-06-02 03:33:39,878 INFO] Step 41150/50000; acc:  91.66; ppl:  1.31; xent: 0.27; lr: 1.00000; 14392/14621 tok/s;   1886 sec\n",
            "[2020-06-02 03:33:42,149 INFO] Step 41200/50000; acc:  90.44; ppl:  1.38; xent: 0.32; lr: 1.00000; 14863/14807 tok/s;   1888 sec\n",
            "[2020-06-02 03:33:44,391 INFO] Step 41250/50000; acc:  89.76; ppl:  1.41; xent: 0.34; lr: 1.00000; 14373/15022 tok/s;   1891 sec\n",
            "[2020-06-02 03:33:46,522 INFO] Step 41300/50000; acc:  90.75; ppl:  1.37; xent: 0.31; lr: 1.00000; 14086/14771 tok/s;   1893 sec\n",
            "[2020-06-02 03:33:46,856 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:33:47,155 INFO] number of examples: 26141\n",
            "[2020-06-02 03:33:49,331 INFO] Step 41350/50000; acc:  89.70; ppl:  1.41; xent: 0.34; lr: 1.00000; 12015/12425 tok/s;   1896 sec\n",
            "[2020-06-02 03:33:51,652 INFO] Step 41400/50000; acc:  89.74; ppl:  1.42; xent: 0.35; lr: 1.00000; 14942/15072 tok/s;   1898 sec\n",
            "[2020-06-02 03:33:53,858 INFO] Step 41450/50000; acc:  90.58; ppl:  1.36; xent: 0.31; lr: 1.00000; 14788/15079 tok/s;   1900 sec\n",
            "[2020-06-02 03:33:56,154 INFO] Step 41500/50000; acc:  90.59; ppl:  1.38; xent: 0.32; lr: 1.00000; 14829/15122 tok/s;   1902 sec\n",
            "[2020-06-02 03:33:58,188 INFO] Step 41550/50000; acc:  92.03; ppl:  1.30; xent: 0.26; lr: 1.00000; 14606/14928 tok/s;   1905 sec\n",
            "[2020-06-02 03:34:00,452 INFO] Step 41600/50000; acc:  90.23; ppl:  1.39; xent: 0.33; lr: 1.00000; 14530/14660 tok/s;   1907 sec\n",
            "[2020-06-02 03:34:02,739 INFO] Step 41650/50000; acc:  89.86; ppl:  1.40; xent: 0.34; lr: 1.00000; 14654/14964 tok/s;   1909 sec\n",
            "[2020-06-02 03:34:04,776 INFO] Step 41700/50000; acc:  91.42; ppl:  1.32; xent: 0.28; lr: 1.00000; 14458/14933 tok/s;   1911 sec\n",
            "[2020-06-02 03:34:05,525 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:34:05,828 INFO] number of examples: 26141\n",
            "[2020-06-02 03:34:07,520 INFO] Step 41750/50000; acc:  89.41; ppl:  1.42; xent: 0.35; lr: 1.00000; 11415/12253 tok/s;   1914 sec\n",
            "[2020-06-02 03:34:09,872 INFO] Step 41800/50000; acc:  90.46; ppl:  1.38; xent: 0.33; lr: 1.00000; 15308/15184 tok/s;   1916 sec\n",
            "[2020-06-02 03:34:12,178 INFO] Step 41850/50000; acc:  90.13; ppl:  1.39; xent: 0.33; lr: 1.00000; 14729/14820 tok/s;   1919 sec\n",
            "[2020-06-02 03:34:14,350 INFO] Step 41900/50000; acc:  91.73; ppl:  1.32; xent: 0.27; lr: 1.00000; 15019/15437 tok/s;   1921 sec\n",
            "[2020-06-02 03:34:16,602 INFO] Step 41950/50000; acc:  90.68; ppl:  1.37; xent: 0.32; lr: 1.00000; 14443/14958 tok/s;   1923 sec\n",
            "[2020-06-02 03:34:18,726 INFO] Step 42000/50000; acc:  90.56; ppl:  1.37; xent: 0.32; lr: 1.00000; 14614/14351 tok/s;   1925 sec\n",
            "[2020-06-02 03:34:20,879 INFO] Step 42050/50000; acc:  90.20; ppl:  1.40; xent: 0.33; lr: 1.00000; 14612/14857 tok/s;   1927 sec\n",
            "[2020-06-02 03:34:23,168 INFO] Step 42100/50000; acc:  91.24; ppl:  1.34; xent: 0.30; lr: 1.00000; 14470/15113 tok/s;   1929 sec\n",
            "[2020-06-02 03:34:24,201 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:34:24,518 INFO] number of examples: 26141\n",
            "[2020-06-02 03:34:25,744 INFO] Step 42150/50000; acc:  90.48; ppl:  1.37; xent: 0.32; lr: 1.00000; 11262/12108 tok/s;   1932 sec\n",
            "[2020-06-02 03:34:28,048 INFO] Step 42200/50000; acc:  90.92; ppl:  1.35; xent: 0.30; lr: 1.00000; 14852/14976 tok/s;   1934 sec\n",
            "[2020-06-02 03:34:30,461 INFO] Step 42250/50000; acc:  89.36; ppl:  1.42; xent: 0.35; lr: 1.00000; 14813/14678 tok/s;   1937 sec\n",
            "[2020-06-02 03:34:32,705 INFO] Step 42300/50000; acc:  91.28; ppl:  1.34; xent: 0.29; lr: 1.00000; 14684/15352 tok/s;   1939 sec\n",
            "[2020-06-02 03:34:34,998 INFO] Step 42350/50000; acc:  91.58; ppl:  1.33; xent: 0.28; lr: 1.00000; 14327/15000 tok/s;   1941 sec\n",
            "[2020-06-02 03:34:37,063 INFO] Step 42400/50000; acc:  90.62; ppl:  1.37; xent: 0.32; lr: 1.00000; 14998/14329 tok/s;   1943 sec\n",
            "[2020-06-02 03:34:39,116 INFO] Step 42450/50000; acc:  91.87; ppl:  1.31; xent: 0.27; lr: 1.00000; 14607/15012 tok/s;   1945 sec\n",
            "[2020-06-02 03:34:41,515 INFO] Step 42500/50000; acc:  90.14; ppl:  1.40; xent: 0.33; lr: 1.00000; 14071/14675 tok/s;   1948 sec\n",
            "[2020-06-02 03:34:42,973 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:34:43,281 INFO] number of examples: 26141\n",
            "[2020-06-02 03:34:44,041 INFO] Step 42550/50000; acc:  90.56; ppl:  1.37; xent: 0.31; lr: 1.00000; 11989/12739 tok/s;   1950 sec\n",
            "[2020-06-02 03:34:46,381 INFO] Step 42600/50000; acc:  90.17; ppl:  1.39; xent: 0.33; lr: 1.00000; 14086/14580 tok/s;   1953 sec\n",
            "[2020-06-02 03:34:48,794 INFO] Step 42650/50000; acc:  89.74; ppl:  1.42; xent: 0.35; lr: 1.00000; 15193/14826 tok/s;   1955 sec\n",
            "[2020-06-02 03:34:50,984 INFO] Step 42700/50000; acc:  91.50; ppl:  1.33; xent: 0.28; lr: 1.00000; 14690/15429 tok/s;   1957 sec\n",
            "[2020-06-02 03:34:53,373 INFO] Step 42750/50000; acc:  91.40; ppl:  1.33; xent: 0.28; lr: 1.00000; 14333/14755 tok/s;   1960 sec\n",
            "[2020-06-02 03:34:55,340 INFO] Step 42800/50000; acc:  91.27; ppl:  1.34; xent: 0.29; lr: 1.00000; 14968/14302 tok/s;   1962 sec\n",
            "[2020-06-02 03:34:57,424 INFO] Step 42850/50000; acc:  91.59; ppl:  1.32; xent: 0.28; lr: 1.00000; 14925/15216 tok/s;   1964 sec\n",
            "[2020-06-02 03:34:59,852 INFO] Step 42900/50000; acc:  89.50; ppl:  1.43; xent: 0.36; lr: 1.00000; 14124/14778 tok/s;   1966 sec\n",
            "[2020-06-02 03:35:01,658 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:35:01,975 INFO] number of examples: 26141\n",
            "[2020-06-02 03:35:02,318 INFO] Step 42950/50000; acc:  91.90; ppl:  1.31; xent: 0.27; lr: 1.00000; 11709/12407 tok/s;   1969 sec\n",
            "[2020-06-02 03:35:04,784 INFO] Step 43000/50000; acc:  89.57; ppl:  1.41; xent: 0.34; lr: 1.00000; 14265/14716 tok/s;   1971 sec\n",
            "[2020-06-02 03:35:07,167 INFO] Step 43050/50000; acc:  90.24; ppl:  1.39; xent: 0.33; lr: 1.00000; 15069/14933 tok/s;   1973 sec\n",
            "[2020-06-02 03:35:09,306 INFO] Step 43100/50000; acc:  91.61; ppl:  1.32; xent: 0.28; lr: 1.00000; 14656/15234 tok/s;   1976 sec\n",
            "[2020-06-02 03:35:11,648 INFO] Step 43150/50000; acc:  91.09; ppl:  1.34; xent: 0.30; lr: 1.00000; 14504/14879 tok/s;   1978 sec\n",
            "[2020-06-02 03:35:13,562 INFO] Step 43200/50000; acc:  92.07; ppl:  1.30; xent: 0.26; lr: 1.00000; 14904/14749 tok/s;   1980 sec\n",
            "[2020-06-02 03:35:15,881 INFO] Step 43250/50000; acc:  90.82; ppl:  1.35; xent: 0.30; lr: 1.00000; 14729/14758 tok/s;   1982 sec\n",
            "[2020-06-02 03:35:18,130 INFO] Step 43300/50000; acc:  90.32; ppl:  1.39; xent: 0.33; lr: 1.00000; 14214/14949 tok/s;   1984 sec\n",
            "[2020-06-02 03:35:20,229 INFO] Step 43350/50000; acc:  91.09; ppl:  1.34; xent: 0.29; lr: 1.00000; 14201/14895 tok/s;   1987 sec\n",
            "[2020-06-02 03:35:20,376 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:35:20,611 INFO] number of examples: 26141\n",
            "[2020-06-02 03:35:23,065 INFO] Step 43400/50000; acc:  89.51; ppl:  1.41; xent: 0.34; lr: 1.00000; 12601/12905 tok/s;   1989 sec\n",
            "[2020-06-02 03:35:25,284 INFO] Step 43450/50000; acc:  90.58; ppl:  1.37; xent: 0.31; lr: 1.00000; 14766/15019 tok/s;   1992 sec\n",
            "[2020-06-02 03:35:27,510 INFO] Step 43500/50000; acc:  90.95; ppl:  1.35; xent: 0.30; lr: 1.00000; 14828/15053 tok/s;   1994 sec\n",
            "[2020-06-02 03:35:29,813 INFO] Step 43550/50000; acc:  91.56; ppl:  1.32; xent: 0.28; lr: 1.00000; 14836/15106 tok/s;   1996 sec\n",
            "[2020-06-02 03:35:31,813 INFO] Step 43600/50000; acc:  91.88; ppl:  1.31; xent: 0.27; lr: 1.00000; 14394/14792 tok/s;   1998 sec\n",
            "[2020-06-02 03:35:34,068 INFO] Step 43650/50000; acc:  90.65; ppl:  1.36; xent: 0.31; lr: 1.00000; 14859/14842 tok/s;   2000 sec\n",
            "[2020-06-02 03:35:36,318 INFO] Step 43700/50000; acc:  90.46; ppl:  1.38; xent: 0.32; lr: 1.00000; 14519/15040 tok/s;   2003 sec\n",
            "[2020-06-02 03:35:38,356 INFO] Step 43750/50000; acc:  91.95; ppl:  1.31; xent: 0.27; lr: 1.00000; 14327/14929 tok/s;   2005 sec\n",
            "[2020-06-02 03:35:38,946 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:35:39,233 INFO] number of examples: 26141\n",
            "[2020-06-02 03:35:41,186 INFO] Step 43800/50000; acc:  89.76; ppl:  1.40; xent: 0.34; lr: 1.00000; 11993/12589 tok/s;   2008 sec\n",
            "[2020-06-02 03:35:43,583 INFO] Step 43850/50000; acc:  90.46; ppl:  1.38; xent: 0.32; lr: 1.00000; 15213/14947 tok/s;   2010 sec\n",
            "[2020-06-02 03:35:45,730 INFO] Step 43900/50000; acc:  91.08; ppl:  1.34; xent: 0.29; lr: 1.00000; 14531/15066 tok/s;   2012 sec\n",
            "[2020-06-02 03:35:47,992 INFO] Step 43950/50000; acc:  91.57; ppl:  1.33; xent: 0.28; lr: 1.00000; 14885/15139 tok/s;   2014 sec\n",
            "[2020-06-02 03:35:50,151 INFO] Step 44000/50000; acc:  91.50; ppl:  1.33; xent: 0.28; lr: 1.00000; 14615/14955 tok/s;   2016 sec\n",
            "[2020-06-02 03:35:52,379 INFO] Step 44050/50000; acc:  90.63; ppl:  1.37; xent: 0.31; lr: 1.00000; 14538/14598 tok/s;   2019 sec\n",
            "[2020-06-02 03:35:54,601 INFO] Step 44100/50000; acc:  90.48; ppl:  1.38; xent: 0.32; lr: 1.00000; 14561/14802 tok/s;   2021 sec\n",
            "[2020-06-02 03:35:56,746 INFO] Step 44150/50000; acc:  91.74; ppl:  1.31; xent: 0.27; lr: 1.00000; 14450/15044 tok/s;   2023 sec\n",
            "[2020-06-02 03:35:57,617 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:35:57,903 INFO] number of examples: 26141\n",
            "[2020-06-02 03:35:59,414 INFO] Step 44200/50000; acc:  90.23; ppl:  1.39; xent: 0.33; lr: 1.00000; 11377/12195 tok/s;   2026 sec\n",
            "[2020-06-02 03:36:01,686 INFO] Step 44250/50000; acc:  92.01; ppl:  1.30; xent: 0.26; lr: 1.00000; 15180/15221 tok/s;   2028 sec\n",
            "[2020-06-02 03:36:04,089 INFO] Step 44300/50000; acc:  89.64; ppl:  1.42; xent: 0.35; lr: 1.00000; 15004/14843 tok/s;   2030 sec\n",
            "[2020-06-02 03:36:06,296 INFO] Step 44350/50000; acc:  92.31; ppl:  1.29; xent: 0.26; lr: 1.00000; 14704/15379 tok/s;   2033 sec\n",
            "[2020-06-02 03:36:08,548 INFO] Step 44400/50000; acc:  91.51; ppl:  1.33; xent: 0.28; lr: 1.00000; 14381/15015 tok/s;   2035 sec\n",
            "[2020-06-02 03:36:10,622 INFO] Step 44450/50000; acc:  91.36; ppl:  1.33; xent: 0.29; lr: 1.00000; 14972/14363 tok/s;   2037 sec\n",
            "[2020-06-02 03:36:12,805 INFO] Step 44500/50000; acc:  90.97; ppl:  1.35; xent: 0.30; lr: 1.00000; 14498/14736 tok/s;   2039 sec\n",
            "[2020-06-02 03:36:15,051 INFO] Step 44550/50000; acc:  91.47; ppl:  1.32; xent: 0.28; lr: 1.00000; 14229/15190 tok/s;   2041 sec\n",
            "[2020-06-02 03:36:16,286 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:36:16,579 INFO] number of examples: 26141\n",
            "[2020-06-02 03:36:17,626 INFO] Step 44600/50000; acc:  91.14; ppl:  1.35; xent: 0.30; lr: 1.00000; 11639/12223 tok/s;   2044 sec\n",
            "[2020-06-02 03:36:19,948 INFO] Step 44650/50000; acc:  91.10; ppl:  1.34; xent: 0.29; lr: 1.00000; 14573/15090 tok/s;   2046 sec\n",
            "[2020-06-02 03:36:22,285 INFO] Step 44700/50000; acc:  90.34; ppl:  1.38; xent: 0.32; lr: 1.00000; 15306/14822 tok/s;   2049 sec\n",
            "[2020-06-02 03:36:24,546 INFO] Step 44750/50000; acc:  91.80; ppl:  1.31; xent: 0.27; lr: 1.00000; 14542/15459 tok/s;   2051 sec\n",
            "[2020-06-02 03:36:26,904 INFO] Step 44800/50000; acc:  91.73; ppl:  1.32; xent: 0.28; lr: 1.00000; 14276/14746 tok/s;   2053 sec\n",
            "[2020-06-02 03:36:28,878 INFO] Step 44850/50000; acc:  91.46; ppl:  1.33; xent: 0.29; lr: 1.00000; 14885/14131 tok/s;   2055 sec\n",
            "[2020-06-02 03:36:30,931 INFO] Step 44900/50000; acc:  91.95; ppl:  1.30; xent: 0.26; lr: 1.00000; 14937/15404 tok/s;   2057 sec\n",
            "[2020-06-02 03:36:33,335 INFO] Step 44950/50000; acc:  89.88; ppl:  1.40; xent: 0.33; lr: 1.00000; 14237/14752 tok/s;   2060 sec\n",
            "[2020-06-02 03:36:34,973 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:36:35,268 INFO] number of examples: 26141\n",
            "[2020-06-02 03:36:35,822 INFO] Step 45000/50000; acc:  91.39; ppl:  1.32; xent: 0.28; lr: 1.00000; 11966/12635 tok/s;   2062 sec\n",
            "[2020-06-02 03:36:35,844 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_45000.pt\n",
            "[2020-06-02 03:36:38,545 INFO] Step 45050/50000; acc:  90.84; ppl:  1.36; xent: 0.31; lr: 1.00000; 12759/13221 tok/s;   2065 sec\n",
            "[2020-06-02 03:36:40,939 INFO] Step 45100/50000; acc:  90.13; ppl:  1.39; xent: 0.33; lr: 1.00000; 15080/14883 tok/s;   2067 sec\n",
            "[2020-06-02 03:36:43,075 INFO] Step 45150/50000; acc:  92.12; ppl:  1.30; xent: 0.26; lr: 1.00000; 14518/15153 tok/s;   2069 sec\n",
            "[2020-06-02 03:36:45,467 INFO] Step 45200/50000; acc:  91.74; ppl:  1.32; xent: 0.28; lr: 1.00000; 14320/14808 tok/s;   2072 sec\n",
            "[2020-06-02 03:36:47,558 INFO] Step 45250/50000; acc:  92.29; ppl:  1.28; xent: 0.25; lr: 1.00000; 13876/13287 tok/s;   2074 sec\n",
            "[2020-06-02 03:36:49,766 INFO] Step 45300/50000; acc:  90.98; ppl:  1.35; xent: 0.30; lr: 1.00000; 14657/14899 tok/s;   2076 sec\n",
            "[2020-06-02 03:36:52,012 INFO] Step 45350/50000; acc:  90.73; ppl:  1.37; xent: 0.31; lr: 1.00000; 14175/14961 tok/s;   2078 sec\n",
            "[2020-06-02 03:36:54,141 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:36:54,447 INFO] number of examples: 26141\n",
            "[2020-06-02 03:36:54,614 INFO] Step 45400/50000; acc:  91.37; ppl:  1.34; xent: 0.29; lr: 1.00000; 12052/12674 tok/s;   2081 sec\n",
            "[2020-06-02 03:36:57,111 INFO] Step 45450/50000; acc:  90.36; ppl:  1.38; xent: 0.33; lr: 1.00000; 14205/14569 tok/s;   2083 sec\n",
            "[2020-06-02 03:36:59,402 INFO] Step 45500/50000; acc:  90.39; ppl:  1.37; xent: 0.32; lr: 1.00000; 15004/15039 tok/s;   2086 sec\n",
            "[2020-06-02 03:37:01,544 INFO] Step 45550/50000; acc:  91.86; ppl:  1.32; xent: 0.27; lr: 1.00000; 14598/15041 tok/s;   2088 sec\n",
            "[2020-06-02 03:37:03,902 INFO] Step 45600/50000; acc:  91.79; ppl:  1.31; xent: 0.27; lr: 1.00000; 14983/15249 tok/s;   2090 sec\n",
            "[2020-06-02 03:37:05,846 INFO] Step 45650/50000; acc:  92.49; ppl:  1.27; xent: 0.24; lr: 1.00000; 14475/14641 tok/s;   2092 sec\n",
            "[2020-06-02 03:37:08,101 INFO] Step 45700/50000; acc:  91.09; ppl:  1.34; xent: 0.29; lr: 1.00000; 14891/14863 tok/s;   2094 sec\n",
            "[2020-06-02 03:37:10,366 INFO] Step 45750/50000; acc:  90.56; ppl:  1.38; xent: 0.32; lr: 1.00000; 14395/14959 tok/s;   2097 sec\n",
            "[2020-06-02 03:37:12,496 INFO] Step 45800/50000; acc:  91.60; ppl:  1.32; xent: 0.28; lr: 1.00000; 13996/14765 tok/s;   2099 sec\n",
            "[2020-06-02 03:37:12,805 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:37:13,111 INFO] number of examples: 26141\n",
            "[2020-06-02 03:37:15,337 INFO] Step 45850/50000; acc:  90.72; ppl:  1.36; xent: 0.31; lr: 1.00000; 12084/12384 tok/s;   2102 sec\n",
            "[2020-06-02 03:37:17,681 INFO] Step 45900/50000; acc:  90.58; ppl:  1.38; xent: 0.32; lr: 1.00000; 14827/15056 tok/s;   2104 sec\n",
            "[2020-06-02 03:37:19,873 INFO] Step 45950/50000; acc:  91.35; ppl:  1.33; xent: 0.29; lr: 1.00000; 14589/14852 tok/s;   2106 sec\n",
            "[2020-06-02 03:37:22,170 INFO] Step 46000/50000; acc:  91.49; ppl:  1.33; xent: 0.29; lr: 1.00000; 14903/15154 tok/s;   2108 sec\n",
            "[2020-06-02 03:37:24,202 INFO] Step 46050/50000; acc:  92.73; ppl:  1.27; xent: 0.24; lr: 1.00000; 14401/14803 tok/s;   2111 sec\n",
            "[2020-06-02 03:37:26,494 INFO] Step 46100/50000; acc:  91.05; ppl:  1.34; xent: 0.30; lr: 1.00000; 14576/14676 tok/s;   2113 sec\n",
            "[2020-06-02 03:37:28,757 INFO] Step 46150/50000; acc:  90.93; ppl:  1.36; xent: 0.31; lr: 1.00000; 14696/15005 tok/s;   2115 sec\n",
            "[2020-06-02 03:37:30,822 INFO] Step 46200/50000; acc:  92.51; ppl:  1.28; xent: 0.25; lr: 1.00000; 14202/14725 tok/s;   2117 sec\n",
            "[2020-06-02 03:37:31,552 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:37:31,864 INFO] number of examples: 26141\n",
            "[2020-06-02 03:37:33,630 INFO] Step 46250/50000; acc:  90.28; ppl:  1.39; xent: 0.33; lr: 1.00000; 11518/12242 tok/s;   2120 sec\n",
            "[2020-06-02 03:37:36,050 INFO] Step 46300/50000; acc:  90.97; ppl:  1.36; xent: 0.31; lr: 1.00000; 15076/14950 tok/s;   2122 sec\n",
            "[2020-06-02 03:37:38,309 INFO] Step 46350/50000; acc:  91.48; ppl:  1.32; xent: 0.28; lr: 1.00000; 14652/14850 tok/s;   2125 sec\n",
            "[2020-06-02 03:37:40,494 INFO] Step 46400/50000; acc:  92.54; ppl:  1.28; xent: 0.25; lr: 1.00000; 14789/15204 tok/s;   2127 sec\n",
            "[2020-06-02 03:37:42,743 INFO] Step 46450/50000; acc:  91.39; ppl:  1.33; xent: 0.29; lr: 1.00000; 14544/14921 tok/s;   2129 sec\n",
            "[2020-06-02 03:37:44,847 INFO] Step 46500/50000; acc:  91.74; ppl:  1.31; xent: 0.27; lr: 1.00000; 14637/14489 tok/s;   2131 sec\n",
            "[2020-06-02 03:37:47,025 INFO] Step 46550/50000; acc:  91.05; ppl:  1.35; xent: 0.30; lr: 1.00000; 14678/14872 tok/s;   2133 sec\n",
            "[2020-06-02 03:37:49,296 INFO] Step 46600/50000; acc:  91.77; ppl:  1.32; xent: 0.28; lr: 1.00000; 14444/15110 tok/s;   2136 sec\n",
            "[2020-06-02 03:37:50,285 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:37:50,606 INFO] number of examples: 26141\n",
            "[2020-06-02 03:37:51,854 INFO] Step 46650/50000; acc:  91.38; ppl:  1.33; xent: 0.29; lr: 1.00000; 11244/12146 tok/s;   2138 sec\n",
            "[2020-06-02 03:37:54,176 INFO] Step 46700/50000; acc:  91.64; ppl:  1.33; xent: 0.28; lr: 1.00000; 15008/15076 tok/s;   2141 sec\n",
            "[2020-06-02 03:37:56,545 INFO] Step 46750/50000; acc:  90.60; ppl:  1.38; xent: 0.32; lr: 1.00000; 14953/14816 tok/s;   2143 sec\n",
            "[2020-06-02 03:37:58,802 INFO] Step 46800/50000; acc:  92.31; ppl:  1.30; xent: 0.26; lr: 1.00000; 14744/15440 tok/s;   2145 sec\n",
            "[2020-06-02 03:38:01,042 INFO] Step 46850/50000; acc:  92.23; ppl:  1.30; xent: 0.26; lr: 1.00000; 14519/15120 tok/s;   2147 sec\n",
            "[2020-06-02 03:38:03,091 INFO] Step 46900/50000; acc:  91.22; ppl:  1.34; xent: 0.30; lr: 1.00000; 14806/14257 tok/s;   2149 sec\n",
            "[2020-06-02 03:38:05,158 INFO] Step 46950/50000; acc:  92.55; ppl:  1.28; xent: 0.25; lr: 1.00000; 14786/15188 tok/s;   2151 sec\n",
            "[2020-06-02 03:38:07,506 INFO] Step 47000/50000; acc:  90.75; ppl:  1.37; xent: 0.31; lr: 1.00000; 14348/15021 tok/s;   2154 sec\n",
            "[2020-06-02 03:38:08,922 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:38:09,254 INFO] number of examples: 26141\n",
            "[2020-06-02 03:38:10,032 INFO] Step 47050/50000; acc:  91.38; ppl:  1.33; xent: 0.28; lr: 1.00000; 11782/12481 tok/s;   2156 sec\n",
            "[2020-06-02 03:38:12,403 INFO] Step 47100/50000; acc:  91.23; ppl:  1.34; xent: 0.29; lr: 1.00000; 14197/14630 tok/s;   2159 sec\n",
            "[2020-06-02 03:38:14,772 INFO] Step 47150/50000; acc:  90.95; ppl:  1.36; xent: 0.30; lr: 1.00000; 15372/14999 tok/s;   2161 sec\n",
            "[2020-06-02 03:38:16,947 INFO] Step 47200/50000; acc:  92.53; ppl:  1.28; xent: 0.25; lr: 1.00000; 14610/15432 tok/s;   2163 sec\n",
            "[2020-06-02 03:38:19,312 INFO] Step 47250/50000; acc:  91.92; ppl:  1.30; xent: 0.27; lr: 1.00000; 14538/14919 tok/s;   2166 sec\n",
            "[2020-06-02 03:38:21,310 INFO] Step 47300/50000; acc:  91.78; ppl:  1.31; xent: 0.27; lr: 1.00000; 15148/14533 tok/s;   2168 sec\n",
            "[2020-06-02 03:38:23,397 INFO] Step 47350/50000; acc:  92.34; ppl:  1.28; xent: 0.25; lr: 1.00000; 14629/14941 tok/s;   2170 sec\n",
            "[2020-06-02 03:38:25,829 INFO] Step 47400/50000; acc:  90.42; ppl:  1.38; xent: 0.32; lr: 1.00000; 14131/14758 tok/s;   2172 sec\n",
            "[2020-06-02 03:38:27,621 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:38:27,844 INFO] number of examples: 26141\n",
            "[2020-06-02 03:38:28,217 INFO] Step 47450/50000; acc:  92.29; ppl:  1.29; xent: 0.25; lr: 1.00000; 11954/12674 tok/s;   2175 sec\n",
            "[2020-06-02 03:38:30,708 INFO] Step 47500/50000; acc:  90.57; ppl:  1.37; xent: 0.31; lr: 1.00000; 14357/14803 tok/s;   2177 sec\n",
            "[2020-06-02 03:38:33,078 INFO] Step 47550/50000; acc:  90.90; ppl:  1.35; xent: 0.30; lr: 1.00000; 14964/14773 tok/s;   2179 sec\n",
            "[2020-06-02 03:38:35,211 INFO] Step 47600/50000; acc:  92.45; ppl:  1.28; xent: 0.25; lr: 1.00000; 14539/15178 tok/s;   2182 sec\n",
            "[2020-06-02 03:38:37,604 INFO] Step 47650/50000; acc:  92.12; ppl:  1.30; xent: 0.26; lr: 1.00000; 14412/14853 tok/s;   2184 sec\n",
            "[2020-06-02 03:38:39,504 INFO] Step 47700/50000; acc:  92.69; ppl:  1.27; xent: 0.24; lr: 1.00000; 15016/14699 tok/s;   2186 sec\n",
            "[2020-06-02 03:38:41,781 INFO] Step 47750/50000; acc:  91.81; ppl:  1.31; xent: 0.27; lr: 1.00000; 14775/14860 tok/s;   2188 sec\n",
            "[2020-06-02 03:38:44,014 INFO] Step 47800/50000; acc:  91.37; ppl:  1.33; xent: 0.29; lr: 1.00000; 14316/15056 tok/s;   2190 sec\n",
            "[2020-06-02 03:38:46,131 INFO] Step 47850/50000; acc:  92.13; ppl:  1.30; xent: 0.26; lr: 1.00000; 14201/14888 tok/s;   2192 sec\n",
            "[2020-06-02 03:38:46,248 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:38:46,536 INFO] number of examples: 26141\n",
            "[2020-06-02 03:38:49,034 INFO] Step 47900/50000; acc:  90.87; ppl:  1.35; xent: 0.30; lr: 1.00000; 12332/12674 tok/s;   2195 sec\n",
            "[2020-06-02 03:38:51,275 INFO] Step 47950/50000; acc:  91.46; ppl:  1.32; xent: 0.28; lr: 1.00000; 14826/15076 tok/s;   2198 sec\n",
            "[2020-06-02 03:38:53,465 INFO] Step 48000/50000; acc:  91.78; ppl:  1.32; xent: 0.27; lr: 1.00000; 14954/15065 tok/s;   2200 sec\n",
            "[2020-06-02 03:38:55,787 INFO] Step 48050/50000; acc:  92.17; ppl:  1.30; xent: 0.26; lr: 1.00000; 14963/15231 tok/s;   2202 sec\n",
            "[2020-06-02 03:38:57,793 INFO] Step 48100/50000; acc:  93.13; ppl:  1.25; xent: 0.23; lr: 1.00000; 14153/14613 tok/s;   2204 sec\n",
            "[2020-06-02 03:39:00,083 INFO] Step 48150/50000; acc:  91.72; ppl:  1.32; xent: 0.28; lr: 1.00000; 14692/14675 tok/s;   2206 sec\n",
            "[2020-06-02 03:39:02,324 INFO] Step 48200/50000; acc:  91.13; ppl:  1.34; xent: 0.29; lr: 1.00000; 14377/14900 tok/s;   2209 sec\n",
            "[2020-06-02 03:39:04,396 INFO] Step 48250/50000; acc:  92.56; ppl:  1.27; xent: 0.24; lr: 1.00000; 14309/14940 tok/s;   2211 sec\n",
            "[2020-06-02 03:39:04,921 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:39:05,223 INFO] number of examples: 26141\n",
            "[2020-06-02 03:39:07,264 INFO] Step 48300/50000; acc:  90.78; ppl:  1.35; xent: 0.30; lr: 1.00000; 11869/12386 tok/s;   2214 sec\n",
            "[2020-06-02 03:39:09,632 INFO] Step 48350/50000; acc:  91.37; ppl:  1.34; xent: 0.29; lr: 1.00000; 15300/15114 tok/s;   2216 sec\n",
            "[2020-06-02 03:39:11,755 INFO] Step 48400/50000; acc:  92.06; ppl:  1.30; xent: 0.26; lr: 1.00000; 14489/15054 tok/s;   2218 sec\n",
            "[2020-06-02 03:39:14,017 INFO] Step 48450/50000; acc:  92.53; ppl:  1.29; xent: 0.25; lr: 1.00000; 14994/15191 tok/s;   2220 sec\n",
            "[2020-06-02 03:39:16,166 INFO] Step 48500/50000; acc:  92.78; ppl:  1.28; xent: 0.24; lr: 1.00000; 14717/15033 tok/s;   2222 sec\n",
            "[2020-06-02 03:39:18,375 INFO] Step 48550/50000; acc:  91.54; ppl:  1.33; xent: 0.28; lr: 1.00000; 14461/14574 tok/s;   2225 sec\n",
            "[2020-06-02 03:39:20,617 INFO] Step 48600/50000; acc:  91.68; ppl:  1.33; xent: 0.28; lr: 1.00000; 14605/14815 tok/s;   2227 sec\n",
            "[2020-06-02 03:39:22,751 INFO] Step 48650/50000; acc:  92.55; ppl:  1.28; xent: 0.24; lr: 1.00000; 14555/15064 tok/s;   2229 sec\n",
            "[2020-06-02 03:39:23,576 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:39:23,867 INFO] number of examples: 26141\n",
            "[2020-06-02 03:39:25,432 INFO] Step 48700/50000; acc:  90.62; ppl:  1.37; xent: 0.31; lr: 1.00000; 11464/12321 tok/s;   2232 sec\n",
            "[2020-06-02 03:39:27,715 INFO] Step 48750/50000; acc:  92.36; ppl:  1.29; xent: 0.25; lr: 1.00000; 15216/15201 tok/s;   2234 sec\n",
            "[2020-06-02 03:39:30,124 INFO] Step 48800/50000; acc:  90.96; ppl:  1.35; xent: 0.30; lr: 1.00000; 14702/14710 tok/s;   2236 sec\n",
            "[2020-06-02 03:39:32,318 INFO] Step 48850/50000; acc:  92.86; ppl:  1.26; xent: 0.23; lr: 1.00000; 14791/15278 tok/s;   2239 sec\n",
            "[2020-06-02 03:39:34,570 INFO] Step 48900/50000; acc:  92.18; ppl:  1.29; xent: 0.26; lr: 1.00000; 14328/15030 tok/s;   2241 sec\n",
            "[2020-06-02 03:39:36,653 INFO] Step 48950/50000; acc:  91.82; ppl:  1.31; xent: 0.27; lr: 1.00000; 14840/14353 tok/s;   2243 sec\n",
            "[2020-06-02 03:39:38,835 INFO] Step 49000/50000; acc:  91.67; ppl:  1.32; xent: 0.28; lr: 1.00000; 14649/14814 tok/s;   2245 sec\n",
            "[2020-06-02 03:39:41,092 INFO] Step 49050/50000; acc:  92.10; ppl:  1.30; xent: 0.26; lr: 1.00000; 14337/15199 tok/s;   2247 sec\n",
            "[2020-06-02 03:39:42,262 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:39:42,562 INFO] number of examples: 26141\n",
            "[2020-06-02 03:39:43,654 INFO] Step 49100/50000; acc:  91.81; ppl:  1.31; xent: 0.27; lr: 1.00000; 11595/12196 tok/s;   2250 sec\n",
            "[2020-06-02 03:39:45,926 INFO] Step 49150/50000; acc:  92.14; ppl:  1.30; xent: 0.26; lr: 1.00000; 14559/15154 tok/s;   2252 sec\n",
            "[2020-06-02 03:39:48,307 INFO] Step 49200/50000; acc:  91.01; ppl:  1.35; xent: 0.30; lr: 1.00000; 15385/14860 tok/s;   2255 sec\n",
            "[2020-06-02 03:39:50,521 INFO] Step 49250/50000; acc:  92.73; ppl:  1.27; xent: 0.24; lr: 1.00000; 14777/15666 tok/s;   2257 sec\n",
            "[2020-06-02 03:39:52,858 INFO] Step 49300/50000; acc:  92.38; ppl:  1.29; xent: 0.26; lr: 1.00000; 14212/14782 tok/s;   2259 sec\n",
            "[2020-06-02 03:39:54,854 INFO] Step 49350/50000; acc:  92.27; ppl:  1.29; xent: 0.25; lr: 1.00000; 14846/14068 tok/s;   2261 sec\n",
            "[2020-06-02 03:39:56,917 INFO] Step 49400/50000; acc:  93.00; ppl:  1.26; xent: 0.23; lr: 1.00000; 14832/15328 tok/s;   2263 sec\n",
            "[2020-06-02 03:39:59,317 INFO] Step 49450/50000; acc:  90.95; ppl:  1.36; xent: 0.30; lr: 1.00000; 14292/14755 tok/s;   2266 sec\n",
            "[2020-06-02 03:40:00,911 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:40:01,220 INFO] number of examples: 26141\n",
            "[2020-06-02 03:40:01,814 INFO] Step 49500/50000; acc:  92.09; ppl:  1.29; xent: 0.25; lr: 1.00000; 11790/12556 tok/s;   2268 sec\n",
            "[2020-06-02 03:40:04,275 INFO] Step 49550/50000; acc:  91.45; ppl:  1.33; xent: 0.28; lr: 1.00000; 14065/14567 tok/s;   2271 sec\n",
            "[2020-06-02 03:40:06,683 INFO] Step 49600/50000; acc:  91.31; ppl:  1.33; xent: 0.29; lr: 1.00000; 15178/14915 tok/s;   2273 sec\n",
            "[2020-06-02 03:40:08,822 INFO] Step 49650/50000; acc:  92.76; ppl:  1.27; xent: 0.24; lr: 1.00000; 14650/15332 tok/s;   2275 sec\n",
            "[2020-06-02 03:40:11,180 INFO] Step 49700/50000; acc:  92.74; ppl:  1.27; xent: 0.24; lr: 1.00000; 14414/14865 tok/s;   2278 sec\n",
            "[2020-06-02 03:40:13,075 INFO] Step 49750/50000; acc:  92.88; ppl:  1.26; xent: 0.23; lr: 1.00000; 15083/14467 tok/s;   2279 sec\n",
            "[2020-06-02 03:40:15,290 INFO] Step 49800/50000; acc:  92.09; ppl:  1.30; xent: 0.26; lr: 1.00000; 14720/14932 tok/s;   2282 sec\n",
            "[2020-06-02 03:40:17,533 INFO] Step 49850/50000; acc:  91.51; ppl:  1.33; xent: 0.28; lr: 1.00000; 14198/15106 tok/s;   2284 sec\n",
            "[2020-06-02 03:40:19,614 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.train.0.pt\n",
            "[2020-06-02 03:40:19,917 INFO] number of examples: 26141\n",
            "[2020-06-02 03:40:20,123 INFO] Step 49900/50000; acc:  92.07; ppl:  1.30; xent: 0.26; lr: 1.00000; 12026/12536 tok/s;   2286 sec\n",
            "[2020-06-02 03:40:22,614 INFO] Step 49950/50000; acc:  91.54; ppl:  1.32; xent: 0.28; lr: 1.00000; 14327/14728 tok/s;   2289 sec\n",
            "[2020-06-02 03:40:24,904 INFO] Step 50000/50000; acc:  91.56; ppl:  1.33; xent: 0.29; lr: 0.50000; 14953/14988 tok/s;   2291 sec\n",
            "[2020-06-02 03:40:24,904 INFO] Loading dataset from En2Fa-Translation/BPE_Cleaned.valid.0.pt\n",
            "[2020-06-02 03:40:24,908 INFO] number of examples: 276\n",
            "[2020-06-02 03:40:25,187 INFO] Validation perplexity: 455.051\n",
            "[2020-06-02 03:40:25,187 INFO] Validation accuracy: 42.5389\n",
            "[2020-06-02 03:40:25,209 INFO] Saving checkpoint En2Fa-Translation/with_bpe_rnn_model_step_50000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT0oxZiXJAQy",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ajbhtBN7-Rt",
        "colab_type": "code",
        "outputId": "810aa540-8518-423c-c77e-47af4e6cd69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python OpenNMT-py/translate.py -model En2Fa-Translation/with_bpe_rnn_model_step_50000.pt -src En2Fa-Translation/Test/Q2test.en -output En2Fa-Translation/BPEpred.txt -replace_unk -verbose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 03:46:51,736 INFO] Translating shard 0.\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "\n",
            "SENT 1: ['hello', ',', 'do', 'we', 'drive', 'together', 'to', 'Hanover', 'on', 'the', 'twenty-eighth', 'of', 'March', '?']\n",
            "PRED 1: سلام ، ما میتوانیم تا Hanover در دفترم Hanover ؟\n",
            "PRED SCORE: -3.7620\n",
            "\n",
            "SENT 2: ['it', 'is', 'more', 'comfortable', 'by', 'train', '.']\n",
            "PRED 2: این به تعداد زمانی نزدیک است .\n",
            "PRED SCORE: -1.8948\n",
            "\n",
            "SENT 3: ['do', 'you', 'go', 'by', 'car', 'and', 'I', 'go', 'by', 'train', '?']\n",
            "PRED 3: آیا شما با قطار و من پرواز میکنم ؟\n",
            "PRED SCORE: -3.3481\n",
            "\n",
            "SENT 4: ['I', 'would', 'like', 'to', 'go', 'by', 'train', '.', 'and', 'what', 'would', 'you', 'like', '?']\n",
            "PRED 4: من مایلم با قطار . و چه موقع . شما چه ترجیح میدهید ؟\n",
            "PRED SCORE: -1.9212\n",
            "\n",
            "SENT 5: ['if', 'we', 'take', 'the', '$I-$C-$E', 'train', 'at', 'six', 'past', 'seven', ',', 'we', 'will', 'arrive', 'at', 'twenty-@@', 'five', 'past', 'eight', '.']\n",
            "PRED 5: اگر ما قطار ساعت شش بعد از ساعت شش ، ما حرکت کنیم تا پنج و نیم ساعت پنج .\n",
            "PRED SCORE: -2.0634\n",
            "\n",
            "SENT 6: ['which', 'cafe', '?']\n",
            "PRED 6: که که کجاست ؟\n",
            "PRED SCORE: -1.5758\n",
            "\n",
            "SENT 7: ['the', 'cafe', 'at', 'pla@@', 't@@', 'form', 'fourteen', '.']\n",
            "PRED 7: صبحانه میتوانند به خانه برسیم .\n",
            "PRED SCORE: -2.6353\n",
            "\n",
            "SENT 8: ['in', 'any', 'case', 'a', 'che@@', 'a@@', 'p', 'hotel', '.']\n",
            "PRED 8: در هر حال یک مقدمات است .\n",
            "PRED SCORE: -3.6498\n",
            "\n",
            "SENT 9: ['what', 'did', 'you', 'say', ',', 'please', '?']\n",
            "PRED 9: ببخشید چی شما را میبینم ؟\n",
            "PRED SCORE: -0.8596\n",
            "\n",
            "SENT 10: ['and', 'how', 'much', 'is', 'a', 'single', 'room', '?']\n",
            "PRED 10: و چه موقع یک اتاق وجود دارد ؟\n",
            "PRED SCORE: -0.8961\n",
            "\n",
            "SENT 11: ['we', 'can', 'take', 'a', 'taxi', 'from', 'the', 'station', 'to', 'the', 'hotel', '.']\n",
            "PRED 11: میتوانیم از ایستگاه central میتوانیم از ایستگاه انتخاب کنیم .\n",
            "PRED SCORE: -2.3230\n",
            "\n",
            "SENT 12: ['at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'a', 'room', 'now', 'and', 'how', 'much', 'is', 'a', 'single', 'room', '?']\n",
            "PRED 12: در واقع شما میخواهید که آنها را انجام دهید حالا چطور است و چه موقع اتاق است ؟\n",
            "PRED SCORE: -4.4586\n",
            "\n",
            "SENT 13: ['okay', ',', 'should', 'we', 'drive', 'back', 'on', 'Friday', 'evening', '?']\n",
            "PRED 13: باشه ، باید جمعه عصر ما به آنجا برویم ؟\n",
            "PRED SCORE: -3.0878\n",
            "\n",
            "SENT 14: ['I', 'think', 'we', 'rather', 'drive', 'back', 'at', 'thir@@', 'ty-@@', 'three', 'past', 'nine', 'then', 'we', 'will', 'arrive', 'at', 'Hamburg', 'at', 'fif@@', 'ty-@@', 'two', 'past', 'ten', '.']\n",
            "PRED 14: من فکر میکنم ما تقریبا نزدیک سه و نیم ساعت را باقی میگذارد ما ساعت دو و نیم است .\n",
            "PRED SCORE: -7.0908\n",
            "\n",
            "SENT 15: ['fine', 'and', \"don't\", 'forget', 'your', 'swimming', 'stuff', ',', 'maybe', 'we', 'can', 'go', 'swimming', 'together', '.']\n",
            "PRED 15: بسیار خوب . البته اگر ما میتوانیم با هم به بیرون برویم .\n",
            "PRED SCORE: -4.2422\n",
            "\n",
            "SENT 16: ['yes', '.', 'when', 'and', 'where', 'do', 'we', 'want', 'to', 'meet', '?']\n",
            "PRED 16: بله . چه موقع ما میخواهیم ملاقات کنیم ؟\n",
            "PRED SCORE: -1.8258\n",
            "\n",
            "SENT 17: ['I', 'prefer', 'the', 'plane', '.']\n",
            "PRED 17: من مراقب را را ترجیح میدهم .\n",
            "PRED SCORE: -0.7644\n",
            "\n",
            "SENT 18: ['a', 'good', 'idea', '.', 'then', 'we', 'will', 'meet', 'at', 'the', 'airport', 'tomorrow', '.']\n",
            "PRED 18: خوبی بنظر میرسد . بنابراین ما همدیگر را راس ظهر ملاقات خواهیم کرد .\n",
            "PRED SCORE: -3.4189\n",
            "\n",
            "SENT 19: ['no', 'idea', '.', 'we', 'will', 'see', '.', 'it', 'does', 'not', 'matter', '.']\n",
            "PRED 19: فکر . . آن fun عملی نیست .\n",
            "PRED SCORE: -2.3986\n",
            "\n",
            "SENT 20: ['good', '.', 'let', 'us', 'meet', 'at', 'nine', \"o'clock\", '.', 'hopefully', 'the', 'plane', \"won't\", 'be', 'hi@@', 'j@@', 'ac@@', 'ked', 'tomorrow', '.']\n",
            "PRED 20: خوب است . اجازه بدهید ساعت نه . ساعت نه رستوران زودترینی است .\n",
            "PRED SCORE: -4.8571\n",
            "\n",
            "SENT 21: ['I', 'have', 'already', 'booked', 'two', 'rooms', 'at', 'the', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '.']\n",
            "PRED 21: من پیشاپیش دراین و جایی که ع@@ ع@@ و راضی بودم .\n",
            "PRED SCORE: -8.5745\n",
            "\n",
            "SENT 22: ['what', 'did', 'you', 'say', '?']\n",
            "PRED 22: نظر شما چیست ؟\n",
            "PRED SCORE: -0.1485\n",
            "\n",
            "SENT 23: ['yes', '.', 'we', 'have', 'two', 'rooms', 'at', 'the', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '.', 'I', 'will', 'reserve', 'a', 'taxi', 'right', 'now', '.']\n",
            "PRED 23: بله . ما ساعت دو ما در پیتسبرگ مراقب رزرواسیون هستم و من نام شما را مینویسم .\n",
            "PRED SCORE: -6.0725\n",
            "\n",
            "SENT 24: ['what', 'is', 'planned', 'for', 'the', 'evening', '?']\n",
            "PRED 24: برنامه شما برای عصر چیست ؟\n",
            "PRED SCORE: -0.5772\n",
            "\n",
            "SENT 25: ['a', 'good', 'idea', '.', 'I', 'have', 'heard', ',', 'P@@', 'han@@', 'to@@', 'm', 'of', 'the', 'opera', 'is', 'supposed', 'to', 'be', 'pla@@', 'yed', '.']\n",
            "PRED 25: ایده خوبی . فکر کنم ، درباره نخواهید دی اف چه شده است .\n",
            "PRED SCORE: -9.6279\n",
            "\n",
            "SENT 26: ['fine', '.', 'I', 'think', 'we', 'have', 'arranged', 'everything', '.', 'then', 'we', 'will', 'meet', 'tomorrow', '.']\n",
            "PRED 26: خوب است . من فکر میکنم ما همدیگر را ملاقات کنیم . فردا ساعت یک .\n",
            "PRED SCORE: -3.1877\n",
            "\n",
            "SENT 27: ['hello', '.', 'we', 'have', 'to', 'talk', 'about', 'our', 'trip', 'to', 'Hanover', '.']\n",
            "PRED 27: سلام . من باید صحبت کنیم تا در مورد سفر صحبت کنیم .\n",
            "PRED SCORE: -1.5838\n",
            "\n",
            "SENT 28: ['right', '.', 'we', 'will', 'be', 'at', 'the', 'E@@', 'x@@', 'p@@', 'o', 'two', 'th@@', 'ous@@', 'and', 'in', 'Hanover', 'on', 'the', 'fourth', 'and', 'fifth', 'of', 'September', '.']\n",
            "PRED 28: خوب است . ما همدیگر را در آن زمان و در چهارم و پنجم سپتامبر در شهر خواهم بود و سپتامبر .\n",
            "PRED SCORE: -5.2208\n",
            "\n",
            "SENT 29: ['I', 'have', 'already', 'booked', 'a', 'flight', '.']\n",
            "PRED 29: من قبلا asked پرواز .\n",
            "PRED SCORE: -1.0564\n",
            "\n",
            "SENT 30: ['we', 'will', 'set', 'off', 'at', 'a', 'quarter', 'past', 'eight', 'and', 'arrive', 'at', 'Hanover', 'at', 'twelve', \"o'clock\", '.']\n",
            "PRED 30: ما وجود دارد ساعت یک و نیم ساعت دوازده و بعد از ساعت دوازده .\n",
            "PRED SCORE: -1.0948\n",
            "\n",
            "SENT 31: ['we', 'will', 'have', 'to', 'meet', 'at', 'the', 'airport', 'at', 'seven', \"o'clock\", '.']\n",
            "PRED 31: ما باید ساعت هفت در دفتر شما همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -1.1342\n",
            "\n",
            "SENT 32: ['we', 'arrive', 'at', 'Hanover', 'at', 'twelve', \"o'clock\", 'midday', '.']\n",
            "PRED 32: ما ساعت دوازده Hanover .\n",
            "PRED SCORE: -1.2400\n",
            "\n",
            "SENT 33: ['fine', '.', 'which', 'hotel', 'do', 'you', 'have', 'in', 'mind', '?']\n",
            "PRED 33: خوب . میتوانی شما درباره آن چه نظری دارید ؟\n",
            "PRED SCORE: -3.9855\n",
            "\n",
            "SENT 34: ['the', 'In@@', 'ter@@', 'con@@', 'tin@@', 'en@@', 'tal', 'is', 'my', 'fav@@', 'ou@@', 'ri@@', 'te', 'hotel', 'in', 'Hanover', '.']\n",
            "PRED 34: جای های زیادی خارج از همکار است ، دفتر من است .\n",
            "PRED SCORE: -6.0010\n",
            "\n",
            "SENT 35: ['thank', 'you', '.', 'how', 'do', 'we', 'go', 'back', 'again', 'to', 'Hamburg', '?']\n",
            "PRED 35: متشکرم . شما دوباره برمیگردید ؟\n",
            "PRED SCORE: -2.5297\n",
            "\n",
            "SENT 36: ['we', 'will', 'go', 'back', 'by', 'train', 'on', 'the', 'fifth', 'of', 'September', '.']\n",
            "PRED 36: ما آنجا از پنجم سپتامبر به بعد خواهیم رفت .\n",
            "PRED SCORE: -0.8776\n",
            "\n",
            "SENT 37: ['the', 'best', 'thing', 'is', 'we', 'meet', 'at', 'the', 'train', 'station', 'at', 'eight', \"o'clock\", '.']\n",
            "PRED 37: بهترین چیزی است که ما همدیگر را ساعت هشت در ایستگاه ملاقات کنیم .\n",
            "PRED SCORE: -2.6478\n",
            "\n",
            "SENT 38: ['exactly', '.', 'the', 'train', 'leaves', 'Hanover', 'at', 'six', 'minutes', 'after', 'eight', '.']\n",
            "PRED 38: دقیقا . بین ساعت شش نزدیک ایستگاه اصلی قطار ،\n",
            "PRED SCORE: -3.7063\n",
            "\n",
            "SENT 39: ['we', 'leave', 'Hanover', 'at', 'eight', \"o'clock\", 'and', 'arrive', 'at', 'Hamburg', 'at', 'half', 'past', 'nine', '.']\n",
            "PRED 39: ما ساعت هشت بعد از ساعت هشت و نیم است و نیم .\n",
            "PRED SCORE: -1.4448\n",
            "\n",
            "SENT 40: ['goodbye', '.']\n",
            "PRED 40: خداحافظ .\n",
            "PRED SCORE: -0.3973\n",
            "\n",
            "SENT 41: ['I', 'would', 'prefer', 'to', 'fly', '.']\n",
            "PRED 41: من ترجیح میدهم که پرواز میکنم .\n",
            "PRED SCORE: -0.8657\n",
            "\n",
            "SENT 42: ['yes', ',', 'there', 'is', 'a', 'flight', 'at', 'a', 'quarter', 'past', 'nine', '.']\n",
            "PRED 42: بله ، یک ساعت شش بعد از ساعت نه .\n",
            "PRED SCORE: -2.1718\n",
            "\n",
            "SENT 43: ['the', 'plane', 'arri@@', 'ves', 'in', 'Hanover', 'at', 'twenty-@@', 'five', 'past', 'twelve', '.']\n",
            "PRED 43: flights در هتل Hanover پنج بعد از پنج .\n",
            "PRED SCORE: -3.1103\n",
            "\n",
            "SENT 44: ['I', 'did', 'not', 'understand', ',', 'what', 'you', 'said', 'about', 'the', 'hotel', '.']\n",
            "PRED 44: من نمیدانم ، چه احساسی درباره آن است .\n",
            "PRED SCORE: -2.3498\n",
            "\n",
            "SENT 45: ['yes', ',', 'would', 'you', 'please', 'book', 'two', 'rooms', '.']\n",
            "PRED 45: بله ، میتوانید دو ساعتی را پیشنهاد کنید .\n",
            "PRED SCORE: -2.8542\n",
            "\n",
            "SENT 46: ['the', 'single', 'room', 'costs', 'a', 'hundred', 'D@@', 'e@@', 'ut@@', 'sch@@', '-@@', 'marks', '.', 'did', 'I', 'understand', 'you', 'right', '?']\n",
            "PRED 46: ما هنوز یک اتاق e-mai@@ l every@@ تی را دارم . آیا شما درست در است ؟\n",
            "PRED SCORE: -8.7072\n",
            "\n",
            "SENT 47: ['where', 'is', 'this', 'hotel', '?']\n",
            "PRED 47: کجا کجاست ؟\n",
            "PRED SCORE: -0.1572\n",
            "\n",
            "SENT 48: ['when', 'do', 'we', 'meet', '?']\n",
            "PRED 48: چه زمانی همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -0.9137\n",
            "\n",
            "SENT 49: ['yes', ',', 'would', 'you', 'please', 'book', 'this', 'hotel', '.']\n",
            "PRED 49: بله ، آیا این درباره این بستگی دارد .\n",
            "PRED SCORE: -1.5471\n",
            "\n",
            "SENT 50: ['please', 'repeat', 'this', 'once', 'again', '.']\n",
            "PRED 50: لطفا دوباره این را هماهنگ کنید .\n",
            "PRED SCORE: -1.5796\n",
            "\n",
            "SENT 51: ['do', 'you', 'mean', 'you', 'always', 'stay', 'there', '?']\n",
            "PRED 51: منظورتان منظورتان اولویتی دارید ؟\n",
            "PRED SCORE: -0.1699\n",
            "\n",
            "SENT 52: ['fine', ',', 'would', 'you', 'like', 'to', 'do', 'something', 'in', 'the', 'evening', '?']\n",
            "PRED 52: خوب ، آیا شما دوست دارید عصر دیگری باشد ؟\n",
            "PRED SCORE: -2.3534\n",
            "\n",
            "SENT 53: ['unfortunately', 'I', 'did', 'not', 'understand', 'you', '.', 'would', 'you', 'like', 'to', 'go', 'to', 'the', 'cinema', '?']\n",
            "PRED 53: متاسفانه من نمیدانم . آیا شما میتوانید به سینما مایل هستید ؟\n",
            "PRED SCORE: -3.0450\n",
            "\n",
            "SENT 54: ['would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'afterwards', '?']\n",
            "PRED 54: آیا میتوانید بعد از آن برای یک ناهار مایل باشید ؟\n",
            "PRED SCORE: -1.7081\n",
            "\n",
            "SENT 55: ['we', 'still', 'have', 'to', 'plan', 'our', 'return', 'trip', '.']\n",
            "PRED 55: ما هنوز باید برای سفر تجاریمان مقدمات را تهیه کنیم .\n",
            "PRED SCORE: -0.5598\n",
            "\n",
            "SENT 56: ['when', 'do', 'we', 'want', 'to', 'travel', 'back', 'to', 'Hamburg', '?']\n",
            "PRED 56: چه موقع میخواهیم دور هم جمع شویم ؟\n",
            "PRED SCORE: -2.2367\n",
            "\n",
            "SENT 57: ['could', 'you', 'repeat', 'that', 'once', 'again', 'please', '?']\n",
            "PRED 57: میشود دوباره اسمتان را تکرار کنید ؟\n",
            "PRED SCORE: -0.8030\n",
            "\n",
            "SENT 58: ['yes', ',', 'I', 'agree', '.', 'should', 'we', 'also', 'fly', 'back', 'or', 'go', 'by', 'train', '?']\n",
            "PRED 58: بله ، من هم don't . آیا ما باید پرواز میکنم ؟\n",
            "PRED SCORE: -3.8142\n",
            "\n",
            "SENT 59: ['there', 'is', 'a', 'flight', 'leaving', 'Hanover', 'at', 'a', 'quarter', 'past', 'seven', '$P-$M', '.']\n",
            "PRED 59: پرواز Hanover Hanover ساعت یک ربع و یک ربع بعد از ظهر .\n",
            "PRED SCORE: -1.9304\n",
            "\n",
            "SENT 60: ['fine', ',', 'shall', 'I', 'book', 'this', 'flight', '?']\n",
            "PRED 60: خوب است ، من از قبل این را تایید میکنم ؟\n",
            "PRED SCORE: -2.1974\n",
            "\n",
            "SENT 61: ['goodbye', '.']\n",
            "PRED 61: خداحافظ .\n",
            "PRED SCORE: -0.3973\n",
            "\n",
            "SENT 62: ['no', ',', 'we', 'go', 'on', 'the', 'twenty-third', '.']\n",
            "PRED 62: نه ، ما باید به کتابخانه بروم .\n",
            "PRED SCORE: -1.8010\n",
            "\n",
            "SENT 63: ['no', ',', 'I', 'suggest', 'to', 'take', 'the', 'train', 'in', 'the', 'morning', '.']\n",
            "PRED 63: نه ، من پیشنهاد میدهم که از صبح .\n",
            "PRED SCORE: -0.9021\n",
            "\n",
            "SENT 64: ['six', \"o'clock\", 'is', 'too', 'early', ',', 'I', 'propose', 'to', 'take', 'the', 'train', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', '.']\n",
            "PRED 64: ساعت شش خیلی زود است ، پیشنهاد من ساعت ده صبح است .\n",
            "PRED SCORE: -2.1614\n",
            "\n",
            "SENT 65: ['do', 'you', 'agree', '?']\n",
            "PRED 65: موافق هستید ؟\n",
            "PRED SCORE: -0.0025\n",
            "\n",
            "SENT 66: ['I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 66: من آنرا نوشتم .\n",
            "PRED SCORE: -0.0717\n",
            "\n",
            "SENT 67: ['I', 'did', 'not', 'understand', 'that', 'again', '.']\n",
            "PRED 67: دوباره متوجه نشدم .\n",
            "PRED SCORE: -1.3305\n",
            "\n",
            "SENT 68: ['I', 'still', 'have', 'not', 'un@@', 'der@@', 'stood', 'anything', '.']\n",
            "PRED 68: هنوز تعهداتی نگذاشتم .\n",
            "PRED SCORE: -2.6408\n",
            "\n",
            "SENT 69: ['I', 'suggest', 'to', 'stay', 'at', 'the', 'hotel', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', 'in', 'Hanover', '.']\n",
            "PRED 69: من پیشنهاد میکنم که در هتل ویر گ@@ p@@ ly belong در منییم همدیگر Hanover .\n",
            "PRED SCORE: -6.5240\n",
            "\n",
            "SENT 70: ['yes', 'please', '.']\n",
            "PRED 70: بله لطفا .\n",
            "PRED SCORE: -0.0885\n",
            "\n",
            "SENT 71: ['so', 'shall', 'we', 'take', 'the', 'hotel', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '?']\n",
            "PRED 71: بطوریکه سر@@ ه­@@ -@@ ing در کر@@ چیزهایی صحبت میکنیم ؟\n",
            "PRED SCORE: -6.7878\n",
            "\n",
            "SENT 72: ['well', 'once', 'again', ',', 'should', 'we', 'stay', 'at', 'the', 'hotel', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '?']\n",
            "PRED 72: خب ، دوباره از آن@@ paying با وجود دارد ؟\n",
            "PRED SCORE: -4.1136\n",
            "\n",
            "SENT 73: ['once', 'again', ',', 'shall', 'we', 'stay', 'at', 'the', 'hotel', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '?']\n",
            "PRED 73: دوباره سخ@@ لم ، ما در هتل فکر‌ نمیکنم ؟\n",
            "PRED SCORE: -6.0198\n",
            "\n",
            "SENT 74: ['yes', ',', 'that', 'is', 'a', 'good', 'idea', '.']\n",
            "PRED 74: بله ، ایده خوبی است .\n",
            "PRED SCORE: -0.0021\n",
            "\n",
            "SENT 75: ['I', 'did', 'not', 'understand', 'that', ',', 'I', 'suggest', 'to', 'go', 'back', 'to', 'Hamburg', 'on', 'the', 'twenty-fourth', 'in', 'the', 'evening', '.']\n",
            "PRED 75: خوبم که من نمیخواهم ، که از قبل قسمتی از ظهر به دفترم بروم .\n",
            "PRED SCORE: -6.0276\n",
            "\n",
            "SENT 76: ['yes', 'I', 'agree', ',', 'I', 'propose', 'to', 'take', 'the', 'train', 'again', '.']\n",
            "PRED 76: بله ، من پیشنهاد میکنم که ، ما دوباره از .\n",
            "PRED SCORE: -2.6268\n",
            "\n",
            "SENT 77: ['I', 'agree', ',', 'everything', 'okay', '?']\n",
            "PRED 77: من با آن موافق هستم ؟\n",
            "PRED SCORE: -1.9593\n",
            "\n",
            "SENT 78: ['hello', '.', 'should', 'we', 'plan', 'our', 'journey', 'to', 'the', 'E@@', 'x@@', 'p@@', 'o', 'on', 'October', 'the', 'ninth', '?']\n",
            "PRED 78: سلام . فکر میکنی ما باید برای نهم تا نهم اکتبر برنامه­ریزی کنیم ؟\n",
            "PRED SCORE: -4.2171\n",
            "\n",
            "SENT 79: ['I', 'would', 'prefer', 'to', 'take', 'the', 'train', '.']\n",
            "PRED 79: من ترجیح میدهم که قطار را ترجیح میدهم .\n",
            "PRED SCORE: -1.6416\n",
            "\n",
            "SENT 80: ['we', 'could', 'leave', 'Hamburg', 'at', 'twenty-@@', 'four', 'past', 'seven', 'and', 'we', 'would', 'be', 'in', 'Hanover', 'at', 'thir@@', 'ty-@@', 'nine', 'past', 'eight', '.']\n",
            "PRED 80: ما میتوانیم در پرواز ساعت چهار و سی دقیقه و ما در Hanover پرواز ساعت نه و سی و ‌یکم .\n",
            "PRED SCORE: -4.7186\n",
            "\n",
            "SENT 81: ['fine', '.', 'and', 'where', 'at', 'the', 'station', '?']\n",
            "PRED 81: خوب است . و کجا ؟\n",
            "PRED SCORE: -1.0319\n",
            "\n",
            "SENT 82: ['do', 'you', 'also', 'want', 'to', 'reserve', 'seats', 'for', 'us', '?']\n",
            "PRED 82: آیا شما هم میخواهم به آن رسیدگی‌ کنی ؟\n",
            "PRED SCORE: -1.8348\n",
            "\n",
            "SENT 83: ['are', 'the', 'single', 'rooms', 'che@@', 'a@@', 'p', 'there', '?']\n",
            "PRED 83: آیا واقعا ایده­ای وجود دارد ؟\n",
            "PRED SCORE: -2.4044\n",
            "\n",
            "SENT 84: ['three', 'hundred', 'de@@', 'ut@@', 'sch@@', 'marks', 'is', 'a', 'bit', 'expensive', '.', \"isn't\", 'there', 'anything', 'cheaper', '?']\n",
            "PRED 84: ساعت سه و سی دقیقه کمی دانشگاه است . یک چیز دیگری وجود دارد ؟\n",
            "PRED SCORE: -7.3346\n",
            "\n",
            "SENT 85: ['are', 'there', 'single', 'rooms', 'for', 'eighty', 'D@@', 'e@@', 'ut@@', 'sch@@', '-@@', 'marks', '?']\n",
            "PRED 85: تنها آیا هنوز برای تولد paying تری آلمان ؟\n",
            "PRED SCORE: -4.8259\n",
            "\n",
            "SENT 86: ['fine', '.', 'but', 'at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'now', '?']\n",
            "PRED 86: خوب است . ولی شما چه فکر میکنید که شما میخواهید ؟\n",
            "PRED SCORE: -2.9194\n",
            "\n",
            "SENT 87: ['where', 'is', 'our', 'hotel', 'and', 'what', 'is', 'its', 'name', '?']\n",
            "PRED 87: هی و در هتل فیلمی است و چه موقع ؟\n",
            "PRED SCORE: -2.8493\n",
            "\n",
            "SENT 88: ['at', 'which', 'hotel', 'do', 'you', 'want', 'to', 'reserve', 'for', 'us', 'and', 'where', 'is', 'the', 'hotel', '?']\n",
            "PRED 88: در واقع شما میخواهید که آنها را آماده کنید و کجا ؟\n",
            "PRED SCORE: -2.7736\n",
            "\n",
            "SENT 89: ['would', 'you', 'repeat', 'the', 'hotel', 'name', 'then', ',', 'please', '?']\n",
            "PRED 89: پس دوباره با آقای موافقید صحبت میکنم ، لطفا ؟\n",
            "PRED SCORE: -2.9313\n",
            "\n",
            "SENT 90: ['what', 'is', 'the', 'name', 'of', 'our', 'hotel', '?']\n",
            "PRED 90: موضوع درباره همه چیز ؟\n",
            "PRED SCORE: -2.4332\n",
            "\n",
            "SENT 91: ['in', 'the', 'evening', 'I', 'would', 'like', 'to', 'relax', 'and', 'maybe', 'go', 'to', 'the', 'sauna', '.', 'what', 'do', 'you', 'think', '?']\n",
            "PRED 91: پس از ظهر مراقب رزرواسیون هستم و شاید به دیدن شوید چه موقع و شما دوست دارید ؟\n",
            "PRED SCORE: -7.2828\n",
            "\n",
            "SENT 92: ['okay', '.', 'the', 'program', 'of', 'the', 'evening', 'we', 'can', 'plan', 'later', 'on', '.']\n",
            "PRED 92: باشه . خیلی خوب است ما میتوانیم برای بعد از آن برویم .\n",
            "PRED SCORE: -4.6997\n",
            "\n",
            "SENT 93: ['I', 'would', 'like', 'to', 'take', 'the', 'train', 'at', 'eighteen', 'past', 'nine', '$P-$M', '.', 'is', 'that', 'okay', 'for', 'you', '?']\n",
            "PRED 93: من میخواهم قطار از ساعت نه و سی دقیقه را پیشنهاد کنم . آیا آن برای شما خوب است ؟\n",
            "PRED SCORE: -6.2128\n",
            "\n",
            "SENT 94: ['fine', '.', 'see', 'you', 'later', 'then', '.']\n",
            "PRED 94: بسیار خوب . میبینمتان .\n",
            "PRED SCORE: -1.1367\n",
            "\n",
            "SENT 95: ['fine', '.', 'at', 'what', 'time', 'would', 'you', 'like', 'to', 'leave', '?']\n",
            "PRED 95: خوب است . آیا شما چه زمانی را ترجیح میدهید ؟\n",
            "PRED SCORE: -0.8056\n",
            "\n",
            "SENT 96: ['I', 'would', 'prefer', 'the', 'train', '.']\n",
            "PRED 96: من قطار را ترجیح میدهم .\n",
            "PRED SCORE: -0.0199\n",
            "\n",
            "SENT 97: ['that', 'is', 'okay', '.', 'should', 'we', 'meet', 'at', 'the', 'station', 'at', 'eight', \"o'clock\", 'then', '?']\n",
            "PRED 97: خوب . میتوانی ما ساعت هشت همدیگر را در ایستگاه ملاقات کنیم ؟\n",
            "PRED SCORE: -3.1068\n",
            "\n",
            "SENT 98: ['okay', '.', 'do', 'you', 'want', 'me', 'to', 'reserve', 'a', 'hotel', 'for', 'us', '?']\n",
            "PRED 98: باشه . آیا شما میخواهید که به من یک کنفرانس دارم ؟\n",
            "PRED SCORE: -1.9892\n",
            "\n",
            "SENT 99: ['I', 'would', 'suggest', 'the', 'S@@', 'ta@@', 'd@@', 'th@@', 'o@@', 'tel', ',', 'because', 'it', 'is', 'the', 'cheapest', 'one', '.']\n",
            "PRED 99: من یک کافه or@@ ِ@@ e را پیشنهاد میکنم ، چون آن یک ایستگاه است .\n",
            "PRED SCORE: -5.3420\n",
            "\n",
            "SENT 100: ['the', 'S@@', 'ta@@', 'd@@', 'th@@', 'o@@', 'tel', '.']\n",
            "PRED 100: غذای فدرال عالی است .\n",
            "PRED SCORE: -2.9480\n",
            "\n",
            "SENT 101: ['would', 'you', 'like', 'a', 'single', 'room', 'or', 'a', 'double', 'room', '?']\n",
            "PRED 101: آیا میتوانید تنها یک اتاق دویست و نیم را هماهنگ کنید ؟\n",
            "PRED SCORE: -2.5017\n",
            "\n",
            "SENT 102: ['okay', '.', 'should', 'we', 'go', 'to', 'the', 'hotel', 'by', 'taxi', 'immediately', '?']\n",
            "PRED 102: باشه . آیا ما به کنفرانس دی او اس چه داریم ؟\n",
            "PRED SCORE: -2.1812\n",
            "\n",
            "SENT 103: ['would', 'you', 'like', 'to', 'do', 'something', 'in', 'the', 'evening', '?']\n",
            "PRED 103: آیا شما میخواهید در عصر چیزی باشد ؟\n",
            "PRED SCORE: -2.8183\n",
            "\n",
            "SENT 104: ['fine', '.', 'I', 'agree', 'with', 'that', '.']\n",
            "PRED 104: خوب است . من با آن موافقم .\n",
            "PRED SCORE: -0.0566\n",
            "\n",
            "SENT 105: ['could', 'you', 'find', 'out', 'a', 'train', 'connection', 'for', 'Wednesday', 'evening', '?']\n",
            "PRED 105: آیا شما میتوانید برای چهارشنبه عصر یک پرواز وقت داشته باشید ؟\n",
            "PRED SCORE: -1.7131\n",
            "\n",
            "SENT 106: ['sorry', '.', 'when', 'will', 'we', 'arrive', 'at', 'Hamburg', '?']\n",
            "PRED 106: ببخشید . چه موقع ما در منزل قصد دارید ؟\n",
            "PRED SCORE: -1.3938\n",
            "\n",
            "SENT 107: ['that', 'is', 'okay', '.', 'then', 'we', 'can', 'go', 'back', 'by', 'taxi', '.']\n",
            "PRED 107: بسیار خوب . پس ما میتوانیم به دقت بروم .\n",
            "PRED SCORE: -2.8137\n",
            "\n",
            "SENT 108: ['okay', '.', 'goodbye', '.']\n",
            "PRED 108: باشد . خداحافظ .\n",
            "PRED SCORE: -0.5829\n",
            "\n",
            "SENT 109: ['hello', '.', 'I', 'call', 'you', 'to', 'plan', 'the', 'journey', 'to', 'Hanover', 'with', 'you', '.']\n",
            "PRED 109: سلام . من با شما تماس گرفتم تا در مورد بعضی مسائل صحبت کنم .\n",
            "PRED SCORE: -1.9723\n",
            "\n",
            "SENT 110: ['yes', ',', 'I', 'would', 'like', 'to', 'leave', 'on', 'Wednesday', 'the', 'twenty-@@', 'sixth', 'of', 'January', '.']\n",
            "PRED 110: بله ، من میخواهم چهارشنبه ششم ژانویه را پیشنهاد کنم .\n",
            "PRED SCORE: -3.6474\n",
            "\n",
            "SENT 111: ['I', 'prefer', 'the', 'plane', '.']\n",
            "PRED 111: من مراقب را را ترجیح میدهم .\n",
            "PRED SCORE: -0.7644\n",
            "\n",
            "SENT 112: ['fine', '.', 'at', 'what', 'time', 'should', 'we', 'leave', '?']\n",
            "PRED 112: خوب . و چه ساعتی باید قرار بگذاریم ؟\n",
            "PRED SCORE: -1.7295\n",
            "\n",
            "SENT 113: ['I', 'propose', 'to', 'leave', 'at', 'nine', \"o'clock\", 'in', 'the', 'morning', '.']\n",
            "PRED 113: من پیشنهاد میکنم که ساعت نه صبح باشد .\n",
            "PRED SCORE: -0.7290\n",
            "\n",
            "SENT 114: ['where', 'should', 'we', 'meet', '?']\n",
            "PRED 114: کجا باید همدیگر را ببینیم ؟\n",
            "PRED SCORE: -0.4778\n",
            "\n",
            "SENT 115: ['at', 'which', 'office', 'please', '?']\n",
            "PRED 115: نزد تو ؟\n",
            "PRED SCORE: -0.5763\n",
            "\n",
            "SENT 116: ['fine', '.', 'do', 'you', 'want', 'me', 'to', 'reserve', 'a', 'hotel', 'for', 'us', '?']\n",
            "PRED 116: بسیار خوب . آیا شما میخواهید که به من یک کنفرانس دارم ؟\n",
            "PRED SCORE: -1.6577\n",
            "\n",
            "SENT 117: ['the', 'hotel', 'is', 'called', 'Prinzenhof', 'and', 'it', 'is', 'in', 'the', 'city', 'center', '.']\n",
            "PRED 117: هتل Zentral صحبت‌ دارد و آن در center شهر است .\n",
            "PRED SCORE: -2.7056\n",
            "\n",
            "SENT 118: ['do', 'you', 'agree', 'on', 'a', 'double', 'room', '?']\n",
            "PRED 118: آیا شما به یک اتاق تمرین رزرو میکنید ؟\n",
            "PRED SCORE: -2.7229\n",
            "\n",
            "SENT 119: ['great', '.', 'I', 'will', 'reserve', 'two', 'single', 'rooms', '.']\n",
            "PRED 119: عالی است . من دو واقعا فکر میکنم .\n",
            "PRED SCORE: -2.3191\n",
            "\n",
            "SENT 120: ['would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '?']\n",
            "PRED 120: آیا شما میخواهید برای یک movie در عصر ؟\n",
            "PRED SCORE: -0.5824\n",
            "\n",
            "SENT 121: ['fine', '.', 'I', 'will', 'choose', 'a', 'restaurant', '.']\n",
            "PRED 121: خوب است . من یک رستوران را .\n",
            "PRED SCORE: -1.6771\n",
            "\n",
            "SENT 122: ['I', 'would', 'like', 'to', 'leave', 'on', 'Thursday', 'afternoon', '.']\n",
            "PRED 122: من دوست دارم که پنجشنبه بعد از ظهر باشد .\n",
            "PRED SCORE: -0.7536\n",
            "\n",
            "SENT 123: ['yes', ',', 'I', 'agree', 'with', 'that', '.']\n",
            "PRED 123: بله ، با آن موافقم .\n",
            "PRED SCORE: -0.5528\n",
            "\n",
            "SENT 124: ['yes', ',', 'I', 'agree', 'that', 'we', 'leave', 'at', 'five', \"o'clock\", '.']\n",
            "PRED 124: بله ، من فکر میکنم که ما ساعت پنج تمام کنیم .\n",
            "PRED SCORE: -2.1389\n",
            "\n",
            "SENT 125: ['I', 'think', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 125: من فکر کنم ما درباره چی صحبت کردیم . خدانگهدار .\n",
            "PRED SCORE: -3.4506\n",
            "\n",
            "SENT 126: ['should', 'we', 'meet', 'at', 'the', 'E@@', 'x@@', 'p@@', 'o', 'in', 'Hanover', 'in', 'June', '?']\n",
            "PRED 126: آیا میتوانیم در هتل ما@@ ک@@ سیم در ژوئن همدیگر را ببینیم ؟\n",
            "PRED SCORE: -2.5222\n",
            "\n",
            "SENT 127: ['yes', ',', 'I', 'thought', ',', 'we', 'would', 'go', 'to', 'Hanover', 'on', 'the', 'ninth', 'and', 'tenth', 'of', 'June', '.']\n",
            "PRED 127: بله ، فکر میکنم ، ما به Hanover نهم و دهم ژوئن .\n",
            "PRED SCORE: -0.7370\n",
            "\n",
            "SENT 128: ['yes', ',', 'I', 'have', 'got', 'a', 'ti@@', 'me@@', 'table', '.', 'when', 'would', 'you', 'like', 'to', 'go', '?']\n",
            "PRED 128: بله ، من یک gotten دارم . چه موقع شما میخواهید ؟\n",
            "PRED SCORE: -2.9442\n",
            "\n",
            "SENT 129: ['\"ahm', 'there', 'is', 'a', 'train', 'leaving', 'Hamburg', 'at', 'twenty-@@', 'four', 'past', 'ten', '.', 'it', 'arri@@', 'ves', 'at', 'Hanover', 'at', 'thir@@', 'ty-@@', 'nine', 'past', 'eleven', '.']\n",
            "PRED 129: اوم یک قطار ساعت ده بعد از ساعت ده . وقت دارم ، از ساعت چهار و نیم است پرواز میکنم .\n",
            "PRED SCORE: -6.7526\n",
            "\n",
            "SENT 130: ['I', 'agree', '.', 'then', 'we', 'could', 'have', 'breakfast', 'together', '.']\n",
            "PRED 130: موافقم . پس ما میتوانیم صبحانه را با هم بخوریم .\n",
            "PRED SCORE: -0.5198\n",
            "\n",
            "SENT 131: ['I', 'agree', '.', 'we', 'need', 'a', 'hotel', 'in', 'Hanover', '.']\n",
            "PRED 131: من فکر میکنم . ما نیاز داریم که در هتل Hanover .\n",
            "PRED SCORE: -1.2651\n",
            "\n",
            "SENT 132: ['unfortunately', 'I', 'did', 'not', 'understand', 'you', '.']\n",
            "PRED 132: متاسفانه من متوجه شما نشدم .\n",
            "PRED SCORE: -0.0085\n",
            "\n",
            "SENT 133: ['in', 'May', 'on', 'the', 'eighteenth', 'and', 'nineteenth', 'of', 'May', 'we', 'are', 'going', 'together', 'to', 'Hanover', '.']\n",
            "PRED 133: در هجدهم می و نوزدهم می ما با هم به Hanover .\n",
            "PRED SCORE: -1.5308\n",
            "\n",
            "SENT 134: ['I', 'would', 'like', 'to', '\"ahm', 'go', 'by', 'plane', '.', 'do', 'you', 'have', 'a', 'plan', '?']\n",
            "PRED 134: من مایل هستم که خودم را ببینم . آیا شما یک چیزی را ترجیح میدهم ؟\n",
            "PRED SCORE: -4.6773\n",
            "\n",
            "SENT 135: ['I', 'would', 'like', 'to', 'fly', 'and', 'to', 'be', 'in', 'Hanover', 'at', 'about', 'ten', \"o'clock\", '.']\n",
            "PRED 135: من میخواهم پرواز میکنم و در Hanover حدود ساعت ده .\n",
            "PRED SCORE: -1.8276\n",
            "\n",
            "SENT 136: ['where', 'should', 'we', 'meet', '?']\n",
            "PRED 136: کجا باید همدیگر را ببینیم ؟\n",
            "PRED SCORE: -0.4778\n",
            "\n",
            "SENT 137: ['should', 'we', 'meet', 'at', 'the', 'meeting', 'point', 'at', 'the', 'airport', '?']\n",
            "PRED 137: ما باید در دفتر شما همدیگر را ببینیم ؟\n",
            "PRED SCORE: -1.4892\n",
            "\n",
            "SENT 138: ['would', 'you', 'please', 'repeat', 'that', 'once', 'again', '?']\n",
            "PRED 138: آیا ممکن است دوباره اتاق@@ بیاندازید ؟\n",
            "PRED SCORE: -1.4003\n",
            "\n",
            "SENT 139: ['I', 'agree', '.', 'how', 'can', 'I', 're@@', 'co@@', 'g@@', 'ni@@', 'ze', 'you', '?']\n",
            "PRED 139: ببخشید . من شما را ترک کردم ؟\n",
            "PRED SCORE: -2.8365\n",
            "\n",
            "SENT 140: ['well', ',', 'when', 'would', 'you', 'like', 'to', 'fly', 'back', '?']\n",
            "PRED 140: خب ، چه موقع شما دوست دارید ؟\n",
            "PRED SCORE: -0.4889\n",
            "\n",
            "SENT 141: ['I', 'agree', '.', 'when', 'exactly', 'does', 'the', 'plane', 'take', 'off', '?']\n",
            "PRED 141: من خانم میزنم . چه زمانی در طول روز ؟\n",
            "PRED SCORE: -3.0611\n",
            "\n",
            "SENT 142: ['please', 'repeat', 'that', 'once', 'again', '.']\n",
            "PRED 142: لطفا دوباره به من کمک@@ ‌ کنید .\n",
            "PRED SCORE: -1.3747\n",
            "\n",
            "SENT 143: ['that', 'sounds', 'great', '.', '\"ahm', ',', 'fine', ',', 'you', 'arrange', 'the', 'flight', '.']\n",
            "PRED 143: عالی به نظر میرسد . اوهوم ، خوب است ، شما را میبینم .\n",
            "PRED SCORE: -0.7416\n",
            "\n",
            "SENT 144: ['do', 'you', 'want', 'me', 'to', '\"ah', 'book', 'the', 'hotel', '?', 'do', 'you', 'have', 'any', 'preferences', '?']\n",
            "PRED 144: آیا میخواهید من آه به دفتر شما step رسیدگی کنم ؟\n",
            "PRED SCORE: -4.7850\n",
            "\n",
            "SENT 145: ['a', 'single', 'room', 'and', 'it', 'is', 'important', 'for', 'you', 'to', 'have', 'a', 'bar', '.']\n",
            "PRED 145: اتاق تنها یک اتاق دویست و و Euros شما را دارم .\n",
            "PRED SCORE: -3.7392\n",
            "\n",
            "SENT 146: ['I', 'think', 'there', 'is', 'a', 'T@@', 'V', 'in', 'all', 'the', 'hotels', '.']\n",
            "PRED 146: من فکر میکنم یک co@@ lle@@ gu@@ e در hotels است .\n",
            "PRED SCORE: -1.0805\n",
            "\n",
            "SENT 147: ['there', 'is', 'a', 'hotel', 'near', 'the', 'fair@@', 'ground', ',', 'but', 'it', 'is', 'very', 'expensive', '.']\n",
            "PRED 147: وجود دارد که یک کافه تریا ، اما آن بسیار دلپذیر است .\n",
            "PRED SCORE: -3.0233\n",
            "\n",
            "SENT 148: ['I', 'agree', '.', 'a', 'single', 'room', 'costs', 'three', 'hundred', 'D@@', 'e@@', 'ut@@', 'sch@@', '-@@', 'marks', 'a', 'night', '.']\n",
            "PRED 148: من تنها . اتاق دویست fifty سه marks برای یک اتاق شب seventy است\n",
            "PRED SCORE: -6.8165\n",
            "\n",
            "SENT 149: ['okay', '.', 'I', 'book', 'the', 'hotel', '.']\n",
            "PRED 149: باشه . من در هتل را .\n",
            "PRED SCORE: -1.2135\n",
            "\n",
            "SENT 150: ['\"ahm', 'should', 'we', 'meet', 'on', 'May', 'the', 'eighteenth', 'in', 'the', 'evening', '?']\n",
            "PRED 150: اوم ما باید هجدهم می همدیگر را ببینیم ؟\n",
            "PRED SCORE: -1.6325\n",
            "\n",
            "SENT 151: ['okay', '.', 'should', 'we', 'meet', 'at', 'the', 'hotel', 'at', 'half', 'past', 'seven', '?']\n",
            "PRED 151: باشه . آیا ما ساعت هفت و نیم همدیگر را ملاقات کنیم ؟\n",
            "PRED SCORE: -1.6942\n",
            "\n",
            "SENT 152: ['fine', '.', 'we', 'still', 'have', 'to', 'arrange', 'the', 'ride', 'from', 'the', 'airport', 'to', 'the', 'hotel', '.']\n",
            "PRED 152: خوب است . ما هنوز باید ترتیب یک سری کنفرانس دارم از فرودگاه .\n",
            "PRED SCORE: -3.2739\n",
            "\n",
            "SENT 153: ['I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 153: من آنرا نوشتم .\n",
            "PRED SCORE: -0.0717\n",
            "\n",
            "SENT 154: ['I', 'suggest', 'we', 'take', 'the', 'subway', 'to', 'the', 'hotel', '.']\n",
            "PRED 154: من پیشنهاد میدهم که در هتل پارک traveling .\n",
            "PRED SCORE: -2.6815\n",
            "\n",
            "SENT 155: ['the', 'subway', 'takes', 'about', 'twenty', 'minutes', 'to', 'the', 'station', '.']\n",
            "PRED 155: چهل و هشتم نزدیک ایستگاه central .\n",
            "PRED SCORE: -3.2672\n",
            "\n",
            "SENT 156: ['I', 'agree', '.', 'then', 'we', 'have', 'to', 'have', 'dinner', 'earlier', '.']\n",
            "PRED 156: ببخشید . و من باید زودتر شام بخوریم .\n",
            "PRED SCORE: -3.0221\n",
            "\n",
            "SENT 157: ['yes', '.', 'is', 'everything', 'okay', 'so', 'far', 'then', '?']\n",
            "PRED 157: بله . بنظر من خیلی زمان نیاز نیست ؟\n",
            "PRED SCORE: -0.7783\n",
            "\n",
            "SENT 158: ['yes', ',', 'well', 'see', 'you', 'on', 'the', 'eighteenth', 'then', '.']\n",
            "PRED 158: بله ، پس هجدهم میبینمت .\n",
            "PRED SCORE: -2.9622\n",
            "\n",
            "SENT 159: ['hello', '.', 'I', 'would', 'like', 'to', 'go', 'with', 'you', 'to', 'the', 'E@@', 'x@@', 'p@@', 'o', 'in', 'Hanover', '.']\n",
            "PRED 159: سلام . من میخواستم با شما تماس هستم تا در هتل پارک Hanover .\n",
            "PRED SCORE: -4.6354\n",
            "\n",
            "SENT 160: ['I', 'did', 'not', 'understand', 'that', '.', 'would', 'you', 'prefer', 'to', 'fly', 'or', 'to', 'drive', '?']\n",
            "PRED 160: من آن را یادداشت میکنم . آیا شما میخواهید آن یا تا حدی ؟\n",
            "PRED SCORE: -4.1141\n",
            "\n",
            "SENT 161: ['I', 'would', 'like', 'to', 'be', 'in', 'Hanover', 'until', 'noon', ',', 'but', 'I', 'still', 'do', 'not', 'know', 'if', 'you', 'want', 'to', 'fly', 'or', 'to', 'drive', '.']\n",
            "PRED 161: من دوست دارم که از نه تا ظهر باشم ، اما من حدس میزنم اگر شما میخواهید به دفتر من یا حتی .\n",
            "PRED SCORE: -8.1008\n",
            "\n",
            "SENT 162: ['that', 'sounds', 'very', 'good', '.', 'where', 'should', 'we', 'meet', '?']\n",
            "PRED 162: ظاهرا خوب به نظر میرسد . آیا ما باید ملاقات کنیم ؟\n",
            "PRED SCORE: -1.8748\n",
            "\n",
            "SENT 163: ['yes', 'fine', '.', 'how', 'would', 'half', 'past', 'seven', 'suit', 'you', '?']\n",
            "PRED 163: بله . آیا آن ساعت هفت و سی دقیقه چطور است ؟\n",
            "PRED SCORE: -1.7452\n",
            "\n",
            "SENT 164: ['fine', '.', 'I', 'have', 'a', 'list', 'of', 'hotels', 'for', 'Hanover', '.']\n",
            "PRED 164: خوب است . من list hotels .\n",
            "PRED SCORE: -1.0110\n",
            "\n",
            "SENT 165: ['I', 'would', 'prefer', 'a', 'hotel', 'in', 'the', 'city', 'center', ',', 'then', 'we', 'can', 'do', 'something', 'in', 'the', 'evening', '.']\n",
            "PRED 165: من ترجیح میدهم که در هتل Luisenhof ، پس ما میتوانیم چیزی در عصر .\n",
            "PRED SCORE: -2.0296\n",
            "\n",
            "SENT 166: ['unfortunately', 'I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 166: متاسفانه من متوجه نشدم .\n",
            "PRED SCORE: -0.9825\n",
            "\n",
            "SENT 167: ['I', 'could', 'not', 'understand', 'you', 'again', '.']\n",
            "PRED 167: دوباره نمیتوانم شما را ناامید کنم .\n",
            "PRED SCORE: -2.1620\n",
            "\n",
            "SENT 168: ['fine', '.', 'then', 'I', 'propose', 'the', 'hotel', 'Prinzenhof', ',', 'that', 'is', 'si@@', 'tu@@', 'ated', 'in', 'the', 'city', 'center', '.']\n",
            "PRED 168: خوب است . پس من یک در هتل ، که آن هم خارج از شهر هستم .\n",
            "PRED SCORE: -4.0212\n",
            "\n",
            "SENT 169: ['did', 'you', 'understand', 'that', 'I', 'have', 'proposed', 'the', 'hotel', 'Prinzenhof', '?']\n",
            "PRED 169: آیا شما در هتل looked که من یک si@@ دارم ؟\n",
            "PRED SCORE: -3.1290\n",
            "\n",
            "SENT 170: ['fine', '.', 'I', 'will', 'book', 'two', 'single', 'rooms', 'for', 'two', 'hundred', 'D@@', 'e@@', 'ut@@', 'sch@@', '-@@', 'marks', 'each', '.']\n",
            "PRED 170: خوب است . من دو اتاق برای اسکی به د@@ نو@@ ر آلمان بروم .\n",
            "PRED SCORE: -5.0966\n",
            "\n",
            "SENT 171: ['do', 'you', 'know', 'a', 'restaurant', 'in', 'Hanover', '?', 'for', 'I', 'do', 'not', 'know', 'any', '.']\n",
            "PRED 171: آیا شما یک رستوران دلپذیر دارم چون من نمیدانم هیچ وجود دارد .\n",
            "PRED SCORE: -4.7671\n",
            "\n",
            "SENT 172: ['I', 'would', 'really', 'like', 'to', 'have', 'Chinese', 'or', 'J@@', 'ap@@', 'an@@', 'es@@', 'e', 'food', ',', 'but', 'not', 'Itali@@', 'en', 'food', '.', 'is', 'that', 'possible', '?']\n",
            "PRED 172: من واقعا مایل هستم یا از بعضی ت استفاده بخورم . اما ، آن به نظر محتمل میرسد . آیا آن عملی است ؟\n",
            "PRED SCORE: -13.3249\n",
            "\n",
            "SENT 173: ['that', 'is', 'fine', '.', 'then', 'we', 'still', 'have', 'to', 'arrange', 'the', 'return', 'journey', '.', 'do', 'you', 'have', 'a', 'schedule', 'for', 'a', 'return', 'flight', '?']\n",
            "PRED 173: آن خوب است . پس ما هنوز باید برنامه­ریزی کنیم که ما هنوز باید یک سخنرانی دارم . برای یک پرواز ؟\n",
            "PRED SCORE: -3.9624\n",
            "\n",
            "SENT 174: ['I', 'have', 'to', 'be', 'back', 'in', 'Hamburg', 'on', 'Friday', 'at', 'three', \"o'clock\", '$P-$M', 'at', 'the', 'latest', '.']\n",
            "PRED 174: من باید در دفتر جمعه ساعت سه بعد از ظهر به کلانژ بروم .\n",
            "PRED SCORE: -1.9472\n",
            "\n",
            "SENT 175: ['I', 'did', 'not', 'understand', 'when', 'the', 'plane', 'leaves', 'Hanover', 'and', 'when', 'it', 'is', 'supposed', 'to', 'arrive', 'at', 'Hamburg', '.']\n",
            "PRED 175: من چه زمانی را در نظر دارم و کی که چه زمانی است ما قرار است .\n",
            "PRED SCORE: -6.6342\n",
            "\n",
            "SENT 176: ['I', 'did', 'not', 'understand', 'that', 'yet', '.']\n",
            "PRED 176: من هنوز متوجه نشدم .\n",
            "PRED SCORE: -0.7494\n",
            "\n",
            "SENT 177: ['that', 'is', 'fine', '.', 'when', 'does', 'the', 'plane', 'leave', 'Hanover', '?']\n",
            "PRED 177: آن خوب است . چه موقع از آن دو ؟\n",
            "PRED SCORE: -2.6824\n",
            "\n",
            "SENT 178: ['then', 'we', 'arrive', 'at', 'the', 'airport', 'in', 'Hamburg', 'again', '.', 'right', '?']\n",
            "PRED 178: پس ما دوباره در منزل بروم . باشد .\n",
            "PRED SCORE: -1.7506\n",
            "\n",
            "SENT 179: ['then', 'everything', 'is', 'sor@@', 'ted', 'out', 'now', '.', 'then', 'we', 'will', 'see', 'each', 'other', 'on', 'August', 'the', 'seventeenth', '.']\n",
            "PRED 179: پس در حقیقت به نسبت پر است . پس هفدهم آگوست ما میتوانیم شروع کنیم .\n",
            "PRED SCORE: -5.1984\n",
            "\n",
            "SENT 180: ['okay', '.', 'goodbye', '.']\n",
            "PRED 180: باشد . خداحافظ .\n",
            "PRED SCORE: -0.5829\n",
            "\n",
            "SENT 181: ['good', 'morning', '.', 'how', 'are', 'you', '?']\n",
            "PRED 181: صبح . خوب است ؟\n",
            "PRED SCORE: -1.1104\n",
            "\n",
            "SENT 182: ['when', 'should', 'we', 'go', 'to', 'Hanover', '?']\n",
            "PRED 182: چه موقع ما باید به Hanover ؟\n",
            "PRED SCORE: -0.2814\n",
            "\n",
            "SENT 183: ['fine', '.', 'let', 'us', 'meet', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', '.', 'should', 'we', 'go', 'by', 'train', '?']\n",
            "PRED 183: بسیار خوب . اجازه دهید ساعت ده همدیگر را ملاقات کنیم . آیا شما میخواهید تا قطار ؟\n",
            "PRED SCORE: -3.2073\n",
            "\n",
            "SENT 184: ['thanks', '.', 'then', 'we', 'meet', 'at', 'the', 'train', 'station', '.']\n",
            "PRED 184: ممنون . و ما همدیگر را در ایستگاه مشابه ببینیم .\n",
            "PRED SCORE: -1.8649\n",
            "\n",
            "SENT 185: ['when', 'will', 'we', 'arrive', 'in', 'Hanover', '?']\n",
            "PRED 185: چه موقع خواهد رسید ؟\n",
            "PRED SCORE: -1.0055\n",
            "\n",
            "SENT 186: ['I', 'have', 'asked', ',', 'when', 'we', 'will', 'arrive', 'in', 'Hanover', '.']\n",
            "PRED 186: من دارم ، چه زمانی Hanover ، چه Zentral Hanover .\n",
            "PRED SCORE: -3.1113\n",
            "\n",
            "SENT 187: ['fine', '.', 'I', 'have', 'already', 'reserved', 'a', 'hotel', '.']\n",
            "PRED 187: خوب است . من قبلا یک کنفرانس دارم .\n",
            "PRED SCORE: -1.2026\n",
            "\n",
            "SENT 188: ['at', 'the', 'hotel', 'Maritim', '.', 'we', 'can', 'go', 'there', 'by', 'taxi', '.']\n",
            "PRED 188: در هتل Luisenhof . ما میتوانیم آنجا از Cologne-Bonn .\n",
            "PRED SCORE: -2.4387\n",
            "\n",
            "SENT 189: ['yes', ',', 'I', 'have', 'already', 'booked', 'the', 'hotel', '.']\n",
            "PRED 189: بله ، من آن موقع کنفرانس دارم .\n",
            "PRED SCORE: -1.2903\n",
            "\n",
            "SENT 190: ['I', 'have', 'booked', 'two', 'single', 'rooms', '.', 'one', 'for', 'me', 'and', 'one', 'for', 'you', '.']\n",
            "PRED 190: من دو اتاق تنها دو قرار دارم . برای شما و برای شما .\n",
            "PRED SCORE: -4.8067\n",
            "\n",
            "SENT 191: ['in', 'the', 'evening', 'we', 'should', 'w@@', 'at@@', 'ch', 'the', 'new@@', 'est', 'movie', 'with', 'Ar@@', 'no@@', 'ld', 'Sch@@', 'war@@', 'z@@', 'en@@', 'e@@', 'gg@@', 'er', '.']\n",
            "PRED 191: در غروب چ@@ ویر@@ ش@@ ency ما باید بدون چیزهایی برای مذاکرات آز@@ در نر@@ فت صحبت کنیم .\n",
            "PRED SCORE: -11.0243\n",
            "\n",
            "SENT 192: ['fine', '.', 'let', 'us', 'meet', 'at', 'the', 'station', 'at', 'nine', \"o'clock\", 'on', 'Thursday', 'morning', '.']\n",
            "PRED 192: خوب است . اجازه بدهید در ساعت نه صبح پنجشنبه همدیگر را ملاقات کنیم .\n",
            "PRED SCORE: -2.9484\n",
            "\n",
            "SENT 193: ['what', 'did', 'you', 'say', ',', 'please', '?']\n",
            "PRED 193: ببخشید چی شما را میبینم ؟\n",
            "PRED SCORE: -0.8596\n",
            "\n",
            "SENT 194: ['yes', '.', 'we', 'leave', 'at', 'nine', \"o'clock\", 'and', 'arrive', 'at', 'Hamburg', 'at', 'one', \"o'clock\", '.', 'right', '?']\n",
            "PRED 194: بله . ما ساعت نه و ما در ساعت یک . بسیار خوب .\n",
            "PRED SCORE: -1.6301\n",
            "\n",
            "SENT 195: ['yes', '.', 'is', 'everything', 'c@@', 'lea@@', 'red', 'up', 'then', '?']\n",
            "PRED 195: بله . میتوانی یک چیزی رزرو کنم ؟\n",
            "PRED SCORE: -2.5511\n",
            "\n",
            "SENT 196: ['then', 'everything', 'is', 'arranged', '.', 'goodbye', '.']\n",
            "PRED 196: پس همه چیز واضح است . خداحافظ .\n",
            "PRED SCORE: -0.0921\n",
            "\n",
            "SENT 197: ['hello', '.', 'I', 'would', 'prefer', 'the', 'In@@', 'ter@@', 'con@@', 'tin@@', 'en@@', 'tal', '.']\n",
            "PRED 197: سلام . من عاشق غذاهای منسا هستم .\n",
            "PRED SCORE: -3.2206\n",
            "\n",
            "SENT 198: ['fine', '.', 'let', 'us', 'take', 'the', 'In@@', 'ter@@', 'con@@', 'tin@@', 'en@@', 'tal', '.', 'should', 'we', 'fly', '?']\n",
            "PRED 198: بسیار خوب . اجازه دهید زود به دفتر برویم . ما کلاس دارید ؟\n",
            "PRED SCORE: -4.4358\n",
            "\n",
            "SENT 199: ['no', 'problem', '.', 'then', 'let', 'us', 'meet', '.', 'where', 'should', 'we', 'meet', '?']\n",
            "PRED 199: مسئله­ای نیست . پس بگذار همدیگر را ببینم .\n",
            "PRED SCORE: -2.4016\n",
            "\n",
            "SENT 200: ['yes', ',', 'we', 'take', 'the', 'A@@', 't@@', 'lan@@', 'ti@@', 'c@@', '-@@', 'Hotel', '.']\n",
            "PRED 200: بله ، ما s@@ ِ@@ ut@@ هم درباره آن گفتگو کنیم .\n",
            "PRED SCORE: -4.3619\n",
            "\n",
            "SENT 201: ['thanks', '.', 'by', 'the', 'way', ',', 'we', 'fly', 'to', 'Hanover', '.']\n",
            "PRED 201: ممنون . از ، برگشت اصلی قطار ، ما وجود دارد .\n",
            "PRED SCORE: -3.5717\n",
            "\n",
            "SENT 202: ['yes', '.', 'our', 'plane', 'will', 'take', 'off', 'at', 'a', 'quarter', 'to', 'seven', 'and', 'will', 'land', 'at', 'Hanover', 'at', 'ten', 'past', 'ten', '.']\n",
            "PRED 202: بله . ما در یک ساعت یک ربع به هفت و نیم ساعت ده و نیم .\n",
            "PRED SCORE: -3.2678\n",
            "\n",
            "SENT 203: ['fine', '.', 'by', 'taxi', 'we', 'will', 'be', 'at', 'the', 'hotel', 'within', 'ten', 'minutes', '.']\n",
            "PRED 203: خوب است . ملاقات ما در هتل Luisenhof ده .\n",
            "PRED SCORE: -1.8847\n",
            "\n",
            "SENT 204: ['yes', ',', 'let', 'us', 'take', 'two', 'single', 'rooms', '.', 'and', 'what', 'would', 'you', 'like', 'to', 'do', 'in', 'the', 'evening', '?']\n",
            "PRED 204: بله ، بگذار بگوییم دو اتاق وقت کافی است . و شما چه زمانی را ترجیح میدهید ؟\n",
            "PRED SCORE: -4.1768\n",
            "\n",
            "SENT 205: ['fine', '.', 'let', 'us', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '.', 'the', 'best', 'would', 'be', 'the', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '.']\n",
            "PRED 205: خوب است . اجازه بدهید برای ناهار همدیگر را ملاقات کنیم . بهترین وقت شما در یک ساعت از معلم هجی میکند .\n",
            "PRED SCORE: -8.8789\n",
            "\n",
            "SENT 206: ['on', 'Wednesday', 'we', 'will', 'go', 'back', 'by', 'train', 'to', 'Hamburg', '.']\n",
            "PRED 206: چهارشنبه از branch تا branch میروم .\n",
            "PRED SCORE: -2.8971\n",
            "\n",
            "SENT 207: ['we', 'will', 'leave', 'at', 'half', 'past', 'eight', 'and', 'will', 'arrive', 'at', 'Hamburg', 'at', 'ten', \"o'clock\", '.']\n",
            "PRED 207: ما ساعت هشت و نیم پرواز ساعت ده و بعد از ساعت هشت .\n",
            "PRED SCORE: -1.5794\n",
            "\n",
            "SENT 208: ['the', 'best', 'thing', 'would', 'be', 'for', 'us', 'to', 'take', 'the', 'subway', 'from', 'our', 'hotel', 'to', 'the', 'station', '.']\n",
            "PRED 208: بهترین بهتر برای نظر من است که از ایستگاه central .\n",
            "PRED SCORE: -3.1211\n",
            "\n",
            "SENT 209: ['fine', '.', 'let', 'us', 'go', 'for', 'a', 'little', 'walk', 'in', 'Hamburg', '.']\n",
            "PRED 209: خوب است . اجازه بدهید یک کمی s@@ r@@ b@@ et .\n",
            "PRED SCORE: -4.6632\n",
            "\n",
            "SENT 210: ['I', 'am', 'looking', 'forward', 'to', 'that', '.', 'goodbye', '.']\n",
            "PRED 210: من منتظر آن روز هستم . خدانگهدار .\n",
            "PRED SCORE: -0.8380\n",
            "\n",
            "SENT 211: ['hello', '.', 'should', 'we', 'go', 'by', 'car', 'to', 'Hanover', '?']\n",
            "PRED 211: سلام . آیا ما به Hanover تا Hanover ؟\n",
            "PRED SCORE: -1.2701\n",
            "\n",
            "SENT 212: ['we', 'should', 'leave', 'at', 'ten', \"o'clock\", 'in', 'the', 'morning', 'to', 'be', 'in', 'Hanover', 'at', 'twelve', \"o'clock\", '.']\n",
            "PRED 212: ما باید ساعت ده صبح از ساعت دوازده در Hanover .\n",
            "PRED SCORE: -2.8646\n",
            "\n",
            "SENT 213: ['do', 'you', 'want', 'me', 'to', 'book', 'a', 'hotel', '?']\n",
            "PRED 213: آیا میخواهید از قبل هتل ؟\n",
            "PRED SCORE: -1.3366\n",
            "\n",
            "SENT 214: ['I', 'will', 'book', 'two', 'single', 'rooms', 'with', 'a', 'sho@@', 'wer', 'at', 'the', 'K\"onig@@', 's@@', 'hotel']\n",
            "PRED 214: من دو اتاق تنها با هتل ride در هتل Cristal Hanover .\n",
            "PRED SCORE: -5.3662\n",
            "\n",
            "SENT 215: ['yes', ',', 'I', 'would', 'suggest', 'we', 'fly', 'back', '.']\n",
            "PRED 215: بله ، من پیشنهاد میکنم که ما وجود دارد .\n",
            "PRED SCORE: -0.6070\n",
            "\n",
            "SENT 216: ['yes', ',', 'I', 'would', 'suggest', 'the', 'flight', 'at', 'a', 'quarter', 'past', 'seven', '.']\n",
            "PRED 216: بله ، من پرواز ساعت یک ربع به هفت را پیشنهاد میکنم .\n",
            "PRED SCORE: -0.9222\n",
            "\n",
            "SENT 217: ['I', 'agree', '.']\n",
            "PRED 217: موافقم .\n",
            "PRED SCORE: -0.2415\n",
            "\n",
            "SENT 218: ['we', 'will', 'be', 'back', 'in', 'Hamburg', 'at', 'five', 'past', 'ten', '.']\n",
            "PRED 218: ما آنجا ساعت ده و بعد از آن .\n",
            "PRED SCORE: -2.1022\n",
            "\n",
            "SENT 219: ['yes', ',', 'we', 'will', 'be', 'back', 'at', 'Hamburg', 'at', 'five', 'past', 'ten', '.', 'would', 'you', 'like', 'to', 'go', 'to', 'the', 'Wi@@', 'en@@', 'er@@', 'wa@@', 'ld', 'in', 'Hanover', 'in', 'the', 'evening', '?']\n",
            "PRED 219: بله ، ما آنجا ساعت پنج بعد از ساعت ده . ما وجود دارد که شما به یک اطلاعات در Hanover آلمان و عصر آلمان ؟\n",
            "PRED SCORE: -8.3633\n",
            "\n",
            "SENT 220: ['okay', ',', 'goodbye', '.']\n",
            "PRED 220: باشه ، خدانگهدار .\n",
            "PRED SCORE: -1.6116\n",
            "\n",
            "SENT 221: ['Mrs', 'Schmidt', ',', 'we', 'still', 'want', 'to', 'plan', 'the', 'journey', 'to', 'Hanover', '.']\n",
            "PRED 221: خانم ولاک ، ما هنوز باید برای یک جلسه تجاری طرح‌ریزی‌ کنیم .\n",
            "PRED SCORE: -2.8354\n",
            "\n",
            "SENT 222: ['I', 'would', 'like', 'to', 'take', 'the', 'train', 'on', 'the', 'thirtieth', '.']\n",
            "PRED 222: من دوست دارم که سی ام را حذف کنم .\n",
            "PRED SCORE: -2.1169\n",
            "\n",
            "SENT 223: ['during', 'a', 'flight', 'I', 'always', 'get', 'si@@', 'ck', '.', 'I', 'would', 'like', 'to', 'take', 'the', 'train', '.']\n",
            "PRED 223: در صورتی . پرواز من دوست دارم تا پرواز برگردم وجود دارد .\n",
            "PRED SCORE: -3.8917\n",
            "\n",
            "SENT 224: ['well', ',', 'I', 'would', 'like', 'to', 'take', 'the', 'train', '.', 'during', 'a', 'flight', 'I', 'get', 'si@@', 'ck', '.']\n",
            "PRED 224: خب ، من میخواهم از . برگردم یک پرواز برگردم .\n",
            "PRED SCORE: -4.2913\n",
            "\n",
            "SENT 225: ['please', 'let', 'us', 'take', 'the', 'train', '.']\n",
            "PRED 225: لطفا اجازه دهید آن را انتخاب کنیم .\n",
            "PRED SCORE: -1.4661\n",
            "\n",
            "SENT 226: ['let', 'us', 'take', 'the', 'train', 'at', 'nine', \"o'clock\", '.']\n",
            "PRED 226: بگذار درست از ساعت نه را انتخاب کنیم .\n",
            "PRED SCORE: -1.8400\n",
            "\n",
            "SENT 227: ['at', 'six', 'past', 'nine', 'then', '.', 'then', 'let', 'us', 'meet', 'at', 'the', 'station', 'at', 'half', 'past', 'eight', '.']\n",
            "PRED 227: ساعت شش بعد از نه . پس بگذار همدیگر را ساعت شش و نیم در ایستگاه ملاقات کنیم .\n",
            "PRED SCORE: -2.7929\n",
            "\n",
            "SENT 228: ['when', 'do', 'we', 'arrive', 'at', 'Hanover', '?']\n",
            "PRED 228: چه موقع خواهد رسید پس ما ؟\n",
            "PRED SCORE: -0.5286\n",
            "\n",
            "SENT 229: ['that', 'is', 'very', 'good', '.', 'at', 'which', 'hotel', 'should', 'we', 'stay', 'then', '?', 'what', 'about', 'the', 'G@@', 'r@@', '\"@@', 'un@@', 'sch@@', 'na@@', 'be@@', 'l', '?']\n",
            "PRED 229: خیلی خوب است . ما باید شما را ببینم . در هتل پارک شما چطور است ؟\n",
            "PRED SCORE: -7.6914\n",
            "\n",
            "SENT 230: ['I', 'think', 'we', 'will', 'take', 'the', 'Me@@', 't@@', 'ro@@', 'po@@', 'l', 'hotel', '.', 'could', 'you', 'reserve', 'two', 'single', 'rooms', '?']\n",
            "PRED 230: من فکر میکنم ما باید اینجا تماس باشیم تا در مورد آنچه صحبت کنیم . آیا شما میتوانید در اتاق الگوریتم ؟\n",
            "PRED SCORE: -8.1176\n",
            "\n",
            "SENT 231: ['that', 'is', 'perfect', '.', 'would', 'you', 'like', 'to', 'go', 'out', 'for', 'a', 'meal', 'in', 'the', 'evening', '?']\n",
            "PRED 231: عالی است . آیا شما میتوانید برای یک ناهار در عصر ؟\n",
            "PRED SCORE: -2.3857\n",
            "\n",
            "SENT 232: ['yes', ',', 'the', 'ste@@', 'a@@', 'ks', 'at', 'the', 'B@@', 'lo@@', 'ck@@', '-@@', 'H@@', 'ou@@', 'se', 'are', 'always', 'very', 'suc@@', 'cul@@', 'ent', '.']\n",
            "PRED 232: بله ، راه­حل خوبی است که prices همیشه همیشه گل@@ چینی از معلم است .\n",
            "PRED SCORE: -6.5119\n",
            "\n",
            "SENT 233: ['good', 'idea', '.', 'we', 'could', 'take', 'the', 'one', 'at', 'the', 'Ma@@', 'sch@@', 'see', '.']\n",
            "PRED 233: خوب به نظر میرسد . ما میتوانیم آن را در یک آلمان .\n",
            "PRED SCORE: -2.2390\n",
            "\n",
            "SENT 234: ['that', 'is', 'perfect', '.', 'then', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 234: عالی است . پس ما آنها را مشخص کردیم . بنابراین .\n",
            "PRED SCORE: -3.2185\n",
            "\n",
            "SENT 235: ['hello', '.', 'we', 'still', 'have', 'to', 'plan', 'our', 'trip', 'to', 'Hanover', '.']\n",
            "PRED 235: سلام . ما هنوز باید برنامه­ریزی برای تدارک سفر Hanover .\n",
            "PRED SCORE: -1.3165\n",
            "\n",
            "SENT 236: ['I', 'would', 'like', 'to', 'fly', '.', 'that', 'looks', 'more', 'important', '.']\n",
            "PRED 236: من دوست دارم . ظاهرا خوب است .\n",
            "PRED SCORE: -3.5655\n",
            "\n",
            "SENT 237: ['the', 'earliest', 'flight', 'leaves', 'at', 'five', 'past', 'eight', '.', 'should', 'we', 'take', 'that', 'one', '?']\n",
            "PRED 237: پرواز ساعت هشت و سی دقیقه است . آیا ما باید آن را یک ؟\n",
            "PRED SCORE: -3.8321\n",
            "\n",
            "SENT 238: ['the', 'plane', 'arri@@', 'ves', 'at', 'Hanover', 'at', 'a', 'quarter', 'past', 'eleven', '.']\n",
            "PRED 238: flights Hanover بعد از ساعت یک ربع به یازده .\n",
            "PRED SCORE: -2.2857\n",
            "\n",
            "SENT 239: ['let', 'us', 'meet', 'at', 'seven', \"o'clock\", '.', 'we', 'still', 'have', 'to', 'check', 'in', '.']\n",
            "PRED 239: بیا ساعت هفت ملاقات کنیم . ما هنوز باید در مورد ساعت هفت .\n",
            "PRED SCORE: -2.3524\n",
            "\n",
            "SENT 240: ['what', 'do', 'you', 'think', 'about', 'the', 'hotel', 'G@@', 'e@@', 'wan@@', 'd@@', 'ha@@', 'us', '?']\n",
            "PRED 240: نظر شما در مورد هتل آتزینگر چیست ؟\n",
            "PRED SCORE: -2.9841\n",
            "\n",
            "SENT 241: ['I', 'would', 'like', 'one', ',', 'I', 'would', 'like', 'to', 'have', 'one', 'single', 'room', '.']\n",
            "PRED 241: من مایلم بگویم ، من یک اتاق را دوست دارم .\n",
            "PRED SCORE: -2.3066\n",
            "\n",
            "SENT 242: ['you', 'would', 'like', 'to', 'have', 'a', 'room', 'with', 'T@@', 'V', 'and', 'B@@', 'ar', '?']\n",
            "PRED 242: آیا شما دوست دارید با اتاق آموزش و اصلا@@ آور@@ تان باشد ؟\n",
            "PRED SCORE: -4.6394\n",
            "\n",
            "SENT 243: ['I', 'will', 'book', 'the', 'hote@@', 'l@@', 'room', '.']\n",
            "PRED 243: من تقریبا همراهی میکنم .\n",
            "PRED SCORE: -1.4650\n",
            "\n",
            "SENT 244: ['we', 'have', 'already', 'agreed', 'on', 'the', 'hotel', '.']\n",
            "PRED 244: باید از قبل هتل چیزها را تنظیم کنیم .\n",
            "PRED SCORE: -2.3802\n",
            "\n",
            "SENT 245: ['unfortunately', 'I', 'did', 'not', 'understand', 'that', '.']\n",
            "PRED 245: متاسفانه من متوجه نشدم .\n",
            "PRED SCORE: -0.9825\n",
            "\n",
            "SENT 246: ['let', 'us', 'leave', 'at', 'eight', \"o'clock\", '$P-$M', '.', 'there', 'is', 'a', 'flight', 'to', 'Hamburg', 'going', 'over', 'M@@', 'il@@', 'an', '.', \"isn't\", 'that', 'great', '?']\n",
            "PRED 246: اجازه بدهید ساعت هشت بعد از ساعت هشت . اولین ساعت پرواز . آیا پرواز زیادی عملی است ؟\n",
            "PRED SCORE: -2.6347\n",
            "\n",
            "SENT 247: ['let', 'yourself', 'get', 'surprised', '!']\n",
            "PRED 247: اجازه دهید آبجو دارید .\n",
            "PRED SCORE: -2.4178\n",
            "\n",
            "SENT 248: ['I', 'could', ',', 'but', 'I', \"don't\", 'do', 'it', '.']\n",
            "PRED 248: میدانم ، اما من متوجه شدم این کار را بکنیم .\n",
            "PRED SCORE: -2.2618\n",
            "\n",
            "SENT 249: ['at', 'eight', \"o'clock\", '$P-$M', '.']\n",
            "PRED 249: ساعت هشت بعد از ظهر .\n",
            "PRED SCORE: -0.4099\n",
            "\n",
            "SENT 250: ['yes', ',', 'that', 'is', 'in', 'the', 'evening', '.', 'now', 'we', 'have', 'talked', 'about', 'everything', '.', 'goodbye', '.']\n",
            "PRED 250: بله ، عصر در عصر . ما فکر میکردم . برنامه‌ریزی خوبی است .\n",
            "PRED SCORE: -6.5663\n",
            "PRED AVG SCORE: -0.2561, PRED PPL: 1.2919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74sox8UmGcbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -i \"s/@@ //g\"  En2Fa-Translation/BPEpred.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfXa7CGQJLep",
        "colab_type": "code",
        "outputId": "2d36a24a-cc10-4e34-9cc0-489b7ae3030a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!perl  OpenNMT-py/tools/multi-bleu.perl En2Fa-Translation/Test/test.fa0 En2Fa-Translation/Test/test.fa1 En2Fa-Translation/Test/test.fa2 En2Fa-Translation/Test/test.fa3 < En2Fa-Translation/BPEpred.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU = 23.43, 61.6/30.7/17.1/9.4 (BP=0.996, ratio=0.996, hyp_len=2631, ref_len=2641)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhWZVZ_cKejG",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Transliteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-FLDPEl6RQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_values = []\n",
        "with open('Transliteration/train.fa', 'r') as fp:\n",
        "  content = fp.read().split('\\n')\n",
        "  for this_sent in content:\n",
        "    this_sent_fixed = []\n",
        "    for this_char in this_sent:\n",
        "      if this_char == ' ':\n",
        "        this_sent_fixed.append('<b>')\n",
        "      else:\n",
        "        this_sent_fixed.append(this_char)\n",
        "      this_sent_fixed.append(' ')\n",
        "    this_sent_joined = ' '.join(this_sent_fixed)\n",
        "    this_sent_joined = this_sent_joined.strip()\n",
        "    fixed_values.append(this_sent_joined)\n",
        "\n",
        "with open('Transliteration/fixed_train.fa', 'w') as fp:\n",
        "  for v in fixed_values:\n",
        "    fp.write(v+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm2ApDVc6Rs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_values = []\n",
        "with open('Transliteration/dev.fa', 'r') as fp:\n",
        "  content = fp.read().split('\\n')\n",
        "  for this_sent in content:\n",
        "    this_sent_fixed = []\n",
        "    for this_char in this_sent:\n",
        "      if this_char == ' ':\n",
        "        this_sent_fixed.append('<b>')\n",
        "      else:\n",
        "        this_sent_fixed.append(this_char)\n",
        "      this_sent_fixed.append(' ')\n",
        "    this_sent_joined = ' '.join(this_sent_fixed)\n",
        "    this_sent_joined = this_sent_joined.strip()\n",
        "    fixed_values.append(this_sent_joined)\n",
        "\n",
        "with open('Transliteration/fixed_dev.fa', 'w') as fp:\n",
        "  for v in fixed_values:\n",
        "    fp.write(v+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vYToW5l6R_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_values = []\n",
        "with open('Transliteration/test.fa', 'r') as fp:\n",
        "  content = fp.read().split('\\n')\n",
        "  for this_sent in content:\n",
        "    this_sent_fixed = []\n",
        "    for this_char in this_sent:\n",
        "      if this_char == ' ':\n",
        "        this_sent_fixed.append('<b>')\n",
        "      else:\n",
        "        this_sent_fixed.append(this_char)\n",
        "      this_sent_fixed.append(' ')\n",
        "    this_sent_joined = ' '.join(this_sent_fixed)\n",
        "    this_sent_joined = this_sent_joined.strip()\n",
        "    fixed_values.append(this_sent_joined)\n",
        "\n",
        "with open('Transliteration/fixed_test.fa', 'w') as fp:\n",
        "  for v in fixed_values:\n",
        "    fp.write(v+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQu9wvix6SHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3142ef0d-e491-4b70-bbbc-a8432dfa6399"
      },
      "source": [
        "!python OpenNMT-py/preprocess.py -train_src Transliteration/fixed_train.fa -train_tgt Transliteration/train.en -valid_src Transliteration/fixed_dev.fa -valid_tgt Transliteration/dev.en -save_data Transliteration/Cleaned"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 05:09:31,668 INFO] Extracting features...\n",
            "[2020-06-02 05:09:31,982 INFO]  * number of source features: 0.\n",
            "[2020-06-02 05:09:31,983 INFO]  * number of target features: 0.\n",
            "[2020-06-02 05:09:31,983 INFO] Building `Fields` object...\n",
            "[2020-06-02 05:09:31,983 INFO] Building & saving training data...\n",
            "[2020-06-02 05:09:32,279 INFO] Building shard 0.\n",
            "[2020-06-02 05:09:32,704 INFO]  * saving 0th train data shard to Transliteration/Cleaned.train.0.pt.\n",
            "[2020-06-02 05:09:33,106 INFO]  * tgt vocab size: 6065.\n",
            "[2020-06-02 05:09:33,106 INFO]  * src vocab size: 43.\n",
            "[2020-06-02 05:09:33,165 INFO] Building & saving validation data...\n",
            "[2020-06-02 05:09:33,511 INFO] Building shard 0.\n",
            "[2020-06-02 05:09:33,542 INFO]  * saving 0th valid data shard to Transliteration/Cleaned.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvP9TiEX6SbR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff1ff1cb-28a3-4f44-f61b-e44694e83790"
      },
      "source": [
        "!python OpenNMT-py/train.py -data Transliteration/Cleaned -save_model Transliteration/rnn_model -world_size 1 -gpu_rank 0 --rnn_size 512 --layers 4 --rnn_type LSTM -train_steps 50000"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 05:10:07,566 INFO]  * src vocab size = 43\n",
            "[2020-06-02 05:10:07,566 INFO]  * tgt vocab size = 6065\n",
            "[2020-06-02 05:10:07,566 INFO] Building model...\n",
            "[2020-06-02 05:10:17,519 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(43, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): LSTM(500, 512, num_layers=4, dropout=0.3)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(6065, 500, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedLSTM(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): LSTMCell(1012, 512)\n",
            "        (1): LSTMCell(512, 512)\n",
            "        (2): LSTMCell(512, 512)\n",
            "        (3): LSTMCell(512, 512)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
            "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=6065, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2020-06-02 05:10:17,520 INFO] encoder: 8401916\n",
            "[2020-06-02 05:10:17,520 INFO] decoder: 16359269\n",
            "[2020-06-02 05:10:17,520 INFO] * number of parameters: 24761185\n",
            "[2020-06-02 05:10:17,524 INFO] Starting training on GPU: [0]\n",
            "[2020-06-02 05:10:17,524 INFO] Start training loop and validate every 10000 steps...\n",
            "[2020-06-02 05:10:17,525 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:17,613 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:21,165 INFO] Step 50/50000; acc:   7.90; ppl: 13615.32; xent: 9.52; lr: 1.00000; 25147/6596 tok/s;      4 sec\n",
            "[2020-06-02 05:10:24,393 INFO] Step 100/50000; acc:   9.94; ppl: 4630.61; xent: 8.44; lr: 1.00000; 29472/7674 tok/s;      7 sec\n",
            "[2020-06-02 05:10:25,196 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:25,317 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:27,795 INFO] Step 150/50000; acc:  10.60; ppl: 909.26; xent: 6.81; lr: 1.00000; 27011/7130 tok/s;     10 sec\n",
            "[2020-06-02 05:10:30,961 INFO] Step 200/50000; acc:  10.92; ppl: 909.05; xent: 6.81; lr: 1.00000; 29390/7667 tok/s;     13 sec\n",
            "[2020-06-02 05:10:32,576 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:32,642 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:34,311 INFO] Step 250/50000; acc:  11.83; ppl: 627.04; xent: 6.44; lr: 1.00000; 27765/7304 tok/s;     17 sec\n",
            "[2020-06-02 05:10:37,535 INFO] Step 300/50000; acc:  11.94; ppl: 681.25; xent: 6.52; lr: 1.00000; 29021/7589 tok/s;     20 sec\n",
            "[2020-06-02 05:10:39,903 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:40,012 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:40,715 INFO] Step 350/50000; acc:   9.11; ppl: 1154.30; xent: 7.05; lr: 1.00000; 27502/7254 tok/s;     23 sec\n",
            "[2020-06-02 05:10:44,017 INFO] Step 400/50000; acc:  10.06; ppl: 978.40; xent: 6.89; lr: 1.00000; 28808/7557 tok/s;     26 sec\n",
            "[2020-06-02 05:10:47,233 INFO] Step 450/50000; acc:   8.94; ppl: 920.99; xent: 6.83; lr: 1.00000; 28637/7496 tok/s;     30 sec\n",
            "[2020-06-02 05:10:47,333 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:47,450 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:50,539 INFO] Step 500/50000; acc:   9.98; ppl: 797.48; xent: 6.68; lr: 1.00000; 27292/7172 tok/s;     33 sec\n",
            "[2020-06-02 05:10:53,757 INFO] Step 550/50000; acc:  11.13; ppl: 874.88; xent: 6.77; lr: 1.00000; 29017/7551 tok/s;     36 sec\n",
            "[2020-06-02 05:10:54,729 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:10:54,794 INFO] number of examples: 7231\n",
            "[2020-06-02 05:10:57,146 INFO] Step 600/50000; acc:  10.83; ppl: 884.33; xent: 6.78; lr: 1.00000; 27834/7371 tok/s;     40 sec\n",
            "[2020-06-02 05:11:00,290 INFO] Step 650/50000; acc:  12.37; ppl: 664.16; xent: 6.50; lr: 1.00000; 29514/7692 tok/s;     43 sec\n",
            "[2020-06-02 05:11:02,044 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:02,156 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:03,635 INFO] Step 700/50000; acc:  11.38; ppl: 723.31; xent: 6.58; lr: 1.00000; 27063/7119 tok/s;     46 sec\n",
            "[2020-06-02 05:11:06,878 INFO] Step 750/50000; acc:  11.71; ppl: 660.09; xent: 6.49; lr: 1.00000; 29341/7672 tok/s;     49 sec\n",
            "[2020-06-02 05:11:09,402 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:09,467 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:10,030 INFO] Step 800/50000; acc:  14.76; ppl: 450.04; xent: 6.11; lr: 1.00000; 27774/7337 tok/s;     53 sec\n",
            "[2020-06-02 05:11:13,221 INFO] Step 850/50000; acc:  16.28; ppl: 363.36; xent: 5.90; lr: 1.00000; 29447/7722 tok/s;     56 sec\n",
            "[2020-06-02 05:11:16,457 INFO] Step 900/50000; acc:  16.28; ppl: 356.16; xent: 5.88; lr: 1.00000; 29038/7563 tok/s;     59 sec\n",
            "[2020-06-02 05:11:16,685 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:16,786 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:19,765 INFO] Step 950/50000; acc:  16.17; ppl: 367.50; xent: 5.91; lr: 1.00000; 27503/7220 tok/s;     62 sec\n",
            "[2020-06-02 05:11:22,924 INFO] Step 1000/50000; acc:  17.09; ppl: 322.81; xent: 5.78; lr: 1.00000; 29041/7580 tok/s;     65 sec\n",
            "[2020-06-02 05:11:24,038 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:24,163 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:26,440 INFO] Step 1050/50000; acc:  16.17; ppl: 324.05; xent: 5.78; lr: 1.00000; 27253/7208 tok/s;     69 sec\n",
            "[2020-06-02 05:11:29,567 INFO] Step 1100/50000; acc:  17.77; ppl: 295.87; xent: 5.69; lr: 1.00000; 29318/7640 tok/s;     72 sec\n",
            "[2020-06-02 05:11:31,442 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:31,506 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:32,832 INFO] Step 1150/50000; acc:  17.38; ppl: 292.48; xent: 5.68; lr: 1.00000; 27602/7252 tok/s;     75 sec\n",
            "[2020-06-02 05:11:36,109 INFO] Step 1200/50000; acc:  17.95; ppl: 273.23; xent: 5.61; lr: 1.00000; 29248/7677 tok/s;     79 sec\n",
            "[2020-06-02 05:11:38,788 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:38,895 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:39,326 INFO] Step 1250/50000; acc:  18.15; ppl: 278.03; xent: 5.63; lr: 1.00000; 27066/7162 tok/s;     82 sec\n",
            "[2020-06-02 05:11:42,541 INFO] Step 1300/50000; acc:  18.32; ppl: 263.49; xent: 5.57; lr: 1.00000; 28986/7607 tok/s;     85 sec\n",
            "[2020-06-02 05:11:45,800 INFO] Step 1350/50000; acc:  18.44; ppl: 262.48; xent: 5.57; lr: 1.00000; 29638/7685 tok/s;     88 sec\n",
            "[2020-06-02 05:11:46,106 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:46,172 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:49,078 INFO] Step 1400/50000; acc:  19.33; ppl: 244.82; xent: 5.50; lr: 1.00000; 27378/7194 tok/s;     92 sec\n",
            "[2020-06-02 05:11:52,235 INFO] Step 1450/50000; acc:  19.33; ppl: 234.77; xent: 5.46; lr: 1.00000; 29342/7655 tok/s;     95 sec\n",
            "[2020-06-02 05:11:53,445 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:11:53,548 INFO] number of examples: 7231\n",
            "[2020-06-02 05:11:55,675 INFO] Step 1500/50000; acc:  19.21; ppl: 224.29; xent: 5.41; lr: 1.00000; 27672/7310 tok/s;     98 sec\n",
            "[2020-06-02 05:11:58,740 INFO] Step 1550/50000; acc:  20.93; ppl: 203.09; xent: 5.31; lr: 1.00000; 28996/7610 tok/s;    101 sec\n",
            "[2020-06-02 05:12:00,798 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:00,925 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:02,116 INFO] Step 1600/50000; acc:  19.03; ppl: 222.76; xent: 5.41; lr: 1.00000; 27561/7230 tok/s;    105 sec\n",
            "[2020-06-02 05:12:05,323 INFO] Step 1650/50000; acc:  20.79; ppl: 192.43; xent: 5.26; lr: 1.00000; 29580/7746 tok/s;    108 sec\n",
            "[2020-06-02 05:12:08,117 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:08,184 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:08,525 INFO] Step 1700/50000; acc:  20.79; ppl: 191.76; xent: 5.26; lr: 1.00000; 27697/7312 tok/s;    111 sec\n",
            "[2020-06-02 05:12:11,709 INFO] Step 1750/50000; acc:  21.03; ppl: 181.51; xent: 5.20; lr: 1.00000; 28875/7570 tok/s;    114 sec\n",
            "[2020-06-02 05:12:14,933 INFO] Step 1800/50000; acc:  20.39; ppl: 188.93; xent: 5.24; lr: 1.00000; 29713/7689 tok/s;    117 sec\n",
            "[2020-06-02 05:12:15,411 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:15,518 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:18,274 INFO] Step 1850/50000; acc:  21.26; ppl: 170.52; xent: 5.14; lr: 1.00000; 27102/7178 tok/s;    121 sec\n",
            "[2020-06-02 05:12:21,440 INFO] Step 1900/50000; acc:  21.85; ppl: 164.50; xent: 5.10; lr: 1.00000; 29121/7593 tok/s;    124 sec\n",
            "[2020-06-02 05:12:22,767 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:22,832 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:24,862 INFO] Step 1950/50000; acc:  21.66; ppl: 161.67; xent: 5.09; lr: 1.00000; 27691/7324 tok/s;    127 sec\n",
            "[2020-06-02 05:12:27,922 INFO] Step 2000/50000; acc:  23.33; ppl: 144.63; xent: 4.97; lr: 1.00000; 29625/7750 tok/s;    130 sec\n",
            "[2020-06-02 05:12:30,041 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:30,108 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:31,197 INFO] Step 2050/50000; acc:  21.65; ppl: 157.77; xent: 5.06; lr: 1.00000; 28125/7363 tok/s;    134 sec\n",
            "[2020-06-02 05:12:34,448 INFO] Step 2100/50000; acc:  23.49; ppl: 135.59; xent: 4.91; lr: 1.00000; 29219/7671 tok/s;    137 sec\n",
            "[2020-06-02 05:12:37,327 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:37,448 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:37,696 INFO] Step 2150/50000; acc:  22.95; ppl: 141.32; xent: 4.95; lr: 1.00000; 27590/7277 tok/s;    140 sec\n",
            "[2020-06-02 05:12:40,795 INFO] Step 2200/50000; acc:  24.13; ppl: 127.48; xent: 4.85; lr: 1.00000; 29025/7611 tok/s;    143 sec\n",
            "[2020-06-02 05:12:44,046 INFO] Step 2250/50000; acc:  23.75; ppl: 129.72; xent: 4.87; lr: 1.00000; 29861/7726 tok/s;    147 sec\n",
            "[2020-06-02 05:12:44,627 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:44,695 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:47,344 INFO] Step 2300/50000; acc:  24.06; ppl: 123.99; xent: 4.82; lr: 1.00000; 27516/7300 tok/s;    150 sec\n",
            "[2020-06-02 05:12:50,418 INFO] Step 2350/50000; acc:  25.02; ppl: 117.62; xent: 4.77; lr: 1.00000; 29814/7756 tok/s;    153 sec\n",
            "[2020-06-02 05:12:51,898 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:52,017 INFO] number of examples: 7231\n",
            "[2020-06-02 05:12:53,840 INFO] Step 2400/50000; acc:  24.25; ppl: 116.64; xent: 4.76; lr: 1.00000; 27533/7261 tok/s;    156 sec\n",
            "[2020-06-02 05:12:56,963 INFO] Step 2450/50000; acc:  25.52; ppl: 106.57; xent: 4.67; lr: 1.00000; 29307/7701 tok/s;    159 sec\n",
            "[2020-06-02 05:12:59,212 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:12:59,279 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:00,283 INFO] Step 2500/50000; acc:  24.78; ppl: 108.65; xent: 4.69; lr: 1.00000; 27513/7208 tok/s;    163 sec\n",
            "[2020-06-02 05:13:03,511 INFO] Step 2550/50000; acc:  25.66; ppl: 101.98; xent: 4.62; lr: 1.00000; 29200/7658 tok/s;    166 sec\n",
            "[2020-06-02 05:13:06,527 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:06,596 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:06,670 INFO] Step 2600/50000; acc:  23.89; ppl: 120.09; xent: 4.79; lr: 1.00000; 28281/7446 tok/s;    169 sec\n",
            "[2020-06-02 05:13:09,938 INFO] Step 2650/50000; acc:  24.31; ppl: 113.49; xent: 4.73; lr: 1.00000; 28470/7459 tok/s;    172 sec\n",
            "[2020-06-02 05:13:13,160 INFO] Step 2700/50000; acc:  25.61; ppl: 98.45; xent: 4.59; lr: 1.00000; 29362/7628 tok/s;    176 sec\n",
            "[2020-06-02 05:13:13,886 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:14,010 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:16,487 INFO] Step 2750/50000; acc:  26.45; ppl: 89.53; xent: 4.49; lr: 1.00000; 27332/7224 tok/s;    179 sec\n",
            "[2020-06-02 05:13:19,675 INFO] Step 2800/50000; acc:  27.54; ppl: 84.13; xent: 4.43; lr: 1.00000; 29558/7686 tok/s;    182 sec\n",
            "[2020-06-02 05:13:21,204 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:21,272 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:22,964 INFO] Step 2850/50000; acc:  27.18; ppl: 84.00; xent: 4.43; lr: 1.00000; 28233/7446 tok/s;    185 sec\n",
            "[2020-06-02 05:13:26,104 INFO] Step 2900/50000; acc:  27.86; ppl: 77.32; xent: 4.35; lr: 1.00000; 29309/7689 tok/s;    189 sec\n",
            "[2020-06-02 05:13:28,431 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:28,539 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:29,302 INFO] Step 2950/50000; acc:  28.17; ppl: 75.26; xent: 4.32; lr: 1.00000; 27853/7321 tok/s;    192 sec\n",
            "[2020-06-02 05:13:32,628 INFO] Step 3000/50000; acc:  28.28; ppl: 71.72; xent: 4.27; lr: 1.00000; 28688/7538 tok/s;    195 sec\n",
            "[2020-06-02 05:13:35,796 INFO] Step 3050/50000; acc:  28.52; ppl: 68.56; xent: 4.23; lr: 1.00000; 28513/7487 tok/s;    198 sec\n",
            "[2020-06-02 05:13:35,864 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:35,942 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:39,141 INFO] Step 3100/50000; acc:  29.03; ppl: 65.71; xent: 4.19; lr: 1.00000; 27443/7184 tok/s;    202 sec\n",
            "[2020-06-02 05:13:42,365 INFO] Step 3150/50000; acc:  29.04; ppl: 63.84; xent: 4.16; lr: 1.00000; 29110/7592 tok/s;    205 sec\n",
            "[2020-06-02 05:13:43,229 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:43,296 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:45,720 INFO] Step 3200/50000; acc:  29.13; ppl: 62.13; xent: 4.13; lr: 1.00000; 27520/7276 tok/s;    208 sec\n",
            "[2020-06-02 05:13:48,899 INFO] Step 3250/50000; acc:  29.54; ppl: 59.32; xent: 4.08; lr: 1.00000; 29342/7646 tok/s;    211 sec\n",
            "[2020-06-02 05:13:50,595 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:50,716 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:52,295 INFO] Step 3300/50000; acc:  29.63; ppl: 58.47; xent: 4.07; lr: 1.00000; 27077/7110 tok/s;    215 sec\n",
            "[2020-06-02 05:13:55,575 INFO] Step 3350/50000; acc:  30.34; ppl: 52.83; xent: 3.97; lr: 1.00000; 29051/7584 tok/s;    218 sec\n",
            "[2020-06-02 05:13:58,013 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:13:58,081 INFO] number of examples: 7231\n",
            "[2020-06-02 05:13:58,736 INFO] Step 3400/50000; acc:  30.20; ppl: 53.14; xent: 3.97; lr: 1.00000; 27598/7291 tok/s;    221 sec\n",
            "[2020-06-02 05:14:01,993 INFO] Step 3450/50000; acc:  30.81; ppl: 48.70; xent: 3.89; lr: 1.00000; 28826/7560 tok/s;    224 sec\n",
            "[2020-06-02 05:14:05,150 INFO] Step 3500/50000; acc:  30.64; ppl: 49.81; xent: 3.91; lr: 1.00000; 29072/7609 tok/s;    228 sec\n",
            "[2020-06-02 05:14:05,363 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:05,478 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:08,512 INFO] Step 3550/50000; acc:  31.42; ppl: 44.20; xent: 3.79; lr: 1.00000; 27602/7244 tok/s;    231 sec\n",
            "[2020-06-02 05:14:11,674 INFO] Step 3600/50000; acc:  31.83; ppl: 43.35; xent: 3.77; lr: 1.00000; 29253/7613 tok/s;    234 sec\n",
            "[2020-06-02 05:14:12,696 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:12,781 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:15,143 INFO] Step 3650/50000; acc:  31.59; ppl: 42.69; xent: 3.75; lr: 1.00000; 27320/7244 tok/s;    238 sec\n",
            "[2020-06-02 05:14:18,252 INFO] Step 3700/50000; acc:  32.26; ppl: 40.30; xent: 3.70; lr: 1.00000; 29480/7673 tok/s;    241 sec\n",
            "[2020-06-02 05:14:20,049 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:20,116 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:21,531 INFO] Step 3750/50000; acc:  32.07; ppl: 39.50; xent: 3.68; lr: 1.00000; 27862/7322 tok/s;    244 sec\n",
            "[2020-06-02 05:14:24,750 INFO] Step 3800/50000; acc:  32.96; ppl: 37.19; xent: 3.62; lr: 1.00000; 29359/7691 tok/s;    247 sec\n",
            "[2020-06-02 05:14:27,318 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:27,433 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:27,951 INFO] Step 3850/50000; acc:  33.11; ppl: 36.05; xent: 3.58; lr: 1.00000; 27622/7296 tok/s;    250 sec\n",
            "[2020-06-02 05:14:31,115 INFO] Step 3900/50000; acc:  33.93; ppl: 32.73; xent: 3.49; lr: 1.00000; 28954/7623 tok/s;    254 sec\n",
            "[2020-06-02 05:14:34,353 INFO] Step 3950/50000; acc:  33.75; ppl: 33.42; xent: 3.51; lr: 1.00000; 29521/7671 tok/s;    257 sec\n",
            "[2020-06-02 05:14:34,625 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:34,691 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:37,618 INFO] Step 4000/50000; acc:  34.30; ppl: 31.31; xent: 3.44; lr: 1.00000; 27808/7290 tok/s;    260 sec\n",
            "[2020-06-02 05:14:40,734 INFO] Step 4050/50000; acc:  34.38; ppl: 30.75; xent: 3.43; lr: 1.00000; 29560/7712 tok/s;    263 sec\n",
            "[2020-06-02 05:14:41,891 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:42,001 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:44,208 INFO] Step 4100/50000; acc:  34.83; ppl: 28.67; xent: 3.36; lr: 1.00000; 27566/7290 tok/s;    267 sec\n",
            "[2020-06-02 05:14:47,230 INFO] Step 4150/50000; acc:  36.34; ppl: 26.48; xent: 3.28; lr: 1.00000; 29771/7778 tok/s;    270 sec\n",
            "[2020-06-02 05:14:49,214 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:49,344 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:50,600 INFO] Step 4200/50000; acc:  36.25; ppl: 25.74; xent: 3.25; lr: 1.00000; 27103/7134 tok/s;    273 sec\n",
            "[2020-06-02 05:14:53,842 INFO] Step 4250/50000; acc:  37.43; ppl: 23.85; xent: 3.17; lr: 1.00000; 29382/7712 tok/s;    276 sec\n",
            "[2020-06-02 05:14:56,568 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:14:56,633 INFO] number of examples: 7231\n",
            "[2020-06-02 05:14:57,019 INFO] Step 4300/50000; acc:  37.44; ppl: 23.78; xent: 3.17; lr: 1.00000; 27727/7318 tok/s;    279 sec\n",
            "[2020-06-02 05:15:00,185 INFO] Step 4350/50000; acc:  38.06; ppl: 22.33; xent: 3.11; lr: 1.00000; 29233/7651 tok/s;    283 sec\n",
            "[2020-06-02 05:15:03,405 INFO] Step 4400/50000; acc:  38.22; ppl: 21.96; xent: 3.09; lr: 1.00000; 30014/7781 tok/s;    286 sec\n",
            "[2020-06-02 05:15:03,797 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:03,921 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:06,755 INFO] Step 4450/50000; acc:  39.15; ppl: 20.55; xent: 3.02; lr: 1.00000; 27202/7157 tok/s;    289 sec\n",
            "[2020-06-02 05:15:09,871 INFO] Step 4500/50000; acc:  39.86; ppl: 19.66; xent: 2.98; lr: 1.00000; 29328/7657 tok/s;    292 sec\n",
            "[2020-06-02 05:15:11,137 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:11,203 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:13,255 INFO] Step 4550/50000; acc:  40.09; ppl: 19.13; xent: 2.95; lr: 1.00000; 27997/7425 tok/s;    296 sec\n",
            "[2020-06-02 05:15:16,311 INFO] Step 4600/50000; acc:  40.93; ppl: 17.91; xent: 2.89; lr: 1.00000; 29692/7748 tok/s;    299 sec\n",
            "[2020-06-02 05:15:18,373 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:18,482 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:19,651 INFO] Step 4650/50000; acc:  40.70; ppl: 17.69; xent: 2.87; lr: 1.00000; 27535/7223 tok/s;    302 sec\n",
            "[2020-06-02 05:15:22,894 INFO] Step 4700/50000; acc:  41.80; ppl: 16.68; xent: 2.81; lr: 1.00000; 29451/7719 tok/s;    305 sec\n",
            "[2020-06-02 05:15:25,730 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:25,862 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:26,164 INFO] Step 4750/50000; acc:  42.11; ppl: 16.07; xent: 2.78; lr: 1.00000; 27107/7163 tok/s;    309 sec\n",
            "[2020-06-02 05:15:29,327 INFO] Step 4800/50000; acc:  43.18; ppl: 14.83; xent: 2.70; lr: 1.00000; 28588/7497 tok/s;    312 sec\n",
            "[2020-06-02 05:15:32,595 INFO] Step 4850/50000; acc:  43.08; ppl: 15.14; xent: 2.72; lr: 1.00000; 29640/7671 tok/s;    315 sec\n",
            "[2020-06-02 05:15:33,115 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:33,183 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:35,878 INFO] Step 4900/50000; acc:  44.51; ppl: 13.64; xent: 2.61; lr: 1.00000; 27603/7318 tok/s;    318 sec\n",
            "[2020-06-02 05:15:39,053 INFO] Step 4950/50000; acc:  44.94; ppl: 13.13; xent: 2.58; lr: 1.00000; 29283/7615 tok/s;    322 sec\n",
            "[2020-06-02 05:15:40,408 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:40,517 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:42,396 INFO] Step 5000/50000; acc:  45.04; ppl: 12.86; xent: 2.55; lr: 1.00000; 27731/7345 tok/s;    325 sec\n",
            "[2020-06-02 05:15:42,417 INFO] Saving checkpoint Transliteration/rnn_model_step_5000.pt\n",
            "[2020-06-02 05:15:45,802 INFO] Step 5050/50000; acc:  47.06; ppl: 11.51; xent: 2.44; lr: 1.00000; 26718/7009 tok/s;    328 sec\n",
            "[2020-06-02 05:15:48,046 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:48,120 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:49,160 INFO] Step 5100/50000; acc:  46.51; ppl: 11.85; xent: 2.47; lr: 1.00000; 27745/7240 tok/s;    332 sec\n",
            "[2020-06-02 05:15:52,355 INFO] Step 5150/50000; acc:  48.22; ppl: 10.74; xent: 2.37; lr: 1.00000; 29428/7734 tok/s;    335 sec\n",
            "[2020-06-02 05:15:55,655 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:15:55,766 INFO] number of examples: 7231\n",
            "[2020-06-02 05:15:55,924 INFO] Step 5200/50000; acc:  48.00; ppl: 10.62; xent: 2.36; lr: 1.00000; 24949/6589 tok/s;    338 sec\n",
            "[2020-06-02 05:15:59,122 INFO] Step 5250/50000; acc:  48.85; ppl: 10.00; xent: 2.30; lr: 1.00000; 28929/7553 tok/s;    342 sec\n",
            "[2020-06-02 05:16:02,310 INFO] Step 5300/50000; acc:  49.52; ppl:  9.80; xent: 2.28; lr: 1.00000; 29910/7772 tok/s;    345 sec\n",
            "[2020-06-02 05:16:02,928 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:03,048 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:05,594 INFO] Step 5350/50000; acc:  50.81; ppl:  9.04; xent: 2.20; lr: 1.00000; 27300/7240 tok/s;    348 sec\n",
            "[2020-06-02 05:16:08,772 INFO] Step 5400/50000; acc:  51.48; ppl:  8.60; xent: 2.15; lr: 1.00000; 29638/7689 tok/s;    351 sec\n",
            "[2020-06-02 05:16:10,261 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:10,332 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:12,059 INFO] Step 5450/50000; acc:  51.09; ppl:  8.78; xent: 2.17; lr: 1.00000; 28133/7434 tok/s;    355 sec\n",
            "[2020-06-02 05:16:15,223 INFO] Step 5500/50000; acc:  53.48; ppl:  7.76; xent: 2.05; lr: 1.00000; 29393/7715 tok/s;    358 sec\n",
            "[2020-06-02 05:16:17,506 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:17,626 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:18,458 INFO] Step 5550/50000; acc:  53.15; ppl:  7.84; xent: 2.06; lr: 1.00000; 27490/7201 tok/s;    361 sec\n",
            "[2020-06-02 05:16:21,689 INFO] Step 5600/50000; acc:  54.19; ppl:  7.40; xent: 2.00; lr: 1.00000; 29297/7714 tok/s;    364 sec\n",
            "[2020-06-02 05:16:24,809 INFO] Step 5650/50000; acc:  54.26; ppl:  7.25; xent: 1.98; lr: 1.00000; 29111/7632 tok/s;    367 sec\n",
            "[2020-06-02 05:16:24,809 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:24,875 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:28,076 INFO] Step 5700/50000; acc:  55.45; ppl:  6.82; xent: 1.92; lr: 1.00000; 28018/7349 tok/s;    371 sec\n",
            "[2020-06-02 05:16:31,257 INFO] Step 5750/50000; acc:  55.62; ppl:  6.83; xent: 1.92; lr: 1.00000; 29907/7788 tok/s;    374 sec\n",
            "[2020-06-02 05:16:32,045 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:32,150 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:34,593 INFO] Step 5800/50000; acc:  56.64; ppl:  6.26; xent: 1.83; lr: 1.00000; 27544/7270 tok/s;    377 sec\n",
            "[2020-06-02 05:16:37,750 INFO] Step 5850/50000; acc:  57.18; ppl:  6.12; xent: 1.81; lr: 1.00000; 29483/7691 tok/s;    380 sec\n",
            "[2020-06-02 05:16:39,368 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:39,484 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:41,138 INFO] Step 5900/50000; acc:  57.29; ppl:  6.10; xent: 1.81; lr: 1.00000; 27448/7221 tok/s;    384 sec\n",
            "[2020-06-02 05:16:44,297 INFO] Step 5950/50000; acc:  59.60; ppl:  5.46; xent: 1.70; lr: 1.00000; 29619/7745 tok/s;    387 sec\n",
            "[2020-06-02 05:16:46,661 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:46,728 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:47,431 INFO] Step 6000/50000; acc:  59.77; ppl:  5.44; xent: 1.69; lr: 1.00000; 27911/7362 tok/s;    390 sec\n",
            "[2020-06-02 05:16:50,701 INFO] Step 6050/50000; acc:  59.77; ppl:  5.42; xent: 1.69; lr: 1.00000; 29086/7630 tok/s;    393 sec\n",
            "[2020-06-02 05:16:53,859 INFO] Step 6100/50000; acc:  60.49; ppl:  5.13; xent: 1.63; lr: 1.00000; 29167/7635 tok/s;    396 sec\n",
            "[2020-06-02 05:16:53,957 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:16:54,077 INFO] number of examples: 7231\n",
            "[2020-06-02 05:16:57,158 INFO] Step 6150/50000; acc:  62.41; ppl:  4.76; xent: 1.56; lr: 1.00000; 27347/7187 tok/s;    400 sec\n",
            "[2020-06-02 05:17:00,294 INFO] Step 6200/50000; acc:  62.86; ppl:  4.66; xent: 1.54; lr: 1.00000; 29769/7747 tok/s;    403 sec\n",
            "[2020-06-02 05:17:01,261 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:01,327 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:03,719 INFO] Step 6250/50000; acc:  63.25; ppl:  4.55; xent: 1.51; lr: 1.00000; 27539/7293 tok/s;    406 sec\n",
            "[2020-06-02 05:17:06,890 INFO] Step 6300/50000; acc:  64.68; ppl:  4.26; xent: 1.45; lr: 1.00000; 29268/7628 tok/s;    409 sec\n",
            "[2020-06-02 05:17:08,581 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:08,646 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:10,112 INFO] Step 6350/50000; acc:  64.53; ppl:  4.21; xent: 1.44; lr: 1.00000; 28091/7389 tok/s;    413 sec\n",
            "[2020-06-02 05:17:13,341 INFO] Step 6400/50000; acc:  65.49; ppl:  4.02; xent: 1.39; lr: 1.00000; 29476/7708 tok/s;    416 sec\n",
            "[2020-06-02 05:17:15,861 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:15,978 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:16,539 INFO] Step 6450/50000; acc:  66.41; ppl:  3.87; xent: 1.35; lr: 1.00000; 27378/7232 tok/s;    419 sec\n",
            "[2020-06-02 05:17:19,789 INFO] Step 6500/50000; acc:  67.05; ppl:  3.76; xent: 1.32; lr: 1.00000; 28903/7579 tok/s;    422 sec\n",
            "[2020-06-02 05:17:22,973 INFO] Step 6550/50000; acc:  67.30; ppl:  3.72; xent: 1.31; lr: 1.00000; 29523/7689 tok/s;    425 sec\n",
            "[2020-06-02 05:17:23,197 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:23,263 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:26,207 INFO] Step 6600/50000; acc:  68.32; ppl:  3.55; xent: 1.27; lr: 1.00000; 28131/7385 tok/s;    429 sec\n",
            "[2020-06-02 05:17:29,343 INFO] Step 6650/50000; acc:  69.24; ppl:  3.39; xent: 1.22; lr: 1.00000; 29256/7636 tok/s;    432 sec\n",
            "[2020-06-02 05:17:30,442 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:30,553 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:32,808 INFO] Step 6700/50000; acc:  68.97; ppl:  3.49; xent: 1.25; lr: 1.00000; 27644/7311 tok/s;    435 sec\n",
            "[2020-06-02 05:17:35,928 INFO] Step 6750/50000; acc:  70.37; ppl:  3.21; xent: 1.16; lr: 1.00000; 29383/7657 tok/s;    438 sec\n",
            "[2020-06-02 05:17:37,812 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:37,879 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:39,287 INFO] Step 6800/50000; acc:  71.33; ppl:  3.11; xent: 1.13; lr: 1.00000; 26842/7053 tok/s;    442 sec\n",
            "[2020-06-02 05:17:42,529 INFO] Step 6850/50000; acc:  71.42; ppl:  3.09; xent: 1.13; lr: 1.00000; 29561/7759 tok/s;    445 sec\n",
            "[2020-06-02 05:17:45,181 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:45,249 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:45,685 INFO] Step 6900/50000; acc:  72.30; ppl:  2.97; xent: 1.09; lr: 1.00000; 27582/7299 tok/s;    448 sec\n",
            "[2020-06-02 05:17:48,897 INFO] Step 6950/50000; acc:  72.07; ppl:  2.97; xent: 1.09; lr: 1.00000; 29021/7616 tok/s;    451 sec\n",
            "[2020-06-02 05:17:52,134 INFO] Step 7000/50000; acc:  72.68; ppl:  2.91; xent: 1.07; lr: 1.00000; 29833/7736 tok/s;    455 sec\n",
            "[2020-06-02 05:17:52,443 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:52,567 INFO] number of examples: 7231\n",
            "[2020-06-02 05:17:55,425 INFO] Step 7050/50000; acc:  73.99; ppl:  2.76; xent: 1.02; lr: 1.00000; 27269/7166 tok/s;    458 sec\n",
            "[2020-06-02 05:17:58,590 INFO] Step 7100/50000; acc:  74.21; ppl:  2.74; xent: 1.01; lr: 1.00000; 29269/7636 tok/s;    461 sec\n",
            "[2020-06-02 05:17:59,792 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:17:59,861 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:02,000 INFO] Step 7150/50000; acc:  74.19; ppl:  2.74; xent: 1.01; lr: 1.00000; 27919/7375 tok/s;    464 sec\n",
            "[2020-06-02 05:18:05,031 INFO] Step 7200/50000; acc:  75.32; ppl:  2.54; xent: 0.93; lr: 1.00000; 29318/7694 tok/s;    468 sec\n",
            "[2020-06-02 05:18:07,077 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:07,194 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:08,400 INFO] Step 7250/50000; acc:  75.55; ppl:  2.56; xent: 0.94; lr: 1.00000; 27615/7244 tok/s;    471 sec\n",
            "[2020-06-02 05:18:11,611 INFO] Step 7300/50000; acc:  76.09; ppl:  2.46; xent: 0.90; lr: 1.00000; 29554/7740 tok/s;    474 sec\n",
            "[2020-06-02 05:18:14,430 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:14,499 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:14,897 INFO] Step 7350/50000; acc:  77.49; ppl:  2.35; xent: 0.86; lr: 1.00000; 26986/7124 tok/s;    477 sec\n",
            "[2020-06-02 05:18:18,060 INFO] Step 7400/50000; acc:  77.57; ppl:  2.33; xent: 0.85; lr: 1.00000; 29063/7619 tok/s;    481 sec\n",
            "[2020-06-02 05:18:21,298 INFO] Step 7450/50000; acc:  77.84; ppl:  2.30; xent: 0.83; lr: 1.00000; 29583/7655 tok/s;    484 sec\n",
            "[2020-06-02 05:18:21,772 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:21,839 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:24,568 INFO] Step 7500/50000; acc:  78.00; ppl:  2.29; xent: 0.83; lr: 1.00000; 27691/7334 tok/s;    487 sec\n",
            "[2020-06-02 05:18:27,680 INFO] Step 7550/50000; acc:  79.24; ppl:  2.18; xent: 0.78; lr: 1.00000; 29624/7723 tok/s;    490 sec\n",
            "[2020-06-02 05:18:29,001 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:29,118 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:31,102 INFO] Step 7600/50000; acc:  79.23; ppl:  2.16; xent: 0.77; lr: 1.00000; 27694/7324 tok/s;    494 sec\n",
            "[2020-06-02 05:18:34,214 INFO] Step 7650/50000; acc:  80.98; ppl:  2.01; xent: 0.70; lr: 1.00000; 29132/7621 tok/s;    497 sec\n",
            "[2020-06-02 05:18:36,326 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:36,392 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:37,478 INFO] Step 7700/50000; acc:  80.45; ppl:  2.06; xent: 0.72; lr: 1.00000; 28222/7388 tok/s;    500 sec\n",
            "[2020-06-02 05:18:40,711 INFO] Step 7750/50000; acc:  81.52; ppl:  1.99; xent: 0.69; lr: 1.00000; 29375/7712 tok/s;    503 sec\n",
            "[2020-06-02 05:18:43,601 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:43,731 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:43,970 INFO] Step 7800/50000; acc:  82.25; ppl:  1.92; xent: 0.65; lr: 1.00000; 27500/7253 tok/s;    506 sec\n",
            "[2020-06-02 05:18:47,084 INFO] Step 7850/50000; acc:  82.87; ppl:  1.88; xent: 0.63; lr: 1.00000; 28890/7576 tok/s;    510 sec\n",
            "[2020-06-02 05:18:50,377 INFO] Step 7900/50000; acc:  82.62; ppl:  1.89; xent: 0.64; lr: 1.00000; 29479/7627 tok/s;    513 sec\n",
            "[2020-06-02 05:18:50,957 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:51,025 INFO] number of examples: 7231\n",
            "[2020-06-02 05:18:53,709 INFO] Step 7950/50000; acc:  84.29; ppl:  1.78; xent: 0.57; lr: 1.00000; 27237/7226 tok/s;    516 sec\n",
            "[2020-06-02 05:18:56,788 INFO] Step 8000/50000; acc:  84.98; ppl:  1.72; xent: 0.54; lr: 1.00000; 29762/7742 tok/s;    519 sec\n",
            "[2020-06-02 05:18:58,272 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:18:58,339 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:00,164 INFO] Step 8050/50000; acc:  83.94; ppl:  1.78; xent: 0.57; lr: 1.00000; 27901/7358 tok/s;    523 sec\n",
            "[2020-06-02 05:19:03,297 INFO] Step 8100/50000; acc:  86.43; ppl:  1.63; xent: 0.49; lr: 1.00000; 29210/7676 tok/s;    526 sec\n",
            "[2020-06-02 05:19:05,538 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:05,654 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:06,598 INFO] Step 8150/50000; acc:  86.12; ppl:  1.65; xent: 0.50; lr: 1.00000; 27676/7250 tok/s;    529 sec\n",
            "[2020-06-02 05:19:09,823 INFO] Step 8200/50000; acc:  86.58; ppl:  1.64; xent: 0.49; lr: 1.00000; 29224/7665 tok/s;    532 sec\n",
            "[2020-06-02 05:19:12,850 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:12,916 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:12,992 INFO] Step 8250/50000; acc:  87.69; ppl:  1.57; xent: 0.45; lr: 1.00000; 28198/7424 tok/s;    535 sec\n",
            "[2020-06-02 05:19:16,218 INFO] Step 8300/50000; acc:  87.76; ppl:  1.55; xent: 0.44; lr: 1.00000; 28839/7556 tok/s;    539 sec\n",
            "[2020-06-02 05:19:19,522 INFO] Step 8350/50000; acc:  88.29; ppl:  1.54; xent: 0.43; lr: 1.00000; 28636/7439 tok/s;    542 sec\n",
            "[2020-06-02 05:19:20,255 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:20,362 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:22,906 INFO] Step 8400/50000; acc:  88.75; ppl:  1.50; xent: 0.40; lr: 1.00000; 26866/7101 tok/s;    545 sec\n",
            "[2020-06-02 05:19:26,096 INFO] Step 8450/50000; acc:  89.62; ppl:  1.45; xent: 0.37; lr: 1.00000; 29537/7681 tok/s;    549 sec\n",
            "[2020-06-02 05:19:27,638 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:27,759 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:29,468 INFO] Step 8500/50000; acc:  89.27; ppl:  1.45; xent: 0.37; lr: 1.00000; 27542/7264 tok/s;    552 sec\n",
            "[2020-06-02 05:19:32,585 INFO] Step 8550/50000; acc:  90.59; ppl:  1.41; xent: 0.34; lr: 1.00000; 29520/7744 tok/s;    555 sec\n",
            "[2020-06-02 05:19:34,917 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:34,984 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:35,750 INFO] Step 8600/50000; acc:  90.24; ppl:  1.41; xent: 0.34; lr: 1.00000; 28146/7398 tok/s;    558 sec\n",
            "[2020-06-02 05:19:38,999 INFO] Step 8650/50000; acc:  90.86; ppl:  1.39; xent: 0.33; lr: 1.00000; 29373/7718 tok/s;    561 sec\n",
            "[2020-06-02 05:19:42,085 INFO] Step 8700/50000; acc:  91.54; ppl:  1.36; xent: 0.31; lr: 1.00000; 29270/7686 tok/s;    565 sec\n",
            "[2020-06-02 05:19:42,142 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:42,255 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:45,417 INFO] Step 8750/50000; acc:  91.58; ppl:  1.36; xent: 0.31; lr: 1.00000; 27546/7211 tok/s;    568 sec\n",
            "[2020-06-02 05:19:48,570 INFO] Step 8800/50000; acc:  91.80; ppl:  1.34; xent: 0.30; lr: 1.00000; 29761/7762 tok/s;    571 sec\n",
            "[2020-06-02 05:19:49,437 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:49,507 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:51,897 INFO] Step 8850/50000; acc:  92.13; ppl:  1.33; xent: 0.28; lr: 1.00000; 27753/7338 tok/s;    574 sec\n",
            "[2020-06-02 05:19:55,029 INFO] Step 8900/50000; acc:  92.13; ppl:  1.32; xent: 0.28; lr: 1.00000; 29794/7764 tok/s;    578 sec\n",
            "[2020-06-02 05:19:56,687 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:19:56,802 INFO] number of examples: 7231\n",
            "[2020-06-02 05:19:58,379 INFO] Step 8950/50000; acc:  92.23; ppl:  1.33; xent: 0.28; lr: 1.00000; 27442/7206 tok/s;    581 sec\n",
            "[2020-06-02 05:20:01,588 INFO] Step 9000/50000; acc:  92.95; ppl:  1.29; xent: 0.26; lr: 1.00000; 29694/7751 tok/s;    584 sec\n",
            "[2020-06-02 05:20:04,027 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:04,148 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:04,780 INFO] Step 9050/50000; acc:  92.59; ppl:  1.33; xent: 0.28; lr: 1.00000; 27336/7222 tok/s;    587 sec\n",
            "[2020-06-02 05:20:08,043 INFO] Step 9100/50000; acc:  92.97; ppl:  1.29; xent: 0.26; lr: 1.00000; 28768/7545 tok/s;    591 sec\n",
            "[2020-06-02 05:20:11,171 INFO] Step 9150/50000; acc:  93.34; ppl:  1.27; xent: 0.24; lr: 1.00000; 29336/7678 tok/s;    594 sec\n",
            "[2020-06-02 05:20:11,362 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:11,429 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:14,453 INFO] Step 9200/50000; acc:  93.37; ppl:  1.26; xent: 0.23; lr: 1.00000; 28277/7421 tok/s;    597 sec\n",
            "[2020-06-02 05:20:17,547 INFO] Step 9250/50000; acc:  93.82; ppl:  1.25; xent: 0.22; lr: 1.00000; 29896/7780 tok/s;    600 sec\n",
            "[2020-06-02 05:20:18,544 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:18,657 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:20,946 INFO] Step 9300/50000; acc:  93.80; ppl:  1.26; xent: 0.23; lr: 1.00000; 27894/7396 tok/s;    603 sec\n",
            "[2020-06-02 05:20:24,037 INFO] Step 9350/50000; acc:  93.81; ppl:  1.25; xent: 0.22; lr: 1.00000; 29645/7716 tok/s;    607 sec\n",
            "[2020-06-02 05:20:25,817 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:25,895 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:27,309 INFO] Step 9400/50000; acc:  94.10; ppl:  1.23; xent: 0.21; lr: 1.00000; 27917/7337 tok/s;    610 sec\n",
            "[2020-06-02 05:20:30,482 INFO] Step 9450/50000; acc:  94.63; ppl:  1.21; xent: 0.19; lr: 1.00000; 29796/7805 tok/s;    613 sec\n",
            "[2020-06-02 05:20:33,067 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:33,178 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:33,701 INFO] Step 9500/50000; acc:  94.25; ppl:  1.23; xent: 0.21; lr: 1.00000; 27462/7254 tok/s;    616 sec\n",
            "[2020-06-02 05:20:36,893 INFO] Step 9550/50000; acc:  94.47; ppl:  1.22; xent: 0.20; lr: 1.00000; 28700/7556 tok/s;    619 sec\n",
            "[2020-06-02 05:20:40,140 INFO] Step 9600/50000; acc:  94.86; ppl:  1.20; xent: 0.19; lr: 1.00000; 29439/7649 tok/s;    623 sec\n",
            "[2020-06-02 05:20:40,430 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:40,548 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:43,438 INFO] Step 9650/50000; acc:  94.89; ppl:  1.20; xent: 0.18; lr: 1.00000; 27534/7218 tok/s;    626 sec\n",
            "[2020-06-02 05:20:46,580 INFO] Step 9700/50000; acc:  94.97; ppl:  1.20; xent: 0.18; lr: 1.00000; 29315/7648 tok/s;    629 sec\n",
            "[2020-06-02 05:20:47,727 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:47,792 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:49,982 INFO] Step 9750/50000; acc:  94.94; ppl:  1.20; xent: 0.19; lr: 1.00000; 28142/7442 tok/s;    632 sec\n",
            "[2020-06-02 05:20:53,013 INFO] Step 9800/50000; acc:  95.57; ppl:  1.17; xent: 0.16; lr: 1.00000; 29691/7757 tok/s;    635 sec\n",
            "[2020-06-02 05:20:54,978 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:20:55,093 INFO] number of examples: 7231\n",
            "[2020-06-02 05:20:56,334 INFO] Step 9850/50000; acc:  95.33; ppl:  1.19; xent: 0.17; lr: 1.00000; 27495/7238 tok/s;    639 sec\n",
            "[2020-06-02 05:20:59,540 INFO] Step 9900/50000; acc:  95.18; ppl:  1.19; xent: 0.17; lr: 1.00000; 29716/7799 tok/s;    642 sec\n",
            "[2020-06-02 05:21:02,280 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:02,347 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:02,731 INFO] Step 9950/50000; acc:  95.62; ppl:  1.17; xent: 0.16; lr: 1.00000; 27605/7286 tok/s;    645 sec\n",
            "[2020-06-02 05:21:05,879 INFO] Step 10000/50000; acc:  95.54; ppl:  1.18; xent: 0.16; lr: 1.00000; 29401/7695 tok/s;    648 sec\n",
            "[2020-06-02 05:21:05,880 INFO] Loading dataset from Transliteration/Cleaned.valid.0.pt\n",
            "[2020-06-02 05:21:05,944 INFO] number of examples: 1000\n",
            "[2020-06-02 05:21:08,275 INFO] Validation perplexity: 879818\n",
            "[2020-06-02 05:21:08,275 INFO] Validation accuracy: 24.3924\n",
            "[2020-06-02 05:21:08,298 INFO] Saving checkpoint Transliteration/rnn_model_step_10000.pt\n",
            "[2020-06-02 05:21:11,809 INFO] Step 10050/50000; acc:  95.60; ppl:  1.17; xent: 0.16; lr: 1.00000; 16299/4225 tok/s;    654 sec\n",
            "[2020-06-02 05:21:12,193 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:12,263 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:15,087 INFO] Step 10100/50000; acc:  95.68; ppl:  1.17; xent: 0.16; lr: 1.00000; 27802/7315 tok/s;    658 sec\n",
            "[2020-06-02 05:21:18,179 INFO] Step 10150/50000; acc:  95.66; ppl:  1.18; xent: 0.16; lr: 1.00000; 29548/7714 tok/s;    661 sec\n",
            "[2020-06-02 05:21:19,742 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:19,864 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:21,872 INFO] Step 10200/50000; acc:  95.58; ppl:  1.18; xent: 0.16; lr: 1.00000; 25658/6805 tok/s;    664 sec\n",
            "[2020-06-02 05:21:24,901 INFO] Step 10250/50000; acc:  95.70; ppl:  1.17; xent: 0.15; lr: 1.00000; 29951/7816 tok/s;    667 sec\n",
            "[2020-06-02 05:21:26,951 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:27,023 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:28,182 INFO] Step 10300/50000; acc:  95.64; ppl:  1.17; xent: 0.16; lr: 1.00000; 28024/7351 tok/s;    671 sec\n",
            "[2020-06-02 05:21:31,365 INFO] Step 10350/50000; acc:  95.90; ppl:  1.16; xent: 0.15; lr: 1.00000; 30012/7866 tok/s;    674 sec\n",
            "[2020-06-02 05:21:34,153 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:34,271 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:34,572 INFO] Step 10400/50000; acc:  95.59; ppl:  1.17; xent: 0.16; lr: 1.00000; 27637/7303 tok/s;    677 sec\n",
            "[2020-06-02 05:21:37,685 INFO] Step 10450/50000; acc:  96.06; ppl:  1.16; xent: 0.15; lr: 1.00000; 29045/7617 tok/s;    680 sec\n",
            "[2020-06-02 05:21:40,939 INFO] Step 10500/50000; acc:  96.12; ppl:  1.15; xent: 0.14; lr: 1.00000; 29775/7706 tok/s;    683 sec\n",
            "[2020-06-02 05:21:41,455 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:41,590 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:44,257 INFO] Step 10550/50000; acc:  96.12; ppl:  1.15; xent: 0.14; lr: 1.00000; 27312/7241 tok/s;    687 sec\n",
            "[2020-06-02 05:21:47,363 INFO] Step 10600/50000; acc:  96.28; ppl:  1.15; xent: 0.14; lr: 1.00000; 29938/7785 tok/s;    690 sec\n",
            "[2020-06-02 05:21:48,740 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:48,809 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:50,677 INFO] Step 10650/50000; acc:  96.14; ppl:  1.15; xent: 0.14; lr: 1.00000; 27963/7406 tok/s;    693 sec\n",
            "[2020-06-02 05:21:53,792 INFO] Step 10700/50000; acc:  96.32; ppl:  1.15; xent: 0.14; lr: 1.00000; 29220/7666 tok/s;    696 sec\n",
            "[2020-06-02 05:21:56,009 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:21:56,128 INFO] number of examples: 7231\n",
            "[2020-06-02 05:21:57,162 INFO] Step 10750/50000; acc:  96.29; ppl:  1.15; xent: 0.14; lr: 1.00000; 27652/7216 tok/s;    700 sec\n",
            "[2020-06-02 05:22:00,381 INFO] Step 10800/50000; acc:  96.41; ppl:  1.14; xent: 0.13; lr: 1.00000; 29202/7674 tok/s;    703 sec\n",
            "[2020-06-02 05:22:03,332 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:03,399 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:03,552 INFO] Step 10850/50000; acc:  96.35; ppl:  1.14; xent: 0.13; lr: 1.00000; 28077/7415 tok/s;    706 sec\n",
            "[2020-06-02 05:22:06,726 INFO] Step 10900/50000; acc:  96.34; ppl:  1.14; xent: 0.13; lr: 1.00000; 29151/7611 tok/s;    709 sec\n",
            "[2020-06-02 05:22:09,955 INFO] Step 10950/50000; acc:  96.45; ppl:  1.14; xent: 0.13; lr: 1.00000; 29535/7674 tok/s;    712 sec\n",
            "[2020-06-02 05:22:10,595 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:10,710 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:13,230 INFO] Step 11000/50000; acc:  96.18; ppl:  1.15; xent: 0.14; lr: 1.00000; 27366/7258 tok/s;    716 sec\n",
            "[2020-06-02 05:22:16,397 INFO] Step 11050/50000; acc:  96.39; ppl:  1.14; xent: 0.13; lr: 1.00000; 29744/7716 tok/s;    719 sec\n",
            "[2020-06-02 05:22:17,897 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:18,022 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:19,764 INFO] Step 11100/50000; acc:  96.57; ppl:  1.14; xent: 0.13; lr: 1.00000; 27465/7257 tok/s;    722 sec\n",
            "[2020-06-02 05:22:22,950 INFO] Step 11150/50000; acc:  96.80; ppl:  1.12; xent: 0.12; lr: 1.00000; 29189/7661 tok/s;    725 sec\n",
            "[2020-06-02 05:22:25,214 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:25,280 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:26,110 INFO] Step 11200/50000; acc:  96.52; ppl:  1.13; xent: 0.12; lr: 1.00000; 28139/7371 tok/s;    729 sec\n",
            "[2020-06-02 05:22:29,340 INFO] Step 11250/50000; acc:  96.74; ppl:  1.12; xent: 0.12; lr: 1.00000; 29311/7717 tok/s;    732 sec\n",
            "[2020-06-02 05:22:32,445 INFO] Step 11300/50000; acc:  96.93; ppl:  1.12; xent: 0.11; lr: 1.00000; 29255/7670 tok/s;    735 sec\n",
            "[2020-06-02 05:22:32,445 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:32,562 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:35,728 INFO] Step 11350/50000; acc:  96.96; ppl:  1.12; xent: 0.11; lr: 1.00000; 27885/7314 tok/s;    738 sec\n",
            "[2020-06-02 05:22:38,906 INFO] Step 11400/50000; acc:  96.78; ppl:  1.13; xent: 0.12; lr: 1.00000; 29936/7795 tok/s;    741 sec\n",
            "[2020-06-02 05:22:39,696 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:39,774 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:42,194 INFO] Step 11450/50000; acc:  96.81; ppl:  1.12; xent: 0.12; lr: 1.00000; 27943/7376 tok/s;    745 sec\n",
            "[2020-06-02 05:22:45,335 INFO] Step 11500/50000; acc:  96.97; ppl:  1.12; xent: 0.12; lr: 1.00000; 29635/7731 tok/s;    748 sec\n",
            "[2020-06-02 05:22:46,928 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:47,044 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:48,698 INFO] Step 11550/50000; acc:  96.56; ppl:  1.13; xent: 0.13; lr: 1.00000; 27650/7274 tok/s;    751 sec\n",
            "[2020-06-02 05:22:51,866 INFO] Step 11600/50000; acc:  97.02; ppl:  1.12; xent: 0.11; lr: 1.00000; 29535/7723 tok/s;    754 sec\n",
            "[2020-06-02 05:22:54,234 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:22:54,357 INFO] number of examples: 7231\n",
            "[2020-06-02 05:22:55,043 INFO] Step 11650/50000; acc:  96.98; ppl:  1.12; xent: 0.11; lr: 1.00000; 27534/7262 tok/s;    758 sec\n",
            "[2020-06-02 05:22:58,330 INFO] Step 11700/50000; acc:  97.14; ppl:  1.11; xent: 0.10; lr: 1.00000; 28929/7589 tok/s;    761 sec\n",
            "[2020-06-02 05:23:01,474 INFO] Step 11750/50000; acc:  97.21; ppl:  1.11; xent: 0.10; lr: 1.00000; 29303/7670 tok/s;    764 sec\n",
            "[2020-06-02 05:23:01,573 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:01,640 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:04,650 INFO] Step 11800/50000; acc:  97.12; ppl:  1.11; xent: 0.11; lr: 1.00000; 28408/7466 tok/s;    767 sec\n",
            "[2020-06-02 05:23:07,796 INFO] Step 11850/50000; acc:  97.08; ppl:  1.11; xent: 0.10; lr: 1.00000; 29674/7722 tok/s;    770 sec\n",
            "[2020-06-02 05:23:08,747 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:08,865 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:11,183 INFO] Step 11900/50000; acc:  97.12; ppl:  1.11; xent: 0.10; lr: 1.00000; 27851/7376 tok/s;    774 sec\n",
            "[2020-06-02 05:23:14,300 INFO] Step 11950/50000; acc:  97.34; ppl:  1.11; xent: 0.10; lr: 1.00000; 29773/7760 tok/s;    777 sec\n",
            "[2020-06-02 05:23:16,018 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:16,086 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:17,546 INFO] Step 12000/50000; acc:  97.07; ppl:  1.12; xent: 0.11; lr: 1.00000; 27888/7336 tok/s;    780 sec\n",
            "[2020-06-02 05:23:20,772 INFO] Step 12050/50000; acc:  97.41; ppl:  1.11; xent: 0.10; lr: 1.00000; 29491/7712 tok/s;    783 sec\n",
            "[2020-06-02 05:23:23,292 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:23,406 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:23,962 INFO] Step 12100/50000; acc:  97.36; ppl:  1.10; xent: 0.10; lr: 1.00000; 27453/7252 tok/s;    786 sec\n",
            "[2020-06-02 05:23:27,161 INFO] Step 12150/50000; acc:  97.01; ppl:  1.12; xent: 0.12; lr: 1.00000; 29363/7700 tok/s;    790 sec\n",
            "[2020-06-02 05:23:30,348 INFO] Step 12200/50000; acc:  97.22; ppl:  1.11; xent: 0.11; lr: 1.00000; 29493/7681 tok/s;    793 sec\n",
            "[2020-06-02 05:23:30,571 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:30,706 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:33,664 INFO] Step 12250/50000; acc:  97.28; ppl:  1.11; xent: 0.10; lr: 1.00000; 27433/7202 tok/s;    796 sec\n",
            "[2020-06-02 05:23:36,781 INFO] Step 12300/50000; acc:  97.28; ppl:  1.11; xent: 0.10; lr: 1.00000; 29434/7682 tok/s;    799 sec\n",
            "[2020-06-02 05:23:37,889 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:37,957 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:40,181 INFO] Step 12350/50000; acc:  97.17; ppl:  1.11; xent: 0.11; lr: 1.00000; 28173/7451 tok/s;    803 sec\n",
            "[2020-06-02 05:23:43,257 INFO] Step 12400/50000; acc:  97.53; ppl:  1.10; xent: 0.10; lr: 1.00000; 29808/7768 tok/s;    806 sec\n",
            "[2020-06-02 05:23:45,097 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:45,221 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:46,533 INFO] Step 12450/50000; acc:  97.34; ppl:  1.11; xent: 0.10; lr: 1.00000; 27513/7229 tok/s;    809 sec\n",
            "[2020-06-02 05:23:49,763 INFO] Step 12500/50000; acc:  97.40; ppl:  1.10; xent: 0.10; lr: 1.00000; 29670/7788 tok/s;    812 sec\n",
            "[2020-06-02 05:23:52,428 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:52,496 INFO] number of examples: 7231\n",
            "[2020-06-02 05:23:52,988 INFO] Step 12550/50000; acc:  97.44; ppl:  1.10; xent: 0.10; lr: 1.00000; 26997/7144 tok/s;    815 sec\n",
            "[2020-06-02 05:23:56,158 INFO] Step 12600/50000; acc:  97.46; ppl:  1.10; xent: 0.10; lr: 1.00000; 29410/7718 tok/s;    819 sec\n",
            "[2020-06-02 05:23:59,382 INFO] Step 12650/50000; acc:  97.44; ppl:  1.10; xent: 0.10; lr: 1.00000; 29950/7766 tok/s;    822 sec\n",
            "[2020-06-02 05:23:59,697 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:23:59,767 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:02,581 INFO] Step 12700/50000; acc:  97.31; ppl:  1.10; xent: 0.09; lr: 1.00000; 28057/7373 tok/s;    825 sec\n",
            "[2020-06-02 05:24:05,686 INFO] Step 12750/50000; acc:  97.52; ppl:  1.10; xent: 0.09; lr: 1.00000; 29829/7782 tok/s;    828 sec\n",
            "[2020-06-02 05:24:06,873 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:06,994 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:09,104 INFO] Step 12800/50000; acc:  97.48; ppl:  1.10; xent: 0.10; lr: 1.00000; 27851/7357 tok/s;    832 sec\n",
            "[2020-06-02 05:24:12,108 INFO] Step 12850/50000; acc:  97.77; ppl:  1.09; xent: 0.08; lr: 1.00000; 29583/7764 tok/s;    835 sec\n",
            "[2020-06-02 05:24:14,152 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:14,220 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:15,426 INFO] Step 12900/50000; acc:  97.74; ppl:  1.09; xent: 0.09; lr: 1.00000; 28044/7356 tok/s;    838 sec\n",
            "[2020-06-02 05:24:18,631 INFO] Step 12950/50000; acc:  97.71; ppl:  1.09; xent: 0.08; lr: 1.00000; 29608/7754 tok/s;    841 sec\n",
            "[2020-06-02 05:24:21,388 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:21,507 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:21,837 INFO] Step 13000/50000; acc:  97.57; ppl:  1.09; xent: 0.09; lr: 1.00000; 27660/7302 tok/s;    844 sec\n",
            "[2020-06-02 05:24:24,957 INFO] Step 13050/50000; acc:  97.70; ppl:  1.09; xent: 0.09; lr: 1.00000; 29463/7724 tok/s;    847 sec\n",
            "[2020-06-02 05:24:28,152 INFO] Step 13100/50000; acc:  97.55; ppl:  1.10; xent: 0.10; lr: 1.00000; 29978/7757 tok/s;    851 sec\n",
            "[2020-06-02 05:24:28,624 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:28,690 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:31,458 INFO] Step 13150/50000; acc:  97.71; ppl:  1.09; xent: 0.09; lr: 1.00000; 27395/7256 tok/s;    854 sec\n",
            "[2020-06-02 05:24:34,556 INFO] Step 13200/50000; acc:  97.92; ppl:  1.08; xent: 0.08; lr: 1.00000; 29764/7760 tok/s;    857 sec\n",
            "[2020-06-02 05:24:35,874 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:35,941 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:37,899 INFO] Step 13250/50000; acc:  97.76; ppl:  1.09; xent: 0.08; lr: 1.00000; 28339/7495 tok/s;    860 sec\n",
            "[2020-06-02 05:24:40,992 INFO] Step 13300/50000; acc:  98.03; ppl:  1.08; xent: 0.08; lr: 1.00000; 29308/7667 tok/s;    863 sec\n",
            "[2020-06-02 05:24:43,142 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:43,266 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:44,335 INFO] Step 13350/50000; acc:  97.82; ppl:  1.09; xent: 0.08; lr: 1.00000; 27559/7215 tok/s;    867 sec\n",
            "[2020-06-02 05:24:47,546 INFO] Step 13400/50000; acc:  97.94; ppl:  1.08; xent: 0.07; lr: 1.00000; 29581/7766 tok/s;    870 sec\n",
            "[2020-06-02 05:24:50,415 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:50,481 INFO] number of examples: 7231\n",
            "[2020-06-02 05:24:50,723 INFO] Step 13450/50000; acc:  98.28; ppl:  1.07; xent: 0.07; lr: 1.00000; 28202/7438 tok/s;    873 sec\n",
            "[2020-06-02 05:24:53,845 INFO] Step 13500/50000; acc:  98.12; ppl:  1.07; xent: 0.07; lr: 1.00000; 28819/7557 tok/s;    876 sec\n",
            "[2020-06-02 05:24:57,107 INFO] Step 13550/50000; acc:  97.86; ppl:  1.09; xent: 0.08; lr: 1.00000; 29758/7699 tok/s;    880 sec\n",
            "[2020-06-02 05:24:57,672 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:24:57,797 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:00,410 INFO] Step 13600/50000; acc:  98.11; ppl:  1.07; xent: 0.07; lr: 1.00000; 27475/7289 tok/s;    883 sec\n",
            "[2020-06-02 05:25:03,520 INFO] Step 13650/50000; acc:  98.06; ppl:  1.08; xent: 0.07; lr: 1.00000; 29464/7665 tok/s;    886 sec\n",
            "[2020-06-02 05:25:04,972 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:05,038 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:06,919 INFO] Step 13700/50000; acc:  97.82; ppl:  1.09; xent: 0.08; lr: 1.00000; 27716/7309 tok/s;    889 sec\n",
            "[2020-06-02 05:25:10,013 INFO] Step 13750/50000; acc:  98.07; ppl:  1.08; xent: 0.07; lr: 1.00000; 29578/7772 tok/s;    892 sec\n",
            "[2020-06-02 05:25:12,247 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:12,315 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:13,258 INFO] Step 13800/50000; acc:  97.86; ppl:  1.08; xent: 0.08; lr: 1.00000; 28154/7376 tok/s;    896 sec\n",
            "[2020-06-02 05:25:16,459 INFO] Step 13850/50000; acc:  98.04; ppl:  1.08; xent: 0.07; lr: 1.00000; 29445/7723 tok/s;    899 sec\n",
            "[2020-06-02 05:25:19,457 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:19,578 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:19,653 INFO] Step 13900/50000; acc:  98.22; ppl:  1.07; xent: 0.07; lr: 1.00000; 27977/7366 tok/s;    902 sec\n",
            "[2020-06-02 05:25:22,815 INFO] Step 13950/50000; acc:  98.03; ppl:  1.07; xent: 0.07; lr: 1.00000; 29426/7709 tok/s;    905 sec\n",
            "[2020-06-02 05:25:25,980 INFO] Step 14000/50000; acc:  98.07; ppl:  1.07; xent: 0.07; lr: 1.00000; 29885/7764 tok/s;    908 sec\n",
            "[2020-06-02 05:25:26,713 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:26,782 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:29,257 INFO] Step 14050/50000; acc:  98.30; ppl:  1.06; xent: 0.06; lr: 1.00000; 27753/7335 tok/s;    912 sec\n",
            "[2020-06-02 05:25:32,424 INFO] Step 14100/50000; acc:  98.08; ppl:  1.08; xent: 0.08; lr: 1.00000; 29749/7736 tok/s;    915 sec\n",
            "[2020-06-02 05:25:33,922 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:34,038 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:35,750 INFO] Step 14150/50000; acc:  98.05; ppl:  1.08; xent: 0.08; lr: 1.00000; 27920/7363 tok/s;    918 sec\n",
            "[2020-06-02 05:25:38,892 INFO] Step 14200/50000; acc:  98.24; ppl:  1.07; xent: 0.07; lr: 1.00000; 29285/7683 tok/s;    921 sec\n",
            "[2020-06-02 05:25:41,250 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:41,322 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:42,151 INFO] Step 14250/50000; acc:  98.12; ppl:  1.07; xent: 0.07; lr: 1.00000; 27339/7186 tok/s;    925 sec\n",
            "[2020-06-02 05:25:45,408 INFO] Step 14300/50000; acc:  98.08; ppl:  1.07; xent: 0.07; lr: 1.00000; 29294/7697 tok/s;    928 sec\n",
            "[2020-06-02 05:25:48,525 INFO] Step 14350/50000; acc:  98.43; ppl:  1.06; xent: 0.06; lr: 1.00000; 28979/7610 tok/s;    931 sec\n",
            "[2020-06-02 05:25:48,582 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:48,652 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:51,786 INFO] Step 14400/50000; acc:  98.58; ppl:  1.06; xent: 0.05; lr: 1.00000; 28149/7369 tok/s;    934 sec\n",
            "[2020-06-02 05:25:54,965 INFO] Step 14450/50000; acc:  98.15; ppl:  1.07; xent: 0.07; lr: 1.00000; 29518/7698 tok/s;    937 sec\n",
            "[2020-06-02 05:25:55,822 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:25:55,945 INFO] number of examples: 7231\n",
            "[2020-06-02 05:25:58,313 INFO] Step 14500/50000; acc:  98.36; ppl:  1.07; xent: 0.07; lr: 1.00000; 27583/7293 tok/s;    941 sec\n",
            "[2020-06-02 05:26:01,427 INFO] Step 14550/50000; acc:  98.41; ppl:  1.07; xent: 0.07; lr: 1.00000; 29958/7806 tok/s;    944 sec\n",
            "[2020-06-02 05:26:03,096 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:03,161 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:04,710 INFO] Step 14600/50000; acc:  98.37; ppl:  1.06; xent: 0.06; lr: 1.00000; 28005/7354 tok/s;    947 sec\n",
            "[2020-06-02 05:26:07,893 INFO] Step 14650/50000; acc:  98.22; ppl:  1.07; xent: 0.07; lr: 1.00000; 29938/7815 tok/s;    950 sec\n",
            "[2020-06-02 05:26:10,323 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:10,446 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:11,072 INFO] Step 14700/50000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 1.00000; 27446/7251 tok/s;    954 sec\n",
            "[2020-06-02 05:26:14,210 INFO] Step 14750/50000; acc:  98.22; ppl:  1.07; xent: 0.07; lr: 1.00000; 29910/7844 tok/s;    957 sec\n",
            "[2020-06-02 05:26:17,306 INFO] Step 14800/50000; acc:  98.24; ppl:  1.07; xent: 0.07; lr: 1.00000; 29644/7759 tok/s;    960 sec\n",
            "[2020-06-02 05:26:17,508 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:17,642 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:20,660 INFO] Step 14850/50000; acc:  98.32; ppl:  1.07; xent: 0.06; lr: 1.00000; 27673/7263 tok/s;    963 sec\n",
            "[2020-06-02 05:26:23,791 INFO] Step 14900/50000; acc:  98.39; ppl:  1.07; xent: 0.06; lr: 1.00000; 29542/7688 tok/s;    966 sec\n",
            "[2020-06-02 05:26:24,793 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:24,860 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:27,117 INFO] Step 14950/50000; acc:  98.13; ppl:  1.07; xent: 0.07; lr: 1.00000; 28498/7556 tok/s;    970 sec\n",
            "[2020-06-02 05:26:30,189 INFO] Step 15000/50000; acc:  98.30; ppl:  1.07; xent: 0.07; lr: 1.00000; 29832/7765 tok/s;    973 sec\n",
            "[2020-06-02 05:26:30,213 INFO] Saving checkpoint Transliteration/rnn_model_step_15000.pt\n",
            "[2020-06-02 05:26:32,264 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:32,391 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:33,792 INFO] Step 15050/50000; acc:  98.28; ppl:  1.07; xent: 0.07; lr: 1.00000; 25356/6664 tok/s;    976 sec\n",
            "[2020-06-02 05:26:36,919 INFO] Step 15100/50000; acc:  98.47; ppl:  1.06; xent: 0.05; lr: 1.00000; 30223/7917 tok/s;    979 sec\n",
            "[2020-06-02 05:26:39,519 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:39,588 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:40,106 INFO] Step 15150/50000; acc:  98.38; ppl:  1.06; xent: 0.06; lr: 1.00000; 27740/7327 tok/s;    983 sec\n",
            "[2020-06-02 05:26:43,507 INFO] Step 15200/50000; acc:  98.24; ppl:  1.06; xent: 0.06; lr: 1.00000; 26940/7093 tok/s;    986 sec\n",
            "[2020-06-02 05:26:46,755 INFO] Step 15250/50000; acc:  98.42; ppl:  1.06; xent: 0.06; lr: 1.00000; 29429/7647 tok/s;    989 sec\n",
            "[2020-06-02 05:26:47,035 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:47,161 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:50,023 INFO] Step 15300/50000; acc:  98.36; ppl:  1.07; xent: 0.06; lr: 1.00000; 27785/7284 tok/s;    992 sec\n",
            "[2020-06-02 05:26:53,112 INFO] Step 15350/50000; acc:  98.68; ppl:  1.05; xent: 0.05; lr: 1.00000; 29816/7779 tok/s;    996 sec\n",
            "[2020-06-02 05:26:54,242 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:26:54,379 INFO] number of examples: 7231\n",
            "[2020-06-02 05:26:56,542 INFO] Step 15400/50000; acc:  98.32; ppl:  1.06; xent: 0.06; lr: 1.00000; 27915/7382 tok/s;    999 sec\n",
            "[2020-06-02 05:26:59,561 INFO] Step 15450/50000; acc:  98.50; ppl:  1.06; xent: 0.06; lr: 1.00000; 29813/7789 tok/s;   1002 sec\n",
            "[2020-06-02 05:27:01,513 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:01,581 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:02,833 INFO] Step 15500/50000; acc:  98.26; ppl:  1.06; xent: 0.06; lr: 1.00000; 27911/7347 tok/s;   1005 sec\n",
            "[2020-06-02 05:27:06,037 INFO] Step 15550/50000; acc:  98.45; ppl:  1.06; xent: 0.06; lr: 1.00000; 29730/7803 tok/s;   1009 sec\n",
            "[2020-06-02 05:27:08,759 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:08,886 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:09,266 INFO] Step 15600/50000; acc:  98.43; ppl:  1.07; xent: 0.06; lr: 1.00000; 27276/7199 tok/s;   1012 sec\n",
            "[2020-06-02 05:27:12,442 INFO] Step 15650/50000; acc:  98.53; ppl:  1.06; xent: 0.06; lr: 1.00000; 29143/7627 tok/s;   1015 sec\n",
            "[2020-06-02 05:27:15,661 INFO] Step 15700/50000; acc:  98.33; ppl:  1.06; xent: 0.06; lr: 1.00000; 30029/7785 tok/s;   1018 sec\n",
            "[2020-06-02 05:27:16,043 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:16,108 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:18,928 INFO] Step 15750/50000; acc:  97.94; ppl:  1.11; xent: 0.10; lr: 1.00000; 27888/7337 tok/s;   1021 sec\n",
            "[2020-06-02 05:27:22,027 INFO] Step 15800/50000; acc:  97.86; ppl:  1.11; xent: 0.10; lr: 1.00000; 29488/7698 tok/s;   1025 sec\n",
            "[2020-06-02 05:27:23,290 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:23,403 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:25,421 INFO] Step 15850/50000; acc:  97.79; ppl:  1.10; xent: 0.10; lr: 1.00000; 27918/7404 tok/s;   1028 sec\n",
            "[2020-06-02 05:27:28,485 INFO] Step 15900/50000; acc:  97.99; ppl:  1.09; xent: 0.09; lr: 1.00000; 29603/7725 tok/s;   1031 sec\n",
            "[2020-06-02 05:27:30,546 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:30,671 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:31,824 INFO] Step 15950/50000; acc:  98.23; ppl:  1.07; xent: 0.07; lr: 1.00000; 27548/7226 tok/s;   1034 sec\n",
            "[2020-06-02 05:27:34,988 INFO] Step 16000/50000; acc:  98.25; ppl:  1.07; xent: 0.06; lr: 1.00000; 30180/7910 tok/s;   1037 sec\n",
            "[2020-06-02 05:27:37,793 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:37,860 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:38,154 INFO] Step 16050/50000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 1.00000; 28003/7399 tok/s;   1041 sec\n",
            "[2020-06-02 05:27:41,267 INFO] Step 16100/50000; acc:  98.38; ppl:  1.06; xent: 0.06; lr: 1.00000; 29046/7617 tok/s;   1044 sec\n",
            "[2020-06-02 05:27:44,507 INFO] Step 16150/50000; acc:  98.47; ppl:  1.06; xent: 0.06; lr: 1.00000; 29907/7740 tok/s;   1047 sec\n",
            "[2020-06-02 05:27:45,015 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:45,134 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:47,785 INFO] Step 16200/50000; acc:  98.47; ppl:  1.06; xent: 0.06; lr: 1.00000; 27641/7329 tok/s;   1050 sec\n",
            "[2020-06-02 05:27:50,866 INFO] Step 16250/50000; acc:  98.65; ppl:  1.05; xent: 0.05; lr: 1.00000; 30180/7848 tok/s;   1053 sec\n",
            "[2020-06-02 05:27:52,222 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:52,290 INFO] number of examples: 7231\n",
            "[2020-06-02 05:27:54,158 INFO] Step 16300/50000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 1.00000; 28152/7456 tok/s;   1057 sec\n",
            "[2020-06-02 05:27:57,224 INFO] Step 16350/50000; acc:  98.53; ppl:  1.06; xent: 0.05; lr: 1.00000; 29679/7786 tok/s;   1060 sec\n",
            "[2020-06-02 05:27:59,405 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:27:59,518 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:00,543 INFO] Step 16400/50000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 1.00000; 28079/7327 tok/s;   1063 sec\n",
            "[2020-06-02 05:28:03,720 INFO] Step 16450/50000; acc:  98.83; ppl:  1.05; xent: 0.04; lr: 1.00000; 29595/7778 tok/s;   1066 sec\n",
            "[2020-06-02 05:28:06,636 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:06,769 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:06,931 INFO] Step 16500/50000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 1.00000; 27726/7323 tok/s;   1069 sec\n",
            "[2020-06-02 05:28:10,077 INFO] Step 16550/50000; acc:  98.64; ppl:  1.06; xent: 0.05; lr: 1.00000; 29413/7680 tok/s;   1073 sec\n",
            "[2020-06-02 05:28:13,297 INFO] Step 16600/50000; acc:  98.61; ppl:  1.06; xent: 0.06; lr: 1.00000; 29612/7694 tok/s;   1076 sec\n",
            "[2020-06-02 05:28:13,935 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:14,002 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:16,541 INFO] Step 16650/50000; acc:  98.76; ppl:  1.06; xent: 0.05; lr: 1.00000; 27624/7326 tok/s;   1079 sec\n",
            "[2020-06-02 05:28:19,699 INFO] Step 16700/50000; acc:  98.66; ppl:  1.06; xent: 0.05; lr: 1.00000; 29830/7739 tok/s;   1082 sec\n",
            "[2020-06-02 05:28:21,165 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:21,288 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:23,013 INFO] Step 16750/50000; acc:  98.71; ppl:  1.05; xent: 0.05; lr: 1.00000; 27907/7374 tok/s;   1085 sec\n",
            "[2020-06-02 05:28:26,177 INFO] Step 16800/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 29393/7715 tok/s;   1089 sec\n",
            "[2020-06-02 05:28:28,478 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:28,546 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:29,441 INFO] Step 16850/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 27241/7136 tok/s;   1092 sec\n",
            "[2020-06-02 05:28:32,631 INFO] Step 16900/50000; acc:  98.66; ppl:  1.05; xent: 0.05; lr: 1.00000; 29679/7814 tok/s;   1095 sec\n",
            "[2020-06-02 05:28:35,727 INFO] Step 16950/50000; acc:  98.54; ppl:  1.07; xent: 0.07; lr: 1.00000; 29331/7690 tok/s;   1098 sec\n",
            "[2020-06-02 05:28:35,728 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:35,797 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:38,959 INFO] Step 17000/50000; acc:  98.63; ppl:  1.05; xent: 0.05; lr: 1.00000; 28333/7431 tok/s;   1101 sec\n",
            "[2020-06-02 05:28:42,141 INFO] Step 17050/50000; acc:  98.54; ppl:  1.06; xent: 0.06; lr: 1.00000; 29891/7783 tok/s;   1105 sec\n",
            "[2020-06-02 05:28:42,929 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:43,053 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:45,477 INFO] Step 17100/50000; acc:  98.57; ppl:  1.05; xent: 0.05; lr: 1.00000; 27545/7271 tok/s;   1108 sec\n",
            "[2020-06-02 05:28:48,589 INFO] Step 17150/50000; acc:  98.61; ppl:  1.05; xent: 0.05; lr: 1.00000; 29907/7802 tok/s;   1111 sec\n",
            "[2020-06-02 05:28:50,194 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:50,262 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:51,905 INFO] Step 17200/50000; acc:  98.59; ppl:  1.06; xent: 0.06; lr: 1.00000; 28045/7378 tok/s;   1114 sec\n",
            "[2020-06-02 05:28:55,055 INFO] Step 17250/50000; acc:  98.61; ppl:  1.06; xent: 0.06; lr: 1.00000; 29702/7767 tok/s;   1118 sec\n",
            "[2020-06-02 05:28:57,402 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:28:57,518 INFO] number of examples: 7231\n",
            "[2020-06-02 05:28:58,189 INFO] Step 17300/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 27912/7362 tok/s;   1121 sec\n",
            "[2020-06-02 05:29:01,425 INFO] Step 17350/50000; acc:  98.83; ppl:  1.04; xent: 0.04; lr: 1.00000; 29388/7709 tok/s;   1124 sec\n",
            "[2020-06-02 05:29:04,556 INFO] Step 17400/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 29419/7701 tok/s;   1127 sec\n",
            "[2020-06-02 05:29:04,655 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:04,722 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:07,837 INFO] Step 17450/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 27504/7228 tok/s;   1130 sec\n",
            "[2020-06-02 05:29:10,988 INFO] Step 17500/50000; acc:  98.67; ppl:  1.05; xent: 0.05; lr: 1.00000; 29625/7709 tok/s;   1133 sec\n",
            "[2020-06-02 05:29:11,931 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:12,004 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:14,335 INFO] Step 17550/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 28185/7464 tok/s;   1137 sec\n",
            "[2020-06-02 05:29:17,463 INFO] Step 17600/50000; acc:  98.73; ppl:  1.05; xent: 0.04; lr: 1.00000; 29667/7732 tok/s;   1140 sec\n",
            "[2020-06-02 05:29:19,152 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:19,280 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:20,722 INFO] Step 17650/50000; acc:  98.86; ppl:  1.05; xent: 0.04; lr: 1.00000; 27776/7306 tok/s;   1143 sec\n",
            "[2020-06-02 05:29:23,913 INFO] Step 17700/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 29820/7798 tok/s;   1146 sec\n",
            "[2020-06-02 05:29:26,412 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:26,479 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:27,040 INFO] Step 17750/50000; acc:  98.65; ppl:  1.05; xent: 0.05; lr: 1.00000; 27995/7395 tok/s;   1150 sec\n",
            "[2020-06-02 05:29:30,246 INFO] Step 17800/50000; acc:  98.81; ppl:  1.05; xent: 0.04; lr: 1.00000; 29308/7685 tok/s;   1153 sec\n",
            "[2020-06-02 05:29:33,404 INFO] Step 17850/50000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 1.00000; 29761/7751 tok/s;   1156 sec\n",
            "[2020-06-02 05:29:33,626 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:33,753 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:36,716 INFO] Step 17900/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 27466/7210 tok/s;   1159 sec\n",
            "[2020-06-02 05:29:39,868 INFO] Step 17950/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 29103/7596 tok/s;   1162 sec\n",
            "[2020-06-02 05:29:40,976 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:41,051 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:43,338 INFO] Step 18000/50000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 1.00000; 27614/7303 tok/s;   1166 sec\n",
            "[2020-06-02 05:29:46,431 INFO] Step 18050/50000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 1.00000; 29637/7723 tok/s;   1169 sec\n",
            "[2020-06-02 05:29:48,298 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:48,368 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:49,690 INFO] Step 18100/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 27664/7268 tok/s;   1172 sec\n",
            "[2020-06-02 05:29:52,964 INFO] Step 18150/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 29272/7683 tok/s;   1175 sec\n",
            "[2020-06-02 05:29:55,598 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:29:55,722 INFO] number of examples: 7231\n",
            "[2020-06-02 05:29:56,151 INFO] Step 18200/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 27312/7227 tok/s;   1179 sec\n",
            "[2020-06-02 05:29:59,347 INFO] Step 18250/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 29168/7655 tok/s;   1182 sec\n",
            "[2020-06-02 05:30:02,609 INFO] Step 18300/50000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 1.00000; 29609/7678 tok/s;   1185 sec\n",
            "[2020-06-02 05:30:02,919 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:02,986 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:05,862 INFO] Step 18350/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 27588/7250 tok/s;   1188 sec\n",
            "[2020-06-02 05:30:09,020 INFO] Step 18400/50000; acc:  98.46; ppl:  1.08; xent: 0.07; lr: 1.00000; 29324/7650 tok/s;   1191 sec\n",
            "[2020-06-02 05:30:10,224 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:10,342 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:12,485 INFO] Step 18450/50000; acc:  98.39; ppl:  1.07; xent: 0.07; lr: 1.00000; 27475/7258 tok/s;   1195 sec\n",
            "[2020-06-02 05:30:15,505 INFO] Step 18500/50000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 1.00000; 29428/7723 tok/s;   1198 sec\n",
            "[2020-06-02 05:30:17,543 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:17,620 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:18,885 INFO] Step 18550/50000; acc:  98.66; ppl:  1.05; xent: 0.05; lr: 1.00000; 27532/7222 tok/s;   1201 sec\n",
            "[2020-06-02 05:30:22,127 INFO] Step 18600/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 29265/7664 tok/s;   1205 sec\n",
            "[2020-06-02 05:30:24,857 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:24,932 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:25,275 INFO] Step 18650/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 28168/7436 tok/s;   1208 sec\n",
            "[2020-06-02 05:30:28,419 INFO] Step 18700/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 29236/7664 tok/s;   1211 sec\n",
            "[2020-06-02 05:30:31,618 INFO] Step 18750/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 29949/7750 tok/s;   1214 sec\n",
            "[2020-06-02 05:30:32,090 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:32,219 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:34,957 INFO] Step 18800/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 27116/7182 tok/s;   1217 sec\n",
            "[2020-06-02 05:30:38,073 INFO] Step 18850/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 29593/7715 tok/s;   1221 sec\n",
            "[2020-06-02 05:30:39,432 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:39,499 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:41,477 INFO] Step 18900/50000; acc:  98.71; ppl:  1.05; xent: 0.05; lr: 1.00000; 27836/7362 tok/s;   1224 sec\n",
            "[2020-06-02 05:30:44,549 INFO] Step 18950/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 29505/7719 tok/s;   1227 sec\n",
            "[2020-06-02 05:30:46,701 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:46,817 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:47,918 INFO] Step 19000/50000; acc:  98.76; ppl:  1.05; xent: 0.05; lr: 1.00000; 27346/7159 tok/s;   1230 sec\n",
            "[2020-06-02 05:30:51,176 INFO] Step 19050/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 29156/7654 tok/s;   1234 sec\n",
            "[2020-06-02 05:30:54,109 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:30:54,244 INFO] number of examples: 7231\n",
            "[2020-06-02 05:30:54,483 INFO] Step 19100/50000; acc:  98.67; ppl:  1.05; xent: 0.05; lr: 1.00000; 27093/7146 tok/s;   1237 sec\n",
            "[2020-06-02 05:30:57,662 INFO] Step 19150/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 28301/7421 tok/s;   1240 sec\n",
            "[2020-06-02 05:31:00,943 INFO] Step 19200/50000; acc:  98.59; ppl:  1.06; xent: 0.05; lr: 1.00000; 29586/7655 tok/s;   1243 sec\n",
            "[2020-06-02 05:31:01,522 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:01,590 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:04,234 INFO] Step 19250/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 27573/7315 tok/s;   1247 sec\n",
            "[2020-06-02 05:31:07,360 INFO] Step 19300/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 29321/7627 tok/s;   1250 sec\n",
            "[2020-06-02 05:31:08,820 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:08,961 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:10,820 INFO] Step 19350/50000; acc:  98.84; ppl:  1.05; xent: 0.04; lr: 1.00000; 27228/7180 tok/s;   1253 sec\n",
            "[2020-06-02 05:31:13,962 INFO] Step 19400/50000; acc:  98.97; ppl:  1.05; xent: 0.04; lr: 1.00000; 29124/7653 tok/s;   1256 sec\n",
            "[2020-06-02 05:31:16,215 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:16,285 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:17,231 INFO] Step 19450/50000; acc:  98.91; ppl:  1.05; xent: 0.04; lr: 1.00000; 27942/7320 tok/s;   1260 sec\n",
            "[2020-06-02 05:31:20,438 INFO] Step 19500/50000; acc:  98.86; ppl:  1.05; xent: 0.05; lr: 1.00000; 29393/7709 tok/s;   1263 sec\n",
            "[2020-06-02 05:31:23,489 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:23,607 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:23,681 INFO] Step 19550/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 27556/7255 tok/s;   1266 sec\n",
            "[2020-06-02 05:31:26,885 INFO] Step 19600/50000; acc:  98.82; ppl:  1.05; xent: 0.04; lr: 1.00000; 29036/7607 tok/s;   1269 sec\n",
            "[2020-06-02 05:31:30,092 INFO] Step 19650/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 29496/7663 tok/s;   1273 sec\n",
            "[2020-06-02 05:31:30,813 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:30,942 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:33,431 INFO] Step 19700/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 27233/7197 tok/s;   1276 sec\n",
            "[2020-06-02 05:31:36,646 INFO] Step 19750/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 29307/7621 tok/s;   1279 sec\n",
            "[2020-06-02 05:31:38,181 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:38,249 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:39,972 INFO] Step 19800/50000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 1.00000; 27925/7365 tok/s;   1282 sec\n",
            "[2020-06-02 05:31:43,110 INFO] Step 19850/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 29322/7692 tok/s;   1286 sec\n",
            "[2020-06-02 05:31:45,458 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:45,579 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:46,353 INFO] Step 19900/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 27469/7220 tok/s;   1289 sec\n",
            "[2020-06-02 05:31:49,605 INFO] Step 19950/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 29346/7711 tok/s;   1292 sec\n",
            "[2020-06-02 05:31:52,703 INFO] Step 20000/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 29153/7655 tok/s;   1295 sec\n",
            "[2020-06-02 05:31:52,703 INFO] Loading dataset from Transliteration/Cleaned.valid.0.pt\n",
            "[2020-06-02 05:31:52,726 INFO] number of examples: 1000\n",
            "[2020-06-02 05:31:55,068 INFO] Validation perplexity: 1.35371e+06\n",
            "[2020-06-02 05:31:55,068 INFO] Validation accuracy: 31.3988\n",
            "[2020-06-02 05:31:55,093 INFO] Saving checkpoint Transliteration/rnn_model_step_20000.pt\n",
            "[2020-06-02 05:31:55,444 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:31:55,514 INFO] number of examples: 7231\n",
            "[2020-06-02 05:31:58,644 INFO] Step 20050/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 15451/4045 tok/s;   1301 sec\n",
            "[2020-06-02 05:32:01,861 INFO] Step 20100/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 29172/7608 tok/s;   1304 sec\n",
            "[2020-06-02 05:32:02,737 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:02,852 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:05,298 INFO] Step 20150/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 26866/7103 tok/s;   1308 sec\n",
            "[2020-06-02 05:32:08,753 INFO] Step 20200/50000; acc:  98.84; ppl:  1.05; xent: 0.04; lr: 1.00000; 27007/7037 tok/s;   1311 sec\n",
            "[2020-06-02 05:32:10,438 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:10,562 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:12,119 INFO] Step 20250/50000; acc:  98.89; ppl:  1.05; xent: 0.04; lr: 1.00000; 27316/7173 tok/s;   1315 sec\n",
            "[2020-06-02 05:32:15,332 INFO] Step 20300/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 29654/7741 tok/s;   1318 sec\n",
            "[2020-06-02 05:32:17,771 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:17,840 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:18,482 INFO] Step 20350/50000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 1.00000; 27702/7319 tok/s;   1321 sec\n",
            "[2020-06-02 05:32:21,749 INFO] Step 20400/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 28732/7535 tok/s;   1324 sec\n",
            "[2020-06-02 05:32:24,909 INFO] Step 20450/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 29044/7602 tok/s;   1327 sec\n",
            "[2020-06-02 05:32:25,105 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:25,229 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:28,261 INFO] Step 20500/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 27685/7266 tok/s;   1331 sec\n",
            "[2020-06-02 05:32:31,414 INFO] Step 20550/50000; acc:  98.84; ppl:  1.05; xent: 0.05; lr: 1.00000; 29345/7637 tok/s;   1334 sec\n",
            "[2020-06-02 05:32:32,435 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:32,508 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:34,922 INFO] Step 20600/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 27013/7162 tok/s;   1337 sec\n",
            "[2020-06-02 05:32:38,020 INFO] Step 20650/50000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 1.00000; 29587/7701 tok/s;   1340 sec\n",
            "[2020-06-02 05:32:39,798 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:39,867 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:41,275 INFO] Step 20700/50000; acc:  98.91; ppl:  1.05; xent: 0.04; lr: 1.00000; 28066/7376 tok/s;   1344 sec\n",
            "[2020-06-02 05:32:44,469 INFO] Step 20750/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 29592/7751 tok/s;   1347 sec\n",
            "[2020-06-02 05:32:47,087 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:47,234 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:47,760 INFO] Step 20800/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 26867/7096 tok/s;   1350 sec\n",
            "[2020-06-02 05:32:50,990 INFO] Step 20850/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 28363/7468 tok/s;   1353 sec\n",
            "[2020-06-02 05:32:54,240 INFO] Step 20900/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 29414/7643 tok/s;   1357 sec\n",
            "[2020-06-02 05:32:54,521 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:32:54,593 INFO] number of examples: 7231\n",
            "[2020-06-02 05:32:57,515 INFO] Step 20950/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 27725/7268 tok/s;   1360 sec\n",
            "[2020-06-02 05:33:00,688 INFO] Step 21000/50000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 1.00000; 29023/7572 tok/s;   1363 sec\n",
            "[2020-06-02 05:33:01,858 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:01,980 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:04,226 INFO] Step 21050/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 27062/7157 tok/s;   1367 sec\n",
            "[2020-06-02 05:33:07,280 INFO] Step 21100/50000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 1.00000; 29464/7698 tok/s;   1370 sec\n",
            "[2020-06-02 05:33:09,259 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:09,348 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:10,685 INFO] Step 21150/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 26826/7061 tok/s;   1373 sec\n",
            "[2020-06-02 05:33:13,907 INFO] Step 21200/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 29560/7758 tok/s;   1376 sec\n",
            "[2020-06-02 05:33:16,660 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:16,732 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:17,135 INFO] Step 21250/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 27285/7201 tok/s;   1380 sec\n",
            "[2020-06-02 05:33:20,361 INFO] Step 21300/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28698/7511 tok/s;   1383 sec\n",
            "[2020-06-02 05:33:23,699 INFO] Step 21350/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28956/7507 tok/s;   1386 sec\n",
            "[2020-06-02 05:33:24,093 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:24,224 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:27,094 INFO] Step 21400/50000; acc:  99.02; ppl:  1.04; xent: 0.04; lr: 1.00000; 26842/7062 tok/s;   1390 sec\n",
            "[2020-06-02 05:33:30,264 INFO] Step 21450/50000; acc:  99.12; ppl:  1.04; xent: 0.04; lr: 1.00000; 28824/7525 tok/s;   1393 sec\n",
            "[2020-06-02 05:33:31,574 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:31,648 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:33,721 INFO] Step 21500/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 27412/7270 tok/s;   1396 sec\n",
            "[2020-06-02 05:33:36,871 INFO] Step 21550/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 28798/7514 tok/s;   1399 sec\n",
            "[2020-06-02 05:33:38,952 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:39,072 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:40,242 INFO] Step 21600/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 27275/7154 tok/s;   1403 sec\n",
            "[2020-06-02 05:33:43,541 INFO] Step 21650/50000; acc:  98.79; ppl:  1.06; xent: 0.05; lr: 1.00000; 28958/7590 tok/s;   1406 sec\n",
            "[2020-06-02 05:33:46,401 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:46,544 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:46,848 INFO] Step 21700/50000; acc:  98.60; ppl:  1.07; xent: 0.06; lr: 1.00000; 26801/7082 tok/s;   1409 sec\n",
            "[2020-06-02 05:33:50,027 INFO] Step 21750/50000; acc:  98.64; ppl:  1.07; xent: 0.07; lr: 1.00000; 28444/7459 tok/s;   1413 sec\n",
            "[2020-06-02 05:33:53,349 INFO] Step 21800/50000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 1.00000; 29168/7549 tok/s;   1416 sec\n",
            "[2020-06-02 05:33:53,875 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:33:53,944 INFO] number of examples: 7231\n",
            "[2020-06-02 05:33:56,636 INFO] Step 21850/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 27567/7309 tok/s;   1419 sec\n",
            "[2020-06-02 05:33:59,827 INFO] Step 21900/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 29135/7576 tok/s;   1422 sec\n",
            "[2020-06-02 05:34:01,209 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:01,332 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:03,252 INFO] Step 21950/50000; acc:  98.69; ppl:  1.05; xent: 0.05; lr: 1.00000; 27062/7168 tok/s;   1426 sec\n",
            "[2020-06-02 05:34:06,374 INFO] Step 22000/50000; acc:  98.89; ppl:  1.05; xent: 0.04; lr: 1.00000; 29153/7648 tok/s;   1429 sec\n",
            "[2020-06-02 05:34:08,593 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:08,662 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:09,719 INFO] Step 22050/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 27856/7269 tok/s;   1432 sec\n",
            "[2020-06-02 05:34:12,937 INFO] Step 22100/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 29214/7677 tok/s;   1435 sec\n",
            "[2020-06-02 05:34:15,909 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:16,030 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:16,198 INFO] Step 22150/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 27305/7211 tok/s;   1439 sec\n",
            "[2020-06-02 05:34:19,404 INFO] Step 22200/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 28857/7534 tok/s;   1442 sec\n",
            "[2020-06-02 05:34:22,674 INFO] Step 22250/50000; acc:  98.85; ppl:  1.04; xent: 0.04; lr: 1.00000; 29159/7576 tok/s;   1445 sec\n",
            "[2020-06-02 05:34:23,320 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:23,455 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:25,999 INFO] Step 22300/50000; acc:  98.91; ppl:  1.05; xent: 0.04; lr: 1.00000; 26958/7150 tok/s;   1448 sec\n",
            "[2020-06-02 05:34:29,196 INFO] Step 22350/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 29470/7645 tok/s;   1452 sec\n",
            "[2020-06-02 05:34:30,701 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:30,770 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:32,552 INFO] Step 22400/50000; acc:  98.67; ppl:  1.05; xent: 0.05; lr: 1.00000; 27558/7282 tok/s;   1455 sec\n",
            "[2020-06-02 05:34:35,738 INFO] Step 22450/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 29181/7659 tok/s;   1458 sec\n",
            "[2020-06-02 05:34:38,048 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:38,169 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:39,013 INFO] Step 22500/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 27152/7112 tok/s;   1461 sec\n",
            "[2020-06-02 05:34:42,282 INFO] Step 22550/50000; acc:  98.80; ppl:  1.04; xent: 0.04; lr: 1.00000; 28969/7627 tok/s;   1465 sec\n",
            "[2020-06-02 05:34:45,427 INFO] Step 22600/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 28868/7568 tok/s;   1468 sec\n",
            "[2020-06-02 05:34:45,428 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:45,497 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:48,739 INFO] Step 22650/50000; acc:  98.90; ppl:  1.05; xent: 0.04; lr: 1.00000; 27646/7251 tok/s;   1471 sec\n",
            "[2020-06-02 05:34:51,968 INFO] Step 22700/50000; acc:  98.83; ppl:  1.04; xent: 0.04; lr: 1.00000; 29463/7672 tok/s;   1474 sec\n",
            "[2020-06-02 05:34:52,759 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:34:52,876 INFO] number of examples: 7231\n",
            "[2020-06-02 05:34:55,344 INFO] Step 22750/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 27212/7183 tok/s;   1478 sec\n",
            "[2020-06-02 05:34:58,536 INFO] Step 22800/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 29162/7607 tok/s;   1481 sec\n",
            "[2020-06-02 05:35:00,145 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:00,274 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:01,919 INFO] Step 22850/50000; acc:  98.83; ppl:  1.05; xent: 0.04; lr: 1.00000; 27492/7232 tok/s;   1484 sec\n",
            "[2020-06-02 05:35:05,131 INFO] Step 22900/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 29123/7616 tok/s;   1488 sec\n",
            "[2020-06-02 05:35:07,525 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:07,595 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:08,291 INFO] Step 22950/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 27683/7302 tok/s;   1491 sec\n",
            "[2020-06-02 05:35:11,584 INFO] Step 23000/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 28880/7576 tok/s;   1494 sec\n",
            "[2020-06-02 05:35:14,754 INFO] Step 23050/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 29064/7608 tok/s;   1497 sec\n",
            "[2020-06-02 05:35:14,853 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:14,977 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:18,054 INFO] Step 23100/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 27337/7184 tok/s;   1501 sec\n",
            "[2020-06-02 05:35:21,252 INFO] Step 23150/50000; acc:  99.08; ppl:  1.04; xent: 0.04; lr: 1.00000; 29197/7598 tok/s;   1504 sec\n",
            "[2020-06-02 05:35:22,204 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:22,272 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:24,628 INFO] Step 23200/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 27935/7398 tok/s;   1507 sec\n",
            "[2020-06-02 05:35:27,803 INFO] Step 23250/50000; acc:  98.90; ppl:  1.05; xent: 0.04; lr: 1.00000; 29232/7619 tok/s;   1510 sec\n",
            "[2020-06-02 05:35:29,532 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:29,646 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:31,126 INFO] Step 23300/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 27238/7165 tok/s;   1514 sec\n",
            "[2020-06-02 05:35:34,369 INFO] Step 23350/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 29349/7674 tok/s;   1517 sec\n",
            "[2020-06-02 05:35:36,926 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:37,065 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:37,635 INFO] Step 23400/50000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 1.00000; 26809/7082 tok/s;   1520 sec\n",
            "[2020-06-02 05:35:40,932 INFO] Step 23450/50000; acc:  98.92; ppl:  1.05; xent: 0.04; lr: 1.00000; 28487/7470 tok/s;   1523 sec\n",
            "[2020-06-02 05:35:44,132 INFO] Step 23500/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 29376/7651 tok/s;   1527 sec\n",
            "[2020-06-02 05:35:44,362 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:44,442 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:47,456 INFO] Step 23550/50000; acc:  98.65; ppl:  1.05; xent: 0.05; lr: 1.00000; 27366/7184 tok/s;   1530 sec\n",
            "[2020-06-02 05:35:50,618 INFO] Step 23600/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 29009/7571 tok/s;   1533 sec\n",
            "[2020-06-02 05:35:51,694 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:51,816 INFO] number of examples: 7231\n",
            "[2020-06-02 05:35:54,088 INFO] Step 23650/50000; acc:  98.84; ppl:  1.05; xent: 0.04; lr: 1.00000; 27610/7302 tok/s;   1537 sec\n",
            "[2020-06-02 05:35:57,266 INFO] Step 23700/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 28852/7519 tok/s;   1540 sec\n",
            "[2020-06-02 05:35:59,142 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:35:59,212 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:00,599 INFO] Step 23750/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 27044/7105 tok/s;   1543 sec\n",
            "[2020-06-02 05:36:03,873 INFO] Step 23800/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 29269/7683 tok/s;   1546 sec\n",
            "[2020-06-02 05:36:06,563 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:06,643 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:07,074 INFO] Step 23850/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 27198/7197 tok/s;   1550 sec\n",
            "[2020-06-02 05:36:10,316 INFO] Step 23900/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 28753/7546 tok/s;   1553 sec\n",
            "[2020-06-02 05:36:13,640 INFO] Step 23950/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 29058/7535 tok/s;   1556 sec\n",
            "[2020-06-02 05:36:13,973 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:14,099 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:16,966 INFO] Step 24000/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 26982/7090 tok/s;   1559 sec\n",
            "[2020-06-02 05:36:20,140 INFO] Step 24050/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 29177/7612 tok/s;   1563 sec\n",
            "[2020-06-02 05:36:21,350 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:21,420 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:23,578 INFO] Step 24100/50000; acc:  98.86; ppl:  1.05; xent: 0.05; lr: 1.00000; 27697/7316 tok/s;   1566 sec\n",
            "[2020-06-02 05:36:26,625 INFO] Step 24150/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 29159/7653 tok/s;   1569 sec\n",
            "[2020-06-02 05:36:28,697 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:28,819 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:30,043 INFO] Step 24200/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 27228/7142 tok/s;   1573 sec\n",
            "[2020-06-02 05:36:33,301 INFO] Step 24250/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 29114/7625 tok/s;   1576 sec\n",
            "[2020-06-02 05:36:36,093 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:36,163 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:36,581 INFO] Step 24300/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 27040/7139 tok/s;   1579 sec\n",
            "[2020-06-02 05:36:39,745 INFO] Step 24350/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 29055/7617 tok/s;   1582 sec\n",
            "[2020-06-02 05:36:42,992 INFO] Step 24400/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 29494/7632 tok/s;   1585 sec\n",
            "[2020-06-02 05:36:43,456 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:43,533 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:46,312 INFO] Step 24450/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 27279/7225 tok/s;   1589 sec\n",
            "[2020-06-02 05:36:49,494 INFO] Step 24500/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 28971/7553 tok/s;   1592 sec\n",
            "[2020-06-02 05:36:50,858 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:50,988 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:52,976 INFO] Step 24550/50000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 1.00000; 27215/7198 tok/s;   1595 sec\n",
            "[2020-06-02 05:36:56,110 INFO] Step 24600/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 28929/7568 tok/s;   1599 sec\n",
            "[2020-06-02 05:36:58,249 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:36:58,319 INFO] number of examples: 7231\n",
            "[2020-06-02 05:36:59,412 INFO] Step 24650/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 27898/7303 tok/s;   1602 sec\n",
            "[2020-06-02 05:37:02,694 INFO] Step 24700/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 28938/7597 tok/s;   1605 sec\n",
            "[2020-06-02 05:37:05,601 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:05,729 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:05,980 INFO] Step 24750/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 27268/7192 tok/s;   1608 sec\n",
            "[2020-06-02 05:37:09,108 INFO] Step 24800/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 28765/7543 tok/s;   1612 sec\n",
            "[2020-06-02 05:37:12,439 INFO] Step 24850/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 29144/7540 tok/s;   1615 sec\n",
            "[2020-06-02 05:37:13,017 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:13,087 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:15,823 INFO] Step 24900/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 26818/7115 tok/s;   1618 sec\n",
            "[2020-06-02 05:37:18,956 INFO] Step 24950/50000; acc:  99.16; ppl:  1.03; xent: 0.03; lr: 1.00000; 29246/7608 tok/s;   1621 sec\n",
            "[2020-06-02 05:37:20,425 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:20,496 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:22,346 INFO] Step 25000/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 27795/7330 tok/s;   1625 sec\n",
            "[2020-06-02 05:37:22,376 INFO] Saving checkpoint Transliteration/rnn_model_step_25000.pt\n",
            "[2020-06-02 05:37:25,801 INFO] Step 25050/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 26486/6960 tok/s;   1628 sec\n",
            "[2020-06-02 05:37:28,118 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:28,245 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:29,201 INFO] Step 25100/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 26863/7038 tok/s;   1632 sec\n",
            "[2020-06-02 05:37:32,488 INFO] Step 25150/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 28682/7523 tok/s;   1635 sec\n",
            "[2020-06-02 05:37:35,838 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:35,909 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:35,988 INFO] Step 25200/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 25529/6721 tok/s;   1638 sec\n",
            "[2020-06-02 05:37:39,196 INFO] Step 25250/50000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 1.00000; 29003/7599 tok/s;   1642 sec\n",
            "[2020-06-02 05:37:42,464 INFO] Step 25300/50000; acc:  99.09; ppl:  1.04; xent: 0.04; lr: 1.00000; 28945/7520 tok/s;   1645 sec\n",
            "[2020-06-02 05:37:43,196 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:43,322 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:45,855 INFO] Step 25350/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 26814/7087 tok/s;   1648 sec\n",
            "[2020-06-02 05:37:49,081 INFO] Step 25400/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 29207/7595 tok/s;   1652 sec\n",
            "[2020-06-02 05:37:50,623 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:50,696 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:52,487 INFO] Step 25450/50000; acc:  99.06; ppl:  1.03; xent: 0.03; lr: 1.00000; 27270/7192 tok/s;   1655 sec\n",
            "[2020-06-02 05:37:55,674 INFO] Step 25500/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 28873/7574 tok/s;   1658 sec\n",
            "[2020-06-02 05:37:58,047 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:37:58,119 INFO] number of examples: 7231\n",
            "[2020-06-02 05:37:58,897 INFO] Step 25550/50000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 1.00000; 27632/7263 tok/s;   1661 sec\n",
            "[2020-06-02 05:38:02,210 INFO] Step 25600/50000; acc:  99.16; ppl:  1.03; xent: 0.03; lr: 1.00000; 28807/7569 tok/s;   1665 sec\n",
            "[2020-06-02 05:38:05,306 INFO] Step 25650/50000; acc:  99.04; ppl:  1.04; xent: 0.03; lr: 1.00000; 29170/7660 tok/s;   1668 sec\n",
            "[2020-06-02 05:38:05,371 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:05,498 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:08,692 INFO] Step 25700/50000; acc:  99.13; ppl:  1.03; xent: 0.03; lr: 1.00000; 27112/7098 tok/s;   1671 sec\n",
            "[2020-06-02 05:38:11,952 INFO] Step 25750/50000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 1.00000; 28783/7507 tok/s;   1674 sec\n",
            "[2020-06-02 05:38:12,844 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:12,915 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:15,336 INFO] Step 25800/50000; acc:  99.25; ppl:  1.03; xent: 0.03; lr: 1.00000; 27289/7215 tok/s;   1678 sec\n",
            "[2020-06-02 05:38:18,548 INFO] Step 25850/50000; acc:  99.21; ppl:  1.03; xent: 0.03; lr: 1.00000; 29043/7568 tok/s;   1681 sec\n",
            "[2020-06-02 05:38:20,227 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:20,349 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:21,932 INFO] Step 25900/50000; acc:  99.11; ppl:  1.04; xent: 0.04; lr: 1.00000; 27174/7136 tok/s;   1684 sec\n",
            "[2020-06-02 05:38:25,219 INFO] Step 25950/50000; acc:  99.23; ppl:  1.03; xent: 0.03; lr: 1.00000; 28983/7566 tok/s;   1688 sec\n",
            "[2020-06-02 05:38:27,662 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:27,801 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:28,455 INFO] Step 26000/50000; acc:  99.17; ppl:  1.03; xent: 0.03; lr: 1.00000; 26960/7123 tok/s;   1691 sec\n",
            "[2020-06-02 05:38:31,733 INFO] Step 26050/50000; acc:  99.09; ppl:  1.04; xent: 0.03; lr: 1.00000; 28640/7511 tok/s;   1694 sec\n",
            "[2020-06-02 05:38:34,884 INFO] Step 26100/50000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 1.00000; 29127/7624 tok/s;   1697 sec\n",
            "[2020-06-02 05:38:35,094 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:35,173 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:38,255 INFO] Step 26150/50000; acc:  99.13; ppl:  1.03; xent: 0.03; lr: 1.00000; 27535/7226 tok/s;   1701 sec\n",
            "[2020-06-02 05:38:41,508 INFO] Step 26200/50000; acc:  99.10; ppl:  1.04; xent: 0.04; lr: 1.00000; 28429/7398 tok/s;   1704 sec\n",
            "[2020-06-02 05:38:42,540 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:42,668 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:45,011 INFO] Step 26250/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 27057/7174 tok/s;   1707 sec\n",
            "[2020-06-02 05:38:48,173 INFO] Step 26300/50000; acc:  99.13; ppl:  1.04; xent: 0.04; lr: 1.00000; 28987/7545 tok/s;   1711 sec\n",
            "[2020-06-02 05:38:49,995 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:50,065 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:51,493 INFO] Step 26350/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 27517/7232 tok/s;   1714 sec\n",
            "[2020-06-02 05:38:54,763 INFO] Step 26400/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 28909/7572 tok/s;   1717 sec\n",
            "[2020-06-02 05:38:57,377 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:38:57,503 INFO] number of examples: 7231\n",
            "[2020-06-02 05:38:58,040 INFO] Step 26450/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 26978/7126 tok/s;   1721 sec\n",
            "[2020-06-02 05:39:01,210 INFO] Step 26500/50000; acc:  99.08; ppl:  1.04; xent: 0.04; lr: 1.00000; 28902/7610 tok/s;   1724 sec\n",
            "[2020-06-02 05:39:04,477 INFO] Step 26550/50000; acc:  99.15; ppl:  1.04; xent: 0.04; lr: 1.00000; 29251/7600 tok/s;   1727 sec\n",
            "[2020-06-02 05:39:04,775 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:04,908 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:07,868 INFO] Step 26600/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 26778/7020 tok/s;   1730 sec\n",
            "[2020-06-02 05:39:11,018 INFO] Step 26650/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 29241/7628 tok/s;   1733 sec\n",
            "[2020-06-02 05:39:12,191 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:12,264 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:14,467 INFO] Step 26700/50000; acc:  98.83; ppl:  1.04; xent: 0.04; lr: 1.00000; 27762/7342 tok/s;   1737 sec\n",
            "[2020-06-02 05:39:17,532 INFO] Step 26750/50000; acc:  99.09; ppl:  1.03; xent: 0.03; lr: 1.00000; 29358/7670 tok/s;   1740 sec\n",
            "[2020-06-02 05:39:19,494 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:19,618 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:20,911 INFO] Step 26800/50000; acc:  99.09; ppl:  1.03; xent: 0.03; lr: 1.00000; 27029/7115 tok/s;   1743 sec\n",
            "[2020-06-02 05:39:24,206 INFO] Step 26850/50000; acc:  99.08; ppl:  1.04; xent: 0.04; lr: 1.00000; 28906/7587 tok/s;   1747 sec\n",
            "[2020-06-02 05:39:26,920 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:26,992 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:27,379 INFO] Step 26900/50000; acc:  99.08; ppl:  1.03; xent: 0.03; lr: 1.00000; 27766/7328 tok/s;   1750 sec\n",
            "[2020-06-02 05:39:30,612 INFO] Step 26950/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 28627/7492 tok/s;   1753 sec\n",
            "[2020-06-02 05:39:33,920 INFO] Step 27000/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 29222/7576 tok/s;   1756 sec\n",
            "[2020-06-02 05:39:34,310 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:34,438 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:37,285 INFO] Step 27050/50000; acc:  99.02; ppl:  1.04; xent: 0.04; lr: 1.00000; 27082/7125 tok/s;   1760 sec\n",
            "[2020-06-02 05:39:40,468 INFO] Step 27100/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 28699/7492 tok/s;   1763 sec\n",
            "[2020-06-02 05:39:41,743 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:41,872 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:43,934 INFO] Step 27150/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 27343/7252 tok/s;   1766 sec\n",
            "[2020-06-02 05:39:47,018 INFO] Step 27200/50000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 1.00000; 29415/7676 tok/s;   1769 sec\n",
            "[2020-06-02 05:39:49,142 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:49,226 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:50,394 INFO] Step 27250/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 27237/7144 tok/s;   1773 sec\n",
            "[2020-06-02 05:39:53,680 INFO] Step 27300/50000; acc:  99.24; ppl:  1.03; xent: 0.03; lr: 1.00000; 29065/7618 tok/s;   1776 sec\n",
            "[2020-06-02 05:39:56,520 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:39:56,644 INFO] number of examples: 7231\n",
            "[2020-06-02 05:39:56,956 INFO] Step 27350/50000; acc:  99.14; ppl:  1.03; xent: 0.03; lr: 1.00000; 27060/7150 tok/s;   1779 sec\n",
            "[2020-06-02 05:40:00,116 INFO] Step 27400/50000; acc:  99.09; ppl:  1.04; xent: 0.04; lr: 1.00000; 28616/7504 tok/s;   1783 sec\n",
            "[2020-06-02 05:40:03,462 INFO] Step 27450/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 28956/7494 tok/s;   1786 sec\n",
            "[2020-06-02 05:40:03,970 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:04,042 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:06,756 INFO] Step 27500/50000; acc:  99.02; ppl:  1.04; xent: 0.04; lr: 1.00000; 27511/7294 tok/s;   1789 sec\n",
            "[2020-06-02 05:40:09,932 INFO] Step 27550/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 29277/7613 tok/s;   1792 sec\n",
            "[2020-06-02 05:40:11,318 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:11,433 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:13,358 INFO] Step 27600/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 27053/7165 tok/s;   1796 sec\n",
            "[2020-06-02 05:40:16,519 INFO] Step 27650/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 28783/7551 tok/s;   1799 sec\n",
            "[2020-06-02 05:40:18,760 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:18,895 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:19,949 INFO] Step 27700/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 27167/7089 tok/s;   1802 sec\n",
            "[2020-06-02 05:40:23,233 INFO] Step 27750/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 28628/7523 tok/s;   1806 sec\n",
            "[2020-06-02 05:40:26,261 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:26,333 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:26,486 INFO] Step 27800/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 27371/7229 tok/s;   1809 sec\n",
            "[2020-06-02 05:40:29,731 INFO] Step 27850/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 28519/7446 tok/s;   1812 sec\n",
            "[2020-06-02 05:40:33,031 INFO] Step 27900/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 28887/7506 tok/s;   1816 sec\n",
            "[2020-06-02 05:40:33,673 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:33,805 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:36,361 INFO] Step 27950/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 26919/7139 tok/s;   1819 sec\n",
            "[2020-06-02 05:40:39,575 INFO] Step 28000/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 29310/7604 tok/s;   1822 sec\n",
            "[2020-06-02 05:40:41,110 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:41,188 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:43,041 INFO] Step 28050/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 26681/7050 tok/s;   1826 sec\n",
            "[2020-06-02 05:40:46,262 INFO] Step 28100/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 28871/7578 tok/s;   1829 sec\n",
            "[2020-06-02 05:40:48,573 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:48,646 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:49,492 INFO] Step 28150/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 27531/7212 tok/s;   1832 sec\n",
            "[2020-06-02 05:40:52,796 INFO] Step 28200/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 28652/7544 tok/s;   1835 sec\n",
            "[2020-06-02 05:40:55,998 INFO] Step 28250/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 28361/7435 tok/s;   1838 sec\n",
            "[2020-06-02 05:40:55,999 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:40:56,128 INFO] number of examples: 7231\n",
            "[2020-06-02 05:40:59,383 INFO] Step 28300/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 27047/7094 tok/s;   1842 sec\n",
            "[2020-06-02 05:41:02,625 INFO] Step 28350/50000; acc:  98.91; ppl:  1.05; xent: 0.04; lr: 1.00000; 29346/7641 tok/s;   1845 sec\n",
            "[2020-06-02 05:41:03,430 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:03,500 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:05,949 INFO] Step 28400/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 27644/7297 tok/s;   1848 sec\n",
            "[2020-06-02 05:41:09,138 INFO] Step 28450/50000; acc:  99.02; ppl:  1.04; xent: 0.04; lr: 1.00000; 29181/7612 tok/s;   1852 sec\n",
            "[2020-06-02 05:41:10,780 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:10,904 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:12,569 INFO] Step 28500/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 27107/7131 tok/s;   1855 sec\n",
            "[2020-06-02 05:41:15,811 INFO] Step 28550/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 28855/7546 tok/s;   1858 sec\n",
            "[2020-06-02 05:41:18,250 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:18,324 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:19,108 INFO] Step 28600/50000; acc:  99.07; ppl:  1.04; xent: 0.03; lr: 1.00000; 26536/6999 tok/s;   1862 sec\n",
            "[2020-06-02 05:41:22,471 INFO] Step 28650/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 28280/7418 tok/s;   1865 sec\n",
            "[2020-06-02 05:41:25,660 INFO] Step 28700/50000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 1.00000; 28878/7559 tok/s;   1868 sec\n",
            "[2020-06-02 05:41:25,762 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:25,834 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:28,905 INFO] Step 28750/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 27809/7308 tok/s;   1871 sec\n",
            "[2020-06-02 05:41:32,127 INFO] Step 28800/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 28975/7540 tok/s;   1875 sec\n",
            "[2020-06-02 05:41:33,093 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:33,225 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:35,622 INFO] Step 28850/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 26990/7148 tok/s;   1878 sec\n",
            "[2020-06-02 05:41:38,814 INFO] Step 28900/50000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 1.00000; 29070/7577 tok/s;   1881 sec\n",
            "[2020-06-02 05:41:40,581 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:40,654 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:42,152 INFO] Step 28950/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 27116/7132 tok/s;   1885 sec\n",
            "[2020-06-02 05:41:45,381 INFO] Step 29000/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 29471/7706 tok/s;   1888 sec\n",
            "[2020-06-02 05:41:47,933 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:48,063 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:48,636 INFO] Step 29050/50000; acc:  98.89; ppl:  1.05; xent: 0.04; lr: 1.00000; 26906/7108 tok/s;   1891 sec\n",
            "[2020-06-02 05:41:51,901 INFO] Step 29100/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28767/7543 tok/s;   1894 sec\n",
            "[2020-06-02 05:41:55,172 INFO] Step 29150/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 28738/7485 tok/s;   1898 sec\n",
            "[2020-06-02 05:41:55,399 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:41:55,476 INFO] number of examples: 7231\n",
            "[2020-06-02 05:41:58,562 INFO] Step 29200/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 26834/7045 tok/s;   1901 sec\n",
            "[2020-06-02 05:42:01,759 INFO] Step 29250/50000; acc:  99.11; ppl:  1.03; xent: 0.03; lr: 1.00000; 28693/7489 tok/s;   1904 sec\n",
            "[2020-06-02 05:42:02,872 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:02,942 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:05,225 INFO] Step 29300/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 27644/7311 tok/s;   1908 sec\n",
            "[2020-06-02 05:42:08,383 INFO] Step 29350/50000; acc:  99.10; ppl:  1.04; xent: 0.03; lr: 1.00000; 29029/7565 tok/s;   1911 sec\n",
            "[2020-06-02 05:42:10,280 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:10,415 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:11,734 INFO] Step 29400/50000; acc:  99.00; ppl:  1.04; xent: 0.04; lr: 1.00000; 26897/7067 tok/s;   1914 sec\n",
            "[2020-06-02 05:42:15,017 INFO] Step 29450/50000; acc:  99.15; ppl:  1.04; xent: 0.04; lr: 1.00000; 29192/7662 tok/s;   1917 sec\n",
            "[2020-06-02 05:42:17,702 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:17,773 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:18,205 INFO] Step 29500/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 27312/7227 tok/s;   1921 sec\n",
            "[2020-06-02 05:42:21,473 INFO] Step 29550/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28525/7486 tok/s;   1924 sec\n",
            "[2020-06-02 05:42:24,779 INFO] Step 29600/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 29211/7575 tok/s;   1927 sec\n",
            "[2020-06-02 05:42:25,092 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:25,219 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:28,134 INFO] Step 29650/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 26744/7028 tok/s;   1931 sec\n",
            "[2020-06-02 05:42:31,325 INFO] Step 29700/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 29033/7574 tok/s;   1934 sec\n",
            "[2020-06-02 05:42:32,546 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:32,618 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:34,857 INFO] Step 29750/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 26951/7119 tok/s;   1937 sec\n",
            "[2020-06-02 05:42:37,952 INFO] Step 29800/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 28708/7534 tok/s;   1940 sec\n",
            "[2020-06-02 05:42:40,049 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:40,119 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:41,351 INFO] Step 29850/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 27380/7182 tok/s;   1944 sec\n",
            "[2020-06-02 05:42:44,623 INFO] Step 29900/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 28999/7594 tok/s;   1947 sec\n",
            "[2020-06-02 05:42:47,461 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:47,592 INFO] number of examples: 7231\n",
            "[2020-06-02 05:42:47,949 INFO] Step 29950/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 26664/7039 tok/s;   1950 sec\n",
            "[2020-06-02 05:42:51,173 INFO] Step 30000/50000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 1.00000; 28504/7472 tok/s;   1954 sec\n",
            "[2020-06-02 05:42:51,174 INFO] Loading dataset from Transliteration/Cleaned.valid.0.pt\n",
            "[2020-06-02 05:42:51,196 INFO] number of examples: 1000\n",
            "[2020-06-02 05:42:53,574 INFO] Validation perplexity: 1.20165e+06\n",
            "[2020-06-02 05:42:53,574 INFO] Validation accuracy: 34.2183\n",
            "[2020-06-02 05:42:53,600 INFO] Saving checkpoint Transliteration/rnn_model_step_30000.pt\n",
            "[2020-06-02 05:42:57,195 INFO] Step 30050/50000; acc:  99.15; ppl:  1.04; xent: 0.04; lr: 1.00000; 15908/4116 tok/s;   1960 sec\n",
            "[2020-06-02 05:42:57,667 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:42:57,742 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:00,602 INFO] Step 30100/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 26577/7039 tok/s;   1963 sec\n",
            "[2020-06-02 05:43:03,763 INFO] Step 30150/50000; acc:  99.20; ppl:  1.03; xent: 0.03; lr: 1.00000; 29169/7605 tok/s;   1966 sec\n",
            "[2020-06-02 05:43:05,385 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:05,502 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:07,528 INFO] Step 30200/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 25167/6656 tok/s;   1970 sec\n",
            "[2020-06-02 05:43:10,685 INFO] Step 30250/50000; acc:  99.16; ppl:  1.04; xent: 0.03; lr: 1.00000; 28714/7511 tok/s;   1973 sec\n",
            "[2020-06-02 05:43:12,872 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:13,004 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:14,106 INFO] Step 30300/50000; acc:  99.11; ppl:  1.04; xent: 0.04; lr: 1.00000; 26933/7051 tok/s;   1977 sec\n",
            "[2020-06-02 05:43:17,381 INFO] Step 30350/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 28998/7613 tok/s;   1980 sec\n",
            "[2020-06-02 05:43:20,302 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:20,372 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:20,631 INFO] Step 30400/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 27572/7272 tok/s;   1983 sec\n",
            "[2020-06-02 05:43:23,830 INFO] Step 30450/50000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 1.00000; 28122/7374 tok/s;   1986 sec\n",
            "[2020-06-02 05:43:27,138 INFO] Step 30500/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 29345/7592 tok/s;   1990 sec\n",
            "[2020-06-02 05:43:27,730 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:27,860 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:30,542 INFO] Step 30550/50000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 1.00000; 26664/7074 tok/s;   1993 sec\n",
            "[2020-06-02 05:43:33,700 INFO] Step 30600/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 29014/7548 tok/s;   1996 sec\n",
            "[2020-06-02 05:43:35,198 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:35,269 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:37,110 INFO] Step 30650/50000; acc:  98.85; ppl:  1.04; xent: 0.04; lr: 1.00000; 27627/7285 tok/s;   2000 sec\n",
            "[2020-06-02 05:43:40,320 INFO] Step 30700/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28509/7491 tok/s;   2003 sec\n",
            "[2020-06-02 05:43:42,610 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:42,729 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:43,734 INFO] Step 30750/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 26757/7010 tok/s;   2006 sec\n",
            "[2020-06-02 05:43:47,029 INFO] Step 30800/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 28606/7503 tok/s;   2010 sec\n",
            "[2020-06-02 05:43:50,101 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:50,230 INFO] number of examples: 7231\n",
            "[2020-06-02 05:43:50,316 INFO] Step 30850/50000; acc:  99.05; ppl:  1.04; xent: 0.04; lr: 1.00000; 27192/7159 tok/s;   2013 sec\n",
            "[2020-06-02 05:43:53,564 INFO] Step 30900/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 28645/7505 tok/s;   2016 sec\n",
            "[2020-06-02 05:43:56,836 INFO] Step 30950/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 28911/7511 tok/s;   2019 sec\n",
            "[2020-06-02 05:43:57,571 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:43:57,643 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:00,173 INFO] Step 31000/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 27244/7200 tok/s;   2023 sec\n",
            "[2020-06-02 05:44:03,399 INFO] Step 31050/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 29209/7596 tok/s;   2026 sec\n",
            "[2020-06-02 05:44:04,946 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:05,069 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:06,815 INFO] Step 31100/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 27190/7171 tok/s;   2029 sec\n",
            "[2020-06-02 05:44:10,012 INFO] Step 31150/50000; acc:  99.10; ppl:  1.03; xent: 0.03; lr: 1.00000; 28780/7550 tok/s;   2032 sec\n",
            "[2020-06-02 05:44:12,425 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:12,495 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:13,275 INFO] Step 31200/50000; acc:  99.09; ppl:  1.04; xent: 0.04; lr: 1.00000; 27303/7176 tok/s;   2036 sec\n",
            "[2020-06-02 05:44:16,592 INFO] Step 31250/50000; acc:  98.98; ppl:  1.05; xent: 0.05; lr: 1.00000; 28763/7558 tok/s;   2039 sec\n",
            "[2020-06-02 05:44:19,726 INFO] Step 31300/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 28823/7569 tok/s;   2042 sec\n",
            "[2020-06-02 05:44:19,785 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:19,902 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:23,078 INFO] Step 31350/50000; acc:  99.03; ppl:  1.04; xent: 0.04; lr: 1.00000; 27380/7168 tok/s;   2046 sec\n",
            "[2020-06-02 05:44:26,310 INFO] Step 31400/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 29041/7574 tok/s;   2049 sec\n",
            "[2020-06-02 05:44:27,189 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:27,318 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:29,750 INFO] Step 31450/50000; acc:  98.81; ppl:  1.04; xent: 0.04; lr: 1.00000; 26843/7097 tok/s;   2052 sec\n",
            "[2020-06-02 05:44:32,969 INFO] Step 31500/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 28978/7551 tok/s;   2055 sec\n",
            "[2020-06-02 05:44:34,677 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:34,750 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:36,353 INFO] Step 31550/50000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 1.00000; 27174/7136 tok/s;   2059 sec\n",
            "[2020-06-02 05:44:39,648 INFO] Step 31600/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 28919/7549 tok/s;   2062 sec\n",
            "[2020-06-02 05:44:42,129 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:42,252 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:42,904 INFO] Step 31650/50000; acc:  98.91; ppl:  1.05; xent: 0.05; lr: 1.00000; 26791/7078 tok/s;   2065 sec\n",
            "[2020-06-02 05:44:46,177 INFO] Step 31700/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 28684/7523 tok/s;   2069 sec\n",
            "[2020-06-02 05:44:49,392 INFO] Step 31750/50000; acc:  98.80; ppl:  1.04; xent: 0.04; lr: 1.00000; 28551/7473 tok/s;   2072 sec\n",
            "[2020-06-02 05:44:49,594 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:49,669 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:52,852 INFO] Step 31800/50000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 1.00000; 26823/7039 tok/s;   2075 sec\n",
            "[2020-06-02 05:44:56,063 INFO] Step 31850/50000; acc:  98.71; ppl:  1.05; xent: 0.05; lr: 1.00000; 28807/7497 tok/s;   2079 sec\n",
            "[2020-06-02 05:44:57,095 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:44:57,164 INFO] number of examples: 7231\n",
            "[2020-06-02 05:44:59,503 INFO] Step 31900/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 27553/7306 tok/s;   2082 sec\n",
            "[2020-06-02 05:45:02,665 INFO] Step 31950/50000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 1.00000; 28982/7544 tok/s;   2085 sec\n",
            "[2020-06-02 05:45:04,492 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:04,622 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:06,076 INFO] Step 32000/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 26783/7039 tok/s;   2089 sec\n",
            "[2020-06-02 05:45:09,314 INFO] Step 32050/50000; acc:  98.61; ppl:  1.08; xent: 0.08; lr: 1.00000; 29191/7646 tok/s;   2092 sec\n",
            "[2020-06-02 05:45:11,939 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:12,011 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:12,564 INFO] Step 32100/50000; acc:  98.45; ppl:  1.07; xent: 0.07; lr: 1.00000; 27205/7186 tok/s;   2095 sec\n",
            "[2020-06-02 05:45:15,767 INFO] Step 32150/50000; acc:  98.50; ppl:  1.07; xent: 0.07; lr: 1.00000; 28598/7530 tok/s;   2098 sec\n",
            "[2020-06-02 05:45:19,063 INFO] Step 32200/50000; acc:  98.53; ppl:  1.07; xent: 0.07; lr: 1.00000; 29008/7537 tok/s;   2102 sec\n",
            "[2020-06-02 05:45:19,358 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:19,478 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:22,458 INFO] Step 32250/50000; acc:  98.42; ppl:  1.07; xent: 0.07; lr: 1.00000; 26736/7009 tok/s;   2105 sec\n",
            "[2020-06-02 05:45:25,650 INFO] Step 32300/50000; acc:  98.60; ppl:  1.06; xent: 0.06; lr: 1.00000; 28858/7529 tok/s;   2108 sec\n",
            "[2020-06-02 05:45:26,819 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:26,896 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:29,181 INFO] Step 32350/50000; acc:  98.63; ppl:  1.06; xent: 0.06; lr: 1.00000; 27119/7172 tok/s;   2112 sec\n",
            "[2020-06-02 05:45:32,277 INFO] Step 32400/50000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 1.00000; 29062/7593 tok/s;   2115 sec\n",
            "[2020-06-02 05:45:34,252 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:34,323 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:35,605 INFO] Step 32450/50000; acc:  98.01; ppl:  1.17; xent: 0.16; lr: 1.00000; 27446/7225 tok/s;   2118 sec\n",
            "[2020-06-02 05:45:38,894 INFO] Step 32500/50000; acc:  98.58; ppl:  1.06; xent: 0.06; lr: 1.00000; 28963/7602 tok/s;   2121 sec\n",
            "[2020-06-02 05:45:41,664 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:41,792 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:42,196 INFO] Step 32550/50000; acc:  98.54; ppl:  1.06; xent: 0.06; lr: 1.00000; 26671/7039 tok/s;   2125 sec\n",
            "[2020-06-02 05:45:45,429 INFO] Step 32600/50000; acc:  98.43; ppl:  1.09; xent: 0.09; lr: 1.00000; 28639/7495 tok/s;   2128 sec\n",
            "[2020-06-02 05:45:48,728 INFO] Step 32650/50000; acc:  98.72; ppl:  1.06; xent: 0.05; lr: 1.00000; 29289/7593 tok/s;   2131 sec\n",
            "[2020-06-02 05:45:49,144 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:49,215 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:52,092 INFO] Step 32700/50000; acc:  98.53; ppl:  1.06; xent: 0.06; lr: 1.00000; 27095/7129 tok/s;   2135 sec\n",
            "[2020-06-02 05:45:55,264 INFO] Step 32750/50000; acc:  98.74; ppl:  1.05; xent: 0.05; lr: 1.00000; 28797/7518 tok/s;   2138 sec\n",
            "[2020-06-02 05:45:56,546 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:45:56,665 INFO] number of examples: 7231\n",
            "[2020-06-02 05:45:58,754 INFO] Step 32800/50000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 1.00000; 27153/7201 tok/s;   2141 sec\n",
            "[2020-06-02 05:46:01,899 INFO] Step 32850/50000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 1.00000; 28844/7527 tok/s;   2144 sec\n",
            "[2020-06-02 05:46:04,032 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:04,167 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:05,342 INFO] Step 32900/50000; acc:  98.35; ppl:  1.07; xent: 0.06; lr: 1.00000; 26709/7006 tok/s;   2148 sec\n",
            "[2020-06-02 05:46:08,623 INFO] Step 32950/50000; acc:  98.61; ppl:  1.05; xent: 0.05; lr: 1.00000; 29111/7630 tok/s;   2151 sec\n",
            "[2020-06-02 05:46:11,464 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:11,542 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:11,844 INFO] Step 33000/50000; acc:  98.78; ppl:  1.05; xent: 0.05; lr: 1.00000; 27524/7273 tok/s;   2154 sec\n",
            "[2020-06-02 05:46:14,999 INFO] Step 33050/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 28661/7516 tok/s;   2157 sec\n",
            "[2020-06-02 05:46:18,318 INFO] Step 33100/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 29192/7555 tok/s;   2161 sec\n",
            "[2020-06-02 05:46:18,855 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:18,983 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:21,746 INFO] Step 33150/50000; acc:  98.99; ppl:  1.04; xent: 0.04; lr: 1.00000; 26435/7009 tok/s;   2164 sec\n",
            "[2020-06-02 05:46:24,910 INFO] Step 33200/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 29383/7641 tok/s;   2167 sec\n",
            "[2020-06-02 05:46:26,320 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:26,392 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:28,316 INFO] Step 33250/50000; acc:  98.77; ppl:  1.05; xent: 0.05; lr: 1.00000; 27212/7207 tok/s;   2171 sec\n",
            "[2020-06-02 05:46:31,497 INFO] Step 33300/50000; acc:  98.85; ppl:  1.05; xent: 0.04; lr: 1.00000; 28605/7504 tok/s;   2174 sec\n",
            "[2020-06-02 05:46:33,748 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:33,868 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:34,933 INFO] Step 33350/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 27126/7079 tok/s;   2177 sec\n",
            "[2020-06-02 05:46:38,210 INFO] Step 33400/50000; acc:  98.89; ppl:  1.06; xent: 0.05; lr: 1.00000; 28690/7540 tok/s;   2181 sec\n",
            "[2020-06-02 05:46:41,220 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:41,354 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:41,525 INFO] Step 33450/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 26860/7094 tok/s;   2184 sec\n",
            "[2020-06-02 05:46:44,746 INFO] Step 33500/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 28723/7500 tok/s;   2187 sec\n",
            "[2020-06-02 05:46:48,037 INFO] Step 33550/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 28970/7527 tok/s;   2191 sec\n",
            "[2020-06-02 05:46:48,722 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:48,795 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:51,375 INFO] Step 33600/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 26849/7121 tok/s;   2194 sec\n",
            "[2020-06-02 05:46:54,603 INFO] Step 33650/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 29190/7573 tok/s;   2197 sec\n",
            "[2020-06-02 05:46:56,101 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:46:56,224 INFO] number of examples: 7231\n",
            "[2020-06-02 05:46:57,984 INFO] Step 33700/50000; acc:  98.87; ppl:  1.05; xent: 0.05; lr: 1.00000; 27353/7227 tok/s;   2200 sec\n",
            "[2020-06-02 05:47:01,233 INFO] Step 33750/50000; acc:  99.05; ppl:  1.03; xent: 0.03; lr: 1.00000; 28616/7511 tok/s;   2204 sec\n",
            "[2020-06-02 05:47:03,552 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:03,624 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:04,465 INFO] Step 33800/50000; acc:  99.08; ppl:  1.04; xent: 0.04; lr: 1.00000; 27513/7207 tok/s;   2207 sec\n",
            "[2020-06-02 05:47:07,756 INFO] Step 33850/50000; acc:  98.95; ppl:  1.05; xent: 0.05; lr: 1.00000; 28775/7576 tok/s;   2210 sec\n",
            "[2020-06-02 05:47:10,998 INFO] Step 33900/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 28007/7343 tok/s;   2213 sec\n",
            "[2020-06-02 05:47:10,999 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:11,114 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:14,347 INFO] Step 33950/50000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 1.00000; 27336/7170 tok/s;   2217 sec\n",
            "[2020-06-02 05:47:17,609 INFO] Step 34000/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 29164/7594 tok/s;   2220 sec\n",
            "[2020-06-02 05:47:18,414 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:18,545 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:21,041 INFO] Step 34050/50000; acc:  98.71; ppl:  1.05; xent: 0.05; lr: 1.00000; 26775/7068 tok/s;   2224 sec\n",
            "[2020-06-02 05:47:24,220 INFO] Step 34100/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 29285/7640 tok/s;   2227 sec\n",
            "[2020-06-02 05:47:25,838 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:25,908 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:27,570 INFO] Step 34150/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 27758/7302 tok/s;   2230 sec\n",
            "[2020-06-02 05:47:30,812 INFO] Step 34200/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 28863/7548 tok/s;   2233 sec\n",
            "[2020-06-02 05:47:33,217 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:33,344 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:34,050 INFO] Step 34250/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 27008/7123 tok/s;   2237 sec\n",
            "[2020-06-02 05:47:37,392 INFO] Step 34300/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 28463/7466 tok/s;   2240 sec\n",
            "[2020-06-02 05:47:40,594 INFO] Step 34350/50000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 1.00000; 28763/7529 tok/s;   2243 sec\n",
            "[2020-06-02 05:47:40,696 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:40,768 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:43,903 INFO] Step 34400/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 27266/7165 tok/s;   2246 sec\n",
            "[2020-06-02 05:47:47,091 INFO] Step 34450/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 29289/7622 tok/s;   2250 sec\n",
            "[2020-06-02 05:47:48,075 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:48,191 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:50,572 INFO] Step 34500/50000; acc:  98.95; ppl:  1.05; xent: 0.05; lr: 1.00000; 27095/7176 tok/s;   2253 sec\n",
            "[2020-06-02 05:47:53,779 INFO] Step 34550/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 28934/7541 tok/s;   2256 sec\n",
            "[2020-06-02 05:47:55,530 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:47:55,672 INFO] number of examples: 7231\n",
            "[2020-06-02 05:47:57,175 INFO] Step 34600/50000; acc:  98.69; ppl:  1.06; xent: 0.06; lr: 1.00000; 26661/7013 tok/s;   2260 sec\n",
            "[2020-06-02 05:48:00,439 INFO] Step 34650/50000; acc:  98.92; ppl:  1.04; xent: 0.04; lr: 1.00000; 29151/7623 tok/s;   2263 sec\n",
            "[2020-06-02 05:48:03,022 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:03,100 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:03,658 INFO] Step 34700/50000; acc:  98.93; ppl:  1.04; xent: 0.04; lr: 1.00000; 27204/7186 tok/s;   2266 sec\n",
            "[2020-06-02 05:48:06,942 INFO] Step 34750/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 28606/7501 tok/s;   2269 sec\n",
            "[2020-06-02 05:48:10,184 INFO] Step 34800/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 28984/7549 tok/s;   2273 sec\n",
            "[2020-06-02 05:48:10,415 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:10,543 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:13,600 INFO] Step 34850/50000; acc:  98.74; ppl:  1.05; xent: 0.05; lr: 1.00000; 26637/6993 tok/s;   2276 sec\n",
            "[2020-06-02 05:48:16,815 INFO] Step 34900/50000; acc:  98.94; ppl:  1.04; xent: 0.04; lr: 1.00000; 28527/7446 tok/s;   2279 sec\n",
            "[2020-06-02 05:48:17,944 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:18,016 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:20,338 INFO] Step 34950/50000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 1.00000; 27194/7192 tok/s;   2283 sec\n",
            "[2020-06-02 05:48:23,484 INFO] Step 35000/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 29140/7594 tok/s;   2286 sec\n",
            "[2020-06-02 05:48:23,519 INFO] Saving checkpoint Transliteration/rnn_model_step_35000.pt\n",
            "[2020-06-02 05:48:25,685 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:25,757 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:27,120 INFO] Step 35050/50000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 1.00000; 24797/6515 tok/s;   2290 sec\n",
            "[2020-06-02 05:48:30,426 INFO] Step 35100/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 28982/7607 tok/s;   2293 sec\n",
            "[2020-06-02 05:48:33,174 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:33,304 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:33,815 INFO] Step 35150/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 25690/6798 tok/s;   2296 sec\n",
            "[2020-06-02 05:48:37,300 INFO] Step 35200/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 26749/7020 tok/s;   2300 sec\n",
            "[2020-06-02 05:48:40,598 INFO] Step 35250/50000; acc:  98.76; ppl:  1.05; xent: 0.05; lr: 1.00000; 29284/7594 tok/s;   2303 sec\n",
            "[2020-06-02 05:48:40,916 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:40,988 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:43,912 INFO] Step 35300/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 27075/7115 tok/s;   2306 sec\n",
            "[2020-06-02 05:48:47,127 INFO] Step 35350/50000; acc:  98.76; ppl:  1.05; xent: 0.04; lr: 1.00000; 28818/7518 tok/s;   2310 sec\n",
            "[2020-06-02 05:48:48,360 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:48,488 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:50,677 INFO] Step 35400/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 26814/7083 tok/s;   2313 sec\n",
            "[2020-06-02 05:48:53,763 INFO] Step 35450/50000; acc:  98.95; ppl:  1.04; xent: 0.04; lr: 1.00000; 28795/7557 tok/s;   2316 sec\n",
            "[2020-06-02 05:48:55,815 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:48:55,887 INFO] number of examples: 7231\n",
            "[2020-06-02 05:48:57,149 INFO] Step 35500/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 27483/7209 tok/s;   2320 sec\n",
            "[2020-06-02 05:49:00,403 INFO] Step 35550/50000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 1.00000; 29158/7636 tok/s;   2323 sec\n",
            "[2020-06-02 05:49:03,180 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:03,252 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:03,609 INFO] Step 35600/50000; acc:  98.78; ppl:  1.04; xent: 0.04; lr: 1.00000; 27664/7303 tok/s;   2326 sec\n",
            "[2020-06-02 05:49:06,833 INFO] Step 35650/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 28504/7472 tok/s;   2329 sec\n",
            "[2020-06-02 05:49:10,125 INFO] Step 35700/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 29096/7529 tok/s;   2333 sec\n",
            "[2020-06-02 05:49:10,615 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:10,750 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:13,540 INFO] Step 35750/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 26524/7025 tok/s;   2336 sec\n",
            "[2020-06-02 05:49:16,724 INFO] Step 35800/50000; acc:  99.07; ppl:  1.04; xent: 0.04; lr: 1.00000; 28953/7549 tok/s;   2339 sec\n",
            "[2020-06-02 05:49:18,095 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:18,165 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:20,190 INFO] Step 35850/50000; acc:  98.90; ppl:  1.05; xent: 0.04; lr: 1.00000; 27342/7231 tok/s;   2343 sec\n",
            "[2020-06-02 05:49:23,324 INFO] Step 35900/50000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 1.00000; 28920/7565 tok/s;   2346 sec\n",
            "[2020-06-02 05:49:25,491 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:25,611 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:26,693 INFO] Step 35950/50000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 1.00000; 27343/7158 tok/s;   2349 sec\n",
            "[2020-06-02 05:49:29,957 INFO] Step 36000/50000; acc:  98.93; ppl:  1.05; xent: 0.05; lr: 1.00000; 29104/7640 tok/s;   2352 sec\n",
            "[2020-06-02 05:49:32,880 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:32,951 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:33,267 INFO] Step 36050/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 27068/7139 tok/s;   2356 sec\n",
            "[2020-06-02 05:49:36,437 INFO] Step 36100/50000; acc:  98.93; ppl:  1.05; xent: 0.05; lr: 1.00000; 28379/7442 tok/s;   2359 sec\n",
            "[2020-06-02 05:49:39,756 INFO] Step 36150/50000; acc:  98.89; ppl:  1.05; xent: 0.04; lr: 1.00000; 29253/7569 tok/s;   2362 sec\n",
            "[2020-06-02 05:49:40,354 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:40,424 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:43,106 INFO] Step 36200/50000; acc:  98.69; ppl:  1.07; xent: 0.07; lr: 1.00000; 27089/7187 tok/s;   2366 sec\n",
            "[2020-06-02 05:49:46,237 INFO] Step 36250/50000; acc:  98.98; ppl:  1.05; xent: 0.05; lr: 1.00000; 29270/7614 tok/s;   2369 sec\n",
            "[2020-06-02 05:49:47,705 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:47,837 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:49,706 INFO] Step 36300/50000; acc:  98.86; ppl:  1.05; xent: 0.05; lr: 1.00000; 27160/7162 tok/s;   2372 sec\n",
            "[2020-06-02 05:49:52,880 INFO] Step 36350/50000; acc:  98.89; ppl:  1.04; xent: 0.04; lr: 1.00000; 28833/7577 tok/s;   2375 sec\n",
            "[2020-06-02 05:49:55,165 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:49:55,236 INFO] number of examples: 7231\n",
            "[2020-06-02 05:49:56,198 INFO] Step 36400/50000; acc:  98.58; ppl:  1.09; xent: 0.09; lr: 1.00000; 27523/7210 tok/s;   2379 sec\n",
            "[2020-06-02 05:49:59,442 INFO] Step 36450/50000; acc:  98.84; ppl:  1.05; xent: 0.05; lr: 1.00000; 29059/7621 tok/s;   2382 sec\n",
            "[2020-06-02 05:50:02,525 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:02,649 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:02,726 INFO] Step 36500/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 27213/7165 tok/s;   2385 sec\n",
            "[2020-06-02 05:50:05,986 INFO] Step 36550/50000; acc:  98.93; ppl:  1.05; xent: 0.05; lr: 1.00000; 28540/7477 tok/s;   2388 sec\n",
            "[2020-06-02 05:50:09,210 INFO] Step 36600/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 29334/7621 tok/s;   2392 sec\n",
            "[2020-06-02 05:50:09,950 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:10,027 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:12,611 INFO] Step 36650/50000; acc:  98.78; ppl:  1.05; xent: 0.05; lr: 1.00000; 26742/7068 tok/s;   2395 sec\n",
            "[2020-06-02 05:50:15,812 INFO] Step 36700/50000; acc:  98.92; ppl:  1.05; xent: 0.04; lr: 1.00000; 29433/7654 tok/s;   2398 sec\n",
            "[2020-06-02 05:50:17,374 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:17,446 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:19,235 INFO] Step 36750/50000; acc:  98.83; ppl:  1.07; xent: 0.06; lr: 1.00000; 27133/7156 tok/s;   2402 sec\n",
            "[2020-06-02 05:50:22,422 INFO] Step 36800/50000; acc:  98.47; ppl:  1.10; xent: 0.09; lr: 1.00000; 28868/7573 tok/s;   2405 sec\n",
            "[2020-06-02 05:50:24,798 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:24,933 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:25,713 INFO] Step 36850/50000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 1.00000; 27064/7113 tok/s;   2408 sec\n",
            "[2020-06-02 05:50:29,067 INFO] Step 36900/50000; acc:  98.78; ppl:  1.05; xent: 0.05; lr: 1.00000; 28456/7477 tok/s;   2412 sec\n",
            "[2020-06-02 05:50:32,193 INFO] Step 36950/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 28890/7586 tok/s;   2415 sec\n",
            "[2020-06-02 05:50:32,252 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:32,324 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:35,510 INFO] Step 37000/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 27671/7244 tok/s;   2418 sec\n",
            "[2020-06-02 05:50:38,760 INFO] Step 37050/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 28881/7532 tok/s;   2421 sec\n",
            "[2020-06-02 05:50:39,636 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:39,760 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:42,191 INFO] Step 37100/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 26911/7115 tok/s;   2425 sec\n",
            "[2020-06-02 05:50:45,395 INFO] Step 37150/50000; acc:  98.74; ppl:  1.05; xent: 0.05; lr: 1.00000; 29111/7586 tok/s;   2428 sec\n",
            "[2020-06-02 05:50:47,080 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:47,222 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:48,803 INFO] Step 37200/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 26985/7086 tok/s;   2431 sec\n",
            "[2020-06-02 05:50:52,080 INFO] Step 37250/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 29078/7591 tok/s;   2435 sec\n",
            "[2020-06-02 05:50:54,532 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:50:54,604 INFO] number of examples: 7231\n",
            "[2020-06-02 05:50:55,257 INFO] Step 37300/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 27463/7256 tok/s;   2438 sec\n",
            "[2020-06-02 05:50:58,534 INFO] Step 37350/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 28644/7512 tok/s;   2441 sec\n",
            "[2020-06-02 05:51:01,734 INFO] Step 37400/50000; acc:  98.82; ppl:  1.04; xent: 0.04; lr: 1.00000; 28686/7508 tok/s;   2444 sec\n",
            "[2020-06-02 05:51:01,934 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:02,066 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:05,140 INFO] Step 37450/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 27251/7152 tok/s;   2448 sec\n",
            "[2020-06-02 05:51:08,355 INFO] Step 37500/50000; acc:  98.83; ppl:  1.05; xent: 0.04; lr: 1.00000; 28764/7485 tok/s;   2451 sec\n",
            "[2020-06-02 05:51:09,379 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:09,451 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:11,800 INFO] Step 37550/50000; acc:  98.67; ppl:  1.05; xent: 0.05; lr: 1.00000; 27520/7297 tok/s;   2454 sec\n",
            "[2020-06-02 05:51:14,910 INFO] Step 37600/50000; acc:  98.87; ppl:  1.05; xent: 0.05; lr: 1.00000; 29466/7670 tok/s;   2457 sec\n",
            "[2020-06-02 05:51:16,737 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:16,856 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:18,291 INFO] Step 37650/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 27016/7100 tok/s;   2461 sec\n",
            "[2020-06-02 05:51:21,495 INFO] Step 37700/50000; acc:  98.90; ppl:  1.04; xent: 0.04; lr: 1.00000; 29507/7729 tok/s;   2464 sec\n",
            "[2020-06-02 05:51:24,145 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:24,279 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:24,815 INFO] Step 37750/50000; acc:  98.96; ppl:  1.04; xent: 0.04; lr: 1.00000; 26624/7032 tok/s;   2467 sec\n",
            "[2020-06-02 05:51:28,029 INFO] Step 37800/50000; acc:  98.68; ppl:  1.07; xent: 0.07; lr: 1.00000; 28506/7505 tok/s;   2471 sec\n",
            "[2020-06-02 05:51:31,320 INFO] Step 37850/50000; acc:  98.76; ppl:  1.06; xent: 0.05; lr: 1.00000; 29047/7547 tok/s;   2474 sec\n",
            "[2020-06-02 05:51:31,606 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:31,678 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:34,682 INFO] Step 37900/50000; acc:  98.55; ppl:  1.07; xent: 0.06; lr: 1.00000; 27002/7079 tok/s;   2477 sec\n",
            "[2020-06-02 05:51:37,927 INFO] Step 37950/50000; acc:  98.52; ppl:  1.08; xent: 0.07; lr: 1.00000; 28386/7405 tok/s;   2480 sec\n",
            "[2020-06-02 05:51:39,133 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:39,261 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:41,475 INFO] Step 38000/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 26987/7137 tok/s;   2484 sec\n",
            "[2020-06-02 05:51:44,590 INFO] Step 38050/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 28886/7547 tok/s;   2487 sec\n",
            "[2020-06-02 05:51:46,580 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:46,652 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:47,901 INFO] Step 38100/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 27582/7261 tok/s;   2490 sec\n",
            "[2020-06-02 05:51:51,200 INFO] Step 38150/50000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 1.00000; 28876/7579 tok/s;   2494 sec\n",
            "[2020-06-02 05:51:53,958 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:51:54,074 INFO] number of examples: 7231\n",
            "[2020-06-02 05:51:54,464 INFO] Step 38200/50000; acc:  98.76; ppl:  1.05; xent: 0.05; lr: 1.00000; 26989/7123 tok/s;   2497 sec\n",
            "[2020-06-02 05:51:57,687 INFO] Step 38250/50000; acc:  98.65; ppl:  1.05; xent: 0.05; lr: 1.00000; 28723/7517 tok/s;   2500 sec\n",
            "[2020-06-02 05:52:00,991 INFO] Step 38300/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 29251/7583 tok/s;   2503 sec\n",
            "[2020-06-02 05:52:01,385 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:01,539 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:04,413 INFO] Step 38350/50000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 1.00000; 26626/7005 tok/s;   2507 sec\n",
            "[2020-06-02 05:52:07,575 INFO] Step 38400/50000; acc:  99.06; ppl:  1.04; xent: 0.04; lr: 1.00000; 28898/7544 tok/s;   2510 sec\n",
            "[2020-06-02 05:52:08,861 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:08,931 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:11,017 INFO] Step 38450/50000; acc:  98.87; ppl:  1.04; xent: 0.04; lr: 1.00000; 27532/7302 tok/s;   2513 sec\n",
            "[2020-06-02 05:52:14,134 INFO] Step 38500/50000; acc:  98.86; ppl:  1.04; xent: 0.04; lr: 1.00000; 29106/7595 tok/s;   2517 sec\n",
            "[2020-06-02 05:52:16,216 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:16,343 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:17,534 INFO] Step 38550/50000; acc:  98.76; ppl:  1.05; xent: 0.05; lr: 1.00000; 27047/7094 tok/s;   2520 sec\n",
            "[2020-06-02 05:52:20,810 INFO] Step 38600/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 29155/7641 tok/s;   2523 sec\n",
            "[2020-06-02 05:52:23,701 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:23,774 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:24,093 INFO] Step 38650/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 27000/7135 tok/s;   2527 sec\n",
            "[2020-06-02 05:52:27,283 INFO] Step 38700/50000; acc:  98.84; ppl:  1.04; xent: 0.04; lr: 1.00000; 28347/7433 tok/s;   2530 sec\n",
            "[2020-06-02 05:52:30,631 INFO] Step 38750/50000; acc:  98.79; ppl:  1.04; xent: 0.04; lr: 1.00000; 28935/7489 tok/s;   2533 sec\n",
            "[2020-06-02 05:52:31,162 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:31,285 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:34,038 INFO] Step 38800/50000; acc:  98.85; ppl:  1.04; xent: 0.04; lr: 1.00000; 26603/7053 tok/s;   2537 sec\n",
            "[2020-06-02 05:52:37,233 INFO] Step 38850/50000; acc:  98.68; ppl:  1.06; xent: 0.05; lr: 1.00000; 29093/7565 tok/s;   2540 sec\n",
            "[2020-06-02 05:52:38,635 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:38,765 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:40,681 INFO] Step 38900/50000; acc:  98.88; ppl:  1.04; xent: 0.04; lr: 1.00000; 26879/7119 tok/s;   2543 sec\n",
            "[2020-06-02 05:52:43,884 INFO] Step 38950/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 28419/7455 tok/s;   2546 sec\n",
            "[2020-06-02 05:52:46,142 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:46,215 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:47,273 INFO] Step 39000/50000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 1.00000; 27494/7175 tok/s;   2550 sec\n",
            "[2020-06-02 05:52:50,547 INFO] Step 39050/50000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 1.00000; 28717/7547 tok/s;   2553 sec\n",
            "[2020-06-02 05:52:53,564 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:52:53,686 INFO] number of examples: 7231\n",
            "[2020-06-02 05:52:53,854 INFO] Step 39100/50000; acc:  98.68; ppl:  1.05; xent: 0.05; lr: 1.00000; 26921/7110 tok/s;   2556 sec\n",
            "[2020-06-02 05:52:57,123 INFO] Step 39150/50000; acc:  98.63; ppl:  1.05; xent: 0.05; lr: 1.00000; 28307/7391 tok/s;   2560 sec\n",
            "[2020-06-02 05:53:00,372 INFO] Step 39200/50000; acc:  98.62; ppl:  1.05; xent: 0.05; lr: 1.00000; 29346/7625 tok/s;   2563 sec\n",
            "[2020-06-02 05:53:01,004 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:01,077 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:03,713 INFO] Step 39250/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 26830/7116 tok/s;   2566 sec\n",
            "[2020-06-02 05:53:06,930 INFO] Step 39300/50000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 1.00000; 29284/7597 tok/s;   2569 sec\n",
            "[2020-06-02 05:53:08,443 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:08,514 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:10,280 INFO] Step 39350/50000; acc:  98.65; ppl:  1.06; xent: 0.06; lr: 1.00000; 27607/7294 tok/s;   2573 sec\n",
            "[2020-06-02 05:53:13,509 INFO] Step 39400/50000; acc:  98.79; ppl:  1.05; xent: 0.05; lr: 1.00000; 28789/7556 tok/s;   2576 sec\n",
            "[2020-06-02 05:53:15,825 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:15,952 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:16,809 INFO] Step 39450/50000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 1.00000; 26948/7059 tok/s;   2579 sec\n",
            "[2020-06-02 05:53:20,095 INFO] Step 39500/50000; acc:  98.84; ppl:  1.05; xent: 0.05; lr: 1.00000; 28815/7587 tok/s;   2583 sec\n",
            "[2020-06-02 05:53:23,277 INFO] Step 39550/50000; acc:  98.87; ppl:  1.05; xent: 0.05; lr: 1.00000; 28541/7482 tok/s;   2586 sec\n",
            "[2020-06-02 05:53:23,278 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:23,364 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:26,563 INFO] Step 39600/50000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 1.00000; 27856/7306 tok/s;   2589 sec\n",
            "[2020-06-02 05:53:29,844 INFO] Step 39650/50000; acc:  98.76; ppl:  1.06; xent: 0.06; lr: 1.00000; 28998/7551 tok/s;   2592 sec\n",
            "[2020-06-02 05:53:30,637 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:30,757 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:33,237 INFO] Step 39700/50000; acc:  98.54; ppl:  1.07; xent: 0.06; lr: 1.00000; 27080/7148 tok/s;   2596 sec\n",
            "[2020-06-02 05:53:36,431 INFO] Step 39750/50000; acc:  98.52; ppl:  1.07; xent: 0.07; lr: 1.00000; 29146/7603 tok/s;   2599 sec\n",
            "[2020-06-02 05:53:38,053 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:38,124 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:39,844 INFO] Step 39800/50000; acc:  98.31; ppl:  1.08; xent: 0.08; lr: 1.00000; 27245/7167 tok/s;   2602 sec\n",
            "[2020-06-02 05:53:43,079 INFO] Step 39850/50000; acc:  98.60; ppl:  1.06; xent: 0.05; lr: 1.00000; 28926/7564 tok/s;   2606 sec\n",
            "[2020-06-02 05:53:45,466 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:45,538 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:46,238 INFO] Step 39900/50000; acc:  98.46; ppl:  1.07; xent: 0.07; lr: 1.00000; 27688/7303 tok/s;   2609 sec\n",
            "[2020-06-02 05:53:49,555 INFO] Step 39950/50000; acc:  98.35; ppl:  1.08; xent: 0.08; lr: 1.00000; 28671/7521 tok/s;   2612 sec\n",
            "[2020-06-02 05:53:52,784 INFO] Step 40000/50000; acc:  98.56; ppl:  1.07; xent: 0.06; lr: 1.00000; 28531/7468 tok/s;   2615 sec\n",
            "[2020-06-02 05:53:52,784 INFO] Loading dataset from Transliteration/Cleaned.valid.0.pt\n",
            "[2020-06-02 05:53:52,809 INFO] number of examples: 1000\n",
            "[2020-06-02 05:53:55,225 INFO] Validation perplexity: 146015\n",
            "[2020-06-02 05:53:55,225 INFO] Validation accuracy: 36.8032\n",
            "[2020-06-02 05:53:55,251 INFO] Saving checkpoint Transliteration/rnn_model_step_40000.pt\n",
            "[2020-06-02 05:53:55,703 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:53:55,836 INFO] number of examples: 7231\n",
            "[2020-06-02 05:53:58,976 INFO] Step 40050/50000; acc:  98.54; ppl:  1.06; xent: 0.06; lr: 1.00000; 14570/3829 tok/s;   2621 sec\n",
            "[2020-06-02 05:54:02,262 INFO] Step 40100/50000; acc:  98.78; ppl:  1.06; xent: 0.06; lr: 1.00000; 28413/7394 tok/s;   2625 sec\n",
            "[2020-06-02 05:54:03,238 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:03,309 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:05,779 INFO] Step 40150/50000; acc:  98.54; ppl:  1.07; xent: 0.07; lr: 1.00000; 26817/7102 tok/s;   2628 sec\n",
            "[2020-06-02 05:54:09,166 INFO] Step 40200/50000; acc:  98.46; ppl:  1.08; xent: 0.08; lr: 1.00000; 27397/7141 tok/s;   2632 sec\n",
            "[2020-06-02 05:54:10,925 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:11,048 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:12,553 INFO] Step 40250/50000; acc:  98.48; ppl:  1.07; xent: 0.07; lr: 1.00000; 26731/7031 tok/s;   2635 sec\n",
            "[2020-06-02 05:54:15,834 INFO] Step 40300/50000; acc:  98.46; ppl:  1.07; xent: 0.06; lr: 1.00000; 29003/7584 tok/s;   2638 sec\n",
            "[2020-06-02 05:54:18,398 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:18,534 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:19,112 INFO] Step 40350/50000; acc:  98.70; ppl:  1.06; xent: 0.06; lr: 1.00000; 26712/7056 tok/s;   2642 sec\n",
            "[2020-06-02 05:54:22,358 INFO] Step 40400/50000; acc:  98.42; ppl:  1.07; xent: 0.07; lr: 1.00000; 28938/7588 tok/s;   2645 sec\n",
            "[2020-06-02 05:54:25,619 INFO] Step 40450/50000; acc:  98.65; ppl:  1.05; xent: 0.05; lr: 1.00000; 28821/7506 tok/s;   2648 sec\n",
            "[2020-06-02 05:54:25,846 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:25,934 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:28,953 INFO] Step 40500/50000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 1.00000; 27290/7164 tok/s;   2651 sec\n",
            "[2020-06-02 05:54:32,167 INFO] Step 40550/50000; acc:  98.73; ppl:  1.06; xent: 0.06; lr: 1.00000; 28542/7450 tok/s;   2655 sec\n",
            "[2020-06-02 05:54:33,305 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:33,429 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:35,719 INFO] Step 40600/50000; acc:  98.70; ppl:  1.05; xent: 0.05; lr: 1.00000; 26971/7133 tok/s;   2658 sec\n",
            "[2020-06-02 05:54:38,850 INFO] Step 40650/50000; acc:  98.78; ppl:  1.05; xent: 0.05; lr: 1.00000; 29278/7630 tok/s;   2661 sec\n",
            "[2020-06-02 05:54:40,725 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:40,795 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:42,148 INFO] Step 40700/50000; acc:  98.69; ppl:  1.05; xent: 0.05; lr: 1.00000; 27339/7183 tok/s;   2665 sec\n",
            "[2020-06-02 05:54:45,448 INFO] Step 40750/50000; acc:  98.66; ppl:  1.06; xent: 0.05; lr: 1.00000; 29034/7621 tok/s;   2668 sec\n",
            "[2020-06-02 05:54:48,131 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:48,251 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:48,689 INFO] Step 40800/50000; acc:  98.53; ppl:  1.06; xent: 0.06; lr: 1.00000; 26866/7109 tok/s;   2671 sec\n",
            "[2020-06-02 05:54:51,947 INFO] Step 40850/50000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 1.00000; 28609/7508 tok/s;   2674 sec\n",
            "[2020-06-02 05:54:55,252 INFO] Step 40900/50000; acc:  98.56; ppl:  1.07; xent: 0.06; lr: 1.00000; 29220/7577 tok/s;   2678 sec\n",
            "[2020-06-02 05:54:55,571 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:54:55,702 INFO] number of examples: 7231\n",
            "[2020-06-02 05:54:58,618 INFO] Step 40950/50000; acc:  98.40; ppl:  1.07; xent: 0.07; lr: 1.00000; 26664/7007 tok/s;   2681 sec\n",
            "[2020-06-02 05:55:01,841 INFO] Step 41000/50000; acc:  98.68; ppl:  1.06; xent: 0.06; lr: 1.00000; 28734/7496 tok/s;   2684 sec\n",
            "[2020-06-02 05:55:03,089 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:03,161 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:05,346 INFO] Step 41050/50000; acc:  98.54; ppl:  1.06; xent: 0.05; lr: 1.00000; 27162/7175 tok/s;   2688 sec\n",
            "[2020-06-02 05:55:08,435 INFO] Step 41100/50000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 1.00000; 28773/7551 tok/s;   2691 sec\n",
            "[2020-06-02 05:55:10,498 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:10,620 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:11,845 INFO] Step 41150/50000; acc:  98.50; ppl:  1.06; xent: 0.06; lr: 1.00000; 27287/7158 tok/s;   2694 sec\n",
            "[2020-06-02 05:55:15,137 INFO] Step 41200/50000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 1.00000; 28823/7548 tok/s;   2698 sec\n",
            "[2020-06-02 05:55:17,946 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:18,020 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:18,368 INFO] Step 41250/50000; acc:  98.69; ppl:  1.06; xent: 0.05; lr: 1.00000; 27448/7246 tok/s;   2701 sec\n",
            "[2020-06-02 05:55:21,569 INFO] Step 41300/50000; acc:  98.64; ppl:  1.05; xent: 0.05; lr: 1.00000; 28708/7526 tok/s;   2704 sec\n",
            "[2020-06-02 05:55:24,848 INFO] Step 41350/50000; acc:  98.68; ppl:  1.05; xent: 0.05; lr: 1.00000; 29213/7559 tok/s;   2707 sec\n",
            "[2020-06-02 05:55:25,333 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:25,455 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:28,244 INFO] Step 41400/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 26671/7064 tok/s;   2711 sec\n",
            "[2020-06-02 05:55:31,411 INFO] Step 41450/50000; acc:  98.71; ppl:  1.05; xent: 0.05; lr: 1.00000; 29112/7590 tok/s;   2714 sec\n",
            "[2020-06-02 05:55:32,788 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:32,919 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:34,925 INFO] Step 41500/50000; acc:  98.63; ppl:  1.05; xent: 0.05; lr: 1.00000; 26966/7132 tok/s;   2717 sec\n",
            "[2020-06-02 05:55:38,082 INFO] Step 41550/50000; acc:  98.88; ppl:  1.05; xent: 0.05; lr: 1.00000; 28709/7510 tok/s;   2721 sec\n",
            "[2020-06-02 05:55:40,263 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:40,333 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:41,435 INFO] Step 41600/50000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 1.00000; 27475/7193 tok/s;   2724 sec\n",
            "[2020-06-02 05:55:44,737 INFO] Step 41650/50000; acc:  98.84; ppl:  1.05; xent: 0.05; lr: 1.00000; 28768/7552 tok/s;   2727 sec\n",
            "[2020-06-02 05:55:47,672 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:47,811 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:48,059 INFO] Step 41700/50000; acc:  98.67; ppl:  1.05; xent: 0.05; lr: 1.00000; 26972/7114 tok/s;   2731 sec\n",
            "[2020-06-02 05:55:51,263 INFO] Step 41750/50000; acc:  98.77; ppl:  1.05; xent: 0.05; lr: 1.00000; 28077/7363 tok/s;   2734 sec\n",
            "[2020-06-02 05:55:54,578 INFO] Step 41800/50000; acc:  98.77; ppl:  1.05; xent: 0.05; lr: 1.00000; 29287/7577 tok/s;   2737 sec\n",
            "[2020-06-02 05:55:55,175 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:55:55,244 INFO] number of examples: 7231\n",
            "[2020-06-02 05:55:57,979 INFO] Step 41850/50000; acc:  98.75; ppl:  1.05; xent: 0.05; lr: 1.00000; 26683/7079 tok/s;   2740 sec\n",
            "[2020-06-02 05:56:01,157 INFO] Step 41900/50000; acc:  98.61; ppl:  1.05; xent: 0.05; lr: 1.00000; 28839/7502 tok/s;   2744 sec\n",
            "[2020-06-02 05:56:02,627 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:02,699 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:04,575 INFO] Step 41950/50000; acc:  98.57; ppl:  1.06; xent: 0.06; lr: 1.00000; 27565/7269 tok/s;   2747 sec\n",
            "[2020-06-02 05:56:07,754 INFO] Step 42000/50000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 1.00000; 28787/7564 tok/s;   2750 sec\n",
            "[2020-06-02 05:56:10,058 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:10,190 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:11,157 INFO] Step 42050/50000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 1.00000; 26841/7032 tok/s;   2754 sec\n",
            "[2020-06-02 05:56:14,473 INFO] Step 42100/50000; acc:  98.72; ppl:  1.06; xent: 0.06; lr: 1.00000; 28420/7454 tok/s;   2757 sec\n",
            "[2020-06-02 05:56:17,545 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:17,616 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:17,693 INFO] Step 42150/50000; acc:  98.51; ppl:  1.07; xent: 0.06; lr: 1.00000; 27758/7308 tok/s;   2760 sec\n",
            "[2020-06-02 05:56:20,913 INFO] Step 42200/50000; acc:  98.69; ppl:  1.06; xent: 0.06; lr: 1.00000; 28886/7568 tok/s;   2763 sec\n",
            "[2020-06-02 05:56:24,150 INFO] Step 42250/50000; acc:  98.49; ppl:  1.06; xent: 0.06; lr: 1.00000; 29231/7594 tok/s;   2767 sec\n",
            "[2020-06-02 05:56:24,891 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:25,015 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:27,521 INFO] Step 42300/50000; acc:  98.58; ppl:  1.06; xent: 0.06; lr: 1.00000; 26972/7129 tok/s;   2770 sec\n",
            "[2020-06-02 05:56:30,754 INFO] Step 42350/50000; acc:  98.36; ppl:  1.10; xent: 0.09; lr: 1.00000; 29145/7579 tok/s;   2773 sec\n",
            "[2020-06-02 05:56:32,327 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:32,406 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:34,203 INFO] Step 42400/50000; acc:  98.06; ppl:  1.11; xent: 0.11; lr: 1.00000; 26924/7101 tok/s;   2777 sec\n",
            "[2020-06-02 05:56:37,393 INFO] Step 42450/50000; acc:  98.21; ppl:  1.09; xent: 0.09; lr: 1.00000; 28847/7568 tok/s;   2780 sec\n",
            "[2020-06-02 05:56:39,790 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:39,863 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:40,644 INFO] Step 42500/50000; acc:  98.04; ppl:  1.10; xent: 0.10; lr: 1.00000; 27400/7202 tok/s;   2783 sec\n",
            "[2020-06-02 05:56:43,986 INFO] Step 42550/50000; acc:  98.32; ppl:  1.08; xent: 0.08; lr: 1.00000; 28555/7503 tok/s;   2786 sec\n",
            "[2020-06-02 05:56:47,189 INFO] Step 42600/50000; acc:  98.14; ppl:  1.08; xent: 0.07; lr: 1.00000; 28196/7404 tok/s;   2790 sec\n",
            "[2020-06-02 05:56:47,249 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:47,393 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:50,618 INFO] Step 42650/50000; acc:  98.18; ppl:  1.08; xent: 0.08; lr: 1.00000; 26773/7009 tok/s;   2793 sec\n",
            "[2020-06-02 05:56:53,920 INFO] Step 42700/50000; acc:  98.27; ppl:  1.09; xent: 0.09; lr: 1.00000; 28421/7412 tok/s;   2796 sec\n",
            "[2020-06-02 05:56:54,807 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:56:54,879 INFO] number of examples: 7231\n",
            "[2020-06-02 05:56:57,298 INFO] Step 42750/50000; acc:  97.96; ppl:  1.11; xent: 0.10; lr: 1.00000; 27337/7228 tok/s;   2800 sec\n",
            "[2020-06-02 05:57:00,491 INFO] Step 42800/50000; acc:  98.36; ppl:  1.07; xent: 0.07; lr: 1.00000; 29211/7612 tok/s;   2803 sec\n",
            "[2020-06-02 05:57:02,197 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:02,317 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:03,913 INFO] Step 42850/50000; acc:  98.24; ppl:  1.09; xent: 0.09; lr: 1.00000; 26873/7057 tok/s;   2806 sec\n",
            "[2020-06-02 05:57:07,202 INFO] Step 42900/50000; acc:  98.29; ppl:  1.08; xent: 0.08; lr: 1.00000; 28971/7563 tok/s;   2810 sec\n",
            "[2020-06-02 05:57:09,667 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:09,737 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:10,442 INFO] Step 42950/50000; acc:  98.15; ppl:  1.09; xent: 0.09; lr: 1.00000; 26922/7113 tok/s;   2813 sec\n",
            "[2020-06-02 05:57:13,753 INFO] Step 43000/50000; acc:  98.29; ppl:  1.08; xent: 0.07; lr: 1.00000; 28351/7435 tok/s;   2816 sec\n",
            "[2020-06-02 05:57:16,936 INFO] Step 43050/50000; acc:  98.17; ppl:  1.08; xent: 0.08; lr: 1.00000; 28836/7547 tok/s;   2819 sec\n",
            "[2020-06-02 05:57:17,137 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:17,215 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:20,297 INFO] Step 43100/50000; acc:  98.26; ppl:  1.08; xent: 0.08; lr: 1.00000; 27613/7247 tok/s;   2823 sec\n",
            "[2020-06-02 05:57:23,496 INFO] Step 43150/50000; acc:  98.10; ppl:  1.08; xent: 0.08; lr: 1.00000; 28919/7526 tok/s;   2826 sec\n",
            "[2020-06-02 05:57:24,523 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:24,652 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:26,999 INFO] Step 43200/50000; acc:  98.22; ppl:  1.08; xent: 0.07; lr: 1.00000; 27055/7173 tok/s;   2829 sec\n",
            "[2020-06-02 05:57:30,178 INFO] Step 43250/50000; acc:  98.35; ppl:  1.07; xent: 0.07; lr: 1.00000; 28825/7503 tok/s;   2833 sec\n",
            "[2020-06-02 05:57:31,982 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:32,054 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:33,516 INFO] Step 43300/50000; acc:  98.45; ppl:  1.07; xent: 0.07; lr: 1.00000; 27370/7193 tok/s;   2836 sec\n",
            "[2020-06-02 05:57:36,778 INFO] Step 43350/50000; acc:  98.59; ppl:  1.06; xent: 0.06; lr: 1.00000; 28979/7591 tok/s;   2839 sec\n",
            "[2020-06-02 05:57:39,410 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:39,534 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:40,057 INFO] Step 43400/50000; acc:  98.39; ppl:  1.07; xent: 0.06; lr: 1.00000; 26962/7121 tok/s;   2843 sec\n",
            "[2020-06-02 05:57:43,295 INFO] Step 43450/50000; acc:  98.50; ppl:  1.08; xent: 0.07; lr: 1.00000; 28294/7449 tok/s;   2846 sec\n",
            "[2020-06-02 05:57:46,618 INFO] Step 43500/50000; acc:  98.47; ppl:  1.07; xent: 0.06; lr: 1.00000; 28768/7475 tok/s;   2849 sec\n",
            "[2020-06-02 05:57:46,900 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:46,977 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:49,993 INFO] Step 43550/50000; acc:  98.29; ppl:  1.08; xent: 0.08; lr: 1.00000; 26897/7051 tok/s;   2852 sec\n",
            "[2020-06-02 05:57:53,198 INFO] Step 43600/50000; acc:  98.36; ppl:  1.07; xent: 0.07; lr: 1.00000; 28745/7499 tok/s;   2856 sec\n",
            "[2020-06-02 05:57:54,384 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:57:54,455 INFO] number of examples: 7231\n",
            "[2020-06-02 05:57:56,705 INFO] Step 43650/50000; acc:  98.08; ppl:  1.09; xent: 0.09; lr: 1.00000; 27296/7219 tok/s;   2859 sec\n",
            "[2020-06-02 05:57:59,794 INFO] Step 43700/50000; acc:  98.49; ppl:  1.07; xent: 0.07; lr: 1.00000; 29137/7612 tok/s;   2862 sec\n",
            "[2020-06-02 05:58:01,776 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:01,924 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:03,208 INFO] Step 43750/50000; acc:  98.28; ppl:  1.08; xent: 0.08; lr: 1.00000; 26747/7041 tok/s;   2866 sec\n",
            "[2020-06-02 05:58:06,508 INFO] Step 43800/50000; acc:  98.28; ppl:  1.08; xent: 0.08; lr: 1.00000; 28871/7577 tok/s;   2869 sec\n",
            "[2020-06-02 05:58:09,293 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:09,362 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:09,749 INFO] Step 43850/50000; acc:  98.26; ppl:  1.08; xent: 0.08; lr: 1.00000; 27176/7172 tok/s;   2872 sec\n",
            "[2020-06-02 05:58:12,993 INFO] Step 43900/50000; acc:  98.32; ppl:  1.07; xent: 0.07; lr: 1.00000; 28536/7469 tok/s;   2875 sec\n",
            "[2020-06-02 05:58:16,377 INFO] Step 43950/50000; acc:  98.28; ppl:  1.08; xent: 0.08; lr: 1.00000; 28557/7403 tok/s;   2879 sec\n",
            "[2020-06-02 05:58:16,775 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:16,897 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:19,767 INFO] Step 44000/50000; acc:  98.16; ppl:  1.08; xent: 0.07; lr: 1.00000; 26884/7073 tok/s;   2882 sec\n",
            "[2020-06-02 05:58:22,934 INFO] Step 44050/50000; acc:  98.44; ppl:  1.06; xent: 0.06; lr: 1.00000; 28845/7531 tok/s;   2885 sec\n",
            "[2020-06-02 05:58:24,226 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:24,359 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:26,446 INFO] Step 44100/50000; acc:  98.25; ppl:  1.08; xent: 0.08; lr: 1.00000; 26986/7157 tok/s;   2889 sec\n",
            "[2020-06-02 05:58:29,607 INFO] Step 44150/50000; acc:  98.26; ppl:  1.08; xent: 0.07; lr: 1.00000; 28691/7487 tok/s;   2892 sec\n",
            "[2020-06-02 05:58:31,725 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:31,797 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:32,968 INFO] Step 44200/50000; acc:  98.33; ppl:  1.07; xent: 0.07; lr: 1.00000; 27360/7177 tok/s;   2895 sec\n",
            "[2020-06-02 05:58:36,267 INFO] Step 44250/50000; acc:  98.37; ppl:  1.08; xent: 0.07; lr: 1.00000; 28958/7590 tok/s;   2899 sec\n",
            "[2020-06-02 05:58:39,139 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:39,269 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:39,581 INFO] Step 44300/50000; acc:  98.48; ppl:  1.07; xent: 0.07; lr: 1.00000; 26750/7068 tok/s;   2902 sec\n",
            "[2020-06-02 05:58:42,773 INFO] Step 44350/50000; acc:  98.37; ppl:  1.08; xent: 0.08; lr: 1.00000; 28326/7428 tok/s;   2905 sec\n",
            "[2020-06-02 05:58:46,153 INFO] Step 44400/50000; acc:  98.24; ppl:  1.08; xent: 0.08; lr: 1.00000; 28661/7418 tok/s;   2909 sec\n",
            "[2020-06-02 05:58:46,685 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:46,757 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:49,497 INFO] Step 44450/50000; acc:  98.24; ppl:  1.08; xent: 0.08; lr: 1.00000; 27101/7185 tok/s;   2912 sec\n",
            "[2020-06-02 05:58:52,716 INFO] Step 44500/50000; acc:  98.48; ppl:  1.07; xent: 0.07; lr: 1.00000; 28887/7512 tok/s;   2915 sec\n",
            "[2020-06-02 05:58:54,122 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:58:54,239 INFO] number of examples: 7231\n",
            "[2020-06-02 05:58:56,167 INFO] Step 44550/50000; acc:  98.26; ppl:  1.08; xent: 0.08; lr: 1.00000; 26854/7112 tok/s;   2919 sec\n",
            "[2020-06-02 05:58:59,353 INFO] Step 44600/50000; acc:  98.44; ppl:  1.07; xent: 0.07; lr: 1.00000; 28566/7494 tok/s;   2922 sec\n",
            "[2020-06-02 05:59:01,621 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:01,767 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:02,844 INFO] Step 44650/50000; acc:  98.18; ppl:  1.07; xent: 0.07; lr: 1.00000; 26695/6966 tok/s;   2925 sec\n",
            "[2020-06-02 05:59:06,088 INFO] Step 44700/50000; acc:  98.32; ppl:  1.08; xent: 0.08; lr: 1.00000; 28974/7614 tok/s;   2929 sec\n",
            "[2020-06-02 05:59:09,112 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:09,182 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:09,335 INFO] Step 44750/50000; acc:  98.34; ppl:  1.07; xent: 0.07; lr: 1.00000; 27429/7244 tok/s;   2932 sec\n",
            "[2020-06-02 05:59:12,587 INFO] Step 44800/50000; acc:  98.31; ppl:  1.07; xent: 0.07; lr: 1.00000; 28450/7428 tok/s;   2935 sec\n",
            "[2020-06-02 05:59:15,891 INFO] Step 44850/50000; acc:  98.11; ppl:  1.08; xent: 0.08; lr: 1.00000; 28852/7497 tok/s;   2938 sec\n",
            "[2020-06-02 05:59:16,530 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:16,665 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:19,230 INFO] Step 44900/50000; acc:  98.29; ppl:  1.08; xent: 0.07; lr: 1.00000; 26849/7121 tok/s;   2942 sec\n",
            "[2020-06-02 05:59:22,470 INFO] Step 44950/50000; acc:  98.34; ppl:  1.07; xent: 0.07; lr: 1.00000; 29069/7541 tok/s;   2945 sec\n",
            "[2020-06-02 05:59:23,966 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:24,037 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:25,788 INFO] Step 45000/50000; acc:  98.19; ppl:  1.07; xent: 0.07; lr: 1.00000; 27878/7366 tok/s;   2948 sec\n",
            "[2020-06-02 05:59:25,824 INFO] Saving checkpoint Transliteration/rnn_model_step_45000.pt\n",
            "[2020-06-02 05:59:29,305 INFO] Step 45050/50000; acc:  98.39; ppl:  1.07; xent: 0.07; lr: 1.00000; 26435/6938 tok/s;   2952 sec\n",
            "[2020-06-02 05:59:31,647 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:31,767 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:32,617 INFO] Step 45100/50000; acc:  98.37; ppl:  1.07; xent: 0.07; lr: 1.00000; 26850/7033 tok/s;   2955 sec\n",
            "[2020-06-02 05:59:35,950 INFO] Step 45150/50000; acc:  98.09; ppl:  1.08; xent: 0.08; lr: 1.00000; 28412/7481 tok/s;   2958 sec\n",
            "[2020-06-02 05:59:39,413 INFO] Step 45200/50000; acc:  98.34; ppl:  1.07; xent: 0.07; lr: 1.00000; 26218/6873 tok/s;   2962 sec\n",
            "[2020-06-02 05:59:39,414 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:39,545 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:42,803 INFO] Step 45250/50000; acc:  98.17; ppl:  1.08; xent: 0.08; lr: 1.00000; 27009/7084 tok/s;   2965 sec\n",
            "[2020-06-02 05:59:46,111 INFO] Step 45300/50000; acc:  98.11; ppl:  1.08; xent: 0.08; lr: 1.00000; 28753/7487 tok/s;   2969 sec\n",
            "[2020-06-02 05:59:46,927 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:47,000 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:49,535 INFO] Step 45350/50000; acc:  97.92; ppl:  1.10; xent: 0.09; lr: 1.00000; 26842/7085 tok/s;   2972 sec\n",
            "[2020-06-02 05:59:52,714 INFO] Step 45400/50000; acc:  98.27; ppl:  1.09; xent: 0.08; lr: 1.00000; 29271/7636 tok/s;   2975 sec\n",
            "[2020-06-02 05:59:54,328 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 05:59:54,451 INFO] number of examples: 7231\n",
            "[2020-06-02 05:59:56,128 INFO] Step 45450/50000; acc:  97.93; ppl:  1.10; xent: 0.09; lr: 1.00000; 27239/7166 tok/s;   2979 sec\n",
            "[2020-06-02 05:59:59,397 INFO] Step 45500/50000; acc:  98.36; ppl:  1.07; xent: 0.07; lr: 1.00000; 28621/7485 tok/s;   2982 sec\n",
            "[2020-06-02 06:00:01,879 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:01,952 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:02,664 INFO] Step 45550/50000; acc:  98.29; ppl:  1.07; xent: 0.07; lr: 1.00000; 26778/7063 tok/s;   2985 sec\n",
            "[2020-06-02 06:00:06,011 INFO] Step 45600/50000; acc:  98.26; ppl:  1.08; xent: 0.07; lr: 1.00000; 28416/7454 tok/s;   2988 sec\n",
            "[2020-06-02 06:00:09,257 INFO] Step 45650/50000; acc:  98.23; ppl:  1.08; xent: 0.08; lr: 1.00000; 28375/7428 tok/s;   2992 sec\n",
            "[2020-06-02 06:00:09,359 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:09,479 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:12,606 INFO] Step 45700/50000; acc:  98.30; ppl:  1.07; xent: 0.07; lr: 1.00000; 26942/7080 tok/s;   2995 sec\n",
            "[2020-06-02 06:00:15,836 INFO] Step 45750/50000; acc:  98.33; ppl:  1.07; xent: 0.07; lr: 1.00000; 28901/7521 tok/s;   2998 sec\n",
            "[2020-06-02 06:00:16,810 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:16,940 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:19,352 INFO] Step 45800/50000; acc:  97.99; ppl:  1.09; xent: 0.09; lr: 1.00000; 26832/7106 tok/s;   3002 sec\n",
            "[2020-06-02 06:00:22,565 INFO] Step 45850/50000; acc:  98.30; ppl:  1.07; xent: 0.07; lr: 1.00000; 28877/7526 tok/s;   3005 sec\n",
            "[2020-06-02 06:00:24,308 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:24,378 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:25,869 INFO] Step 45900/50000; acc:  97.75; ppl:  1.13; xent: 0.12; lr: 1.00000; 27396/7206 tok/s;   3008 sec\n",
            "[2020-06-02 06:00:29,127 INFO] Step 45950/50000; acc:  97.73; ppl:  1.13; xent: 0.12; lr: 1.00000; 29208/7637 tok/s;   3012 sec\n",
            "[2020-06-02 06:00:31,671 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:31,793 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:32,360 INFO] Step 46000/50000; acc:  97.85; ppl:  1.11; xent: 0.10; lr: 1.00000; 27085/7155 tok/s;   3015 sec\n",
            "[2020-06-02 06:00:35,655 INFO] Step 46050/50000; acc:  98.09; ppl:  1.09; xent: 0.09; lr: 1.00000; 28513/7477 tok/s;   3018 sec\n",
            "[2020-06-02 06:00:38,905 INFO] Step 46100/50000; acc:  98.08; ppl:  1.09; xent: 0.09; lr: 1.00000; 28915/7531 tok/s;   3021 sec\n",
            "[2020-06-02 06:00:39,133 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:39,215 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:42,285 INFO] Step 46150/50000; acc:  98.01; ppl:  1.08; xent: 0.08; lr: 1.00000; 26922/7068 tok/s;   3025 sec\n",
            "[2020-06-02 06:00:45,466 INFO] Step 46200/50000; acc:  98.20; ppl:  1.08; xent: 0.08; lr: 1.00000; 28829/7525 tok/s;   3028 sec\n",
            "[2020-06-02 06:00:46,583 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:46,655 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:48,929 INFO] Step 46250/50000; acc:  97.98; ppl:  1.08; xent: 0.08; lr: 1.00000; 27666/7317 tok/s;   3031 sec\n",
            "[2020-06-02 06:00:52,133 INFO] Step 46300/50000; acc:  98.17; ppl:  1.09; xent: 0.08; lr: 1.00000; 28621/7459 tok/s;   3035 sec\n",
            "[2020-06-02 06:00:54,034 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:00:54,166 INFO] number of examples: 7231\n",
            "[2020-06-02 06:00:55,512 INFO] Step 46350/50000; acc:  98.13; ppl:  1.08; xent: 0.07; lr: 1.00000; 26674/7008 tok/s;   3038 sec\n",
            "[2020-06-02 06:00:58,812 INFO] Step 46400/50000; acc:  98.08; ppl:  1.10; xent: 0.09; lr: 1.00000; 29042/7623 tok/s;   3041 sec\n",
            "[2020-06-02 06:01:01,513 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:01,584 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:02,024 INFO] Step 46450/50000; acc:  98.07; ppl:  1.10; xent: 0.09; lr: 1.00000; 27102/7172 tok/s;   3044 sec\n",
            "[2020-06-02 06:01:05,279 INFO] Step 46500/50000; acc:  98.05; ppl:  1.09; xent: 0.09; lr: 1.00000; 28640/7516 tok/s;   3048 sec\n",
            "[2020-06-02 06:01:08,607 INFO] Step 46550/50000; acc:  98.00; ppl:  1.09; xent: 0.09; lr: 1.00000; 29021/7525 tok/s;   3051 sec\n",
            "[2020-06-02 06:01:08,932 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:09,058 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:11,982 INFO] Step 46600/50000; acc:  98.16; ppl:  1.08; xent: 0.08; lr: 1.00000; 26589/6987 tok/s;   3054 sec\n",
            "[2020-06-02 06:01:15,215 INFO] Step 46650/50000; acc:  98.01; ppl:  1.09; xent: 0.08; lr: 1.00000; 28653/7475 tok/s;   3058 sec\n",
            "[2020-06-02 06:01:16,451 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:16,527 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:18,778 INFO] Step 46700/50000; acc:  98.10; ppl:  1.09; xent: 0.08; lr: 1.00000; 26720/7058 tok/s;   3061 sec\n",
            "[2020-06-02 06:01:21,915 INFO] Step 46750/50000; acc:  98.13; ppl:  1.08; xent: 0.08; lr: 1.00000; 28327/7434 tok/s;   3064 sec\n",
            "[2020-06-02 06:01:24,007 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:24,085 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:25,296 INFO] Step 46800/50000; acc:  97.83; ppl:  1.10; xent: 0.10; lr: 1.00000; 27518/7218 tok/s;   3068 sec\n",
            "[2020-06-02 06:01:28,566 INFO] Step 46850/50000; acc:  98.09; ppl:  1.08; xent: 0.08; lr: 1.00000; 29012/7598 tok/s;   3071 sec\n",
            "[2020-06-02 06:01:31,368 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:31,497 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:31,849 INFO] Step 46900/50000; acc:  98.06; ppl:  1.08; xent: 0.08; lr: 1.00000; 27020/7133 tok/s;   3074 sec\n",
            "[2020-06-02 06:01:35,093 INFO] Step 46950/50000; acc:  98.07; ppl:  1.09; xent: 0.09; lr: 1.00000; 28331/7427 tok/s;   3078 sec\n",
            "[2020-06-02 06:01:38,380 INFO] Step 47000/50000; acc:  97.57; ppl:  1.16; xent: 0.15; lr: 1.00000; 29141/7541 tok/s;   3081 sec\n",
            "[2020-06-02 06:01:38,844 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:38,916 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:41,685 INFO] Step 47050/50000; acc:  98.24; ppl:  1.08; xent: 0.08; lr: 1.00000; 27402/7258 tok/s;   3084 sec\n",
            "[2020-06-02 06:01:44,873 INFO] Step 47100/50000; acc:  98.27; ppl:  1.08; xent: 0.07; lr: 1.00000; 28923/7541 tok/s;   3087 sec\n",
            "[2020-06-02 06:01:46,241 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:46,367 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:48,431 INFO] Step 47150/50000; acc:  98.06; ppl:  1.08; xent: 0.08; lr: 1.00000; 26629/7043 tok/s;   3091 sec\n",
            "[2020-06-02 06:01:51,583 INFO] Step 47200/50000; acc:  98.35; ppl:  1.08; xent: 0.08; lr: 1.00000; 28766/7525 tok/s;   3094 sec\n",
            "[2020-06-02 06:01:53,786 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:01:53,857 INFO] number of examples: 7231\n",
            "[2020-06-02 06:01:55,038 INFO] Step 47250/50000; acc:  98.08; ppl:  1.08; xent: 0.08; lr: 1.00000; 26660/6979 tok/s;   3098 sec\n",
            "[2020-06-02 06:01:58,357 INFO] Step 47300/50000; acc:  98.11; ppl:  1.09; xent: 0.08; lr: 1.00000; 28616/7512 tok/s;   3101 sec\n",
            "[2020-06-02 06:02:01,331 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:01,408 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:01,673 INFO] Step 47350/50000; acc:  98.23; ppl:  1.08; xent: 0.08; lr: 1.00000; 27020/7126 tok/s;   3104 sec\n",
            "[2020-06-02 06:02:04,896 INFO] Step 47400/50000; acc:  98.03; ppl:  1.09; xent: 0.09; lr: 1.00000; 27920/7321 tok/s;   3107 sec\n",
            "[2020-06-02 06:02:08,223 INFO] Step 47450/50000; acc:  98.16; ppl:  1.08; xent: 0.07; lr: 1.00000; 29169/7547 tok/s;   3111 sec\n",
            "[2020-06-02 06:02:08,826 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:08,957 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:11,653 INFO] Step 47500/50000; acc:  98.12; ppl:  1.08; xent: 0.08; lr: 1.00000; 26460/7020 tok/s;   3114 sec\n",
            "[2020-06-02 06:02:14,873 INFO] Step 47550/50000; acc:  98.08; ppl:  1.08; xent: 0.08; lr: 1.00000; 28462/7404 tok/s;   3117 sec\n",
            "[2020-06-02 06:02:16,344 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:16,416 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:18,269 INFO] Step 47600/50000; acc:  97.78; ppl:  1.11; xent: 0.11; lr: 1.00000; 27743/7316 tok/s;   3121 sec\n",
            "[2020-06-02 06:02:21,466 INFO] Step 47650/50000; acc:  98.07; ppl:  1.10; xent: 0.09; lr: 1.00000; 28621/7521 tok/s;   3124 sec\n",
            "[2020-06-02 06:02:23,777 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:23,903 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:24,882 INFO] Step 47700/50000; acc:  98.15; ppl:  1.08; xent: 0.08; lr: 1.00000; 26745/7007 tok/s;   3127 sec\n",
            "[2020-06-02 06:02:28,140 INFO] Step 47750/50000; acc:  98.20; ppl:  1.08; xent: 0.08; lr: 1.00000; 28931/7588 tok/s;   3131 sec\n",
            "[2020-06-02 06:02:31,200 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:31,272 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:31,406 INFO] Step 47800/50000; acc:  98.10; ppl:  1.08; xent: 0.08; lr: 1.00000; 27356/7202 tok/s;   3134 sec\n",
            "[2020-06-02 06:02:34,686 INFO] Step 47850/50000; acc:  98.11; ppl:  1.08; xent: 0.08; lr: 1.00000; 28364/7431 tok/s;   3137 sec\n",
            "[2020-06-02 06:02:37,948 INFO] Step 47900/50000; acc:  97.97; ppl:  1.10; xent: 0.10; lr: 1.00000; 29007/7536 tok/s;   3140 sec\n",
            "[2020-06-02 06:02:38,684 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:38,754 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:41,265 INFO] Step 47950/50000; acc:  98.01; ppl:  1.08; xent: 0.08; lr: 1.00000; 27406/7243 tok/s;   3144 sec\n",
            "[2020-06-02 06:02:44,553 INFO] Step 48000/50000; acc:  98.09; ppl:  1.08; xent: 0.08; lr: 1.00000; 28658/7452 tok/s;   3147 sec\n",
            "[2020-06-02 06:02:46,106 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:46,236 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:48,004 INFO] Step 48050/50000; acc:  97.44; ppl:  1.15; xent: 0.14; lr: 1.00000; 26914/7098 tok/s;   3150 sec\n",
            "[2020-06-02 06:02:51,177 INFO] Step 48100/50000; acc:  98.01; ppl:  1.10; xent: 0.09; lr: 1.00000; 28997/7607 tok/s;   3154 sec\n",
            "[2020-06-02 06:02:53,542 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:02:53,627 INFO] number of examples: 7231\n",
            "[2020-06-02 06:02:54,407 INFO] Step 48150/50000; acc:  98.05; ppl:  1.09; xent: 0.09; lr: 1.00000; 27581/7249 tok/s;   3157 sec\n",
            "[2020-06-02 06:02:57,756 INFO] Step 48200/50000; acc:  97.80; ppl:  1.10; xent: 0.10; lr: 1.00000; 28495/7487 tok/s;   3160 sec\n",
            "[2020-06-02 06:03:00,952 INFO] Step 48250/50000; acc:  97.98; ppl:  1.09; xent: 0.08; lr: 1.00000; 28257/7420 tok/s;   3163 sec\n",
            "[2020-06-02 06:03:01,012 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:01,136 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:04,330 INFO] Step 48300/50000; acc:  97.83; ppl:  1.11; xent: 0.10; lr: 1.00000; 27173/7114 tok/s;   3167 sec\n",
            "[2020-06-02 06:03:07,595 INFO] Step 48350/50000; acc:  98.14; ppl:  1.08; xent: 0.08; lr: 1.00000; 28744/7496 tok/s;   3170 sec\n",
            "[2020-06-02 06:03:08,490 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:08,626 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:11,068 INFO] Step 48400/50000; acc:  98.21; ppl:  1.07; xent: 0.07; lr: 1.00000; 26592/7031 tok/s;   3174 sec\n",
            "[2020-06-02 06:03:14,293 INFO] Step 48450/50000; acc:  98.39; ppl:  1.07; xent: 0.07; lr: 1.00000; 28924/7537 tok/s;   3177 sec\n",
            "[2020-06-02 06:03:16,010 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:16,083 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:17,675 INFO] Step 48500/50000; acc:  97.99; ppl:  1.09; xent: 0.08; lr: 1.00000; 27184/7138 tok/s;   3180 sec\n",
            "[2020-06-02 06:03:20,942 INFO] Step 48550/50000; acc:  98.36; ppl:  1.07; xent: 0.07; lr: 1.00000; 29166/7614 tok/s;   3183 sec\n",
            "[2020-06-02 06:03:23,392 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:23,521 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:24,156 INFO] Step 48600/50000; acc:  98.03; ppl:  1.09; xent: 0.09; lr: 1.00000; 27144/7172 tok/s;   3187 sec\n",
            "[2020-06-02 06:03:27,407 INFO] Step 48650/50000; acc:  97.94; ppl:  1.09; xent: 0.09; lr: 1.00000; 28880/7574 tok/s;   3190 sec\n",
            "[2020-06-02 06:03:30,623 INFO] Step 48700/50000; acc:  97.96; ppl:  1.09; xent: 0.09; lr: 1.00000; 28533/7468 tok/s;   3193 sec\n",
            "[2020-06-02 06:03:30,820 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:30,893 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:34,024 INFO] Step 48750/50000; acc:  97.89; ppl:  1.10; xent: 0.09; lr: 1.00000; 27295/7163 tok/s;   3196 sec\n",
            "[2020-06-02 06:03:37,263 INFO] Step 48800/50000; acc:  97.94; ppl:  1.09; xent: 0.09; lr: 1.00000; 28556/7431 tok/s;   3200 sec\n",
            "[2020-06-02 06:03:38,302 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:38,422 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:40,778 INFO] Step 48850/50000; acc:  98.01; ppl:  1.08; xent: 0.08; lr: 1.00000; 26968/7150 tok/s;   3203 sec\n",
            "[2020-06-02 06:03:43,961 INFO] Step 48900/50000; acc:  98.12; ppl:  1.08; xent: 0.08; lr: 1.00000; 28788/7493 tok/s;   3206 sec\n",
            "[2020-06-02 06:03:45,789 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:45,940 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:47,399 INFO] Step 48950/50000; acc:  97.74; ppl:  1.10; xent: 0.10; lr: 1.00000; 26569/6983 tok/s;   3210 sec\n",
            "[2020-06-02 06:03:50,656 INFO] Step 49000/50000; acc:  97.98; ppl:  1.08; xent: 0.08; lr: 1.00000; 29026/7603 tok/s;   3213 sec\n",
            "[2020-06-02 06:03:53,299 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:03:53,379 INFO] number of examples: 7231\n",
            "[2020-06-02 06:03:53,915 INFO] Step 49050/50000; acc:  97.98; ppl:  1.09; xent: 0.09; lr: 1.00000; 27129/7166 tok/s;   3216 sec\n",
            "[2020-06-02 06:03:57,147 INFO] Step 49100/50000; acc:  98.01; ppl:  1.09; xent: 0.09; lr: 1.00000; 28344/7463 tok/s;   3220 sec\n",
            "[2020-06-02 06:04:00,441 INFO] Step 49150/50000; acc:  97.97; ppl:  1.09; xent: 0.09; lr: 1.00000; 29015/7539 tok/s;   3223 sec\n",
            "[2020-06-02 06:04:00,717 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:00,855 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:03,855 INFO] Step 49200/50000; acc:  97.88; ppl:  1.09; xent: 0.09; lr: 1.00000; 26596/6973 tok/s;   3226 sec\n",
            "[2020-06-02 06:04:07,084 INFO] Step 49250/50000; acc:  97.95; ppl:  1.08; xent: 0.08; lr: 1.00000; 28524/7441 tok/s;   3230 sec\n",
            "[2020-06-02 06:04:08,277 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:08,349 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:10,635 INFO] Step 49300/50000; acc:  97.81; ppl:  1.10; xent: 0.10; lr: 1.00000; 26968/7132 tok/s;   3233 sec\n",
            "[2020-06-02 06:04:13,749 INFO] Step 49350/50000; acc:  98.13; ppl:  1.09; xent: 0.09; lr: 1.00000; 28892/7548 tok/s;   3236 sec\n",
            "[2020-06-02 06:04:15,780 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:15,903 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:17,185 INFO] Step 49400/50000; acc:  97.72; ppl:  1.10; xent: 0.10; lr: 1.00000; 26584/6998 tok/s;   3240 sec\n",
            "[2020-06-02 06:04:20,498 INFO] Step 49450/50000; acc:  97.72; ppl:  1.10; xent: 0.09; lr: 1.00000; 28748/7545 tok/s;   3243 sec\n",
            "[2020-06-02 06:04:23,284 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:23,414 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:23,805 INFO] Step 49500/50000; acc:  97.83; ppl:  1.10; xent: 0.10; lr: 1.00000; 26633/7029 tok/s;   3246 sec\n",
            "[2020-06-02 06:04:27,087 INFO] Step 49550/50000; acc:  97.81; ppl:  1.10; xent: 0.10; lr: 1.00000; 28213/7384 tok/s;   3250 sec\n",
            "[2020-06-02 06:04:30,396 INFO] Step 49600/50000; acc:  97.76; ppl:  1.11; xent: 0.10; lr: 1.00000; 29200/7570 tok/s;   3253 sec\n",
            "[2020-06-02 06:04:30,792 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:30,866 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:33,740 INFO] Step 49650/50000; acc:  97.85; ppl:  1.11; xent: 0.10; lr: 1.00000; 27257/7171 tok/s;   3256 sec\n",
            "[2020-06-02 06:04:36,920 INFO] Step 49700/50000; acc:  98.03; ppl:  1.09; xent: 0.08; lr: 1.00000; 28731/7501 tok/s;   3259 sec\n",
            "[2020-06-02 06:04:38,228 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:38,351 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:40,429 INFO] Step 49750/50000; acc:  97.75; ppl:  1.12; xent: 0.11; lr: 1.00000; 27003/7161 tok/s;   3263 sec\n",
            "[2020-06-02 06:04:43,585 INFO] Step 49800/50000; acc:  98.10; ppl:  1.09; xent: 0.09; lr: 1.00000; 28748/7501 tok/s;   3266 sec\n",
            "[2020-06-02 06:04:45,696 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:45,771 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:46,944 INFO] Step 49850/50000; acc:  97.79; ppl:  1.11; xent: 0.10; lr: 1.00000; 27381/7182 tok/s;   3269 sec\n",
            "[2020-06-02 06:04:50,254 INFO] Step 49900/50000; acc:  97.58; ppl:  1.10; xent: 0.10; lr: 1.00000; 28856/7563 tok/s;   3273 sec\n",
            "[2020-06-02 06:04:53,111 INFO] Loading dataset from Transliteration/Cleaned.train.0.pt\n",
            "[2020-06-02 06:04:53,228 INFO] number of examples: 7231\n",
            "[2020-06-02 06:04:53,537 INFO] Step 49950/50000; acc:  98.23; ppl:  1.08; xent: 0.08; lr: 1.00000; 27000/7135 tok/s;   3276 sec\n",
            "[2020-06-02 06:04:56,715 INFO] Step 50000/50000; acc:  97.95; ppl:  1.09; xent: 0.08; lr: 0.50000; 28448/7460 tok/s;   3279 sec\n",
            "[2020-06-02 06:04:56,716 INFO] Loading dataset from Transliteration/Cleaned.valid.0.pt\n",
            "[2020-06-02 06:04:56,741 INFO] number of examples: 1000\n",
            "[2020-06-02 06:04:59,125 INFO] Validation perplexity: 214806\n",
            "[2020-06-02 06:04:59,126 INFO] Validation accuracy: 38.0109\n",
            "[2020-06-02 06:04:59,152 INFO] Saving checkpoint Transliteration/rnn_model_step_50000.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUU5RKuT6SsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ac9e814-dbc1-474f-bf36-8b56812b8998"
      },
      "source": [
        "!python OpenNMT-py/translate.py -model Transliteration/rnn_model_step_50000.pt -src Transliteration/fixed_test.fa -output Transliteration/Transliteration_pred.txt -replace_unk -verbose"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-06-02 06:06:31,499 INFO] Translating shard 0.\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:66: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "\n",
            "SENT 1: ['ن', 'ظ', 'ر', 'ت', '<b>', 'ب', 'ر', 'ا', 'م', '<b>', 'م', 'ه', 'م', 'ه']\n",
            "PRED 1: nazaret baraam bege\n",
            "PRED SCORE: -0.1868\n",
            "\n",
            "SENT 2: ['چ', 'و', 'ن', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'ن', 'د', 'ا', 'ر', 'م', '<b>', 'د', 'ر', 'گ', 'ی', 'ر', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ا', 'ت', '<b>', 'ب', 'ا', 'ش', 'ی', '<b>', 'و', '<b>', 'ت', 'ص', 'م', 'ی', 'م', '<b>', 'ب', 'گ', 'ی', 'ر', 'ی', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'م', 'ن', 'ظ', 'و', 'ر', 'م', '<b>', 'ر', 'و', 'ش', 'ن', 'ه', '<b>', 'ی', 'ا', '<b>', 'ن', 'ه']\n",
            "PRED 2: chon dust nadaaram dar e ehsaasaat baashi o taslim nemidunam\n",
            "PRED SCORE: -1.8105\n",
            "\n",
            "SENT 3: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '\\u200c', 'ص', 'و', 'ر', 'ت', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', 'ش', '<b>', 'چ', 'ش', 'م', '<b>', 'د', 'و', 'خ', 'ت', '<b>', 'و', '<b>', 'ی', 'ک', '<b>', 'ا', 'ن', '<b>', 'ف', 'ک', 'ر', '<b>', 'ک', 'ر', 'د', '<b>', 'ه', 'ی', 'چ', '\\u200c', 'و', 'ق', 'ت', '<b>', 'ک', 'س', 'ی', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', 'د', 'ا', 'ز', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'و', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'ه', '<b>', 'و', '<b>', 'پ', 'س', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ق', 'ا', 'د', 'ر', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ب', 'د', 'و', 'ن', '<b>', 'ا', 'و', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 3: foruq be surat e negaah e kotash dust va yek fekr kard va pas istaad\n",
            "PRED SCORE: -3.5205\n",
            "\n",
            "SENT 4: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'د', 'ی', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'چ', 'ی', 'ز', 'ا', 'ی', '<b>', 'د', 'ی', 'گ', 'ه', '\\u200c', 'ا', 'م', '<b>', 'ه', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ع', 'ق', 'ی', 'د', 'ه', '<b>', 'ا', 'ت', '<b>', 'ر', 'و', '<b>', 'د', 'ر', 'ب', 'ا', 'ر', 'ه', '<b>', 'ش', 'و', 'ن', '<b>', 'ب', 'د', 'و', 'ن', 'م']\n",
            "PRED 4: parviz ke u raa saaket did goft kheyli eydi ke baayad daaiam\n",
            "PRED SCORE: -0.6720\n",
            "\n",
            "SENT 5: ['م', 'م', 'ک', 'ن', 'ه', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ب', 'ا', '<b>', 'م', 'ر', 'د', 'ی', '<b>', 'م', 'ث', 'ل', '<b>', 'م', 'ن', '<b>', 'چ', 'ن', 'د', 'ا', 'ن', '<b>', 'س', 'ا', 'د', 'ه', '<b>', 'ن', 'ب', 'ا', 'ش', 'ه', '<b>', 'ک', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 5: momkene zendegi baa mordan mesl e man nakardi ke fekr mikoni ke fekr mikoni\n",
            "PRED SCORE: -2.4741\n",
            "\n",
            "SENT 6: ['ر', 'ا', 'س', 'ت', 'ش', '<b>', 'ر', 'و', '<b>', 'ب', 'خ', 'و', 'ا', 'ی', '<b>', 'د', 'ف', 'ع', 'ه', '\\u200c', 'ی', '<b>', 'ق', 'ب', 'ل', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', 'م', '<b>', 'ب', 'ه', 'ت', '<b>', 'ب', 'گ', 'م', '<b>', 'ا', 'م', 'ا', '<b>', 'ف', 'ر', 'ص', 'ت', 'ش', '<b>', 'پ', 'ی', 'ش', '<b>', 'ن', 'ی', 'و', 'م', 'د']\n",
            "PRED 6: raastesh ro bekhaay da vaa mikonam mikhaast behet farrokhzaad ammaa farrokhzaad\n",
            "PRED SCORE: -1.5057\n",
            "\n",
            "SENT 7: ['ا', 'ح', 'ت', 'م', 'ا', 'ل', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'م', 'ن', 'و', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'م', 'ا', 'م', 'و', 'ر', 'ی', 'ت', '<b>', 'م', 'د', 'ت', 'ی', '<b>', 'ب', 'ف', 'ر', 'س', 'ت', 'ن', '<b>', 'ج', 'ن', 'و', 'ب', '<b>', 'و', '<b>', 'ا', 'گ', 'ه', '<b>', 'م', 'ا', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ا', 'ز', 'د', 'و', 'ا', 'ج', '<b>', 'ک', 'ن', 'ی', 'م', '<b>', 'م', 'ج', 'ب', 'و', 'ر', 'ی', '<b>', 'ب', 'ا', 'ه', 'ا', 'م', '<b>', 'ب', 'ی', 'ا', 'ی', '<b>', 'چ', 'و', 'ن', '<b>', 'ز', 'م', 'ا', 'ن', 'ش', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 7: haalish daare mano baraaye bimaarestaan e moddati dahande o sard konid\n",
            "PRED SCORE: -3.6226\n",
            "\n",
            "SENT 8: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ق', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ه', 'م', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'ا', 'ش', 'ی', 'م', '<b>', 'ج', 'ا', 'ش', '<b>', 'چ', 'ه', '<b>', 'ا', 'ه', 'م', 'ی', 'ت', 'ی', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 8: foruq baa sedaaqat goft mohemm ine ke baa ham saadeq daare\n",
            "PRED SCORE: -1.1913\n",
            "\n",
            "SENT 9: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ن', 'ی', 'م', 'ر', 'خ', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'ا', 'و', '<b>', 'خ', 'ی', 'ز', 'ه', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ش', 'ک', '<b>', 'ن', 'د', 'ا', 'ر', 'م', '<b>', 'ک', 'ه', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ک', 'ا', 'ر', '<b>', 'د', 'ر', 'س', 'ت', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 9: parviz be narmi aaraam u khire shod va baa khoshhaali goft haalaa daaram\n",
            "PRED SCORE: -2.0360\n",
            "\n",
            "SENT 10: ['ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', 'د', 'ا', 'ز', 'ه', '\\u200c', 'ی', '<b>', 'ص', 'ب', 'ح', '<b>', 'پ', 'ر', 'ی', 'ش', 'ا', 'ن', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 10: foruq ham be andaaze ye sakht ye parviz nashod\n",
            "PRED SCORE: -0.6780\n",
            "\n",
            "SENT 11: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ت', 'ا', '<b>', 'گ', 'ر', 'ف', 'ت', 'ن', '<b>', 'ر', 'ض', 'ا', 'ی', 'ت', '<b>', 'پ', 'د', 'ر', 'ت', '<b>', 'ب', 'ر', 'ا', 'م', '<b>', 'ص', 'ب', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 11: parviz istaad va bi moqaddame porsid taa charandiyaat raahat mikoni baraam\n",
            "PRED SCORE: -3.2047\n",
            "\n",
            "SENT 12: ['م', 'م', 'ک', 'ن', 'ه', '<b>', 'ط', 'و', 'ل', '<b>', 'ب', 'ک', 'ش', 'ه']\n",
            "PRED 12: momkene khosh beshe\n",
            "PRED SCORE: -0.0635\n",
            "\n",
            "SENT 13: ['ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د']\n",
            "PRED 13: foruq ham istaad\n",
            "PRED SCORE: -0.0007\n",
            "\n",
            "SENT 14: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'م', 'ن', '<b>', 'د', 'و', 'س', 'ت', 'ت', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'و', '<b>', 'ت', 'و', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', '<b>', 'ک', 'م', 'ک', '<b>', 'ک', 'ن', 'ی', '<b>', 'ت', 'ا', '<b>', 'ز', 'و', 'د', 'ت', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'ر', 'و', '<b>', 'ب', 'ر', 'د', 'ا', 'ر', 'م']\n",
            "PRED 14: parviz zemzeme kard man dust daaram foruq ham dustet koni\n",
            "PRED SCORE: -1.8954\n",
            "\n",
            "SENT 15: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ی', '<b>', 'ا', 'خ', 'ت', 'ی', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ب', 'ا', '<b>', 'ت', 'و', 'ا', 'م', '<b>', 'پ', 'ر', 'و', 'ی', 'ز']\n",
            "PRED 15: foruq bi aanke goft man baa to parviz\n",
            "PRED SCORE: -1.2178\n",
            "\n",
            "SENT 16: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ز', 'م', 'ا', 'ن', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ه', 'ر', '<b>', 'د', 'و', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'م', 'ت', 'و', 'ق', 'ف', '<b>', 'ش', 'د', 'ه', '<b>', 'و', '<b>', 'د', 'ن', 'ی', 'ا', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'ز', 'ر', 'گ', 'ی', '\\u200c', 'ا', 'ش', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ه', 'ر', '<b>', 'ی', 'ک', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ق', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'خ', 'ل', 'ا', 'ص', 'ه', '\\u200c', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', '.', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'ه', 'ن', 'ر', 'س', 'ت', 'ا', 'ن', '<b>', 'ک', 'ت', 'ا', 'ب', '<b>', 'س', 'ه', 'ر', 'ا', 'ب', '<b>', 'ر', 'ا', '<b>', 'پ', 'س', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ت', 'ش', 'ک', 'ر', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 16: engaar zamaan baraaye har vaqt aanhaa barkhord va arusit e fard baraaye yek hame ye qadd e zanhaand\n",
            "PRED SCORE: -3.6052\n",
            "\n",
            "SENT 17: ['س', 'ه', 'ر', 'ا', 'ب', '<b>', 'د', 'ر', 'و', 'ن', '<b>', 'ه', 'م', 'ه', '<b>', 'گ', 'ر', 'ف', 'ت', 'ن', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ه', '<b>', 'ع', 'ج', 'ل', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 17: sohraab dowr e hamechiz goft che kalame bud\n",
            "PRED SCORE: -2.6456\n",
            "\n",
            "SENT 18: ['ف', 'ر', 'و', 'غ', '<b>', 'ک', 'ه', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ب', 'ه', '\\u200c', 'و', 'ا', 'س', 'ط', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'ر', 'خ', 'و', 'ر', 'د', '<b>', 'ص', 'ب', 'ح', 'ش', '<b>', 'ب', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ی', 'ج', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'س', 'ا', 'خ', 'ت', 'گ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'م', 'ن', 'و', 'ن', 'م', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ل', 'ا', 'ز', 'م', 'ش', '<b>', 'ن', 'د', 'ا', 'ر', 'م']\n",
            "PRED 18: foruq ke hanuz be jaa ye koloftet salaam goft mamnunam laaaqal shabhaa e dige\n",
            "PRED SCORE: -2.9154\n",
            "\n",
            "SENT 19: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'ب', 'ا', '<b>', 'ک', 'ن', 'ج', 'ک', 'ا', 'و', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ت', 'ه', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 19: faride baa konjkaavi goft chete foruq\n",
            "PRED SCORE: -0.5644\n",
            "\n",
            "SENT 20: ['م', 'ع', 'ل', 'و', 'م', '<b>', 'ه', 'س', 'ت']\n",
            "PRED 20: ma r hast\n",
            "PRED SCORE: -0.0805\n",
            "\n",
            "SENT 21: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'خ', 'ن', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ز', 'و', 'ر', 'ک', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'چ', 'ط', 'و', 'ر', 'ی', '\\u200c', 'ا', 'م']\n",
            "PRED 21: foruq baa khunsardi e kudakaanei goft mage chetowri\n",
            "PRED SCORE: -2.1334\n",
            "\n",
            "SENT 22: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ز', '<b>', 'ص', 'ب', 'ح', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'م', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'ن', 'ز', 'د', 'ی']\n",
            "PRED 22: faride goft az sobh yek majmue harf e harf e aadame\n",
            "PRED SCORE: -1.5784\n",
            "\n",
            "SENT 23: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ت', 'ا', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'ت', 'ل', 'ا', 'ف', 'ی', 'ش', '<b>', 'د', 'ر', '<b>', 'ب', 'ی', 'ا', 'د']\n",
            "PRED 23: foruq be shukhi goft haalaa taa khune harfhaa ye harf mikonam ke mibinand\n",
            "PRED SCORE: -1.8121\n",
            "\n",
            "SENT 24: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ز', '<b>', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'چ', 'ت', 'ه']\n",
            "PRED 24: faride goft az shohrat gozashte chete\n",
            "PRED SCORE: -0.9157\n",
            "\n",
            "SENT 25: ['چ', 'ه', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', 'ی', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', 'ه']\n",
            "PRED 25: che ettefaaqi oftaade\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 26: ['ا', 'خ', 'ه', '<b>', 'ت', 'و', '<b>', 'و', '<b>', 'س', 'ک', 'و', 'ت']\n",
            "PRED 26: aakhe to o lajbaaze\n",
            "PRED SCORE: -1.2188\n",
            "\n",
            "SENT 27: ['ی', 'ک', '\\u200c', 'ک', 'م', '<b>', 'ع', 'ج', 'ی', 'ب', '<b>', 'و', '<b>', 'غ', 'ر', 'ی', 'ب', 'ه']\n",
            "PRED 27: yek daqiqe o tajrobe\n",
            "PRED SCORE: -2.9839\n",
            "\n",
            "SENT 28: ['ت', 'و', '<b>', 'ک', 'س', 'ی', '<b>', 'ن', 'ب', 'و', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'ی', 'ک', '<b>', 'ج', 'ا', '<b>', 'ب', 'ن', 'د', '<b>', 'ب', 'ش', 'ی', '<b>', 'ا', 'م', 'ا', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'س', 'ر', 'ت', '<b>', 'ب', 'ه', '<b>', 'ل', 'ا', 'ک', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ب', 'و', 'د']\n",
            "PRED 28: to kasi nabudi ke yek jaa band beshi ammaa emruz khodet be aqab e khodet\n",
            "PRED SCORE: -1.6541\n",
            "\n",
            "SENT 29: ['س', 'ه', 'ر', 'ا', 'ب', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', 'م', '<b>', 'ب', 'ع', 'ض', 'ی', '<b>', 'و', 'ق', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ت', 'و', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ب', 'ا', 'ش', 'م']\n",
            "PRED 29: sohraab goft manam be doaahaa ye dust daaram to khodam baasham\n",
            "PRED SCORE: -1.9188\n",
            "\n",
            "SENT 30: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'ر', '<b>', 'ب', 'ه', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ع', 'ض', 'ی', '<b>', 'و', 'ق', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'د', 'و', 'س', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'س', 'ا', 'ع', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ا', 'ش', 'م', '<b>', 'و', '<b>', 'ف', 'ک', 'ر', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 30: foruq dar ta yidash goft bahs e sakhti baa fekr e tanhaa baasham o fekr konam o\n",
            "PRED SCORE: -1.8637\n",
            "\n",
            "SENT 31: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'ب', 'ا', '<b>', 'ک', 'ن', 'ج', 'ک', 'ا', 'و', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ب', 'ه', '<b>', 'چ', 'ی']\n",
            "PRED 31: faride baa konjkaavi porsid be chi\n",
            "PRED SCORE: -0.0169\n",
            "\n",
            "SENT 32: ['ف', 'ر', 'و', 'غ', '<b>', 'خ', 'ن', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی']\n",
            "PRED 32: foruq khandid va goft be hame chi\n",
            "PRED SCORE: -0.1247\n",
            "\n",
            "SENT 33: ['ا', 'و', 'ن', 'و', 'ق', 'ت', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', 'م', '<b>', 'ر', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'د', 'ا', 'د', '<b>', 'ب', 'ز', 'ن', 'م']\n",
            "PRED 33: unvaqt qablan mikonam dust daaram esteraahat ro baa sedaa ye boland bezanam\n",
            "PRED SCORE: -2.3381\n",
            "\n",
            "SENT 34: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ف', 'ق', 'ط', '<b>', 'ا', 'و', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ا', 'ر', 'و', 'م', '<b>', 'م', 'ی', 'ش', 'م']\n",
            "PRED 34: engaar faqat unjaa aarum mifahmam\n",
            "PRED SCORE: -0.1922\n",
            "\n",
            "SENT 35: ['ب', 'ع', 'د', '<b>', 'خ', 'ن', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'ی', '<b>', 'د', 'ل', 'ی', 'ل', '<b>', 'و', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ه', 'ی', 'ج', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'م', '<b>', 'ک', 'ه', '<b>', 'د', 'ل', 'م', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 35: ba d zendegi e bi dalil o badesh dard o baa qalati mikhaad ke delam mikhaast\n",
            "PRED SCORE: -1.0926\n",
            "\n",
            "SENT 36: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'و', 'س', 'ه', 'ر', 'ا', 'ب', '<b>', 'خ', 'ن', 'د', 'ی', 'د', 'ن', 'د', '<b>', 'ف', 'ر', 'ی', 'د', 'ه', '<b>', 'ب', 'ا', '<b>', 'ت', 'ع', 'ج', 'ب', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ح', 'ا', 'ل', 'ت', '<b>', 'خ', 'و', 'ب', 'ه']\n",
            "PRED 36: faride sohraab khandid baa taajjob goft to taajjob khube\n",
            "PRED SCORE: -1.6260\n",
            "\n",
            "SENT 37: ['ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ی', 'ا', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 37: bel akhare mikhaay be soaalam jaa koni\n",
            "PRED SCORE: -1.2142\n",
            "\n",
            "SENT 38: ['س', 'ه', 'ر', 'ا', 'ب', '<b>', 'ف', 'ی', 'ل', 'س', 'و', 'ف', 'ا', 'ن', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ن', 'د', 'ه', '<b>', 'ب', 'ر', '<b>', 'ه', 'ر', '<b>', 'د', 'ر', 'د', '<b>', 'ب', 'ی', '<b>', 'د', 'ر', 'م', 'ا', 'ن', '<b>', 'د', 'و', 'ا', 'س', 'ت']\n",
            "PRED 38: sohraab naakhodaagaah goft zende bar har dard bi nagoft\n",
            "PRED SCORE: -2.2043\n",
            "\n",
            "SENT 39: ['ف', 'ر', 'و', 'غ', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'س', 'ر', 'د', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ر', 'ی', 'ه', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'ی', 'د', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ی', 'ن', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ک', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', 'س', 'ا', 'ن', '<b>', 'د', 'ا', 'د', 'ه', '<b>', 'ق', 'د', 'ر', 'ت', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', 'ه']\n",
            "PRED 39: foruq havaa ye sarash raa be raah keshidi daaneste ke khodaa niaaz daashte ke khodaa\n",
            "PRED SCORE: -3.3633\n",
            "\n",
            "SENT 40: ['و', 'ا', 'ق', 'ع', 'ا', '<b>', 'ا', 'گ', 'ه', '<b>', 'ا', 'د', 'م', '\\u200c', 'ه', 'ا', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'س', 'ت', 'ن', 'د', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', 'ه', '<b>', 'ب', 'ا', 'ش', 'ن', 'د', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 40: vaaqean age aadamhaa ye hamshahri dust baashe chi mishod\n",
            "PRED SCORE: -0.6516\n",
            "\n",
            "SENT 41: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', '<b>', 'م', 'ن', '<b>', 'ا', 'و', 'ن', 'و', 'ق', 'ت', '<b>', 'ق', 'ل', 'ب', '\\u200c', 'ه', 'ا', '<b>', 'م', 'ث', 'ل', '<b>', 'ی', 'ک', '<b>', 'ت', 'ی', 'ک', 'ه', '<b>', 'ی', 'خ', '<b>', 'س', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ی', '<b>', 'ر', 'و', 'ح', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 41: be nazar e man tafaavot e senni mesl e yek tikke va bi ruz mishod\n",
            "PRED SCORE: -1.4826\n",
            "\n",
            "SENT 42: ['م', 'ی', '<b>', 'د', 'و', 'ن', 'ی', 'د', '<b>', 'م', 'ن', '<b>', 'م', 'ا', 'ی', 'و', 'س', '<b>', 'و', '<b>', 'ن', 'ا', '<b>', 'ا', 'م', 'ی', 'د', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'د', 'ا', 'ش', 'ت', 'م', '<b>', 'ا', 'ز', '<b>', 'ش', 'د', 'ت', '<b>', 'غ', 'ص', 'ه', '<b>', 'م', 'ی', '\\u200c', 'م', 'ر', 'د', 'م', '<b>', 'و', 'ل', 'ی', '<b>', 'ی', 'ک', 'ه', 'و', '<b>', 'ی', 'ک', '<b>', 'د', 'ر', '<b>', 'ب', 'ا', 'ز', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'ر', 'ن', 'گ', '<b>', 'د', 'ی', 'گ', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 42: miduni man mige va na emruz az sheddat shod yek hamun zowq miraftam\n",
            "PRED SCORE: -4.1800\n",
            "\n",
            "SENT 43: ['م', 'ن', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'خ', 'د', 'ا', 'و', 'ن', 'د', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'م', 'ه', 'ر', 'ب', 'و', 'ن', '<b>', 'و', '<b>', 'ب', 'ز', 'ر', 'گ', 'ه', '<b>', 'و', '<b>', 'د', 'ل', '<b>', 'م', 'ن', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ج', 'ا', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'ر', 'و', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', 'ه', '<b>', 'ب', 'ا', 'ش', 'م', '<b>', 'ح', 'ت', 'ی', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', 'ی', 'ی', '<b>', 'ر', 'و', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'م']\n",
            "PRED 43: man fekr mikonam khaale kheyli bozorg o hanuze dorost baasham aaqaa chi baasham\n",
            "PRED SCORE: -2.1232\n",
            "\n",
            "SENT 44: ['ف', 'ر', 'ی', 'د', 'ه', '<b>', 'و', '<b>', 'س', 'ه', 'ر', 'ا', 'ب', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', 'ن', 'د']\n",
            "PRED 44: faride va sohraab moteajjeb be ham negaah kard\n",
            "PRED SCORE: -0.0021\n",
            "\n",
            "SENT 45: ['و', 'ل', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'د', 'ر', '<b>', 'ع', 'ا', 'ل', 'م', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'چ', 'ن', 'ا', 'ن', '<b>', 'م', 'ت', 'ف', 'ک', 'ر', '<b>', 'ب', 'ه', '<b>', 'د', 'و', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'گ', 'و', 'ی', 'ی', '<b>', 'ا', 'ن', 'ط', 'ر', 'ف', '<b>', 'ک', 'و', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ش', 'ت']\n",
            "PRED 45: vali foruq dar e jaa ye digari boland shode va chenaan yakh shode bud ke mobaarak be dur konad\n",
            "PRED SCORE: -5.0367\n",
            "\n",
            "SENT 46: ['ب', 'ه', 'ا', 'ر', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', 'ه', '<b>', 'ز', 'ی', 'ب', 'ا', 'ی', 'ی', '<b>', 'و', '<b>', 'ل', 'ط', 'ا', 'ف', 'ت', 'ش', '<b>', 'د', 'ر', '<b>', 'ر', 'ا', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'د', 'ر', 'ن', 'د', 'ش', 'ت', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ح', 'ا', 'ل', '<b>', 'و', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '\\u200c', 'خ', 'ص', 'و', 'ص', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'س', 'ت', 'ق', 'ب', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'ع', 'ی', 'د', '<b>', 'ح', 'ا', 'ک', 'م', '<b>', 'ب', 'و', 'د']\n",
            "PRED 46: behtar baa hame ye sharaayeti o shekaste dar raah e nozul va hamaanjaa istaad\n",
            "PRED SCORE: -3.2715\n",
            "\n",
            "SENT 47: ['ا', 'ن', '<b>', 'ر', 'و', 'ز', 'ه', 'ا', '<b>', 'ح', 'ت', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'ح', 'ا', 'ل', '<b>', 'و', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'چ', 'ش', 'م', 'ش', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'ن', '<b>', 'ه', 'م', 'ه', '<b>', 'ز', 'ی', 'ب', 'ا', 'ی', 'ی', '<b>', 'ب', 'ا', 'ز', '<b>', 'ش', 'د', 'ه', '<b>', 'و', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', 'ی', 'ی', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', '<b>', 'ا', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 47: aan ruzhaa hattaa foruq ham haal o havaa ye digari baalaa ye aanhaa baaz shode vaase nazar shode\n",
            "PRED SCORE: -2.1926\n",
            "\n",
            "SENT 48: ['گ', 'ا', 'ه', '<b>', 'م', 'د', 'ت', '<b>', 'د', 'ر', 'ا', 'ز', 'ی', '<b>', 'پ', 'ش', 'ت', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'م', 'ی', '\\u200c', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', 'ج', 'ا', '<b>', 'ب', 'ه', '<b>', 'ا', 'م', 'د', '<b>', 'و', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ت', 'ک', 'ا', 'پ', 'و', 'ی', '<b>', 'س', 'ا', 'ک', 'ن', 'ا', 'ن', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'و', '<b>', 'ش', 'و', 'ق', '<b>', 'و', '<b>', 'ه', 'ی', 'ا', 'ه', 'و', 'ی', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', '<b>', 'و', '<b>', 'ب', 'ر', 'ا', 'د', 'ر', 'ه', 'ا', 'ی', '<b>', 'ک', 'و', 'چ', 'ک', '\\u200c', 'ت', 'ر', 'ش', '<b>', 'چ', 'ش', 'م', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'خ', 'ت']\n",
            "PRED 48: negaah e moddat e kudaki posht e panjare ye khoshkide ro be hayaat aazaarash miraft\n",
            "PRED SCORE: -4.7369\n",
            "\n",
            "SENT 49: ['گ', 'ا', 'ه', 'ی', '<b>', 'ن', 'ا', 'ا', 'م', 'ی', 'د', '<b>', 'و', '<b>', 'غ', 'م', 'گ', 'ی', 'ن', '<b>', 'و', '<b>', 'گ', 'ا', 'ه', '<b>', 'ا', 'م', 'ی', 'د', 'و', 'ا', 'ر', '<b>', 'و', 'ش', 'ا', 'د', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', 'ی', '<b>', 'ز', 'ی', 'ب', 'ا', 'ی', '<b>', 'ا', 'ط', 'ر', 'ا', 'ف', 'ش', '<b>', 'ن', 'ش', 'ا', 'ن', 'ی', '<b>', 'ا', 'ز', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'ج', 'س', 'ت', 'ج', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 49: negaah e raadio o jaryaan o chaah soaal e aakharash o dar tamaam e takhtash az parviz raa bast\n",
            "PRED SCORE: -3.7005\n",
            "\n",
            "SENT 50: ['ی', 'ا', 'د', 'ا', 'و', 'ر', 'ی', '<b>', 'ا', 'و', '<b>', 'م', 'و', 'ج', '<b>', 'د', 'ا', 'غ', 'ی', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'و', 'ج', 'و', 'د', 'ش', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ا', 'ن', 'د', '<b>', 'و', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', '<b>', 'د', 'ل', 'چ', 'س', 'ب', 'ی', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'ب', 'ه', '<b>', 'ت', 'ص', 'و', 'ی', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 50: akhiran u mano taa vaz raa dar e vojudash raa dar nazar mirikht\n",
            "PRED SCORE: -4.2639\n",
            "\n",
            "SENT 51: ['خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'پ', 'ش', 'ت', '<b>', 'ب', 'ه', '<b>', 'پ', 'ش', 'ت', '<b>', 'ه', 'م', '<b>', 'ق', 'ر', 'ا', 'ر', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ه', 'ی', 'چ', '<b>', 'و', 'ج', 'ه', '<b>', 'د', 'ی', 'د', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'ا', 'م', 'ا', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ا', 'ه', 'ی', '<b>', 'د', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'چ', 'ش', 'م', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ب', 'ه', '<b>', 'پ', 'ش', 'ت', '<b>', 'ب', 'ا', 'م', '<b>', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'ل', 'ح', 'ظ', 'ا', 'ت', 'ی', '<b>', 'ط', 'و', 'ل', 'ا', 'ن', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'ب', 'ه', '<b>', 'ت', 'م', 'ا', 'ش', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 51: khaane aanhaa posht be posht e ham qaraar az aan faraar be hesaab miaayad\n",
            "PRED SCORE: -2.8887\n",
            "\n",
            "SENT 52: ['ا', 'ی', 'ن', 'ک', 'ا', 'ر', '<b>', 'ب', 'ه', '<b>', 'ا', 'و', '<b>', 'ا', 'ر', 'ا', 'م', 'ش', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ا', 'ع', 'ث', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ف', 'ک', 'ر', '<b>', 'ک', 'ن', 'د', '<b>', 'ب', 'ن', 'و', 'ع', 'ی', '<b>', 'د', 'ر', '<b>', 'ک', 'م', '<b>', 'ک', 'ر', 'د', 'ن', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'م', 'و', 'ث', 'ر', '<b>', 'ب', 'و', 'د', 'ه', '<b>', 'ا', 'س', 'ت']\n",
            "PRED 52: in be u aaraamesh mikard va baaes mizad fekr konad pedar jaan\n",
            "PRED SCORE: -3.2319\n",
            "\n",
            "SENT 53: ['ل', 'ح', 'ظ', 'ا', 'ت', '<b>', 'ن', 'ف', 'س', '<b>', 'گ', 'ی', 'ر', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 53: lahazaat e nafasgiri bud\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 54: ['ا', 'و', '<b>', 'چ', 'ن', 'ا', 'ن', '<b>', 'ع', 'ا', 'ش', 'ق', 'ا', 'ن', 'ه', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', '<b>', 'و', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'س', 'ا', 'خ', 'ت', 'م', 'ا', 'ن', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'و', '<b>', 'ا', 'ط', 'ر', 'ا', 'ف', 'ش', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'گ', 'و', 'ی', 'ی', '<b>', 'ت', 'ص', 'و', 'ی', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ر', '<b>', 'ت', 'ک', '<b>', 'ت', 'ک', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ن', 'ق', 'ش', '<b>', 'ب', 'س', 'ت', 'ه', '<b>', 'ا', 'س', 'ت']\n",
            "PRED 54: u chenaan kaafie be dar o hamsaaye e hayaat e parviz dar baraabarash negaah mikard ke ashkash delesho mikard\n",
            "PRED SCORE: -4.1555\n",
            "\n",
            "SENT 55: ['ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'گ', 'ل', 'ا', 'ی', 'ه', '\\u200c', 'ه', 'ا', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'گ', 'و', 'ش', 'ه', '<b>', 'و', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ط', 'ر', 'ی', 'ق', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'و', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', 'ز', 'گ', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'ن', 'د', '<b>', 'ب', 'ه', '<b>', 'گ', 'و', 'ش', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', '\\u200c', 'ر', 'س', 'ی', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'و', '<b>', 'ه', 'م', '<b>', 'چ', 'ن', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ل', 'خ', 'و', 'ش', '<b>', 'ب', 'و', 'د']\n",
            "PRED 55: albatte qeychi az gush o saal o az qaribi be zehnash por masaaebash mikardand\n",
            "PRED SCORE: -2.4929\n",
            "\n",
            "SENT 56: ['ه', 'ر', '<b>', 'ب', 'ا', 'ر', '<b>', 'ک', 'س', 'ی', '<b>', 'پ', 'ی', 'غ', 'ا', 'م', '<b>', 'ی', 'ا', '<b>', 'گ', 'ل', 'ا', 'ی', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ا', 'ز', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ا', 'و', 'ر', 'د', '<b>', 'ق', 'ل', 'ب', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'غ', 'م', '<b>', 'و', '<b>', 'غ', 'ص', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ز', 'و', 'د', '<b>', 'ب', 'ا', '<b>', 'ب', 'ه', '<b>', 'ی', 'ا', 'د', 'ا', 'و', 'ر', 'د', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'م', 'ی', 'د', '<b>', 'ج', 'ا', 'ی', '<b>', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ف', 'ر', 'ا', 'م', 'و', 'ش', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 56: har baar e kasi faryaadhaa az chehre az shamsi sheddat khord va zabaanash parviz movaajeh mishod\n",
            "PRED SCORE: -5.3345\n",
            "\n",
            "SENT 57: ['ح', 'ا', 'ل', 'ا', '<b>', 'د', 'و', '<b>', 'ه', 'ف', 'ت', 'ه', '<b>', 'ا', 'ز', '<b>', 'ا', 'خ', 'ر', 'ی', 'ن', '<b>', 'د', 'ی', 'د', 'ا', 'ر', 'ش', 'ا', 'ن', '<b>', 'د', 'ر', '<b>', 'خ', 'ی', 'ا', 'ب', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ش', 'ت', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ش', 'د', 'ت', '<b>', 'ب', 'ی', '<b>', 'ت', 'ا', 'ب', '<b>', 'ب', 'و', 'د']\n",
            "PRED 57: haalaa do se az aakharin shaayeaat dar aan e zohr be sheddat miresid\n",
            "PRED SCORE: -3.7255\n",
            "\n",
            "SENT 58: ['ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ع', 'ض', 'ا', 'ی', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'د', 'ر', '<b>', 'ا', 'س', 'ت', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ا', 'ل', '<b>', 'ج', 'د', 'ی', 'د', '<b>', 'م', 'غ', 'م', 'و', 'م', '<b>', 'و', '<b>', 'م', 'ت', 'ف', 'ک', 'ر', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', '<b>', 'م', 'ه', 'م', 'ت', 'ر', 'ی', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 58: hame ye asli e khaanevaade az safar amir dar taariki e saal jaalebi daasht\n",
            "PRED SCORE: -2.7551\n",
            "\n",
            "SENT 59: ['ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'ع', 'ل', 'ی', '<b>', 'ر', 'غ', 'م', '<b>', 'ب', 'د', 'ر', 'ف', 'ت', 'ا', 'ر', 'ی', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ج', 'د', 'ا', 'ی', 'ی', '<b>', 'م', 'ت', 'ا', 'س', 'ف', '<b>', 'ب', 'و', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ا', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ی', 'ا', '<b>', 'م', 'ث', 'ل', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'د', 'ق', 'ی', 'ق', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'ج', 'ا', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'خ', 'ا', 'ل', 'ی', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 59: albatte qalbam mowqe e bardaashtanash amir amir az in jaai raa az khodash dur nemikard\n",
            "PRED SCORE: -2.7982\n",
            "\n",
            "SENT 60: ['ا', 'ز', '<b>', 'ک', 'م', 'ی', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ص', 'ب', 'ح', '<b>', 'ا', 'ق', 'و', 'ا', 'م', '<b>', 'ن', 'ز', 'د', 'ی', 'ک', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ک', 'م', 'ک', '<b>', 'و', '<b>', 'ش', 'ر', 'ک', 'ت', '<b>', 'د', 'ر', '<b>', 'م', 'ه', 'م', 'ا', 'ن', 'ی', '\\u200c', 'ا', 'ش', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د', 'ن', 'د']\n",
            "PRED 60: az kami paride az sobh sepaasgozaaram baraaye kaarash be khaanast ye sarzaneshash miaamad\n",
            "PRED SCORE: -4.2952\n",
            "\n",
            "SENT 61: ['د', 'ی', 'گ', '<b>', 'ب', 'ز', 'ر', 'گ', 'ی', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'ت', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ج', 'و', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ه', 'ر', '<b>', 'س', 'و', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'س', 'ر', '<b>', 'س', 'ل', 'ا', 'م', 'ت', 'ی', '<b>', 'و', '<b>', 'ج', 'ا', '<b>', 'خ', 'ا', 'ل', 'ی', '<b>', 'ن', 'ب', 'ا', 'ش', '<b>', 'و', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'و', '<b>', 'پ', 'ر', 'ی', 'ش', 'ا', 'ن', '<b>', 'و', '<b>', 'س', 'پ', 'ا', 'س', 'گ', 'ز', 'ا', 'ر', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'ر', '<b>', 'ج', 'و', 'ا', 'ب', 'ش', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'گ', 'و', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ر', 'س', 'ی', 'د']\n",
            "PRED 61: dige bozorgvaar kenaar e divaar e hayaat ru ye haal be zanesh lengderaazi mibast\n",
            "PRED SCORE: -4.1689\n",
            "\n",
            "SENT 62: ['ا', 'و', '<b>', 'ک', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ش', 'و', 'ه', 'ر', 'ش', '<b>', 'ح', 'س', 'ا', 'ب', '<b>', 'خ', 'ا', 'ص', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ن', 'و', 'ا', 'ن', '<b>', 'م', 'ر', 'د', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ب', 'ا', 'ز', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'چ', 'ن', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'د', 'و', 'ر', 'ی', '<b>', 'ا', 'و', '<b>', 'م', 'غ', 'م', 'و', 'م', '<b>', 'و', '<b>', 'گ', 'ی', 'ج', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ه', 'ر', '<b>', 'ک', 'س', '<b>', 'ی', 'ا', 'د', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ا', 'ت', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 62: u ke ba d az zohr qablan delgir karde bud ke har gomaan oq karde bud\n",
            "PRED SCORE: -2.1771\n",
            "\n",
            "SENT 63: ['ب', 'ع', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'د', 'س', 'ت', 'خ', 'و', 'ش', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 63: ba dan hattaa khodesh ham atraafam ehsaas e qaribi mishod\n",
            "PRED SCORE: -0.9722\n",
            "\n",
            "SENT 64: ['گ', 'و', 'ی', 'ی', '<b>', 'ا', 'ر', 'ز', 'و', 'ی', '<b>', 'ا', 'ز', 'د', 'و', 'ا', 'ج', '<b>', 'ب', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ن', 'و', 'ع', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ح', 'ک', 'م', '<b>', 'ر', 'و', 'ی', 'ا', 'ی', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'ن', 'ی', 'ا', 'ف', 'ت', 'ن', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ه', '<b>', 'خ', 'ص', 'و', 'ص', '<b>', 'ک', 'ه', '<b>', 'پ', 'ا', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'ظ', 'ه', 'ر', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'و', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ا', 'ز', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'خ', 'ب', 'ر', 'ی', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 64: gui qalbam haasel e ashk e parviz baraaye shamsi tashakkor daasht va hanuz az darun khaarej daasht\n",
            "PRED SCORE: -4.4890\n",
            "\n",
            "SENT 65: ['ه', 'ر', '<b>', 'ب', 'ا', 'ر', '<b>', 'ز', 'ن', 'گ', '<b>', 'د', 'ر', '<b>', 'ب', 'ه', 'ب', 'ه', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ق', 'ل', 'ب', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ه', 'ی', 'ج', 'ا', 'ن', '<b>', 'م', 'ل', 'م', 'و', 'س', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ی', 'د', '<b>', 'و', '<b>', 'ت', 'ق', 'ر', 'ی', 'ب', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ب', 'ا', 'ز', '<b>', 'ک', 'ر', 'د', 'ن', 'ش', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ا', 'ز', '<b>', 'د', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د', '<b>', 'ن', 'ه', '<b>', 'چ', 'ش', 'م', 'ش', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ا', 'ط', 'ر', 'ا', 'ف', '<b>', 'ب', 'و', 'د', '<b>', 'ن', 'ه', '<b>', 'گ', 'و', 'ش', 'ش', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 65: har baar e digar dar be bahaane ye boland boland mishod va aaftaab barandaazash mifahmid\n",
            "PRED SCORE: -3.9713\n",
            "\n",
            "SENT 66: ['ا', 'م', 'ا', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ح', 'و', 'ا', 'ل', 'ی', '<b>', 'س', 'ا', 'ع', 'ت', '<b>', '3', '<b>', 'ب', 'ع', 'د', 'ا', 'ز', 'ظ', 'ه', 'ر', '<b>', 'و', 'ق', 'ت', 'ی', '\\u200c', 'ک', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'ش', 'د', 'ت', '<b>', 'غ', 'ص', 'ه', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', 'ش', '<b>', 'ب', 'ه', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'ر', 'ا', 'ه', '<b>', 'ر', 'س', 'ی', 'د']\n",
            "PRED 66: ammaa bel akhare tanbal o ba d raa ba d be sheddat aavordam bud shamsi tarkeshaan bud\n",
            "PRED SCORE: -3.2230\n",
            "\n",
            "SENT 67: ['ر', 'ف', 'ت', 'ا', 'ر', 'ش', '<b>', 'ب', 'ا', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'ا', 'س', 'ت', 'ق', 'ب', 'ا', 'ل', 'ش', '<b>', 'ر', 'ف', 'ت', '<b>', 'ب', 'ه', '<b>', 'گ', 'ر', 'م', 'ی', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ه', '<b>', 'ظ', 'ا', 'ه', 'ر', '<b>', 'خ', 'و', 'د', 'د', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ن', 'م', 'و', 'د']\n",
            "PRED 67: raftaarash baa turaan ke be haal e raft be cheshmaan e gozashte milarzid\n",
            "PRED SCORE: -4.0296\n",
            "\n",
            "SENT 68: ['ف', 'ر', 'و', 'غ', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ت', 'ا', 'ق', 'ش', '<b>', 'د', 'ی', 'د', '<b>', 'ا', 'ز', '<b>', 'ف', 'ر', 'ط', '<b>', 'ش', 'و', 'ق', '<b>', 'ب', 'ه', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ا', 'ر', 'ه', 'ا', '<b>', 'خ', 'د', 'ا', '<b>', 'ر', 'ا', '<b>', 'ش', 'ک', 'ر', '<b>', 'گ', 'ف', 'ت']\n",
            "PRED 68: foruq vaqti u raa az posht e parde ye biaabaan raa she r khodaa az foruqe oftaad\n",
            "PRED SCORE: -2.4602\n",
            "\n",
            "SENT 69: ['ا', 'ش', 'ک', 'ش', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ب', 'ی', '\\u200c', 'و', 'ق', 'ف', 'ه', '<b>', 'ف', 'ر', 'و', 'م', 'ی', '\\u200c', 'چ', 'ک', 'ی', 'د', '<b>', 'و', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'غ', 'ر', 'ق', '<b>', 'ا', 'ش', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 69: quzposht hamaantowr bud o cheshmaanash baaz ham qarib ashk\n",
            "PRED SCORE: -1.8485\n",
            "\n",
            "SENT 70: ['ت', 'ل', 'ا', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'د', 'س', 'ت', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 70: qasdash kard aaraam baashad ammaa dast e khodash nabud\n",
            "PRED SCORE: -0.8928\n",
            "\n",
            "SENT 71: ['ا', 'گ', 'ر', '<b>', 'ک', 'س', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', '<b>', 'ح', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'چ', 'ه', '<b>', 'ف', 'ک', 'ر', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 71: agar kasi u raa be aan haal mibandand che fekri mikard\n",
            "PRED SCORE: -0.5937\n",
            "\n",
            "SENT 72: ['ب', 'ه', '\\u200c', 'س', 'ر', 'ع', 'ت', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'ا', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ن', 'ف', 'س', 'ی', '<b>', 'ع', 'م', 'ی', 'ق', '<b>', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 72: be cheshmaanash cheshmaanash paak kard va nafas e amiqi keshid\n",
            "PRED SCORE: -0.7851\n",
            "\n",
            "SENT 73: ['ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'چ', 'ه', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ن', '<b>', 'ع', 'ز', 'ی', 'ز', 'ت', 'ر', 'ی', 'ن', '<b>', 'م', 'و', 'ج', 'و', 'د', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '\\u200c', 'ا', 'ش', '<b>', 'ت', 'ا', 'ر', '<b>', 'و', '<b>', 'پ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'د']\n",
            "PRED 73: baar e digar garmaa ye parviz ammaa be bandar e panjare ye jaalebetun o pedarash raa larzaand\n",
            "PRED SCORE: -4.9988\n",
            "\n",
            "SENT 74: ['م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 74: miaan e gerye labkhand zad\n",
            "PRED SCORE: -0.0165\n",
            "\n",
            "SENT 75: ['گ', 'و', 'ش', '<b>', 'ت', 'ی', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'گ', 'ف', 'ت', 'گ', 'و', 'ی', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ش', 'و', 'د']\n",
            "PRED 75: gushash haal kard motevajjeh e labash neshaand va shamsi kardand\n",
            "PRED SCORE: -1.4427\n",
            "\n",
            "SENT 76: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ض', 'م', 'ن', '<b>', 'ب', 'و', 'س', 'ی', 'د', 'ن', 'ش', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ه', '<b>', 'خ', 'و', 'ب', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', 'م', 'د', 'ی', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 76: turaan daasht kami tarez migoft che khub ke umadi khaale jun\n",
            "PRED SCORE: -2.3323\n",
            "\n",
            "SENT 77: ['ه', 'م', 'ی', 'ن', '<b>', 'ا', 'ل', 'ا', 'ن', '<b>', 'ذ', 'ک', 'ر', '<b>', 'خ', 'ی', 'ر', 'ت', '<b>', 'ب', 'و', 'د']\n",
            "PRED 77: havaa alaan jozv e faryaad bud\n",
            "PRED SCORE: -2.3125\n",
            "\n",
            "SENT 78: ['ش', 'م', 'س', 'ی', '<b>', 'پ', 'ش', 'ت', '<b>', 'چ', 'ش', 'م', '<b>', 'ن', 'ا', 'ز', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'س', 'ر', 'ش', '<b>', 'م', 'ن', 'ت', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت']\n",
            "PRED 78: shamsi posht e cheshm naazok kard va be sarash tekye shavad\n",
            "PRED SCORE: -1.7811\n",
            "\n",
            "SENT 79: ['ب', 'ب', 'ی', 'ن', '<b>', 'م', 'ن', '<b>', 'چ', 'ق', 'د', 'ر', '<b>', 'پ', 'و', 'س', 'ت', '<b>', 'ک', 'ل', 'ف', 'ت', 'م', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ز', 'م', '<b>', 'ا', 'و', 'م', 'د', 'م']\n",
            "PRED 79: bebin menba cheqadr ruzi zudtar ke baazam umadam\n",
            "PRED SCORE: -1.4261\n",
            "\n",
            "SENT 80: ['د', 'ل', 'م', '<b>', 'ط', 'ا', 'ق', 'ت', '<b>', 'ن', 'ی', 'ا', 'و', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', 'م', '<b>', 'ت', 'ف', '<b>', 'س', 'ر', 'ب', 'ا', 'ل', 'ا', 'س', 'ت']\n",
            "PRED 80: delam daasht migoft goftam kam negaraanid\n",
            "PRED SCORE: -3.0777\n",
            "\n",
            "SENT 81: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ق', 'د', 'م', 'ت', '<b>', 'ر', 'و', 'ی', '<b>', 'چ', 'ش', 'م']\n",
            "PRED 81: turaan baa sedaa ye larzaani goft haminkeshenidi\n",
            "PRED SCORE: -0.0689\n",
            "\n",
            "SENT 82: ['م', 'گ', 'ه', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'م', 'ن', '<b>', 'ک', 'ی', '<b>', 'ر', 'و', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'غ', 'ی', 'ر', 'ا', 'ز', 'ا', 'ی', 'ن', '<b>', 'چ', 'ن', 'د', '<b>', 'ت', 'ا', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'د', 'و', 'ر', '<b>', 'و', '<b>', 'ن', 'ز', 'د', 'ی', 'ک']\n",
            "PRED 82: mage amir man key daare qaribe chand faamil e dowr o nimqadd\n",
            "PRED SCORE: -2.2084\n",
            "\n",
            "SENT 83: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ک', 'ن', 'ا', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ا', 'ل', 'ا', '<b>', 'ه', 'ر', '<b>', 'ک', 'ی', '<b>', 'ج', 'ا', 'ی', '<b>', 'م', 'ن', '<b>', 'ب', 'و', 'د', '<b>', 'چ', 'ه', '<b>', 'ب', 'س', 'ا', '<b>', 'ب', 'ا', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'ا', 'و', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ش', 'و', 'ه', 'ر', 'ت', '<b>', 'ق', 'ی', 'د', '<b>', 'ا', 'ی', 'ن', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', 'ی', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د']\n",
            "PRED 83: shamsi baa kenaaye goft vaallaa har ki zaaid bud che harekat e un bud\n",
            "PRED SCORE: -1.6963\n",
            "\n",
            "SENT 84: ['ح', 'و', 'ا', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 84: qalb ke bud\n",
            "PRED SCORE: -0.9550\n",
            "\n",
            "SENT 85: ['د', 'س', 'ت', 'ی', '<b>', 'د', 'س', 'ت', 'ی', '<b>', 'ع', 'ذ', 'ر', '<b>', 'م', 'ا', '<b>', 'ر', 'و', '<b>', 'خ', 'و', 'ا', 'س', 'ت']\n",
            "PRED 85: kolli kelaas jelow e maa ro khaast\n",
            "PRED SCORE: -2.0751\n",
            "\n",
            "SENT 86: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ش', 'ر', 'م', 'ن', 'د', 'گ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'م', 'ن', '<b>', 'ب', 'ب', 'خ', 'ش', 'ی', 'د']\n",
            "PRED 86: turaan baa labkhandi goft be man bebakhshid\n",
            "PRED SCORE: -0.0312\n",
            "\n",
            "SENT 87: ['ا', 'ز', '<b>', 'م', 'ن', '<b>', 'ت', 'و', 'ق', 'ع', '<b>', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 87: az man tavaqqo konid\n",
            "PRED SCORE: -0.6318\n",
            "\n",
            "SENT 88: ['ش', 'م', 'س', 'ی', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'پ', 'ل', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ا', 'ل', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ر', 'ا', '<b>', 'ت', 'و']\n",
            "PRED 88: shamsi hamaantowr ke az panjare baalaa goft cheraa cheraa\n",
            "PRED SCORE: -1.6771\n",
            "\n",
            "SENT 89: ['ب', 'ر', 'ا', 'د', 'ر', '<b>', 'ر', 'و', '<b>', 'ک', 'ه', '<b>', 'ج', 'ا', 'ی', '<b>', 'ب', 'ر', 'ا', 'د', 'ر', '<b>', 'گ', 'ر', 'د', 'ن', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ن', 'د']\n",
            "PRED 89: baraadarash ro ke jaa ye baraash sabz nemikonand\n",
            "PRED SCORE: -1.2633\n",
            "\n",
            "SENT 90: ['ا', 'ز', '<b>', 'ق', 'و', 'ل', '<b>', 'م', 'ن', '<b>', 'ب', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'گ', 'و', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'ی', '<b>', 'ش', 'و', 'ه', 'ر', '<b>', 'م', 'ث', 'ل', '<b>', 'پ', 'ل', 'ه', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ه', 'ر', '<b>', 'ک', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'ر', 'و', 'ش', '<b>', 'ب', 'گ', 'ذ', 'ر', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'ا', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ش', 'د']\n",
            "PRED 90: az qowl e man be gush e begu dokhtar e foruq az sarash mesl e shishe ke baayad az sarash bargereft\n",
            "PRED SCORE: -3.2618\n",
            "\n",
            "SENT 91: ['ف', 'ر', 'و', 'غ']\n",
            "PRED 91: foruq\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 92: ['د', 'ا', 'ر', 'ی', '<b>', 'چ', 'ی', 'ک', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 92: daari chikaar mikoni\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 93: ['گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 93: gerye mikoni\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 94: ['چ', 'ت', 'ه']\n",
            "PRED 94: chete\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 95: ['ل', 'ح', 'ن', 'ش', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'و', '<b>', 'ن', 'ا', 'ب', 'ا', 'و', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 95: lahnash moteajjeb va naabaavari bud\n",
            "PRED SCORE: -0.0934\n",
            "\n",
            "SENT 96: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ب', 'ه', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'و', 'ا', 'ر', 'س', 'ی', '<b>', 'گ', 'ن', 'ج', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', 'گ', 'ر', 'د', 'ا', 'ن', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه']\n",
            "PRED 96: foruq be bahaane ye vaase hejdah gush raa gom o goft na\n",
            "PRED SCORE: -1.2413\n",
            "\n",
            "SENT 97: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ر', 'ا', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ک', 'ر', 'د', 'ی']\n",
            "PRED 97: puraan goft cheraa gerye kardi\n",
            "PRED SCORE: -0.2825\n",
            "\n",
            "SENT 98: ['ص', 'د', 'ا', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ب', 'غ', 'ض', '<b>', 'ا', 'ل', 'و', 'د', '<b>', 'و', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'ب', 'و', 'د']\n",
            "PRED 98: sedaa ye khodash ham baqal avvalesh va gerye bud\n",
            "PRED SCORE: -2.2336\n",
            "\n",
            "SENT 99: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'و', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ن', 'م', '<b>', 'ا', 'ل', 'ا', 'ن', '<b>', 'م', 'ی', 'ا', 'م']\n",
            "PRED 99: foruq goft boro puraan manam alaan miaam\n",
            "PRED SCORE: -0.1227\n",
            "\n",
            "SENT 100: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', 'ش', '<b>', 'خ', 'م', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', 'ت', '<b>', 'ب', 'گ', 'ی']\n",
            "PRED 100: puraan be tarafash kham shod va goft nemikhaay be khaaharet begi\n",
            "PRED SCORE: -1.3172\n",
            "\n",
            "SENT 101: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ی', 'ک', '\\u200c', 'ک', 'م', '<b>', 'د', 'ل', 'م', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 101: foruq goft yek kam delam gerefte bud\n",
            "PRED SCORE: -0.1760\n",
            "\n",
            "SENT 102: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'ا', 'م', 'ی', 'ر']\n",
            "PRED 102: puraan porsid vaase amir\n",
            "PRED SCORE: -0.0011\n",
            "\n",
            "SENT 103: ['ف', 'ر', 'و', 'غ', '<b>', 'ح', 'ر', 'ف', 'ی', '<b>', 'ن', 'ز', 'د', '<b>', 'چ', 'ق', 'د', 'ر', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', 'ش', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'د', 'و', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 103: foruq harfi nazad cheqadr afsorde az ham dur bud\n",
            "PRED SCORE: -1.9990\n",
            "\n",
            "SENT 104: ['ا', 'ش', 'ک', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ه', 'م', '<b>', 'س', 'ر', 'ا', 'ز', 'ی', 'ر', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ج', 'ا', 'ش', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'خ', 'ا', 'ل', 'ی', 'ه', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 104: ashk e puraan ham saraazir shod va goft aql e kheyli pokhte\n",
            "PRED SCORE: -1.9788\n",
            "\n",
            "SENT 105: ['ه', 'ی', 'چ', '<b>', 'ف', 'ک', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م', '<b>', 'ی', 'ک', '<b>', 'ر', 'و', 'ز', '<b>', 'ا', 'ن', '<b>', 'ق', 'د', 'ر', '<b>', 'ا', 'ز', '<b>', 'د', 'و', 'ر', 'ی', 'ش', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', '<b>', 'ب', 'ش', 'م']\n",
            "PRED 105: hichvaqt natunestam yek ruz aan qadam az batn naaraahati\n",
            "PRED SCORE: -1.5778\n",
            "\n",
            "SENT 106: ['ف', 'ر', 'و', 'غ', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'د', 'ن', 'د', 'ه', '<b>', 'و', '<b>', 'ز', 'و', 'ر', 'گ', 'و', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ت', 'ل', 'ا', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ا', 'د', 'ا', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ر', 'و', '<b>', 'د', 'ر', '<b>', 'ب', 'ی', 'ا', 'ر', 'ه']\n",
            "PRED 106: foruq zemzeme kard un yek kam o javun bud o hamishe qaraar mikardi\n",
            "PRED SCORE: -1.2227\n",
            "\n",
            "SENT 107: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 107: puraan miaan e gerye labkhand zad\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 108: ['ا', 'م', 'ا', '<b>', 'ق', 'ل', 'ب', '<b>', 'م', 'ه', 'ر', 'ب', 'و', 'ن', 'ی', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 108: ammaa qalb e kuchulu daare foruq\n",
            "PRED SCORE: -0.9585\n",
            "\n",
            "SENT 109: ['ش', 'ا', 'ی', 'د', '<b>', 'ا', 'ی', 'ن', 'و', '<b>', 'ف', 'ق', 'ط', '<b>', 'م', 'ن', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'م']\n",
            "PRED 109: shaayad ino faqat man mishnaasam\n",
            "PRED SCORE: -0.0024\n",
            "\n",
            "SENT 110: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ک', 'ه', '<b>', 'ح', 'ت', 'ی', '<b>', 'ر', 'و', 'ز', '<b>', 'ا', 'خ', 'ر', '<b>', 'م', 'ن', 'و', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'و', '<b>', 'ح', 'س', 'ا', 'ب', 'ی', '<b>', 'ن', 'ب', 'و', 'س', 'ی', 'د']\n",
            "PRED 110: foruq goft vali amaanatie qorur daasht ke hattaa ruz va hesaabi nashenid\n",
            "PRED SCORE: -2.7906\n",
            "\n",
            "SENT 111: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'خ', 'ی', 'س', '<b>', 'ا', 'ز', '<b>', 'ا', 'ش', 'ک', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'ا', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'م', 'ه', 'ر', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ی', 'ا', '<b>', 'ب', 'ر', 'ی', 'م']\n",
            "PRED 111: puraan surat e mizash az ashkash raa paak va baa mehrbaani goft biaa bar\n",
            "PRED SCORE: -1.3578\n",
            "\n",
            "SENT 112: ['ج', 'ل', 'و', 'ی', '<b>', 'م', 'ه', 'م', 'و', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ز', 'ش', 'ت', 'ه']\n",
            "PRED 112: jelow e mohemmi zeshte\n",
            "PRED SCORE: -1.5399\n",
            "\n",
            "SENT 113: ['ر', 'ا', 'س', 'ت', 'ی', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ه', 'م', '<b>', 'ا', 'و', 'م', 'د']\n",
            "PRED 113: raasti khaale shamsi ham umad\n",
            "PRED SCORE: -0.1702\n",
            "\n",
            "SENT 114: ['ه', 'ی', 'چ', '<b>', 'ف', 'ک', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ظ', 'ا', 'ه', 'ر', '<b>', 'ب', 'ه', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'و', 'ش', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ح', 'و', 'ا', 'س', 'ش', '<b>', 'ج', 'ا', 'ی', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'و', 'ی', 'ر', 'ا', 'ن', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ا', 'ب', 'ا', 'د', '<b>', 'ش', 'د', 'ه', '<b>', 'و', '<b>', 'ه', 'د', 'ف', '<b>', 'ا', 'ز', '<b>', 'ه', 'ر', '<b>', 'ز', 'م', 'ا', 'ن', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'ن', 'ز', 'د', 'ی', 'ک', 'ت', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 114: hichvaqt nemikardam biaad foruq be cheshm ye puraan eshaare shode bud\n",
            "PRED SCORE: -1.7789\n",
            "\n",
            "SENT 115: ['ا', 'ی', 'ا', '<b>', 'ا', 'م', 'د', 'ن', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ر', 'ب', 'و', 'ط', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 115: aayaa inke shamsi be parviz qor mishod\n",
            "PRED SCORE: -0.9477\n",
            "\n",
            "SENT 116: ['ن', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت']\n",
            "PRED 116: natarsidi\n",
            "PRED SCORE: -0.6896\n",
            "\n",
            "SENT 117: ['ا', 'ص', 'ل', 'ا', '<b>', 'چ', 'ه', '<b>', 'ا', 'ه', 'م', 'ی', 'ت', 'ی', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 117: aslan che ahammiyati daasht\n",
            "PRED SCORE: -0.0004\n",
            "\n",
            "SENT 118: ['غ', 'ر', 'و', 'ب', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'م', 'ه', 'م', 'ا', 'ن', 'ا', 'ن', '<b>', 'غ', 'ر', 'ی', 'ب', 'ه', '\\u200c', 'ت', 'ر', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ه', 'م', '<b>', 'ک', 'ه', '<b>', 'د', 'ی', 'ر', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ق', 'ص', 'د', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 118: surat e ba d az raftan e puraan ye javaanash ham ke e nadide bude tamaashaa kard\n",
            "PRED SCORE: -5.4649\n",
            "\n",
            "SENT 119: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ع', 'ت', 'ر', 'ض', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'م', 'ا', '<b>', 'ک', 'ج', 'ا', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 119: turaan mokhtasar goft shomaa kojaa khaale jun\n",
            "PRED SCORE: -0.0480\n",
            "\n",
            "SENT 120: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'س', 'ا', 'خ', 'ت', 'گ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'خ', 'ی', '<b>', 'خ', 'و', 'ن', 'ه', '\\u200c', 'ت', 'ن', 'ه', 'ا', 'س', 'ت']\n",
            "PRED 120: shamsi baa labkhandi saakhtegi goft jeddi khune ye qaribast\n",
            "PRED SCORE: -1.0380\n",
            "\n",
            "SENT 121: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ه', 'م', '<b>', 'ل', 'ا', 'ب', 'د', '<b>', 'ت', 'ا', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ا', 'ز', '<b>', 'پ', 'ی', 'ا', 'د', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'ب', 'ر', 'گ', 'ش', 'ت', 'ه']\n",
            "PRED 121: shaapur ham laabod taa haalaa az jaam ru ye saresh\n",
            "PRED SCORE: -0.6125\n",
            "\n",
            "SENT 122: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', 'ز', 'ه', '<b>', 'ا', 'و', 'م', 'د', 'ی']\n",
            "PRED 122: turaan baa mohabbat goft shomaa ke taaze umadi\n",
            "PRED SCORE: -0.7094\n",
            "\n",
            "SENT 123: ['ح', 'ا', 'ل', 'ا', '<b>', 'ی', 'ک', 'س', 'ا', 'ع', 'ت', '<b>', 'د', 'ی', 'ر', 'ت', 'ر']\n",
            "PRED 123: haalaa qorbunet e digari\n",
            "PRED SCORE: -2.0573\n",
            "\n",
            "SENT 124: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ر', 'ف', 'ت', 'ن', 'ی', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ر', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن', '<b>', 'چ', 'ه', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'چ', 'ه', '<b>', 'ی', 'ک', 'س', 'ا', 'ع', 'ت', '<b>', 'د', 'ی', 'گ', 'ه']\n",
            "PRED 124: shamsi goft sharaayet baayad bere turaan jun che haalaa dige\n",
            "PRED SCORE: -1.2934\n",
            "\n",
            "SENT 125: ['م', 'ا', 'د', 'ر', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', 'ا', 'ن', '<b>', 'ج', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'ظ', 'ر', 'ف', '\\u200c', 'ا', 'ش', '<b>', 'ب', 'ک', 'ش', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ب', 'ر', 'ه', '<b>', 'خ', 'و', 'ن', 'ه']\n",
            "PRED 125: maadarshowhar turaan alaan alaan jun yek arusak azash base khune ye khune\n",
            "PRED SCORE: -2.6007\n",
            "\n",
            "SENT 126: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ل', 'ا', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ک', 'ه', '<b>', 'ا', 'ه', 'ل', '\\u200c', 'ا', 'ش', '<b>', 'ن', 'ی', 'س', 'ت', 'ن', 'د']\n",
            "PRED 126: shamsi belaafaasele goft na khaale jun ke e teraaz nistand\n",
            "PRED SCORE: -1.5708\n",
            "\n",
            "SENT 127: ['م', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'ر', 'د', 'م']\n",
            "PRED 127: manam ke pedaram\n",
            "PRED SCORE: -0.6884\n",
            "\n",
            "SENT 128: ['ز', 'ح', 'م', 'ت', '<b>', 'ن', 'ک', 'ش']\n",
            "PRED 128: khaasiyat e nafasgiri\n",
            "PRED SCORE: -1.0990\n",
            "\n",
            "SENT 129: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'س', 'ت', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'و', 'ر', '<b>', 'ک', 'م', 'ر', '<b>', 'پ', 'ه', 'ن', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ح', 'ل', 'ق', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'م', 'ه', 'ر', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ش', 'ر', 'م', 'ن', 'د', 'م', 'و', 'ن', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 129: turaan belaafaasele raa dowr e zarf e shamsi halqe va baa mehrbaani goft kheyli badbakhtam jun\n",
            "PRED SCORE: -1.6677\n",
            "\n",
            "SENT 130: ['ش', 'م', 'س', 'ی', '<b>', 'ه', 'م', '<b>', 'م', 'ت', 'ق', 'ا', 'ب', 'ل', 'ا', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', 'ی', 'م', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 130: shamsi ham moteqaabelan suratash raa busid va goft bel akhare javunie e mane\n",
            "PRED SCORE: -1.3438\n",
            "\n",
            "SENT 131: ['و', 'ظ', 'ی', 'ف', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ی', 'ا', 'م']\n",
            "PRED 131: vagarna bud biaar\n",
            "PRED SCORE: -0.8303\n",
            "\n",
            "SENT 132: ['م', 'ا', 'د', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ر', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 132: maadarbozorg dar bandesh bekesham goft aare maadar\n",
            "PRED SCORE: -0.4618\n",
            "\n",
            "SENT 133: ['ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'گ', 'و', 'ش', 'ت', '<b>', 'ه', 'م', 'د', 'ی', 'گ', 'ه', '<b>', 'ر', 'و', '<b>', 'ب', 'خ', 'و', 'ر', 'ی', 'د', '<b>', 'ا', 'س', 'ت', 'خ', 'و', 'ن', 'ش', '<b>', 'ر', 'و', '<b>', 'ن', 'گ', 'ه', '<b>', 'م', 'ی', 'د', 'ا', 'ر', 'ی', 'د']\n",
            "PRED 133: bel akhare gozasht nakarde ruberaah bishtar ro neshun midaad\n",
            "PRED SCORE: -3.4351\n",
            "\n",
            "SENT 134: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ک', 'ه', '<b>', 'ن', 'ا', 'ر', 'ا', 'ج', 'ت', '<b>', 'ن', 'ی', 'س', 'ت', 'م', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ت', 'م', 'و', 'م', '<b>', 'ش', 'د', '<b>', 'ر', 'ف', 'ت']\n",
            "PRED 134: shamsi baa qorur goft man ke naaraahat nistam yek chizi bud\n",
            "PRED SCORE: -0.0642\n",
            "\n",
            "SENT 135: ['ش', 'ا', 'ی', 'د', 'م', '<b>', 'ق', 'س', 'م', 'ت', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 135: shaayadam talkhast\n",
            "PRED SCORE: -0.6939\n",
            "\n",
            "SENT 136: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ب', 'ه', 'ر', 'ح', 'ا', 'ل', '<b>', 'ا', 'گ', 'ه', '<b>', 'ر', 'ن', 'ج', 'ی', 'د', 'ی', '<b>', 'ب', 'ه', '<b>', 'م', 'ن', '<b>', 'ب', 'ب', 'خ', 'ش', '<b>', 'خ', 'ا', 'ل', 'ه']\n",
            "PRED 136: turaan dobaare suratash raa busid va zemzeme kard be man age be man khaale\n",
            "PRED SCORE: -1.8217\n",
            "\n",
            "SENT 137: ['م', 'ن', '<b>', 'م', 'ع', 'ذ', 'و', 'ر', 'م', '<b>', 'و', 'ض', 'ع', 'م', '<b>', 'ر', 'و', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ی', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'گ', 'ذ', 'ر', 'ا', '<b>', 'ب', 'ه', '\\u200c', 'ص', 'و', 'ر', 'ت', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ش', 'ا', 'ل', 'ا', '<b>', 'ه', 'م', 'ش', 'و', 'ن', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', '<b>', 'ب', 'ش', 'ن']\n",
            "PRED 137: man ma lume foruqam ke miduni shamsi negaah kard o goft haaeri bebusamet\n",
            "PRED SCORE: -1.4810\n",
            "\n",
            "SENT 138: ['ب', 'غ', 'ض', '<b>', 'گ', 'ل', 'و', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د']\n",
            "PRED 138: boqz galu ye foruq raa feshord\n",
            "PRED SCORE: -0.0025\n",
            "\n",
            "SENT 139: ['ا', 'ی', 'ن', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'چ', 'ه', '<b>', 'م', 'ع', 'ن', 'ی', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 139: in harfhaa che ma khir daare\n",
            "PRED SCORE: -0.4443\n",
            "\n",
            "SENT 140: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ح', 'ت', 'ی', '<b>', 'م', 'غ', 'ز', 'ش', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'ک', 'ن', 'د', 'ی', '<b>', 'ع', 'م', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 140: engaar hattaa ma ham be zendegimun e amal mikard\n",
            "PRED SCORE: -1.7090\n",
            "\n",
            "SENT 141: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ا', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'خ', 'د', 'ا', 'ح', 'ا', 'ف', 'ظ', 'ی', '<b>', 'و', '<b>', 'ر', 'و', 'ب', 'و', 'س', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'س', 'ر', 'ز', 'د', 'ه', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 141: shamsi daasht baa baqiye khodaahaafezi e khodaahaafezi mikard ke fereydun mikeshid ke mobaarak\n",
            "PRED SCORE: -1.8836\n",
            "\n",
            "SENT 142: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'د', 'ی', 'د', 'ن', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ی', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 142: turaan baa didanash goft chie maadar\n",
            "PRED SCORE: -0.0206\n",
            "\n",
            "SENT 143: ['ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ب', 'ه', '<b>', 'ک', 'و', 'چ', 'ه', '<b>', 'ع', 'ج', 'ل', 'ه', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ق', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ج', 'ل', 'و', '<b>', 'د', 'ر', 'ن', 'د']\n",
            "PRED 143: fereydun ke baraay be qorub e zebrash daasht goft aaqaa parviz jun kardand\n",
            "PRED SCORE: -2.1970\n",
            "\n",
            "SENT 144: ['ق', 'ل', 'ب', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ف', 'ر', 'و', '<b>', 'ر', 'ی', 'خ', 'ت', '<b>', 'و', '<b>', 'ن', 'ف', 'س', 'ش', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'چ', 'ن', 'د', '<b>', 'ث', 'ا', 'ن', 'ی', 'ه', '<b>', 'ب', 'ن', 'د', '<b>', 'ا', 'م', 'د']\n",
            "PRED 144: qalb e foruq foru rikht va labash baraaye chand band band aamad\n",
            "PRED SCORE: -0.8808\n",
            "\n",
            "SENT 145: ['ش', 'م', 'س', 'ی', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ن']\n",
            "PRED 145: shamsi moteajjeb porsid parviz\n",
            "PRED SCORE: -0.0917\n",
            "\n",
            "SENT 146: ['ک', 'ل', 'م', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '\\u200c', 'ش', 'د', 'ت', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'د']\n",
            "PRED 146: kalamehaa parviz baaz ham e foruq raa be sheddat gozaraand\n",
            "PRED SCORE: -1.6483\n",
            "\n",
            "SENT 147: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ب', '<b>', 'ت', 'ع', 'ا', 'ر', 'ف', 'ش', 'و', 'ن', '<b>', 'ک', 'ن', '<b>', 'ب', 'ی', 'ا', 'ن', '<b>', 'ت', 'و']\n",
            "PRED 147: turaan goft khob taaarofeshun kon biaan tu\n",
            "PRED SCORE: -1.5425\n",
            "\n",
            "SENT 148: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 148: shamsi goft na turaan jun\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 149: ['ب', 'ا', 'ش', 'ه', '<b>', 'ی', 'ه', '<b>', 'و', 'ق', 'ت', '<b>', 'د', 'ی', 'گ', 'ه']\n",
            "PRED 149: baashe az vaqti dige\n",
            "PRED SCORE: -0.9570\n",
            "\n",
            "SENT 150: ['ح', 'ا', 'ل', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ن', 'ح', 'و', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'ی', 'د', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ر', 'ا', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 150: haal e foruq be nahvi bud ke paaltoash baqiye raa pushaand konad\n",
            "PRED SCORE: -1.8608\n",
            "\n",
            "SENT 151: ['م', 'غ', 'ز', '<b>', 'س', 'ر', 'ش', '<b>', 'گ', 'ز', '<b>', 'گ', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'م', 'ث', 'ل', '<b>', 'م', 'ج', 'س', 'م', 'ه', '<b>', 'ب', 'ا', '<b>', 'ر', 'ن', 'گ', '<b>', 'و', '<b>', 'ر', 'و', 'ی', '<b>', 'پ', 'ر', 'ی', 'د', 'ه', '<b>', 'ب', 'ر', '<b>', 'ج', 'ا', '<b>', 'خ', 'ش', 'ک', 'ش', '<b>', 'ز', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 151: panj sarash gol mikard va mesl e panjare bar zehnash zade bud\n",
            "PRED SCORE: -1.8922\n",
            "\n",
            "SENT 152: ['م', 'ا', 'د', 'ر', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ه', '<b>', 'ت', 'ع', 'ا', 'ر', 'ف', 'ی', '<b>', 'ش', 'د', 'ی', '<b>', 'ش', 'م', 'س', 'ی']\n",
            "PRED 152: maadar e turaan goft che taqsiri shodi shamsi\n",
            "PRED SCORE: -0.3484\n",
            "\n",
            "SENT 153: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن', '<b>', 'ب', 'ر', 'و', '<b>', 'ت', 'ع', 'ا', 'ر', 'ف', 'ش', '<b>', 'ک', 'ن', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'ت', 'و', '<b>', 'م', 'ن', 'م', '<b>', 'د', 'ل', 'م', '<b>', 'ب', 'ر', 'ا', 'ش', '<b>', 'ت', 'ن', 'گ', '<b>', 'ش', 'د', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'چ', 'ه', '<b>', 'ک', 'ن', 'د', '<b>', 'ا', 'ی', 'ا', '<b>', 'ر', 'ف', 'ت', 'ن', 'ش', '<b>', 'ا', 'ن', '<b>', 'ه', 'م', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '<b>', 'ت', 'ع', 'ج', 'ب', '<b>', 'ب', 'ر', 'ا', 'ن', 'گ', 'ی', 'ز', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 153: turaan jelo boro haasel kon baayad to manam moshavveqeshun shode bud\n",
            "PRED SCORE: -3.1086\n",
            "\n",
            "SENT 154: ['ا', 'گ', 'ر', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'م', 'ا', 'ن', 'د', '<b>', 'م', 'س', 'ل', 'م', 'ا', '<b>', 'ح', 'ا', 'ل', '<b>', 'ب', 'ه', 'ت', 'ر', 'ی', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'ا', 'ز', '<b>', 'ف', 'ر', 'ط', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', '<b>', 'د', 'چ', 'ا', 'ر', '<b>', 'د', 'ل', '<b>', 'پ', 'ی', 'چ', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 154: agar ham mikhaast mehri haal e delhore az foruq jodaa shod delash mobaarak\n",
            "PRED SCORE: -6.1449\n",
            "\n",
            "SENT 155: ['ح', 'ت', 'ی', '<b>', 'ن', 'ف', 'ه', 'م', 'ی', 'د', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د']\n",
            "PRED 155: hattaa nemiaamad maadarash ki az khaane khaarej shod\n",
            "PRED SCORE: -0.3146\n",
            "\n",
            "SENT 156: ['چ', 'ش', 'م', 'ش', '<b>', 'ب', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ا', 'ف', 'ت', 'ا', 'د']\n",
            "PRED 156: cheshmash be shamsi oftaad\n",
            "PRED SCORE: -0.6521\n",
            "\n",
            "SENT 157: ['ن', 'ا', 'ر', 'ض', 'ا', 'ی', 'ت', 'ی', '<b>', 'د', 'ر', '<b>', 'ع', 'م', 'ق', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ش', 'ر', 'ا', 'ی', 'ط', '<b>', 'ح', 'ا', 'ک', 'م', '<b>', 'م', 'و', 'ج', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'ا', 'ی', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د']\n",
            "PRED 157: naaraahat dar omq e negaah be khaater e khubihaa ye tup e parviz dur aamad\n",
            "PRED SCORE: -4.1917\n",
            "\n",
            "SENT 158: ['ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'م', 'س', 'ت', 'ا', 'ص', 'ل', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ی', 'ا', 'د']\n",
            "PRED 158: shamsi ke mostaqim istaad ke masalan nemiaad\n",
            "PRED SCORE: -1.7404\n",
            "\n",
            "SENT 159: ['ب', 'چ', 'ه', '\\u200c', 'ا', 'م', '<b>', 'خ', 'س', 'ت', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 159: bachcham khaste zade\n",
            "PRED SCORE: -0.6221\n",
            "\n",
            "SENT 160: ['م', 'ا', 'د', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'ت', 'و', '<b>', 'ح', 'ر', 'ف', '<b>', 'ت', 'و', '<b>', 'د', 'ه', 'ن', 'ش', '<b>', 'ن', 'ذ', 'ا', 'ر', 'ی', '<b>', 'م', 'ی', 'ا', 'د', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 160: maadarbozorg be bandesh goft age to harf e to ro nashenid\n",
            "PRED SCORE: -2.6388\n",
            "\n",
            "SENT 161: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'ی', 'و', 'ا', 'ن', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د']\n",
            "PRED 161: shamsi be donbaal e turaan az khaane khire shod va ru ye bahaar istaad\n",
            "PRED SCORE: -1.7721\n",
            "\n",
            "SENT 162: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'م', 'د', 'ن', '<b>', 'ب', 'ی', '<b>', 'م', 'ی', 'ل', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 162: be nazar e parviz baraaye aamadanash bi miaan\n",
            "PRED SCORE: -0.5947\n",
            "\n",
            "SENT 163: ['چ', 'و', 'ن', '<b>', 'چ', 'ن', 'د', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ش', 'و', 'د', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'د', 'ر', '<b>', 'ر', 'ا', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', 'ش', '<b>', 'ب', 'س', 'ت']\n",
            "PRED 163: chon chand lahze ba dhaa kenaar kenaar e kebriti va vaared e sarash raa fut kard\n",
            "PRED SCORE: -2.2668\n",
            "\n",
            "SENT 164: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'م', 'ح', 'ض', '<b>', 'د', 'ی', 'د', 'ن', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'ش', 'ر', 'و', 'ی', 'ی', '<b>', 'س', 'ل', 'ا', 'م', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 164: parviz be mahz e didan e maadarash baa hamle salaam kard\n",
            "PRED SCORE: -2.1214\n",
            "\n",
            "SENT 165: ['ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ا', 'ز', '<b>', 'ا', 'م', 'د', 'ن', 'ش', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'ب', 'و', 'د', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'چ', 'ی', '<b>', 'ش', 'د', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 165: shamsi ke hanuz az avvalesh mohabbat bud porsid chi shode maadar\n",
            "PRED SCORE: -0.9962\n",
            "\n",
            "SENT 166: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 166: parviz baa labkhand goft hichchi maadar\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 167: ['ا', 'و', 'م', 'د', 'م', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ت', 'و', 'ن']\n",
            "PRED 167: umadam donbaalet\n",
            "PRED SCORE: -0.0311\n",
            "\n",
            "SENT 168: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ق', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ا', 'و', 'م', 'د', '<b>', 'ب', 'ه', '<b>', 'ز', 'و', 'ر', '<b>', 'ا', 'و', 'ر', 'د', 'م', 'ش']\n",
            "PRED 168: turaan goft aaqaa parviz nemigoftam be zur e maadaresham\n",
            "PRED SCORE: -1.5262\n",
            "\n",
            "SENT 169: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ا', 'ق', 'ا', '<b>', 'خ', 'و', 'ر', 'د', 'ن', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 169: parviz be shukhi goft bel y e amir e mard e kaare\n",
            "PRED SCORE: -1.8346\n",
            "\n",
            "SENT 170: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'خ', 'و', 'ش', '<b>', 'ا', 'و', 'م', 'د', 'ی', 'ن']\n",
            "PRED 170: turaan baa labkhand goft kheyli khosh umadi\n",
            "PRED SCORE: -0.0195\n",
            "\n",
            "SENT 171: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'س', 'ر', 'د', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'د', 'ا', 'ش', 'ت', 'م', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', 'م']\n",
            "PRED 171: shamsi be sardi goft man daashtam migofti\n",
            "PRED SCORE: -0.2731\n",
            "\n",
            "SENT 172: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'س', '<b>', 'ب', 'م', 'و', 'ق', 'ع', '<b>', 'ا', 'و', 'م', 'د', 'م']\n",
            "PRED 172: parviz goft pas barmigardi umadam\n",
            "PRED SCORE: -1.0559\n",
            "\n",
            "SENT 173: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'و', '<b>', 'د', 'و', 'ر', '<b>', 'ک', 'م', 'ر', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ح', 'ل', 'ق', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'چ', 'ه', '<b>', 'ب', 'ه', 'و', 'ن', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'خ', 'ا', 'ل', 'ه']\n",
            "PRED 173: turaan dastash ro dowr e zarf e shamsi halqe kard va goft dige daari\n",
            "PRED SCORE: -2.3811\n",
            "\n",
            "SENT 174: ['ب', 'ف', 'ر', 'م', 'ا', 'ی', 'ی', 'د', '<b>', 'ت', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ی', 'ک', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ب', 'ا', 'ر', 'ی', '<b>', 'ن', 'ث', 'ا', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 174: befarmaaid to shamsi yek lahze negaah kard va baa tehraan vaared kard\n",
            "PRED SCORE: -0.7296\n",
            "\n",
            "SENT 175: ['د', 'ر', '<b>', 'ح', 'ق', 'ی', 'ق', 'ت', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'د', 'و', 'ن', '<b>', 'ه', 'م', 'ا', 'ه', 'ن', 'گ', 'ی', '<b>', 'ق', 'ب', 'ل', 'ی', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', 'ج', 'ا', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'و', '<b>', 'پ', 'ا', 'ی', '<b>', 'ع', 'و', 'ا', 'ق', 'ب', 'ش', '<b>', 'ه', 'م', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 175: dar haqiqat parviz bodobodo ye hame ye dast e anduh ham ham istaad\n",
            "PRED SCORE: -2.0287\n",
            "\n",
            "SENT 176: ['ا', 'و', '<b>', 'ک', 'ه', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ر', 'ن', 'ج', 'ش', '<b>', 'و', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ت', 'ص', 'م', 'ی', 'م', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ه', '<b>', 'ن', 'و', 'ع', 'ی', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ق', 'ض', 'ی', 'ه', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ج', 'ر', 'ی', 'ا', 'ن', '<b>', 'ب', 'ی', 'ن', 'د', 'ا', 'ز', 'د', '<b>', 'و', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'گ', 'ذ', 'ش', 'ت', '<b>', 'ز', 'م', 'ا', 'ن', '<b>', 'ع', 'ق', 'ی', 'د', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'ت', 'غ', 'ی', 'ی', 'ر', '<b>', 'خ', 'و', 'ا', 'ه', 'د', '<b>', 'د', 'ا', 'د', '<b>', 'ب', 'ه', '\\u200c', 'ش', 'د', 'ت', '<b>', 'م', 'س', 'ت', 'ا', 'ص', 'ل', '<b>', 'و', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ن', 'م', 'و', 'د']\n",
            "PRED 176: u ke motevajjeh e ranjash o qorur e maadarash raa be sheddat e parviz sarak daasht ke haalaa bi band bi tajrobast\n",
            "PRED SCORE: -3.7730\n",
            "\n",
            "SENT 177: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ن', 'ه', '<b>', 'ت', 'ن', 'ه', 'ا', '<b>', 'د', 'ر', '<b>', 'ط', 'و', 'ل', '<b>', 'ا', 'ی', 'ن', '<b>', 'م', 'د', 'ت', '<b>', 'ب', 'ا', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'و', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'پ', 'ی', 'ش', '<b>', 'ن', 'ب', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'ب', 'ی', '<b>', 'ج', 'ه', 'ت', '<b>', 'و', '<b>', 'ن', 'ا', 'خ', 'و', 'ا', 'س', 'ت', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'د', 'س', 'ت', '<b>', 'ک', 'م', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 177: engaar na alaan dar tul e in moddat baa golestaan va negaahash kard\n",
            "PRED SCORE: -2.1993\n",
            "\n",
            "SENT 178: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'م', 'ی', 'ل', '<b>', 'د', 'ل', 'ش', '<b>', 'ع', 'م', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ی', 'ن', '<b>', 'ت', 'ص', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', '<b>', 'ف', 'ر', 'ز', 'ن', 'د', '<b>', 'د', 'ی', 'ر', 'و', 'ز', '<b>', 'ا', 'س', 'ت', '<b>', 'ا', 'ح', 'م', 'ق', 'ا', 'ن', 'ه', '<b>', 'ب', 'ه', '<b>', 'ن', 'ظ', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ر', 'س', 'ی', 'د']\n",
            "PRED 178: parviz be tasavvor e delash raft va in kam ke u amal istaad\n",
            "PRED SCORE: -4.1076\n",
            "\n",
            "SENT 179: ['ا', 'ز', '<b>', 'ط', 'ر', 'ف', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ه', 'م', '<b>', 'ب', 'ا', '<b>', 'ر', 'و', 'ح', 'ی', 'ا', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'س', 'ر', 'ا', 'غ', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'پ', 'ی', 'ش', 'ق', 'د', 'م', '<b>', 'ش', 'د', 'ن', '<b>', 'ر', 'ا', '<b>', 'ن', 'ا', '<b>', 'م', 'م', 'ک', 'ن', '<b>', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'ی', 'ن', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'ب', 'ق', 'و', 'ل', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ن', 'ب', 'ا', 'ی', 'د', '<b>', 'ع', 'ر', 'ص', 'ه', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'س', 'ا', 'د', 'گ', 'ی', '<b>', 'خ', 'ا', 'ل', 'ی', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 179: az taraf e parviz ham baa raaayat e ke dar in maadarash qeyr e naa ye zang sehrash kardand\n",
            "PRED SCORE: -4.5145\n",
            "\n",
            "SENT 180: ['ح', 'ا', 'ل', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ا', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', '<b>', 'خ', 'ا', 'ل', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ر', 'و', 'ب', 'و', 'س', 'ی', '<b>', 'و', '<b>', 'ا', 'ح', 'و', 'ا', 'ل', 'پ', 'ر', 'س', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 180: haalaa parviz daasht baa maadar e saabmordat foruq rowshan mikard\n",
            "PRED SCORE: -3.1078\n",
            "\n",
            "SENT 181: ['ش', 'م', 'س', 'ی', '<b>', 'ز', 'ی', 'ر', 'چ', 'ش', 'م', 'ی', '<b>', 'ب', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ن', 'گ', 'ر', 'ی', 'س', 'ت']\n",
            "PRED 181: shamsi alaaraqm be foruq andaakht\n",
            "PRED SCORE: -0.8275\n",
            "\n",
            "SENT 182: ['ن', 'گ', 'ا', 'ه', '<b>', 'ا', 'و', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ب', 'ا', '<b>', 'ب', 'ر', 'ق', '<b>', 'ع', 'ج', 'ی', 'ب', 'ی', '<b>', 'م', 'ی', '\\u200c', 'د', 'ر', 'خ', 'ش', 'ی', 'د']\n",
            "PRED 182: negaah e u motevajjeh e parviz bud va cheshmaanash baa sari e zaifi milarzid\n",
            "PRED SCORE: -1.8406\n",
            "\n",
            "SENT 183: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', 'ا', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'ا', 'ش', 'ی', 'ن', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 183: turaan be takhteshaan goft harfesh maadar\n",
            "PRED SCORE: -1.9774\n",
            "\n",
            "SENT 184: ['و', 'ا', 'س', 'ه', '<b>', 'ا', 'ق', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'چ', 'ا', 'ی', 'ی', '<b>', 'ب', 'ی', 'ا', 'ر', 'ی', 'ن']\n",
            "PRED 184: vaase hayaat parviz chaai e haml\n",
            "PRED SCORE: -2.8704\n",
            "\n",
            "SENT 185: ['ا', 'ز', 'ش', 'و', 'ن', '<b>', 'پ', 'ذ', 'ی', 'ر', 'ا', 'ی', 'ی', '<b>', 'ک', 'ن', 'ی', 'ن']\n",
            "PRED 185: esmesh mitarsunim\n",
            "PRED SCORE: -1.0204\n",
            "\n",
            "SENT 186: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ت', 'ا', 'ن', 'ت', '<b>', 'گ', 'ف', 'ت', 'ک', '<b>', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ن', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 186: parviz baa mohabbat goft aziz e nazdiktar\n",
            "PRED SCORE: -0.6318\n",
            "\n",
            "SENT 187: ['ا', 'ن', 'گ', 'ا', 'ه', '<b>', 'خ', 'ط', 'ا', 'ب', '<b>', 'ب', 'ه', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '<b>', 'خ', 'و', 'ب', 'ن', 'د']\n",
            "PRED 187: aangaah tebq be puraan goft khaane ye khodetun\n",
            "PRED SCORE: -3.1766\n",
            "\n",
            "SENT 188: ['خ', 'د', 'م', 'ت', '<b>', 'س', 'ی', 'ر', 'و', 'س', '<b>', 'خ', 'ا', 'ن', '<b>', 'س', 'ل', 'ا', 'م', '<b>', 'ب', 'ر', 'س', 'و', 'ن', 'ی', 'د']\n",
            "PRED 188: khodaa ro khodaa aaberu rizi nakonid\n",
            "PRED SCORE: -2.8787\n",
            "\n",
            "SENT 189: ['ف', 'ر', 'و', 'غ', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ش', 'د', 'ت', '<b>', 'ه', 'ی', 'ج', 'ا', 'ن', '\\u200c', 'ز', 'د', 'ه', '<b>', 'و', '<b>', 'د', 'س', 'ت', 'پ', 'ا', 'چ', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ف', 'ر', 'ا', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'ش', 'ر', 'ا', 'ی', 'ط', '<b>', 'ز', 'و', 'د', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'ج', 'ا', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ش', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'د', 'ر', '<b>', 'ی', 'ک', '<b>', 'ل', 'ح', 'ظ', 'ه', '\\u200c', 'ی', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'و', '<b>', 'گ', 'ذ', 'ر', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'د', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ر', 'ه', '<b>', 'خ', 'و', 'ر', 'د', '<b>', 'و', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'پ', 'ر', 'م', 'ع', 'ن', 'ا', '<b>', 'و', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', '<b>', 'ل', 'ب', 'ا', 'ن', 'ش', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'خ', 'و', 'د', '<b>', 'د', 'ی', 'د']\n",
            "PRED 189: foruq ke be surat e inke o jaam baraaye aan chizhaa raa nashenid va golestaan movaajeh shod\n",
            "PRED SCORE: -3.3598\n",
            "\n",
            "SENT 190: ['د', 'س', 'ت', 'پ', 'ا', 'چ', 'ه', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'د', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'ه', 'م', 'ه', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ن', 'ظ', 'ر', '<b>', 'گ', 'ذ', 'ر', 'ا', 'ن', 'د']\n",
            "PRED 190: kalaafe hamaantowr ke be taraf e gerefteash hame raa az nazar gozaraand\n",
            "PRED SCORE: -2.6449\n",
            "\n",
            "SENT 191: ['خ', 'د', 'ا', '<b>', 'ر', 'ا', '<b>', 'ش', 'ک', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ا', 'ح', 'و', 'ا', 'ل', 'ش', '<b>', 'ن', 'ب', 'و', 'د', 'ن', 'د']\n",
            "PRED 191: khodaa ro shokr ke ke baqiye motevajjeh e panjareand nabudi\n",
            "PRED SCORE: -1.8926\n",
            "\n",
            "SENT 192: ['ب', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ب', 'ا', '<b>', 'ق', 'د', 'م', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'س', 'ا', 'خ', 'ت', 'م', 'ا', 'ن', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د']\n",
            "PRED 192: be zahmat baa taaksihaa larzaan az saakhtemaan khaarej shod\n",
            "PRED SCORE: -0.9323\n",
            "\n",
            "SENT 193: ['ا', 'ح', 'س', 'ا', 'س', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'د', 'ر', '<b>', 'ع', 'ی', 'ن', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'ب', 'غ', 'ض', '<b>', 'گ', 'ل', 'و', 'ی', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ش', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ض', 'ع', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'د', 'ل', 'ش', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'ا', 'ز', '<b>', 'ش', 'د', 'ت', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ی', '<b>', 'پ', 'ر', 'و', 'ا', 'ز', '<b>', 'ک', 'ن', 'د', '<b>', 'و', '<b>', 'ی', 'ا', '<b>', 'ب', 'ا', '<b>', 'ح', 'د', 'ا', 'ک', 'ث', 'ر', '<b>', 'ت', 'و', 'ا', 'ن', 'ش', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'ب', 'ز', 'ن', 'د']\n",
            "PRED 193: ehsaas e qaribi daasht dar eyn e inke behet az sheddat gozaraand o hazz mikard\n",
            "PRED SCORE: -2.5332\n",
            "\n",
            "SENT 194: ['ب', 'د', 'ن', '<b>', 'خ', 'ی', 'س', '<b>', 'ا', 'ز', '<b>', 'ع', 'ر', 'ق', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ب', 'ا', 'د', '<b>', 'س', 'ر', 'د', '<b>', 'س', 'پ', 'ر', 'د', '<b>', 'و', '<b>', 'ن', 'ف', 'س', '<b>', 'ع', 'م', 'ی', 'ق', '<b>', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 194: kofr e din az hasrat va be baad e sarash sarak va nafas e qaribi keshid\n",
            "PRED SCORE: -3.7211\n",
            "\n",
            "SENT 195: ['ح', 'ا', 'ل', 'ا', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'ز', 'ی', 'ب', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'ا', 'ن', '<b>', 'گ', 'ر', 'ب', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ی', 'ا', 'ه', '<b>', 'ک', 'ه', '<b>', 'د', 'ا', 'ی', 'م', '<b>', 'م', 'ث', 'ل', '<b>', 'ک', 'ف', 'ت', 'ا', 'ر', 'ی', '<b>', 'ب', 'د', '<b>', 'ت', 'ر', 'ک', 'ی', 'ب', '<b>', 'ر', 'و', 'ی', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'د', 'ر', '<b>', 'ک', 'م', 'ی', 'ن', '<b>', 'ک', 'ف', 'ت', 'ر', 'ه', 'ا', 'ی', '<b>', 'ب', 'ی', 'ن', 'و', 'ا', 'ی', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 195: haalaa hame chie be nazarash e dige miaamad hattaa baayad moch begirad\n",
            "PRED SCORE: -3.7355\n",
            "\n",
            "SENT 196: ['ب', 'ه', '<b>', 'ح', 'ا', 'ل', 'ت', '<b>', 'د', 'و', '<b>', 'ب', 'ه', '<b>', 'ا', 'ش', 'پ', 'ز', 'خ', 'ا', 'ن', 'ه', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'خ', 'ن', 'د', 'ی', 'د']\n",
            "PRED 196: be haalat e do be tekyegaahi raft va naa omidi mifahmid gerye miaad\n",
            "PRED SCORE: -2.1407\n",
            "\n",
            "SENT 197: ['د', 'س', 'ت', 'ش', '<b>', 'ح', 'ت', 'ی', '<b>', 'ت', 'و', 'ا', 'ن', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ک', 'ر', 'د', 'ن', '<b>', 'ق', 'و', 'ر', 'ی', '<b>', 'چ', 'ا', 'ی', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ل', 'ر', 'ز', 'ش', '<b>', 'د', 'ل', 'پ', 'ذ', 'ی', 'ر', 'ی', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ز', 'ا', 'ن', 'و', 'ا', 'ن', 'ش', '<b>', 'ح', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'د', 'ر', '<b>', 'ا', 'ن', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'س', 'ر', 'د', '<b>', 'م', 'ش', 'ت', 'ی', '<b>', 'ا', 'ب', '<b>', 'ب', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'پ', 'ا', 'ش', 'ی', 'د']\n",
            "PRED 197: dastash hattaa alaan boland karde qalban havaa ye maadaret raa dar aan gereft\n",
            "PRED SCORE: -3.3474\n",
            "\n",
            "SENT 198: ['ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'م', 'ث', 'ل', '<b>', 'س', 'ی', 'ل', 'ی', '<b>', 'ه', 'و', 'ش', 'ی', 'ا', 'ر', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 198: naagahaan baayad zerang oftaad mesl e sharmsaari bud\n",
            "PRED SCORE: -2.2656\n",
            "\n",
            "SENT 199: ['چ', 'ق', 'د', 'ر', '<b>', 'ب', 'ا', 'و', 'ج', 'و', 'د', '<b>', 'ا', 'و', '<b>', 'ر', 'و', 'ی', 'ا', 'ی', '<b>', 'ر', 'س', 'ی', 'د', 'ن', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', 'ت', 'ظ', 'ا', 'ر', '<b>', 'ب', 'ه', '<b>', 'ن', 'ظ', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د']\n",
            "PRED 199: cheqadr baa vojud e u tasavvoraati taraf be parviz dur az amaan be nazar miaayad\n",
            "PRED SCORE: -2.1600\n",
            "\n",
            "SENT 200: ['ک', 'م', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ب', '<b>', 'ج', 'و', 'ش', '<b>', 'م', 'و', 'ق', 'ع', '<b>', 'پ', 'ر', '<b>', 'ک', 'ر', 'د', 'ن', '<b>', 'ف', 'ن', 'ج', 'ا', 'ن', '<b>', 'چ', 'ا', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'ن', 'گ', 'ش', 'ت', 'ش', '<b>', 'چ', 'ک', 'ی', 'د', '<b>', 'و', '<b>', 'س', 'و', 'خ', 'ت', '<b>', 'ا', 'م', 'ا', '<b>', 'د', 'س', 'ت', 'ا', 'ن', 'ش', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ی', 'د']\n",
            "PRED 200: kami az aab e jush tasavvoraati por por farqi va sokut e lezzatbakhshi mikhaast o sokut mikardand\n",
            "PRED SCORE: -5.1842\n",
            "\n",
            "SENT 201: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'خ', 'د', 'ا', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ک', 'م', 'ک', '<b>', 'ا', 'ز', '<b>', 'ا', 'س', 'م', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'ف', 'ر', 'س', 'ت', 'ا', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ی', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'چ', 'ا', 'ی', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'د', 'س', 'ت', 'ا', 'ن', 'ش', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'چ', 'و', 'ن', '<b>', 'م', 'ط', 'م', 'ی', 'ن', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ب', 'ت', 'و', 'ا', 'ن', 'د', '<b>', 'ب', 'ا', '<b>', 'ا', 'ر', 'ا', 'م', 'ش', '<b>', 'ا', 'ز', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'پ', 'ذ', 'ی', 'ر', 'ا', 'ی', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 201: engaar khodaa ro baraaye raa khord az a d be zamin ye bishtari bejangam ke baa hamsafaraanash daad ke baa zamin daad\n",
            "PRED SCORE: -4.7106\n",
            "\n",
            "SENT 202: ['م', 'خ', 'ص', 'و', 'ص', 'ا', '<b>', 'د', 'ر', '<b>', 'ج', 'ه', 'ت', 'ی', '<b>', 'ن', 'ش', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'م', 'ع', 'ر', 'ض', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'م', 'س', 'ت', 'ق', 'ی', 'م', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'ب', 'ا', 'ش', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'س', 'ن', 'گ', 'ی', 'ن', 'ی', '<b>', 'ن', 'گ', 'ا', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ر', 'و', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ح', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 202: makhsusan dar kasi neshast ke dar masalan negaah negah aamad ammaa mibinand\n",
            "PRED SCORE: -3.3107\n",
            "\n",
            "SENT 203: ['د', 'ل', 'ش', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ا', 'ن', 'س', 'ت', '<b>', 'ب', 'ه', '<b>', 'ر', 'ا', 'ح', 'ت', 'ی', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', '<b>', 'ک', 'ن', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ش', 'ر', 'م', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'و', '<b>', 'پ', 'ا', '<b>', 'گ', 'ی', 'ر', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ح', 'ض', 'و', 'ر', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'م', 'ا', 'ن', 'ع', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 203: delash mikhaast khodash ham motevajjeh be paa ye ishun o maa qabul mishod\n",
            "PRED SCORE: -2.5512\n",
            "\n",
            "SENT 204: ['م', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'چ', 'ط', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ا', 'ن', 'د', '<b>', 'ب', 'ا', '<b>', 'ا', 'ن', '<b>', 'ا', 'ر', 'ا', 'م', 'ش', '<b>', 'ب', 'ا', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ص', 'ح', 'ب', 'ت', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 204: maande bud parviz chetowr mikhaastam baa aan aaraamesh baa e baqiye saakhtegi konad\n",
            "PRED SCORE: -3.2163\n",
            "\n",
            "SENT 205: ['ز', 'ی', 'ر', 'چ', 'ش', 'م', 'ی', '<b>', 'ب', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 205: zir e be shamsi negaah kard\n",
            "PRED SCORE: -0.1502\n",
            "\n",
            "SENT 206: ['ح', 'س', 'ا', 'ب', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'ل', 'ک', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ل', 'ب', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ا', 'و', 'ی', 'ز', 'ا', 'ن', '<b>', 'و', '<b>', 'ا', 'ب', 'ر', 'و', 'ه', 'ا', 'ی', '<b>', 'د', 'ر', 'ه', 'م', 'ش', '<b>', 'ه', 'ز', 'ا', 'ر', '<b>', 'م', 'ع', 'ن', 'ا', '<b>', 'م', 'ی', 'د', 'ا', 'د']\n",
            "PRED 206: hesaabi tu ye chasb bud va shabhaa ye suznaakash o saabeqei\n",
            "PRED SCORE: -2.6742\n",
            "\n",
            "SENT 207: ['ب', 'خ', 'ص', 'و', 'ص', '<b>', 'ک', 'ه', '<b>', 'ه', 'ر', '<b>', 'چ', 'ن', 'د', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'چ', 'ش', 'م', '<b>', 'غ', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'غ', 'ل', 'ی', 'ظ', 'ی', '<b>', 'ن', 'ث', 'ا', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'ا', 'م', '<b>', 'ح', 'ر', 'ف', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ب', 'ر', 'ع', 'ک', 'س', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'ش', 'ک', 'ر', 'پ', 'ر', 'ا', 'ن', 'ی', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ح', 'س', 'ا', 'ب', 'ی', '<b>', 'ب', 'ه', '<b>', 'و', 'ج', 'د', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ت', 'ح', 'س', 'ی', 'ن', '<b>', 'ب', 'ر', 'ا', 'ن', 'گ', 'ی', 'ز', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'ن', 'د']\n",
            "PRED 207: be ke har chand raaze be yek haal ye parviz negaraan mikard ke az she r e parviz khandeash mikard\n",
            "PRED SCORE: -3.7858\n",
            "\n",
            "SENT 208: ['م', 'ا', 'د', 'ر', 'ب', 'ز', 'ر', 'گ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ج', 'و', 'ن', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'پ', 'س', 'ر', 'ی', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ب', 'ب', 'ا', 'ل', 'ی']\n",
            "PRED 208: maadarbozorg baa labkhand goft shamsi jun be khaater e daashte baayad be khodet bezaar\n",
            "PRED SCORE: -2.5373\n",
            "\n",
            "SENT 209: ['ه', 'ی', 'چ', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ج', 'ا', 'ن', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'م', 'ج', 'ل', 'س', '<b>', 'گ', 'ر', 'م', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 209: hichvaqt parviz motemadden aanqadr garm kone\n",
            "PRED SCORE: -1.9316\n",
            "\n",
            "SENT 210: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ب', 'ی', '<b>', 'م', 'ی', 'ل', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'و', 'چ', 'ی', 'ک', '<b>', 'ش', 'م', 'ا', 'س', 'ت', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 210: shamsi baa labkhandi bi riaa goft haddeaqal harfet khaale jun\n",
            "PRED SCORE: -1.1888\n",
            "\n",
            "SENT 211: ['م', 'ا', 'د', 'ر', 'ب', 'ز', 'ر', 'گ', '<b>', 'ب', 'ه', '<b>', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ی', '<b>', 'خ', 'و', 'د', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'د', 'ل', 'ت', '<b>', 'ن', 'م', 'ی', 'ا', 'د', '<b>', 'ز', 'ن', 'ش', '<b>', 'ب', 'د', 'ی']\n",
            "PRED 211: maadarbozorg be shukhi goft bi khod nist delet khodamo komak bedi\n",
            "PRED SCORE: -1.2640\n",
            "\n",
            "SENT 212: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'و', 'ر', '<b>', 'ش', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ح', 'ل', 'ق', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'د', 'ر', '<b>', 'و', 'ص', 'ر', 'ت', 'ش', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 212: parviz dastash raa dowr e khaane ye maadarash ashk zad va baa molaaheze e zaifi neshast\n",
            "PRED SCORE: -2.9769\n",
            "\n",
            "SENT 213: ['ب', 'ر', '<b>', 'ع', 'ک', 'ی', '<b>', 'ا', 'ی', 'ن', '<b>', 'م', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'م', 'ا', 'د', 'ر', 'ی', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', 'م', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن', '<b>', 'ه', 'ر', '<b>', 'چ', 'ن', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ی', 'ک', '<b>', 'ذ', 'ر', 'ه', '<b>', 'ه', 'م', '<b>', 'ن', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ه', 'ش', '<b>', 'خ', 'ر', 'د', 'ه', '<b>', 'ب', 'گ', 'ی', 'ر', 'م', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ز', 'و', 'د', '<b>', 'ب', 'ه', '<b>', 'ز', 'و', 'د', '<b>', 'د', 'ل', 'ت', 'ن', 'گ', '<b>', 'ش', 'م', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ه']\n",
            "PRED 213: kamkam in manam ke be khaater daade e hamchin ham nabaasham\n",
            "PRED SCORE: -2.6273\n",
            "\n",
            "SENT 214: ['م', 'ا', 'د', 'ر', 'ب', 'ز', 'ر', 'گ', '<b>', 'ب', 'ا', '<b>', 'خ', 'ن', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ا', 'ز', '<b>', 'س', 'ر', '<b>', 'ر', 'ض', 'ا', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', '<b>', 'پ', 'د', 'ر', '<b>', 'ص', 'ل', 'و', 'ا', 'ت', 'ی']\n",
            "PRED 214: maadarbozorg baa khaanomhaa az sar goft ey pedar e badakhlaaqie\n",
            "PRED SCORE: -2.4932\n",
            "\n",
            "SENT 215: ['خ', 'و', 'ب', '<b>', 'ب', 'ل', 'د', 'ی', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ت', 'و', 'ی', '<b>', 'د', 'ل', '<b>', 'ج', 'ا', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 215: khub budi khodeto tu ye del e man\n",
            "PRED SCORE: -1.3258\n",
            "\n",
            "SENT 216: ['م', 'ی', '<b>', 'د', 'و', 'ن', 'ی', '<b>', 'چ', 'ن', 'د', '<b>', 'و', 'ق', 'ت', 'ه', '<b>', 'ن', 'د', 'ی', 'د', 'م', 'ت']\n",
            "PRED 216: miduni chand vaqte nabaashe\n",
            "PRED SCORE: -1.3153\n",
            "\n",
            "SENT 217: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ذ', 'ا', 'ر', 'ی', 'ن', '<b>', 'ب', 'ه', '\\u200c', 'ح', 'س', 'ا', 'ب', '<b>', 'گ', 'ر', 'ف', 'ت', 'ا', 'ر', 'ی', 'ه', 'ا', 'م']\n",
            "PRED 217: parviz baa labkhand goft be asabaaniyat nemigam\n",
            "PRED SCORE: -2.3450\n",
            "\n",
            "SENT 218: ['م', 'ن', '<b>', 'ب', 'ع', 'د', '<b>', 'ت', 'ل', 'ا', 'ف', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 218: man ba d owqaat mikonam khaale jun\n",
            "PRED SCORE: -0.2867\n",
            "\n",
            "SENT 219: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ب', 'ا', 'ر', 'ی', '<b>', 'ن', 'ث', 'ا', 'ر', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'ن', 'ا', 'د', 'ی', 'د', 'ه', '<b>', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 219: shamsi dobaare negaah e sarhang baalaa negaahash kard va parviz aan raa khandidand\n",
            "PRED SCORE: -1.1661\n",
            "\n",
            "SENT 220: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ظ', 'ر', 'ف', '<b>', 'ا', 'ش', 'ی', '<b>', 'ر', 'ا', '<b>', 'ک', 'ه', '<b>', 'ت', 'ز', 'ی', 'ی', 'ن', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', 'ش', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ف', 'ر', 'م', 'ا', 'ی', 'ی', 'د', '<b>', 'ت', 'ا', '<b>', 'س', 'ر', 'د', '<b>', 'ن', 'ش', 'د', 'ه']\n",
            "PRED 220: turaan cheshm jeddi raa ke taqriban karde bud va goft befarmaaid\n",
            "PRED SCORE: -1.3240\n",
            "\n",
            "SENT 221: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ز', 'ا', '<b>', 'ر', 'و', 'ی', '<b>', 'ش', 'ا', 'ن', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ب', 'ر', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', 'ب', 'ه']\n",
            "PRED 221: parviz dastash raa jaa ye zamin shaakhe bardaasht va goft be to\n",
            "PRED SCORE: -2.5246\n",
            "\n",
            "SENT 222: ['ا', 'ی', 'ن', '<b>', 'ا', 'ش', '<b>', 'خ', 'و', 'ر', 'د', 'ن', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 222: in az and daare\n",
            "PRED SCORE: -0.0778\n",
            "\n",
            "SENT 223: ['م', 'ا', 'د', 'ر', 'ب', 'ز', 'ر', 'گ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ش', 'ا', 'ل', 'ا', '<b>', 'ع', 'ر', 'و', 'س', 'ی', 'ت', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ش', 'ا', 'ل', 'ا', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن', '<b>', 'ا', 'ن', 'و', 'ق', 'ت', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'ب', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', '<b>', 'ز', 'ی', 'ر', '<b>', 'ا', 'ن', 'د', 'ا', 'خ', 'ت', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'خ', 'ن', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 223: maadarbozorg aashub arusi maadar parviz be zir e samaavar goft istaad\n",
            "PRED SCORE: -1.7164\n",
            "\n",
            "SENT 224: ['ح', 'ض', 'و', 'ر', '<b>', 'ا', 'و', '<b>', 'چ', 'ه', '<b>', 'ا', 'م', 'ن', 'ی', 'ت', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 224: qabulesh e u che ahammiyati bud\n",
            "PRED SCORE: -0.6020\n",
            "\n",
            "SENT 225: ['ج', 'ا', 'د', 'و', 'ی', '<b>', 'ک', 'ل', 'ا', 'م', 'ش', '<b>', 'و', '<b>', 'و', 'س', 'ع', 'ت', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ب', 'ه', '<b>', 'ه', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'م', 'ر', 'د', '<b>', 'ا', 'ر', 'ز', 'و', 'ه', 'ا', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ر', 'ا', 'ه', '<b>', 'ر', 'س', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 225: eyd e kaamyaar o sokut negaahash negaahash be har haal e az raah miresidand\n",
            "PRED SCORE: -3.4084\n",
            "\n",
            "SENT 226: ['ب', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'س', 'ا', 'د', 'گ', 'ی', '<b>', 'ا', 'ی', 'ا', '<b>', 'ا', 'م', 'ن', 'ی', 'ت', '<b>', 'گ', 'م', '\\u200c', 'ش', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ک', 'ه', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ب', 'و', 'د']\n",
            "PRED 226: be hamin shabih ey baayad mardhaa ke vaase boqz bud hamaanjaa bud\n",
            "PRED SCORE: -2.9371\n",
            "\n",
            "SENT 227: ['ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ف', 'ا', 'و', 'ت', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ب', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'ح', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 227: foruq ashkhaa ye khodash baa parviz raa kaamelan hess mikard\n",
            "PRED SCORE: -1.3577\n",
            "\n",
            "SENT 228: ['ا', 'و', '<b>', 'ی', 'ک', '<b>', 'م', 'ر', 'د', '<b>', 'ک', 'ا', 'م', 'ل', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ا', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'خ', 'ص', 'و', 'ص', 'ی', 'ا', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'د', 'ر', '<b>', 'ی', 'ک', '<b>', 'م', 'ر', 'د', '<b>', 'ک', 'ا', 'م', 'ل', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'ع', 'ا', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'ه', 'ر', 'گ', 'و', 'ن', 'ه', '<b>', 'ت', 'ظ', 'ا', 'ه', 'ر', '<b>', 'و', '<b>', 'ت', 'ج', 'ا', 'ه', 'ل', '<b>', 'و', '<b>', 'ش', 'ر', 'م']\n",
            "PRED 228: u yek mard e kaaresh bud baa tamaam e qazalhaa az sarhang aashnaa baashad\n",
            "PRED SCORE: -2.3977\n",
            "\n",
            "SENT 229: ['چ', 'ق', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ع', 'ج', 'ی', 'ب', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'ا', 'و', '<b>', 'ک', 'م', '<b>', 'ک', 'م', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ع', 'ن', 'و', 'ا', 'ن', '<b>', 'ی', 'ک', '<b>', 'ا', 'د', 'م', '<b>', 'ز', 'ن', 'د', 'ه', '<b>', 'ب', 'ا', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'خ', 'ص', 'و', 'ص', 'ی', 'ا', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ا', 'ز', '<b>', 'ت', 'ر', 'س', '<b>', 'پ', 'د', 'ر', '<b>', 'د', 'ر', '<b>', 'خ', 'ل', 'و', 'ت', '<b>', 'و', 'ج', 'و', 'د', 'ش', '<b>', 'ح', 'ب', 'س', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ش', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 229: cheqadr baraayash keshid ke dar kenaar e u kam qarq e fekr karde bud ke hazz nemikard\n",
            "PRED SCORE: -2.7060\n",
            "\n",
            "SENT 230: ['ی', 'ک', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ج', 'ا', 'ی', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ت', 'ص', 'و', 'ر', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ح', 'ر', 'ا', 'ر', 'ت', '<b>', 'د', 'س', 'ت', 'ا', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'و', 'ی', '<b>', 'ش', 'ا', 'ن', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ع', 'ا', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'م', 'ح', 'ب', 'ت', 'ش', '<b>', 'ب', 'ر', '<b>', 'خ', 'و', 'د', '<b>', 'ل', 'ر', 'ز', 'ی', 'د']\n",
            "PRED 230: yekdaf e khodash raa jaa ye shamsi qabul kard va az tahammol e dar badraqeash shod\n",
            "PRED SCORE: -2.3164\n",
            "\n",
            "SENT 231: ['ا', 'و', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'ب', 'ا', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'و', 'ج', 'و', 'د', 'ش']\n",
            "PRED 231: u raa mikhaast baa tamaam e vojudash\n",
            "PRED SCORE: -0.4747\n",
            "\n",
            "SENT 232: ['ا', 'ی', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'ب', 'ی', '<b>', 'ص', 'د', 'ا', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 232: aayaa parviz in faryaad e bi sedaa raa mishenid\n",
            "PRED SCORE: -0.0185\n",
            "\n",
            "SENT 233: ['د', 'ر', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ب', 'د', 'ر', 'ق', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ا', 'ز', '<b>', 'ج', 'ا', '<b>', 'ب', 'ر', 'خ', 'ا', 'س', 'ت', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ش', 'ل', 'و', 'غ', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'د', 'ی', 'د', 'ن', 'ش', '<b>', 'ب', 'ه', 'ر', 'ه', '<b>', 'ب', 'ر', 'د']\n",
            "PRED 233: dar haqiqat e baqiye baraaye kotak engaar az jaa barkhaast va az she d baraaye zohr baraaye cheshmet\n",
            "PRED SCORE: -3.5143\n",
            "\n",
            "SENT 234: ['ی', 'ک', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'گ', 'ر', 'ه', '<b>', 'خ', 'و', 'ر', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ا', 'ن', '<b>', 'ه', 'م', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'و', '<b>', 'گ', 'ذ', 'ر', 'ا', '<b>', 'ب', 'و', 'د']\n",
            "PRED 234: yek lahze negaah e parviz dar baraabarash gereh khord ammaa lab aamad\n",
            "PRED SCORE: -2.6090\n",
            "\n",
            "SENT 235: ['چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ش', 'د']\n",
            "PRED 235: cheshmaanash ye foruq motevajjeh e fereydun shod\n",
            "PRED SCORE: -0.4810\n",
            "\n",
            "SENT 236: ['ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'ا', '<b>', 'ش', 'ی', 'ف', 'ت', 'گ', 'ی', '<b>', 'گ', 'ف', 'ت', 'ا', 'ر', '<b>', 'و', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'م', 'ج', 'ذ', 'و', 'ب', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ر', 'ق', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'ا', 'م', 'ی', 'ز', '<b>', 'م', 'ح', 'س', 'و', 'ب', '<b>', 'ش', 'د', 'ن', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ب', 'ه', '<b>', 'و', 'ض', 'و', 'ح', '<b>', 'ح', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ا', 'ب', 'ت', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ل', 'ب', 'ر', 'ی', 'ز', '<b>', 'ا', 'ز', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 236: u raa ham baa aaraambakhsh chikaar karde bud va az in aalam be boqz dukht\n",
            "PRED SCORE: -3.0229\n",
            "\n",
            "SENT 237: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'ج', 'د', 'ی', '<b>', 'و', '<b>', 'م', 'ر', 'د', 'ا', 'ن', 'ه', '<b>', 'د', 'س', 'ت', '<b>', 'ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د', '<b>', 'و', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'ر', 'ا', 'ه', 'ر', 'و', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ت', 'ا', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 237: parviz kaamelan jeddi va mardhaa dast e fereydun raa birun va fereydun khandid\n",
            "PRED SCORE: -1.6507\n",
            "\n",
            "SENT 238: ['ح', 'ا', 'ل', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ا', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'خ', 'و', 'ش', '<b>', 'و', '<b>', 'ب', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 238: haalaa parviz daasht baa mostaqim khosh be khodash mikard\n",
            "PRED SCORE: -1.7734\n",
            "\n",
            "SENT 239: ['ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ل', 'ا', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'گ', 'ف', 'ت', 'گ', 'و', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ش', 'و', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'س', 'ر', 'و', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ح', 'ا', 'ض', 'ر', 'ی', 'ن', '<b>', 'ن', 'گ', 'ذ', 'ا', 'ش', 'ت']\n",
            "PRED 239: foruq qaraar kard motevajjeh e naazanin e aanhaa shod ammaa sar e amaan neshast\n",
            "PRED SCORE: -2.3470\n",
            "\n",
            "SENT 240: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'خ', 'م', '<b>', 'ش', 'د', 'ه', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'و', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ش', 'ر', 'م', 'ی', '<b>', 'ک', 'و', 'د', 'ک', 'ا', 'ن', 'ه', '<b>', 'و', 'ل', 'ی', '<b>', 'ل', 'ب', 'ر', 'ی', 'ز', '<b>', 'ا', 'ز', '<b>', 'ر', 'ض', 'ا', 'ی', 'ت', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ه', 'م', 'گ', 'ی', '<b>', 'م', 'ث', 'ل', '<b>', 'ک', 'و', 'ی', 'ر', 'ی', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'ت', 'ش', 'ن', 'ه', '<b>', 'ب', 'ا', 'ر', 'ش', '<b>', 'ب', 'ا', 'ر', 'ا', 'ن']\n",
            "PRED 240: parviz baa mohabbat be ru ye molaaheze goft shode sar e ru ye mane\n",
            "PRED SCORE: -3.2892\n",
            "\n",
            "SENT 241: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'س', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ل', 'ا', 'م', 'ت', '<b>', 'ت', 'ا', 'س', 'ف', '<b>', 'ت', 'ک', 'ا', 'ن', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ا', 'م', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'خ', 'ه', '<b>', 'ز', 'ن', '<b>', 'چ', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 241: shaapur sari be alaamat e taassof tekaan daad va baa khande e larzaani goft aakhe resh hamchin\n",
            "PRED SCORE: -3.1467\n",
            "\n",
            "SENT 242: ['ا', 'س', 'م', 'و', 'ن', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'ن', 'ی', 'و', 'م', 'د', 'ه']\n",
            "PRED 242: aasemun ke be zamin nayumade\n",
            "PRED SCORE: -1.5013\n",
            "\n",
            "SENT 243: ['ش', 'م', 'س', 'ی', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'ا', 'ش', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ن', 'و', '<b>', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ش', 'ت', '<b>', 'ت', 'ا', '<b>', 'ر', 'ا', 'ح', 'ت', '<b>', 'ش', 'م']\n",
            "PRED 243: shamsi hamaantowr ke baa sedaa ye boland gerye goft kaash midaad\n",
            "PRED SCORE: -0.4057\n",
            "\n",
            "SENT 244: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'چ', 'ش', 'م', '<b>', 'د', 'و', 'خ', 'ت', '<b>', 'و', '<b>', 'ل', 'ب', '<b>', 'ب', 'ر', '<b>', 'ه', 'م', '<b>', 'ف', 'ش', 'ر', 'د']\n",
            "PRED 244: shaapur be parviz ke dar sokut e negaahash mikard va lab bar ham feshord\n",
            "PRED SCORE: -1.0456\n",
            "\n",
            "SENT 245: ['ش', 'گ', 'ر', 'د', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 245: shahr e shamsi bud\n",
            "PRED SCORE: -0.1076\n",
            "\n",
            "SENT 246: ['ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'د', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'گ', 'ر', 'ف', 'ت', 'ن', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ا', 'ت', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ا', 'خ', 'ر', 'ی', 'ن', '<b>', 'س', 'ل', 'ا', 'ح', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ک', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'ب', 'ه', '<b>', 'خ', 'ص', 'و', 'ص', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'ض', 'ع', 'ف', '<b>', 'پ', 'س', 'ر', 'ا', 'ن', 'ش', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'ا', 'گ', 'ا', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 246: hamishe baraaye dar e dastpokht e gurand e gurand e mohkami be etmaam pichide bud\n",
            "PRED SCORE: -4.2866\n",
            "\n",
            "SENT 247: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'ا', 'ح', 'ت', 'ی', 'ا', 'ط', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ع', 'ز', 'ی', 'ز', '<b>', 'م', 'ن', '<b>', 'ا', 'ی', 'ن', 'ا', '<b>', 'ک', 'ه', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ب', 'چ', 'ه', '<b>', 'ن', 'ی', 'س', 'ت', 'ن', 'د', '<b>', 'چ', 'ر', 'ا', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ع', 'ذ', 'ا', 'ب', '<b>', 'م', 'ی', 'د', 'ی']\n",
            "PRED 247: shaapur baa ehtiaat goft aziz e man inaa ro dige khodeto saabetqadami\n",
            "PRED SCORE: -1.5471\n",
            "\n",
            "SENT 248: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', 'ح', 'ا', 'ل', 'ت', 'ی', '<b>', 'ت', 'ه', 'ا', 'ج', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'چ', 'ه', '<b>', 'ن', 'ی', 'س', 'ت', 'ن', 'د']\n",
            "PRED 248: shamsi baa haalati ranjide goft bale\n",
            "PRED SCORE: -0.2381\n",
            "\n",
            "SENT 249: ['خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'ع', 'ق', 'ل', '<b>', 'ب', 'ه', '<b>', 'س', 'ن', '<b>', 'و', '<b>', 'س', 'ا', 'ل', 'ه']\n",
            "PRED 249: khiaal mikoni haasel be zan o goshade\n",
            "PRED SCORE: -1.0760\n",
            "\n",
            "SENT 250: ['ا', 'ز', 'ش', '<b>', 'ب', 'پ', 'ر', 'س', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'چ', 'ی', '<b>', 'خ', 'و', 'د', 'ش', 'و', '<b>', 'س', 'ک', 'ه', '\\u200c', 'ی', '<b>', 'ی', 'ک', '<b>', 'پ', 'و', 'ل', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 250: azash derakhshesh vaase chi khodeshun shabhaa ye yek ruz kard\n",
            "PRED SCORE: -3.2180\n",
            "\n",
            "SENT 251: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'م', 'ل', 'ا', 'ی', 'م', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'ب', 'ا', '<b>', 'ا', 'و', 'م', 'د', 'ن', 'م', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', 'ت', 'و', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ا', 'م', 'د', 'م', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 251: parviz be molaayemat goft age midunam baa emruz aanqadr miaam maadar jun\n",
            "PRED SCORE: -2.6976\n",
            "\n",
            "SENT 252: ['م', 'ن', '<b>', 'ا', 'و', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ش', 'م', 'ا']\n",
            "PRED 252: man umade budam donbaal e shomaa\n",
            "PRED SCORE: -0.0284\n",
            "\n",
            "SENT 253: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'و', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ی', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'م', 'ن']\n",
            "PRED 253: shamsi baa asabaaniyat goft umade budi donbaal e man\n",
            "PRED SCORE: -0.1205\n",
            "\n",
            "SENT 254: ['ی', 'ا', '<b>', 'ا', 'و', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ی', '<b>', 'ع', 'ق', 'ب', '<b>', 'د', 'ل', 'ت']\n",
            "PRED 254: yaa emshab budi aqab e kolli\n",
            "PRED SCORE: -2.3693\n",
            "\n",
            "SENT 255: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'ک', 'و', 'ر', 'ه', '<b>', 'د', 'ر', '<b>', 'ر', 'ف', 'ت']\n",
            "PRED 255: shaapur az kure dar raft\n",
            "PRED SCORE: -0.0020\n",
            "\n",
            "SENT 256: ['پ', 'ن', 'ا', 'ه', '<b>', 'ب', 'ر', '<b>', 'خ', 'د', 'ا', '<b>', 'ز', 'ن', '<b>', 'و', 'ل', 'ش', 'و', 'ن', '<b>', 'ک', 'ن', '<b>', 'و', 'ا', 'ل', 'ا', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ب', 'ذ', 'ا', 'ر', '<b>', 'ب', 'ر', 'ن', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', 'و', 'ن']\n",
            "PRED 256: panaah bar khodaa zan e arusam kon vaaqean be khodaa dorost bedan\n",
            "PRED SCORE: -1.5892\n",
            "\n",
            "SENT 257: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ا', 'د', '<b>', 'ز', 'د']\n",
            "PRED 257: shamsi daad zad\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 258: ['ه', 'ی', 'چ', '<b>', 'و', 'ق', 'ت', '<b>', 'ی', 'ک', '<b>', 'ذ', 'ر', 'ه', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', 'ش', 'و', 'ن', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'م', 'س', 'ی', 'و', 'ل', 'ی', 'ت', '<b>', 'ن', 'ک', 'ر', 'د', 'ی', '<b>', 'ح', 'ا', 'ل', 'ا', 'م', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ا', 'ز', '<b>', 'س', 'ر', '<b>', 'ب', 'ا', 'ز', 'ش', 'و', 'ن', '<b>', 'ک', 'ن', 'ی', '<b>', 'ه', 'ی', 'چ', '<b>', 'و', 'ق', 'ت', '<b>', 'ش', 'د', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'پ', 'د', 'ر', 'ی', '<b>', 'ک', 'ن', 'ی', '<b>', 'و', '<b>', 'ن', 'ص', 'ی', 'ح', 'ت', 'ش', 'و', 'ن', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 258: hichvaqt yek zarre dar tehraan e ehsaas e zajresh dahande nadi\n",
            "PRED SCORE: -2.8426\n",
            "\n",
            "SENT 259: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'خ', 'ش', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه']\n",
            "PRED 259: shaapur baa khodam goft na\n",
            "PRED SCORE: -0.0126\n",
            "\n",
            "SENT 260: ['ا', 'خ', 'ه', '<b>', 'ا', 'ز', '<b>', 'ز', 'ی', 'ر', '<b>', 'ب', 'و', 'ت', 'ه', '<b>', 'ب', 'ه', '<b>', 'ع', 'م', 'ل', '<b>', 'ا', 'و', 'م', 'د', 'ن']\n",
            "PRED 260: aakhe az zir e qalb e be dovom aavordi\n",
            "PRED SCORE: -2.4318\n",
            "\n",
            "SENT 261: ['م', 'گ', 'ه', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ا', 'ن', 'د', '<b>', 'ک', 'ه', '<b>', 'ن', 'ص', 'ی', 'ح', 'ت', 'ش', 'و', 'ن', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 261: mage injaast ke negaheshun konam\n",
            "PRED SCORE: -0.2397\n",
            "\n",
            "SENT 262: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'پ', 'د', 'ر', '<b>', 'ب', 'و', 'د', 'ن', '<b>', 'ی', 'ع', 'ن', 'ی', '<b>', 'ن', 'و', 'ن', '<b>', 'د', 'ر', 'ا', 'و', 'ر', 'د', 'ن']\n",
            "PRED 262: shamsi goft to hamishe fekr kardi pedar e yek gale nagu aashnaaimun\n",
            "PRED SCORE: -2.6125\n",
            "\n",
            "SENT 263: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ت', 'ل', 'خ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'د', 'ا', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'م', 'ن', '<b>', 'ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'ش', 'ر', 'ا', 'ف', 'ت', 'م', 'ن', 'د', 'ا', 'ن', 'ه', '<b>', 'ک', 'ا', 'ر', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'و', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ب', 'ن', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ز', 'ن', '<b>', 'و', '<b>', 'ب', 'چ', 'ه', '<b>', 'ب', 'و', 'د', 'م']\n",
            "PRED 263: shaapur baa labkhandi talkh goft khodaa midune miduni ke hamishe zanaanast o hamishe bekhune\n",
            "PRED SCORE: -1.1887\n",
            "\n",
            "SENT 264: ['ب', 'گ', 'ذ', 'ر', '<b>', 'ک', 'ه', '<b>', 'ا', 'خ', 'ر', '<b>', 'ع', 'م', 'ر', 'ی', '<b>', 'ش', 'د', 'م', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'و', '<b>', 'ا', 'و', 'ن', '<b>', 'ع', 'ی', 'ب', '<b>', 'ت', 'و', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'ا', 'و', 'ر', '<b>', 'ک', 'ن', 'ی', '<b>', 'پ', 'س', 'ر', 'ا', 'ت', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ش', 'د', 'ن', 'د']\n",
            "PRED 264: be qowl e aakhar e diplom shodam taavaane morakhas konid o un band e to munde bud\n",
            "PRED SCORE: -5.4058\n",
            "\n",
            "SENT 265: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'ا', 'م', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'س', '<b>', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 265: parviz be miaan aamad va goft to ro be khodaa be khodaa konid\n",
            "PRED SCORE: -0.6520\n",
            "\n",
            "SENT 266: ['ا', 'ص', 'ل', 'ا', '<b>', 'م', 'ق', 'ص', 'ر', '<b>', 'م', 'ن', 'م']\n",
            "PRED 266: aslan moqasser manam\n",
            "PRED SCORE: -0.1461\n",
            "\n",
            "SENT 267: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'س', 'ر', 'د', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ز', 'ن', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'س', 'ت', 'ی', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'ا', 'م', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', 'ی']\n",
            "PRED 267: shamsi be sardi goft to zan e yek domun be khodam migofti\n",
            "PRED SCORE: -0.3610\n",
            "\n",
            "SENT 268: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ا', 'ن', 'و', 'م', '<b>', 'م', 'گ', 'ه', '<b>', 'ز', 'ن', '<b>', 'گ', 'ر', 'ف', 'ت', 'ن', '<b>', 'م', 'ث', 'ل', '<b>', 'خ', 'ر', 'ی', 'د', 'ن', '<b>', 'پ', 'ی', 'ر', 'ه', 'ن', '<b>', 'ت', 'ن', 'ه']\n",
            "PRED 268: shaapur goft khaanum mage zan e gardan mesl e heqaarat mishe\n",
            "PRED SCORE: -1.9518\n",
            "\n",
            "SENT 269: ['ا', 'و', 'ن', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'ب', 'ا', 'ه', 'ا', 'ش', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 269: un mikhaad yek jur baahaash bekesham\n",
            "PRED SCORE: -1.6838\n",
            "\n",
            "SENT 270: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'ا', 'گ', 'ه', '<b>', 'خ', 'و', 'ب', '<b>', 'ر', 'و', '<b>', 'ا', 'ز', '<b>', 'ب', 'د', '<b>', 'ت', 'ش', 'خ', 'ی', 'ص', '<b>', 'م', 'ی', 'د', 'ا', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'س', 'ت', '<b>', 'ر', 'و', 'ی', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'د', 'خ', 'ت', 'ر', 'ی', '<b>', 'ن', 'م', 'ی', 'ذ', 'ا', 'ش', 'ت']\n",
            "PRED 270: shamsi goft un age khub ro az khodaa qaael midaad ke dastet nayumad\n",
            "PRED SCORE: -2.7011\n",
            "\n",
            "SENT 271: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'ز', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'خ', 'و', 'ب', 'ه', '<b>', 'ا', 'ز', '<b>', 'ت', 'ب', 'ا', 'ر', '<b>', 'خ', 'و', 'د', 'ت', 'ن', 'د', '<b>', 'و', '<b>', 'ا', 'ص', 'ل', '<b>', 'و', '<b>', 'ن', 'ص', 'ب', 'ش', '<b>', 'خ', 'ت', 'م', '<b>', 'م', 'ی', 'ش', 'ه', '<b>', 'ب', 'ه', '<b>', 'ش', 'ا', 'ز', 'د', 'ه', '<b>', 'ف', 'ل', 'ا', 'ن', '<b>', 'ا', 'ل', 'د', 'و', 'ل', 'ه']\n",
            "PRED 271: shaapur baa puzkhand goft haalaa khube az qabl khoshhaalam be baqalet naakhunak mishe\n",
            "PRED SCORE: -3.9056\n",
            "\n",
            "SENT 272: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'ن', 'ا', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ی']\n",
            "PRED 272: shamsi baa asabaaniyat goft kenaaye mizani\n",
            "PRED SCORE: -0.2712\n",
            "\n",
            "SENT 273: ['خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'م', 'ن', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', 'ی', '<b>', 'ا', 'و', 'ل', 'ا', 'د', 'م', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ر', 'و', 'ش', 'م']\n",
            "PRED 273: khiaal mikoni man khoshbakhti ro be in chizhaa beresim\n",
            "PRED SCORE: -1.9155\n",
            "\n",
            "SENT 274: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'ت', 'ا', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'ص', 'د', '<b>', 'ج', 'ا', '<b>', 'ن', 'ر', 'ف', 'ت', 'ی', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'گ', 'ا', 'ر', 'ی']\n",
            "PRED 274: shaapur goft mage taa emruz zad jaa ye qaribast bekhaabi\n",
            "PRED SCORE: -2.0281\n",
            "\n",
            "SENT 275: ['ع', 'ز', 'ی', 'ز', '<b>', 'م', 'ن', '<b>', 'ب', 'ر', 'ی', 'ز', '<b>', 'د', 'و', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'ر', 'و', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'د', 'ل', '<b>', 'ص', 'ا', 'ب', '<b>', 'م', 'ر', 'د', 'ه', '<b>', 'گ', 'ی', 'ر', '<b>', 'ک', 'ن', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', '<b>', 'س', 'ر', 'ش', '<b>', 'ن', 'م', 'ی', 'ش', 'ه']\n",
            "PRED 275: aziz e man baraat dowr e in harfhaa ro vaqti morde kone in shaakhe\n",
            "PRED SCORE: -2.9822\n",
            "\n",
            "SENT 276: ['د', 'ل', '<b>', 'م', 'ی', 'ر', 'ه', '<b>', 'ت', 'و', '<b>', 'ه', 'م', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش']\n",
            "PRED 276: dah giri to ham donbaalesh\n",
            "PRED SCORE: -1.6219\n",
            "\n",
            "SENT 277: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ر', '<b>', 'د', 'ل', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ت', 'ح', 'س', 'ی', 'ن', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'چ', 'ن', 'ا', 'ن', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'م', 'ا', 'ن', 'د']\n",
            "PRED 277: parviz dar dah pedarash raa tahsin kard va hanuz saaket maand\n",
            "PRED SCORE: -0.7413\n",
            "\n",
            "SENT 278: ['م', 'ی', 'گ', 'ی', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', 'ش', '<b>', 'ا', 'ل', '<b>', 'و', '<b>', 'ب', 'ل', 'ه', '<b>', 'ب', 'ا', 'ش', 'ه']\n",
            "PRED 278: migi dokhtare o az o baashe\n",
            "PRED SCORE: -0.7208\n",
            "\n",
            "SENT 279: ['م', 'ی', 'گ', 'ی', '<b>', 'د', 'و', '<b>', 'ت', 'ا', '<b>', 'ز', 'ن', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 279: migi do taa zan daare\n",
            "PRED SCORE: -0.0056\n",
            "\n",
            "SENT 280: ['د', 'ا', 'ش', 'ت', 'ه', '<b>', 'ب', 'ا', 'ش', 'ه']\n",
            "PRED 280: daashte baashe\n",
            "PRED SCORE: -0.0209\n",
            "\n",
            "SENT 281: ['ب', 'ه', '<b>', 'م', 'ا', '<b>', 'چ', 'ه', '<b>', 'م', 'ر', 'ب', 'و', 'ط']\n",
            "PRED 281: be maa che marbut\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 282: ['ت', 'و', 'ن', 'س', 'ت', 'ه', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه']\n",
            "PRED 282: unvaqt gereftaare\n",
            "PRED SCORE: -0.3889\n",
            "\n",
            "SENT 283: ['ب', 'ع', 'د', 'ش', 'م', '<b>', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ه', 'ی', 'م', '<b>', 'ب', 'ا', '<b>', 'ب', 'ا', 'ب', 'ا', 'ش', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ن', 'ی', 'م']\n",
            "PRED 283: ba desh maa ke mituni baa baabaa zendegi konim\n",
            "PRED SCORE: -1.6396\n",
            "\n",
            "SENT 284: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'خ', 'ا', 'ن', 'و', 'م', '<b>', 'ه', 'م', '<b>', 'ک', 'ه', '<b>', 'ه', 'م', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ا', 'س', 'ن', 'د', '<b>', 'ح', 'ر', 'ف', '<b>', 'ن', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 284: turaan khaanum ham ke hamechi harf nadaare\n",
            "PRED SCORE: -0.0032\n",
            "\n",
            "SENT 285: ['ش', 'م', 'س', 'ی', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ب', 'ا', '<b>', 'ب', 'ی', '<b>', 'م', 'ی', 'ل', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ب', 'چ', 'ه', '<b>', 'س', 'ت', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ل', 'ا', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'ل', 'ا', 'ب', 'د', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ب', 'و', 'د', 'ه', '<b>', 'ک', 'ه', '<b>', 'د', 'ل', '<b>', 'پ', 'س', 'ر', 'ت', '<b>', 'پ', 'ی', 'ش', 'ش', '<b>', 'گ', 'ی', 'ر', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 285: shamsi miaan e gerye baa bi nidaari goft foruq aanqadr lak ke dah modeleshe\n",
            "PRED SCORE: -3.0702\n",
            "\n",
            "SENT 286: ['ش', 'م', 'س', 'ی', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'و', 'خ', 'ت', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', 'ب', '<b>', 'د', 'ی', 'د', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ا', 'ز', '<b>', 'ج', 'ا', '<b>', 'ب', 'ل', 'ن', 'د', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 286: shamsi navaazeshash raa be parviz dust dukht va moqaabel e dar badraqeash e mane\n",
            "PRED SCORE: -1.5203\n",
            "\n",
            "SENT 287: ['ح', 'ت', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ن', 'ف', 'ه', 'م', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'چ', 'ط', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'س', 'ر', '<b>', 'د', 'ر', '<b>', 'ا', 'و', 'ر', 'د', 'ه']\n",
            "PRED 287: hattaa khodesh ham nafahmid bud chetowr az khaane ye sar e arusi\n",
            "PRED SCORE: -2.0496\n",
            "\n",
            "SENT 288: ['ص', 'د', 'ا', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ر', 'ا', '<b>', 'ا', 'ه', 'س', 'ت', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 288: sedaa ye shaapur raa aaheste\n",
            "PRED SCORE: -1.6534\n",
            "\n",
            "SENT 289: ['ب', 'ذ', 'ا', 'ر', '<b>', 'ب', 'ر', 'ن', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'د', 'ل', 'ش', 'و', 'ن']\n",
            "PRED 289: bezaar jun donbaal e delesh\n",
            "PRED SCORE: -0.9646\n",
            "\n",
            "SENT 290: ['ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ه', 'م', '<b>', 'ب', 'ی', 'ش', 'ت', 'ر', '<b>', 'ا', 'ح', 'ت', 'ر', 'ا', 'م', '<b>', 'د', 'ا', 'ر', 'ی']\n",
            "PRED 290: intowri khodet ham bishtar ehteraam daari\n",
            "PRED SCORE: -0.0087\n",
            "\n",
            "SENT 291: ['ت', 'و', '<b>', 'ت', 'ا', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'و', 'ظ', 'ی', 'ف', '\\u200c', 'ی', '<b>', 'م', 'ا', 'د', 'ر', 'ی', 'ت', '<b>', 'ر', 'و', '<b>', 'ا', 'ن', 'ج', 'ا', 'م', '<b>', 'د', 'ا', 'د', 'ی', '<b>', 'ب', 'ا', 'ق', 'ی', 'ش', '<b>', 'م', 'ا', 'ل', '<b>', 'ا', 'و', 'ن', 'ا', 'س', 'ت']\n",
            "PRED 291: to taa emruz zendeam e maadarish ro enkaar daasht ablahaan maah e toand\n",
            "PRED SCORE: -3.9226\n",
            "\n",
            "SENT 292: ['ب', 'ه', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ا', 'ی', 'ن', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ی', 'ک', '<b>', 'ر', 'و', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'م', 'ن', '<b>', 'ا', 'ن', 'ت', 'ظ', 'ا', 'ر', 'ش', '<b>', 'ر', 'و', '<b>', 'د', 'ا', 'ش', 'ت', 'م']\n",
            "PRED 292: be har haal in ettefaaq baayad yek ruz amali o man anjaam daashtam\n",
            "PRED SCORE: -0.7613\n",
            "\n",
            "SENT 293: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ر', 'د', 'ک', '<b>', 'ا', 'ب', '<b>', 'پ', 'ا', 'ک', 'ی', '<b>', 'ر', 'و', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ی', 'خ', 'ت', '<b>', 'ر', 'و', '<b>', 'د', 'س', 'ت', 'م', 'و', 'ن']\n",
            "PRED 293: shamsi goft mard aab miaay ro tar e ru ye khodesh ro bebus\n",
            "PRED SCORE: -2.1692\n",
            "\n",
            "SENT 294: ['د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ر', 'م', '<b>', 'د', 'س', 'ت', '<b>', 'ب', 'و', 'س']\n",
            "PRED 294: dobaare beram dast e bachche\n",
            "PRED SCORE: -0.1191\n",
            "\n",
            "SENT 295: ['پ', 'س', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ش', 'د', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'چ', 'ی']\n",
            "PRED 295: pas maadar shodi baraaye chi\n",
            "PRED SCORE: -0.0014\n",
            "\n",
            "SENT 296: ['ت', 'و', '<b>', 'ت', 'ل', 'ا', 'ش', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'ک', 'ن', '<b>', 'ب', 'ا', 'ق', 'ی', 'ش', '<b>', 'ب', 'ا', '<b>', 'خ', 'د', 'ا']\n",
            "PRED 296: to aarumtar ro bokon baayad baa khodaa\n",
            "PRED SCORE: -2.2706\n",
            "\n",
            "SENT 297: ['ا', 'خ', 'ه', '<b>', 'م', 'گ', 'ه', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ق', 'ح', 'ط', 'ه', '<b>', '<b>', 'گ', 'ف', 'ت', 'م', '<b>', 'ک', 'ه', '<b>', 'د', 'ل', '<b>', 'ا', 'ی', 'ن', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', '<b>', 'س', 'ر', 'ش', '<b>', 'ن', 'م', 'ی', 'ش', 'ه']\n",
            "PRED 297: aakhe mage dokhtar daashte goftam ke dah chaai e shohrat nemishe\n",
            "PRED SCORE: -1.2928\n",
            "\n",
            "SENT 298: ['ب', 'ع', 'د', '<b>', 'ا', 'ر', 'ا', 'م', '\\u200c', 'ت', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'س', 'ر', 'ت', '<b>', 'گ', 'ل', 'و', 'ش', '<b>', 'ح', 'س', 'ا', 'ب', 'ی', '<b>', 'گ', 'ی', 'ر', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'خ', 'ا', 'ن', 'و', 'م']\n",
            "PRED 298: ba d owqaat goft pustet gush mituni shamsi shamsi khaanum\n",
            "PRED SCORE: -1.3816\n",
            "\n",
            "SENT 299: ['ک', 'ج', 'ا', 'ی', '<b>', 'ک', 'ا', 'ر', 'ی']\n",
            "PRED 299: kojaa ye kaari\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 300: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'د', 'ر', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', 'ی', 'ی', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'گ', 'ل', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ق', 'ا', 'ل', 'ی', '<b>', 'چ', 'ش', 'م', '<b>', 'د', 'و', 'خ', 'ت']\n",
            "PRED 300: parviz naakhodaagaah dar tanhaai labkhand zad va be golestaan cheshm dukht\n",
            "PRED SCORE: -0.5002\n",
            "\n",
            "SENT 301: ['ه', 'ن', 'و', 'ز', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ق', 'ل', 'ق', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت']\n",
            "PRED 301: hanuz ba d az ehsaas e ashk e maadarash raa mibast\n",
            "PRED SCORE: -2.2243\n",
            "\n",
            "SENT 302: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'خ', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'چ', 'ه', '<b>', 'ا', 'ص', 'ل', 'ا', '<b>', 'ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 302: shamsi daasht migoft aakhe in bachche aslan intowr nabud\n",
            "PRED SCORE: -0.5702\n",
            "\n",
            "SENT 303: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'س', 'ح', 'ر', '<b>', 'ش', 'د', 'ه']\n",
            "PRED 303: engaar jur shode\n",
            "PRED SCORE: -0.3439\n",
            "\n",
            "SENT 304: ['ک', 'ی', '<b>', 'ب', 'ا', 'ل', 'ا', 'ی', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ن', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د']\n",
            "PRED 304: tebq e sangini e harf e man harf mizad\n",
            "PRED SCORE: -1.2571\n",
            "\n",
            "SENT 305: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'ش', 'و', 'خ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ن', 'ا', '<b>', 'ه', 'م', 'ش', '<b>', 'ک', 'ا', 'ر', '<b>', 'ع', 'ش', 'ق', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'س', 'و', 'ز', 'ه']\n",
            "PRED 305: shaapur baa lahni jelow goft inaa hamash kaar e pedaresh munde\n",
            "PRED SCORE: -1.7615\n",
            "\n",
            "SENT 306: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', 'خ', 'ت', '\\u200c', 'ه', 'ا', 'ی', '<b>', '*', '*', '*', '<b>', 'چ', 'ش', 'م', '<b>', 'د', 'و', 'خ', 'ت']\n",
            "PRED 306: parviz baaz ham labkhand zad va be entehaa ye kabud cheshm dukht\n",
            "PRED SCORE: -0.8412\n",
            "\n",
            "SENT 307: ['ن', 'ه']\n",
            "PRED 307: na\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 308: ['ب', 'ه', '<b>', 'ه', 'ی', 'چ', '<b>', 'ق', 'ی', 'م', 'ت', 'ی', '<b>', 'ح', 'ا', 'ض', 'ر', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'د', 'س', 'ت', '<b>', 'ب', 'د', 'ه', 'د']\n",
            "PRED 308: be hich qeymati haazer nabud foruq raa az dast bebarad\n",
            "PRED SCORE: -2.9460\n",
            "\n",
            "SENT 309: ['ح', 'ت', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'م', 'ت', 'ح', 'ی', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 309: hattaa khodash ham az in ta bir moqaabel bud\n",
            "PRED SCORE: -0.8065\n",
            "\n",
            "SENT 310: ['چ', 'ی', 'ز', 'ی', '<b>', 'د', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ا', 'و', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', 'ر', '<b>', 'و', '<b>', 'پ', 'و', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ا', 'ن', 'د', '<b>', 'و', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'پ', 'ی', 'ش', '<b>', 'م', 'ص', 'م', 'م', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 310: chizi dar negaah e u bud ke haalaa raah e naqd o bish az posht e maast\n",
            "PRED SCORE: -2.2988\n",
            "\n",
            "SENT 311: ['ش', 'ا', 'ی', 'د', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'گ', 'ن', 'ا', 'ه', '<b>', 'ر', 'س', 'و', 'ا', '<b>', 'ک', 'ر', 'د', 'ن', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'گ', 'ر', 'د', 'ن', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'ا', 'م', 'ا', '<b>', 'ی', 'ک', '<b>', 'ذ', 'ر', 'ه', '<b>', 'ه', 'م', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ت', 'ق', 'ص', 'ی', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 311: shaayad baayad gonaahi ruzi karde karde ammaa be kaarhaam migoft ammaa otaaqet\n",
            "PRED SCORE: -2.6605\n",
            "\n",
            "SENT 312: ['ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ا', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', 'ش', '<b>', 'د', 'ر', 'گ', 'ی', 'ر', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ا', 'م', 'د', 'ن', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ن', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'س', 'ت', 'ه', '<b>', 'ش', 'د', 'ن', '<b>', 'د', 'ر', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ا', 'م', 'د']\n",
            "PRED 312: aanqadr baa taassof e kot bud ke moteajjeb movaajeh dar khodash bast\n",
            "PRED SCORE: -2.7650\n",
            "\n",
            "SENT 313: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'و', '<b>', 'ج', 'د', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ت', 'ه', '<b>', 'پ', 'س', 'ر']\n",
            "PRED 313: shaapur aaraam o asabi goft chete pesaram\n",
            "PRED SCORE: -0.4201\n",
            "\n",
            "SENT 314: ['چ', 'ر', 'ا', '<b>', 'ق', 'ن', 'ب', 'ر', 'ک', '<b>', 'ز', 'د', 'ی']\n",
            "PRED 314: cheraa taaarof jeddi\n",
            "PRED SCORE: -1.0382\n",
            "\n",
            "SENT 315: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ب', 'ه', 'ت', 'ر', 'ه']\n",
            "PRED 315: parviz porsid maadar behtare\n",
            "PRED SCORE: -0.2087\n",
            "\n",
            "SENT 316: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', 'ش', '<b>', 'ن', 'ش', 'س', 'ت', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ه']\n",
            "PRED 316: shaapur moqaabelash neshast va goft behtar mishe\n",
            "PRED SCORE: -0.1058\n",
            "\n",
            "SENT 317: ['ر', 'ف', 'ت', 'ه', '<b>', 'ا', 'ش', 'پ', 'ز', 'خ', 'و', 'ن', 'ه']\n",
            "PRED 317: rafte midune\n",
            "PRED SCORE: -0.2921\n",
            "\n",
            "SENT 318: ['ن', 'م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', 'ش', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 318: nemikhaad negaraan baashi\n",
            "PRED SCORE: -0.2772\n",
            "\n",
            "SENT 319: ['د', 'ن', 'د', 'و', 'ن', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ش', 'م', 'ا', '<b>', 'ر', 'و', '<b>', 'ش', 'م', 'ر', 'د', 'ه']\n",
            "PRED 319: nemiduni shomaa ro miduni\n",
            "PRED SCORE: -1.8924\n",
            "\n",
            "SENT 320: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'م', '<b>', 'ا', 'ز', 'م', '<b>', 'د', 'ل', 'گ', 'ی', 'ر', '<b>', 'ب', 'ا', 'ش', 'ه']\n",
            "PRED 320: parviz goft nemikhaam azam mirin baashe\n",
            "PRED SCORE: -1.3200\n",
            "\n",
            "SENT 321: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ا', 'ه', 'س', 'ت', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ی', 'ک', '\\u200c', 'ک', 'م', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ج', 'ل', 'و', 'ش', '<b>', 'و', 'ا', 'ی', 'س', 'ی', 'د']\n",
            "PRED 321: shaapur aaheste goft Yen baayad towrim nistid\n",
            "PRED SCORE: -1.9202\n",
            "\n",
            "SENT 322: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'ت', 'و', 'ق', 'ع', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', 'ی', '<b>', 'ر', 'و', '<b>', 'ا', 'ز', '<b>', 'م', 'ا', '<b>', 'ن', 'د', 'ا', 'ر', 'ه', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'خ', 'و', 'د', 'ش', 'م', '<b>', 'ب', 'ه', 'ت', 'ر', 'ه', '<b>', 'و', '<b>', 'ت', 'و', '<b>', 'ه', 'م', '<b>', 'ا', 'گ', 'ه', '<b>', 'و', 'ا', 'ق', 'ع', 'ا', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ج', 'ل', 'و', 'ش', '<b>', 'و', 'ا', 'ی', 'س', 'ی', '<b>', 'پ', 'س', 'ر', 'ج', 'و', 'ن']\n",
            "PRED 322: parviz goft un albatte hamchin yidesh ro az maa baraaye maa nasaakhtand\n",
            "PRED SCORE: -1.8013\n",
            "\n",
            "SENT 323: ['ا', 'و', 'ن', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'خ', 'و', 'د', 'ش', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ش', 'م', 'ا', '<b>', 'ب', 'ه', '<b>', 'ک', 'ش', 'ت', 'ن', '<b>', 'م', 'ی', 'د', 'ه']\n",
            "PRED 323: un daare khodesh be khaater e shomaa be fekrete mide\n",
            "PRED SCORE: -0.3191\n",
            "\n",
            "SENT 324: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'ا', 'و', 'ن', '<b>', 'ن', 'خ', 'و', 'ا', 'د', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م']\n",
            "PRED 324: parviz goft age un nazdik nemitunam\n",
            "PRED SCORE: -0.2490\n",
            "\n",
            "SENT 325: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ب', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ح', 'م', 'ق', '<b>', 'ن', 'ش', 'و', '<b>', 'پ', 'س', 'ر', 'ج', 'و', 'ن']\n",
            "PRED 325: shaapur baa lahni sarzaneshbaar goft haddeaqal nagu pesaram\n",
            "PRED SCORE: -1.1281\n",
            "\n",
            "SENT 326: ['ت', 'و', '<b>', 'ا', 'د', 'م', '<b>', 'ت', 'ح', 'ص', 'ی', 'ل', 'ک', 'ر', 'د', 'ه', '<b>', 'و', '<b>', 'ر', 'و', 'ش', 'ن', '<b>', 'ف', 'ک', 'ر', 'ی', '<b>', 'ه', 'س', 'ت', 'ی']\n",
            "PRED 326: to aadam e mehrabuni o qarb fekr hasti\n",
            "PRED SCORE: -2.0619\n",
            "\n",
            "SENT 327: ['خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'ا', 'د', 'م', '<b>', 'چ', 'ن', 'د', '<b>', 'ب', 'ا', 'ر', '<b>', 'ت', 'و', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'د', 'ل', 'ش', '<b>', 'م', 'ی', 'ر', 'ه']\n",
            "PRED 327: khiaal mikoni aadam chand baar tu ye zendegit donbaal e delesh mizaari\n",
            "PRED SCORE: -1.5665\n",
            "\n",
            "SENT 328: ['ب', 'ه', '<b>', 'م', 'ن', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ن']\n",
            "PRED 328: be man negaah kon\n",
            "PRED SCORE: -0.0006\n",
            "\n",
            "SENT 329: ['ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'ب', 'ا', '<b>', 'م', 'ا', 'د', 'ر', 'ت', '<b>', 'م', 'ش', 'ک', 'ل', '<b>', 'د', 'ا', 'ش', 'ت', 'م', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ی', '<b>', 'چ', 'ی', '<b>', 'م', 'ن', 'و', '<b>', 'ت', 'ا', '<b>', 'ا', 'ی', 'ن', 'ج', 'ا', '<b>', 'ن', 'گ', 'ه', '<b>', 'د', 'ا', 'ش', 'ت', 'ه']\n",
            "PRED 329: yek jur baa maadaret moshkel daashtam ammaa miduni ammaa injaa nagu daashte daashte\n",
            "PRED SCORE: -2.4140\n",
            "\n",
            "SENT 330: ['ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'ص', 'ب', 'و', 'ر', '<b>', 'و', '<b>', 'ب', 'ا', 'گ', 'ذ', 'ش', 'ت', '<b>', 'و', '<b>', 'پ', 'ر', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'گ', 'ذ', 'ش', 'ت', 'م', '<b>', 'چ', 'و', 'ن', '<b>', 'م', 'ا', 'د', 'ر', 'ت', '<b>', 'ر', 'و', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'م']\n",
            "PRED 330: yek jur nashnavam o baa arzeshi o por amali o az khodam daaram maadaret\n",
            "PRED SCORE: -2.0304\n",
            "\n",
            "SENT 331: ['چ', 'و', 'ن', '<b>', 'ا', 'و', 'ن', '<b>', 'ا', 'ن', 'ت', 'خ', 'ا', 'ب', '<b>', 'د', 'ل', 'م', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ا', 'ص', 'ل', 'ا', '<b>', 'ه', 'م', '<b>', 'پ', 'ش', 'ی', 'م', 'و', 'ن', '<b>', 'ن', 'ی', 'س', 'ت', 'م', '<b>', 'چ', 'و', 'ن', '<b>', 'م', 'ط', 'م', 'ی', 'ن', 'م', '<b>', 'ا', 'گ', 'ه', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ج', 'و', 'و', 'ن', '<b>', 'م', 'ی', 'ش', 'د', 'م', '<b>', 'ح', 'ت', 'ی', '<b>', 'ا', 'گ', 'ه', '<b>', 'ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'د', 'ن', 'ی', 'ا', '<b>', 'ج', 'م', 'ع', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', 'ن', 'د', '<b>', 'ب', 'ا', 'ز', 'م', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ک', 'ا', 'ر', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م']\n",
            "PRED 331: chon un entekhaab delam bud o aslan dige baavar mishan aaqaa\n",
            "PRED SCORE: -2.8775\n",
            "\n",
            "SENT 332: ['م', 'ا', 'ر', 'د', 'ت', '<b>', 'ز', 'ن', '<b>', 'س', 'ر', '<b>', 'س', 'خ', 'ت', '<b>', 'و', '<b>', 'م', 'غ', 'ر', 'و', 'ر', '<b>', 'و', '<b>', 'ل', 'ج', 'ب', 'ا', 'ز', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'م', 'ن', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ت', 'ح', 'س', 'ی', 'ن', 'ش', '<b>', 'ک', 'ر', 'د', 'م']\n",
            "PRED 332: mitarsid zan o shekaste o manzuret bud vali shabhaa ye man hamishe mitarsidim\n",
            "PRED SCORE: -3.0454\n",
            "\n",
            "SENT 333: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ش', 'گ', 'ف', 'ت', 'ی', '<b>', 'ج', 'ز', 'ء', '<b>', 'ب', 'ه', '<b>', 'ج', 'ز', 'ء', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'ت', 'ک', 'ی', 'د', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ن', 'ظ', 'ر', '<b>', 'گ', 'ذ', 'ر', 'ا', 'ن', 'د', '<b>', 'و', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'م', 'ا', 'ن', 'د']\n",
            "PRED 333: parviz baa zhesti asal be qalb e surat e pedarash raa foru va saaket maand\n",
            "PRED SCORE: -2.8836\n",
            "\n",
            "SENT 334: ['ا', 'ر', 'ه', '<b>', 'پ', 'س', 'ر', 'ج', 'و', 'ن']\n",
            "PRED 334: aare pesareshunand\n",
            "PRED SCORE: -0.2805\n",
            "\n",
            "SENT 335: ['م', 'ن', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ا', 'ف', 'س', 'و', 'س', '<b>', 'ن', 'م', 'ی', '\\u200c', 'خ', 'و', 'ر', 'م', '<b>', 'چ', 'و', 'ن', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ه', 'م', 'و', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'س', 'ت', 'م']\n",
            "PRED 335: man be khaater e hichchi emoshkel nemidam chon mikhaast zendegi kardam ke mikhaast\n",
            "PRED SCORE: -2.1747\n",
            "\n",
            "SENT 336: ['م', 'گ', 'ه', '<b>', 'ا', 'د', 'م', '<b>', 'چ', 'ن', 'د', '<b>', 'ب', 'ا', 'ر', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'ی', 'ا', '<b>', 'م', 'ی', 'ا', 'د']\n",
            "PRED 336: mage aadam chand baar be ru miaad\n",
            "PRED SCORE: -0.6911\n",
            "\n",
            "SENT 337: ['ن', 'م', 'ی', 'گ', 'م', '<b>', 'ج', 'ا', 'ر', '<b>', 'و', '<b>', 'ج', 'ن', 'ج', 'ا', 'ل', '<b>', 'ب', 'پ', 'ا', '<b>', 'ک', 'ن', '<b>', 'ق', 'ا', 'ن', 'ع', 'ش', '<b>', 'ک', 'ن', '<b>', 'ا', 'م', 'ا', '<b>', 'ا', 'گ', 'ه', '<b>', 'ن', 'ت', 'و', 'ن', 'س', 'ت', 'ی', '<b>', 'د', 'ر', 'ن', 'گ', '<b>', 'ن', 'ک', 'ن', '<b>', 'ب', 'ر', 'و', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'د', 'ل', 'ت']\n",
            "PRED 337: nemidaanam kaar o bahsi qaraar kon intowr ammaa ammaa nistand bere dur\n",
            "PRED SCORE: -3.7047\n",
            "\n",
            "SENT 338: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ی', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'د', 'س', 'ت', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'خ', 'م', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'م', 'ا', 'ن', 'ع', 'ش', '<b>', 'ش', 'د']\n",
            "PRED 338: parviz baa khoshhaali be surat e dastash shaapur va shaapur barandaazash shod\n",
            "PRED SCORE: -1.4036\n",
            "\n",
            "SENT 339: ['ا', 'ی', 'ن', 'ک', 'ا', 'ر', '<b>', 'ر', 'و', '<b>', 'ن', 'ک', 'ن']\n",
            "PRED 339: in ro nazan\n",
            "PRED SCORE: -0.4467\n",
            "\n",
            "SENT 340: ['ا', 'م', 'ی', 'د', 'و', 'ا', 'ر', 'م', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 340: omidvaaram khoshbakht baashi\n",
            "PRED SCORE: -0.0066\n",
            "\n",
            "SENT 341: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ک', 'ر', 'د', '<b>', 'ت', 'ا', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '<b>', 'ا', 'خ', 'ر', '<b>', 'ب', 'ر', 'س', 'د', '<b>', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'ب', 'ا', '<b>', 'ا', 'ر', 'ا', 'م', 'ش', '<b>', 'ا', 'د', 'ا', 'م', 'ه', '<b>', 'م', 'ی', 'د', 'ا', 'د']\n",
            "PRED 341: turaan sokut kard taa harfhaa ye shamsi be aakhar e ashk eshaare midaad\n",
            "PRED SCORE: -1.8111\n",
            "\n",
            "SENT 342: ['ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'م', 'ط', 'م', 'ی', 'ن', '\\u200c', 'ت', 'ر', '<b>', 'و', '<b>', 'م', 'ع', 'ت', 'ب', 'ر', 'ت', 'ر']\n",
            "PRED 342: bel akhare kie az khaarej sepaasgozaaram o mioftam\n",
            "PRED SCORE: -2.5347\n",
            "\n",
            "SENT 343: ['ن', 'ق', 'ل', '<b>', 'پ', 'س', 'ر', '<b>', 'م', 'ن', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 343: lahnet pesar e man nist\n",
            "PRED SCORE: -0.6652\n",
            "\n",
            "SENT 344: ['ا', 'ل', 'ا', 'ن', '<b>', 'د', 'و', 'ر', 'ه', '<b>', 'ز', 'م', 'و', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'خ', 'ط', 'ر', 'ن', 'ا', 'ک', 'ی', 'ه']\n",
            "PRED 344: alaan zelzele ye khune ye qajari\n",
            "PRED SCORE: -1.9702\n",
            "\n",
            "SENT 345: ['ا', 'د', 'م', '<b>', 'ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'د', 'ر', 'م', 'ی', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ک', 'ن', 'ه', '<b>', 'ت', 'ا', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ی', 'ا', '<b>', 'ک', 'د', 'و', 'م', '<b>', 'ش', 'ی', 'ر', '<b>', 'پ', 'ا', 'ک', '<b>', 'خ', 'و', 'ر', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'و', 'ر', 'ش', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'ب', 'ر', 'ه']\n",
            "PRED 345: aadam yek qam e pedaresh dar dokhtar e bozorg daare taa badtar daare\n",
            "PRED SCORE: -1.8782\n",
            "\n",
            "SENT 346: ['د', 'خ', 'ت', 'ر', '<b>', 'ع', 'م', 'و', '<b>', 'ر', 'ض', 'ا', '<b>', 'ی', 'ا', 'د', 'ت', 'ه']\n",
            "PRED 346: dokhtar e omr e shomaast khaareje\n",
            "PRED SCORE: -2.3414\n",
            "\n",
            "SENT 347: ['م', 'ی', '\\u200c', 'گ', 'ف', 'ت', 'ن', 'د', '<b>', 'ش', 'و', 'ه', 'ر', 'ش', '<b>', 'ف', 'ل', 'ا', 'ن', '<b>', 'و', '<b>', 'ب', 'ه', 'م', 'ا', 'ن', 'ه']\n",
            "PRED 347: mikhaastam showharesh shabih o bahaane\n",
            "PRED SCORE: -2.1077\n",
            "\n",
            "SENT 348: ['ا', 'ن', 'و', 'ق', 'ت', '<b>', 'گ', 'ن', 'د', 'ش', '<b>', 'د', 'ر', 'ا', 'و', 'م', 'د', '<b>', 'ک', 'ه', '<b>', 'م', 'ر', 'ت', 'ی', 'ک', 'ه', '<b>', 'ع', 'ا', 'ش', '<b>', 'و', '<b>', 'ق', 'م', 'ا', 'ر', '<b>', 'ب', 'ا', 'ز', 'ه']\n",
            "PRED 348: aanvaqt vaasash bargashtand ke momkene saal o qaraar baaz\n",
            "PRED SCORE: -2.2634\n",
            "\n",
            "SENT 349: ['ب', 'ی', 'ن', 'و', 'ا', '<b>', 'س', 'و', 'س', 'ن']\n",
            "PRED 349: unaa jowharie\n",
            "PRED SCORE: -0.5464\n",
            "\n",
            "SENT 350: ['م', 'ث', 'ل', '<b>', 'پ', 'ن', 'ج', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ف', 'ت', 'ا', 'ب']\n",
            "PRED 350: mesl e muhaa ye qajari\n",
            "PRED SCORE: -1.3087\n",
            "\n",
            "SENT 351: ['ح', 'ی', 'ف']\n",
            "PRED 351: heyf e hesaabe\n",
            "PRED SCORE: -1.1656\n",
            "\n",
            "SENT 352: ['ح', 'ی', 'ف', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', 'ن', '<b>', 'س', 'ی', 'ب', '<b>', 'س', 'ر', 'خ']\n",
            "PRED 352: heyf az un kolli\n",
            "PRED SCORE: -1.0445\n",
            "\n",
            "SENT 353: ['ش', 'ا', 'ی', 'د', '<b>', 'ا', 'گ', 'ه', '<b>', 'ه', 'ر', '<b>', 'ک', 'س', '<b>', 'ج', 'ا', 'ی', '<b>', 'م', 'ن', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'ا', 'و', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ش', 'و', 'ه', 'ر', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', 'ش', '<b>', 'ه', 'م', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'م', 'ن', 'ک', 'ه', '<b>', 'ا', 'و', 'ن', 'و', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ا', 'س', 'م', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'م', '<b>', 'غ', 'ر', 'ض', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 353: shaayad age harchi tavajjoh jaa ye man bud az raftan e un raftim khord\n",
            "PRED SCORE: -2.0636\n",
            "\n",
            "SENT 354: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'د', 'ا', '<b>', 'ش', 'ا', 'ه', 'د', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ه', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 354: turaan dar ta yidash e harfesh goft khodaa ro khosh khaale khaale jun\n",
            "PRED SCORE: -2.3427\n",
            "\n",
            "SENT 355: ['ف', 'ق', 'ط', '<b>', 'ظ', 'ا', 'ه', 'ر', 'ش', '<b>', 'ی', 'ک', '\\u200c', 'ک', 'م', '<b>', 'غ', 'ل', 'ط', '<b>', 'ا', 'ن', 'د', 'ا', 'ز', 'ه']\n",
            "PRED 355: faqat laaboz yek kam nadidishun\n",
            "PRED SCORE: -2.9410\n",
            "\n",
            "SENT 356: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'خ', 'ن', 'د', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', 'ش', '<b>', 'ب', 'گ', 'و', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'ک', 'ه', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'ق', 'ی', 'ا', 'ف', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'گ', 'ی', 'ر', 'ه']\n",
            "PRED 356: shamsi baa khande goft behesh begu dige mahfel yekdande ke vaase man\n",
            "PRED SCORE: -2.6364\n",
            "\n",
            "SENT 357: ['ب', 'گ', 'و', '<b>', 'م', 'گ', 'ه', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ا', 'ز', '<b>', 'ک', 'ج', 'ا', '<b>', 'ش', 'ر', 'و', 'ع', '<b>', 'ک', 'ر', 'د', 'ی']\n",
            "PRED 357: begu mage khodet az kojaa shoru kardi\n",
            "PRED SCORE: -0.0338\n",
            "\n",
            "SENT 358: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ر', 'و', 'م', '<b>', 'س', 'ی', 'ا', 'ه', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 358: turaan baa molaaheze goft manam siaasi khaale jun\n",
            "PRED SCORE: -1.3507\n",
            "\n",
            "SENT 359: ['م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', 'ا', 'ش', '<b>', 'ر', 'ا', 'ح', 'ت', '<b>', 'و', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', '<b>', 'ب', 'ا', 'ش', 'ن', 'د']\n",
            "PRED 359: mikhaad khodaahaafezi e raahat o khunsard baashand\n",
            "PRED SCORE: -1.1447\n",
            "\n",
            "SENT 360: ['ت', 'و', 'ر', 'و', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'ه', '<b>', 'د', 'ل', '<b>', 'ن', 'گ', 'ی', 'ر', '<b>', 'م', 'ی', 'گ', 'ه', '<b>', 'ا', 'خ', 'ه', '<b>', 'ب', 'ا', '<b>', 'ن', 'و', 'ن', '<b>', 'ک', 'ا', 'ر', 'م', 'ن', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', 'ش', 'ه', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 360: to ro be del e negaah e nazar mige ke nemishe zendegi ke nemishe\n",
            "PRED SCORE: -1.1428\n",
            "\n",
            "SENT 361: ['ش', 'م', 'س', 'ی', '<b>', 'ا', 'خ', 'م', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ه', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا']\n",
            "PRED 361: shamsi akhm kard va goft che harfhaa\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 362: ['م', 'گ', 'ه', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ز', 'ن', '<b>', 'ن', 'د', 'ا', 'د', 'ن', 'د']\n",
            "PRED 362: mage be khodesh zan e sarbaalaast\n",
            "PRED SCORE: -0.5927\n",
            "\n",
            "SENT 363: ['ی', 'ا', 'د', 'م', 'ه', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ا', 'و', 'م', 'د', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'گ', 'ا', 'ر', 'ی', '<b>', 'ت', 'و', '<b>', 'ا', 'ه', '<b>', 'د', 'ر', '<b>', 'ب', 'س', 'ا', 'ط', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 363: yaadam vaqti umad khaabide to az dar baalaa nadaari\n",
            "PRED SCORE: -2.2104\n",
            "\n",
            "SENT 364: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ن', '<b>', 'د', 'ر', 'س', '<b>', 'خ', 'و', 'ن', 'د', 'ه', '<b>', 'س', 'ن', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'ه', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'س', 'ا', 'ز', 'ه']\n",
            "PRED 364: parviz man dorost khube vali nadaare zendegish ro mibine\n",
            "PRED SCORE: -1.5307\n",
            "\n",
            "SENT 365: ['پ', 'س', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'ه', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'م', '<b>', 'ب', 'ه', 'ا', 'ن', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 365: pas dokhtar be shenidanash nemiaad majles e azaast\n",
            "PRED SCORE: -2.5875\n",
            "\n",
            "SENT 366: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ل', 'ا', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'ه', '<b>', 'د', 'ل', '<b>', 'ن', 'گ', 'ی', 'ر', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'ا', 'ن']\n",
            "PRED 366: turaan belaafaasele goft to ro be khodaa nagir khaale jaan\n",
            "PRED SCORE: -0.0571\n",
            "\n",
            "SENT 367: ['ا', 'ز', '<b>', 'ا', 'و', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'ب', 'گ', 'ذ', 'ر', 'ی', 'م', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'س', 'ا', 'ل', '<b>', 'ف', 'ر', 'ق', 'ش', 'و', 'ن', 'ه']\n",
            "PRED 367: az unam ke bogzarim kheyli saal shode\n",
            "PRED SCORE: -0.3264\n",
            "\n",
            "SENT 368: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ی', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'د', 'خ', 'ت', 'ر', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'م', 'ا', '<b>', 'م', 'ی', 'د', 'ی', '<b>', 'ی', 'ا', '<b>', 'ن', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 368: shamsi bi howsele goft man nemidunam baalaa ye khodaa ro be maa turaan jun\n",
            "PRED SCORE: -2.2239\n",
            "\n",
            "SENT 369: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'س', 'ت', 'ا', 'ص', 'ل', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ا', 'گ', 'ه', '<b>', 'ر', 'ا', 'ض', 'ی', '<b>', 'ب', 'ا', 'ش', 'م', '<b>', 'س', 'ر', '<b>', 'س', 'و', 'ز', 'ن', 'ی', '<b>', 'ا', 'ز', 'م', '<b>', 'ب', 'ر', 'ن', 'ج', 'ی', 'ن']\n",
            "PRED 369: turaan mokhtasar goft be khodaa age baazam baasham didanemun jun\n",
            "PRED SCORE: -1.5601\n",
            "\n",
            "SENT 370: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'ه', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ا', 'گ', 'ه', '<b>', 'ج', 'و', 'ا', 'ب', 'ت', 'و', 'ن', '<b>', 'ن', 'ه', '<b>', 'س', 'ت', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ر', 'ک', '<b>', 'و', '<b>', 'پ', 'و', 'س', 'ت', '<b>', 'ک', 'ن', 'د', 'ه', '<b>', 'ب', 'گ', 'ی', 'ن', '<b>', 'ه', 'ی', 'چ', '<b>', 'ن', 'ظ', 'ر', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'و', '<b>', 'پ', 'ر', 'س', 'ی', 'د', 'ی']\n",
            "PRED 370: shamsi goft be har haal age age gusham na baayad bozorg kon\n",
            "PRED SCORE: -2.2815\n",
            "\n",
            "SENT 371: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'خ', 'ه', '<b>', 'ا', 'و', 'ن', '<b>', 'چ', 'ه', '<b>', 'س', 'ر', '<b>', 'د', 'ر', '<b>', 'م', 'ی', 'ا', 'ر', 'ه', '<b>', 'ا', 'ز', '<b>', 'ص', 'ل', 'ا', 'ح', '<b>', 'و', '<b>', 'م', 'ص', 'ل', 'ح', 'ت']\n",
            "PRED 371: turaan goft aakhe un che sar az hozur o mellat o majalle gozashte\n",
            "PRED SCORE: -3.1393\n",
            "\n",
            "SENT 372: ['ش', 'م', 'س', 'ی', '<b>', 'ا', 'ع', 'ت', 'ر', 'ا', 'ف', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'م', 'ن', 'م', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'د', 'ر', 'ب', 'ا', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'م', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'و', 'ل', 'ی', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ا', 'و', 'ن', 'ا', '<b>', 'ه', 'م', '<b>', 'ح', 'ق', '<b>', 'ح', 'ر', 'ف', '<b>', 'ز', 'د', 'ن', '<b>', 'د', 'ا', 'ر', 'ن', 'د']\n",
            "PRED 372: shamsi ranjide kard manam hamishe haminqadr bar harf zadan mikonam\n",
            "PRED SCORE: -2.9457\n",
            "\n",
            "SENT 373: ['خ', 'ل', 'ا', 'ص', 'ه', '<b>', 'ب', 'ی', '<b>', 'ر', 'و', 'د', 'ر', 'ب', 'ا', 'ی', 'س', 'ت', 'ی', '<b>', 'ب', 'گ', 'م', '<b>', 'د', 'خ', 'ت', 'ر', 'ت', '<b>', 'پ', 'س', 'ر', '<b>', 'م', 'ن', 'و', '<b>', 'ه', 'و', 'ا', 'ی', 'ی', '<b>', 'ک', 'ر', 'د', 'ه']\n",
            "PRED 373: khaale bi rudarbaasi e begam dokhtar mano ye aagaahi karde\n",
            "PRED SCORE: -2.8541\n",
            "\n",
            "SENT 374: ['ا', 'ز', '<b>', 'ت', 'و', '<b>', 'چ', 'ه', '<b>', 'پ', 'ن', 'ه', 'و', 'ن', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ه', 'ر', '<b>', 'ک', 'ا', 'ر', 'ی', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'و', '<b>', 'ا', 'ز', '<b>', 'س', 'ر', 'ش', '<b>', 'ب', 'ن', 'د', 'ا', 'ز', 'م', '<b>', 'ن', 'ت', 'و', 'ن', 'س', 'ت', 'م']\n",
            "PRED 374: az to che mamnunam ba d az khodeshaan sarkub nakarde foruq\n",
            "PRED SCORE: -2.5458\n",
            "\n",
            "SENT 375: ['پ', 'ا', 'ش', 'و', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ت', 'و', 'ی', '<b>', 'ی', 'ک', '<b>', 'ک', 'ف', 'ش', '<b>', 'و', '<b>', 'م', 'ی', 'گ', 'ه', '<b>', 'ا', 'ل', 'ا', '<b>', 'و', '<b>', 'ب', 'ل', 'ا', '<b>', 'م', 'ر', 'غ', '<b>', 'ی', 'ک', '<b>', 'پ', 'ا', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 375: paasho karde tu ye yek kafsh o migan ellaa o bellaa daare\n",
            "PRED SCORE: -0.7851\n",
            "\n",
            "SENT 376: ['و', 'ا', 'ل', 'ا', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ن', 'م', '<b>', 'ا', 'ز', '<b>', 'ا', 'ب', 'ر', 'و', '<b>', 'ر', 'ی', 'ز', 'ی', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'م', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ا', 'ی', 'ن', 'ا', '<b>', 'ج', 'و', 'و', 'ن', 'ن', 'د']\n",
            "PRED 376: vaallaa be khodaa e manam az esmesh naaraahatam mitarsam inaa keshidand\n",
            "PRED SCORE: -2.9409\n",
            "\n",
            "SENT 377: ['خ', 'د', 'ا', '<b>', 'ر', 'و', '<b>', 'خ', 'و', 'ش', '<b>', 'ن', 'م', 'ی', 'ا', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'ل', 'ش', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ب', 'ش', 'ک', 'ن', 'ی', 'م']\n",
            "PRED 377: khodaa ro khosh nemiaad ke dowre ro misuzuni\n",
            "PRED SCORE: -1.8440\n",
            "\n",
            "SENT 378: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ه', 'م', '<b>', 'ق', 'ب', 'و', 'ل', '<b>', 'ک', 'ن', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'م', '<b>', 'ش', 'ر', 'م', 'ن', 'د', 'ت', '<b>', 'ب', 'ش', 'م', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن', '<b>', 'ا', 'ی', 'ن', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'ه', '<b>', 'ی', 'ک', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ر', 'و', '<b>', 'ا', 'د', 'ا', 'ر', 'ه', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 378: turaan goft age pedaresh ham qabul kone in zendegi nemikone\n",
            "PRED SCORE: -0.1831\n",
            "\n",
            "SENT 379: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ن', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'چ', 'ی', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 379: shamsi goft in harfhaa chie turaan jun\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 380: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'د', 'خ', 'ی', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'م', 'ن', '<b>', 'ف', 'ر', 'ق', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 380: foruq baa jeddiyat vaase man farqi nadaare\n",
            "PRED SCORE: -0.0892\n",
            "\n",
            "SENT 381: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ه', 'م', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ا', 'س', 'ی', '<b>', 'ن', 'ه', '<b>', 'ا', 'د', 'م', 'ی', 'ه', '<b>', 'ک', 'ه', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ر', 'و', '<b>', 'س', 'خ', 'ت', '<b>', 'ب', 'گ', 'ی', 'ر', 'ه', '<b>', 'و', '<b>', 'ن', 'ه', '<b>', 'ی', 'ا', 'ل', '<b>', 'و', '<b>', 'ک', 'و', 'پ', 'ا', 'ل', '<b>', 'ا', 'ن', 'چ', 'ن', 'ا', 'ن', 'ی', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 381: parviz ham ke divaanevaar na iraadi ke zendegi ro e aanhaa va dur e aanhaa daare\n",
            "PRED SCORE: -3.6013\n",
            "\n",
            "SENT 382: ['ب', 'چ', 'ه', '\\u200c', 'ا', 'م', '<b>', 'خ', 'ا', 'ک', 'ش', 'ی', 'ر', 'ی', '<b>', 'خ', 'ا', 'ک', 'ش', 'ی', 'ر', 'ی', 'ه']\n",
            "PRED 382: bachcheam khaaksepaari khaanumaa\n",
            "PRED SCORE: -0.8538\n",
            "\n",
            "SENT 383: ['ب', 'ا', '<b>', 'ب', 'ا', 'ب', 'ا', 'ش', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ی']\n",
            "PRED 383: baa baahaash harf mizani\n",
            "PRED SCORE: -0.5622\n",
            "\n",
            "SENT 384: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ت', 'ر', 'د', 'ی', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ر', 'ا', '<b>', 'د', 'ر', 'و', 'غ', '<b>', 'ب', 'گ', 'م', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 384: turaan baa tardid goft cheraa doruq begam khaale jun\n",
            "PRED SCORE: -0.0041\n",
            "\n",
            "SENT 385: ['ج', 'ر', 'ی', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 385: jamaaat nemikonam\n",
            "PRED SCORE: -0.2315\n",
            "\n",
            "SENT 386: ['ش', 'م', 'س', 'ی', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'خ', 'ل', 'ا', 'ف', '<b>', 'ش', 'ر', 'ع', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 386: shamsi moteajjeb goft mage kashtihaat shoru mikoni\n",
            "PRED SCORE: -1.4826\n",
            "\n",
            "SENT 387: ['ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', '<b>', 'خ', 'و', 'ر', 'د', 'ن', '<b>', 'د', 'ر', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ر', 'گ', 'م', '<b>', 'ب', 'د', 'ه']\n",
            "PRED 387: baa sedaa ye be ham khoshetun dar turaan goft khodaa margam bede\n",
            "PRED SCORE: -1.7965\n",
            "\n",
            "SENT 388: ['ف', 'ک', 'ر', '<b>', 'ک', 'ن', 'م', '<b>', 'ا', 'و', 'م', 'د']\n",
            "PRED 388: fekr konam umad\n",
            "PRED SCORE: -0.2493\n",
            "\n",
            "SENT 389: ['س', 'ا', 'ب', 'ق', 'ه', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'ه', '<b>', 'ق', 'ب', 'ل', '<b>', 'ا', 'ز', '<b>', 'ظ', 'ه', 'ر', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'خ', 'و', 'ن', 'ه']\n",
            "PRED 389: albatte nadaashte qabl az zohr biaad khune\n",
            "PRED SCORE: -1.3552\n",
            "\n",
            "SENT 390: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ج', 'م', 'ع', '<b>', 'و', '<b>', 'ج', 'و', 'ر', '<b>', 'ک', 'ر', 'د', 'ن', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', 'چ', 'ه', '<b>', 'ح', 'ل', 'ا', 'ل', '<b>', 'ز', 'ا', 'د', 'ه', '<b>', 'ه', 'م', '<b>', 'ه', 'س', 'ت', '<b>', 'ا', 'ز', '<b>', 'ک', 'ج', 'ا', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ی', '<b>', 'خ', 'و', 'د', 'ش', 'ه']\n",
            "PRED 390: shamsi dar haal e jam o khasheni jam e khodash ham hast az kojaa baashe\n",
            "PRED SCORE: -2.5333\n",
            "\n",
            "SENT 391: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ه', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'ب', 'ه', '<b>', 'ل', 'ط', 'ف', '<b>', 'ش', 'م', 'ا', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'چ', 'ط', 'و', 'ر', 'ن', 'د']\n",
            "PRED 391: sargord be sardi goft be chand shomaa jenaab e shaapur chetowr\n",
            "PRED SCORE: -1.5891\n",
            "\n",
            "SENT 392: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', 'ا', 'و', 'م', 'د', 'ه', '<b>', 'ب', 'ه', '<b>', 'م', 'ن', '<b>', 'س', 'ر', '<b>', 'ب', 'ز', 'ن', 'ه', '<b>', 'ت', 'و', '<b>', 'ر', 'و', '<b>', 'خ', 'د', 'ا', '<b>', 'ا', 'ر', 'و', 'م', 'ت', 'ر', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', '<b>', 'ت', 'ه', 'د', 'ی', 'د', '<b>', 'ا', 'م', 'ی', 'ز', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'ی', 'ا', 'د', 'ت', '<b>', 'ب', 'ا', 'ش', 'ه', '<b>', 'ک', 'ه', '<b>', 'چ', 'ی', '<b>', 'گ', 'ف', 'ت', 'م', '<b>', 'ن', 'ش', 'ن', 'و', 'م', '<b>', 'ب', 'ا', 'ز', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'س', 'ا', 'ب', 'ق', '<b>', 'ر', 'و', '<b>', 'ت', 'ک', 'ر', 'ا', 'ر', '<b>', 'م', 'ی', 'ک', 'ن', 'ن', 'د']\n",
            "PRED 392: turaan kheyli aaraam goft emshab be man sar e to ro qabul kon ke chi midahand\n",
            "PRED SCORE: -2.0811\n",
            "\n",
            "SENT 393: ['ب', 'ع', 'د', '<b>', 'ک', 'م', 'ی', '<b>', 'پ', 'و', 'ل', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ی', 'ز', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'د', 'ر', '<b>', 'ر', 'ف', 'ت', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش', '<b>', 'م', 'ی', 'ر', 'ف', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', 'ک', 'ا', 'ش', '<b>', 'ن', 'ا', 'ه', 'ا', 'ر', '<b>', 'م', 'ی', 'م', 'و', 'ن', 'د', 'ی', 'د', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'د', 'ل', 'ش', 'و', 'ن', '<b>', 'ت', 'ن', 'گ', '<b>', 'ش', 'د', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', 'م', 'ه', 'ر', 'ز', 'ا', 'ن', '<b>', 'ک', 'ج', 'ا', 'س', 'ت']\n",
            "PRED 393: ba d kami mashqul e ru ye man ine chikaaret shode ke donbaal e turaan divune shod\n",
            "PRED SCORE: -3.2297\n",
            "\n",
            "SENT 394: ['ن', 'د', 'ی', 'د', 'م', 'ش', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', 'ر', 'ف', 'ت', 'ه', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ه', 'م', 'س', 'ا', 'ی', 'ه', '<b>', 'ب', 'ا', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ا', 'ن', 'ی', 'س', '<b>', 'خ', 'ا', 'ن', 'و', 'م', '<b>', 'ب', 'ا', 'ز', 'ی', '<b>', 'ک', 'ن', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ع', 'ص', 'ب', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'م', 'گ', 'ه', '<b>', 'غ', 'د', 'غ', 'ن', '<b>', 'ن', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ا', 'و', 'ن', 'ا', '<b>', 'ن', 'ر', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', 'ب', 'ه', '<b>', 'ه', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ب', 'چ', 'ه', '<b>', 'ا', 'س', 'ت', '<b>', 'ا', 'ق', 'ا', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', 'ن', '<b>', 'ص', 'د', 'ا', 'ش', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 394: khodaavand turaan goft rafte khune ye hamchin bachche ye makosh marg be har haal bezan budam\n",
            "PRED SCORE: -3.5558\n",
            "\n",
            "SENT 395: ['ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'پ', 'ل', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'پ', 'ا', 'ی', 'ی', 'ن', '<b>', 'ر', 'ف', 'ت', '<b>', 'ب', 'ی', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'خ', 'د', 'ا', 'ح', 'ا', 'ف', 'ظ', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ب', 'د', 'ه', 'د', '<b>', 'ی', 'ا', '<b>', 'ح', 'ت', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ب', 'ر', 'گ', 'ر', 'د', 'د']\n",
            "PRED 395: ba d az panjare ye kaazeb raft posht e inke zahmat be aqab aavard\n",
            "PRED SCORE: -3.6794\n",
            "\n",
            "SENT 396: ['ع', 'ا', 'د', 'ت', 'ش', '<b>', 'ب', 'و', 'د']\n",
            "PRED 396: jaadde bud\n",
            "PRED SCORE: -0.5141\n",
            "\n",
            "SENT 397: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ت', 'ق', 'ر', 'ی', 'ب', 'ا', '<b>', 'ب', 'ه', '<b>', 'و', 'س', 'ط', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'ر', 'س', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'ک', 'ه', '<b>', 'ر', 'خ', 'ت', '<b>', 'ش', 'و', 'ر', '<b>', 'و', '<b>', 'ا', 'ح', 'ت', 'م', 'ا', 'ل', 'ا', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ش', 'ن', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'س', 'ل', 'ا', 'م', 'ت', '<b>', 'ا', 'ق', 'ا', '<b>', 'د', 'ر', '<b>', 'پ', 'ن', 'ا', 'ه', '<b>', 'خ', 'د', 'ا']\n",
            "PRED 397: farrokhzaad saaf ye ta be nazar e aaqaaye reside ke u dur ke istaad\n",
            "PRED SCORE: -5.0104\n",
            "\n",
            "SENT 398: ['ا', 'ی', 'ن', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ب', 'ن', 'د', '<b>', 'ز', 'د', 'ن', '<b>', 'چ', 'ی', 'ن', 'ی', '<b>', 'غ', 'ر', 'و', 'ر', '<b>', 'ی', 'ک', '<b>', 'ز', 'ن', '<b>', 'ب', 'و', 'د', '<b>', '<b>', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ا', '<b>', 'ق', 'د', 'م', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'م', 'ح', 'ک', 'م', '<b>', 'ا', 'ز', '<b>', 'ک', 'و', 'چ', 'ه', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ک', 'ه', '<b>', 'ک', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', 'ش', '<b>', 'س', 'ل', 'ا', 'م', '<b>', 'د', 'ا', 'د']\n",
            "PRED 398: in hamaan band zadan e sargord dur yek zan bud ke kasi ye sarash ye sarash\n",
            "PRED SCORE: -4.1973\n",
            "\n",
            "SENT 399: ['س', 'ل', 'ا', 'م', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'د', 'ا', 'د', 'ن', '<b>', 'پ', 'ا', 'س', 'خ', '<b>', 'ک', 'م', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ب', 'ر', 'گ', 'ش', 'ت', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'د', 'ی', 'د', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ج', 'ا', '<b>', 'خ', 'و', 'ر', 'د', '<b>', 'و', '<b>', 'ج', 'و', 'ا', 'ب', '<b>', 'س', 'ل', 'ا', 'م', '<b>', 'د', 'ر', '<b>', 'د', 'ه', 'ا', 'ن', 'ش', '<b>', 'م', 'ا', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'ا', 'ب', 'ر', 'و', 'ا', 'ن', 'ش', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'د', 'ر', '<b>', 'ه', 'م', '<b>', 'گ', 'ر', 'ه', '<b>', 'خ', 'و', 'ر', 'د']\n",
            "PRED 399: salaam salaah e sargord baraaye didan e maashin kami khord va qalbash maand\n",
            "PRED SCORE: -3.5442\n",
            "\n",
            "SENT 400: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ت', 'ه', '<b>', 'م', 'ا', 'ن', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ه', 'ا', 'م', 'ت', 'ش', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ش', 'ک', 'س', 'ت', 'ن', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'پ', 'ی', 'ش', 'ق', 'د', 'م', '<b>', 'ش', 'د']\n",
            "PRED 400: parviz baa taajjob barandaazash e sigaarash baraaye shekaste sokut shod\n",
            "PRED SCORE: -3.0393\n",
            "\n",
            "SENT 401: ['ح', 'ا', 'ل', 'ت', 'و', 'ن', '<b>', 'چ', 'ط', 'و', 'ر', 'ه']\n",
            "PRED 401: haalatun chetowre\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 402: ['خ', 'س', 'ت', 'ه', '<b>', 'ن', 'ب', 'ا', 'ش', 'ی', 'د']\n",
            "PRED 402: hanuz nabaashid\n",
            "PRED SCORE: -0.5622\n",
            "\n",
            "SENT 403: ['ص', 'د', 'ا', 'ی', 'ش', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ی', 'د', '<b>', 'و', '<b>', 'چ', 'و', 'ن', '<b>', 'پ', 'ا', 'س', 'خ', 'ی', '<b>', 'ج', 'ز', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'ن', 'د', 'ی', 'د', '<b>', 'ر', 'ن', 'گ', 'ش', '<b>', 'پ', 'ر', 'ی', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'ب', 'ا', 'خ', 'ت']\n",
            "PRED 403: sedaayash sobhaanaro milarzid o chon saaken joz khodash raa nashenid\n",
            "PRED SCORE: -2.1453\n",
            "\n",
            "SENT 404: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'س', 'ر', 'ا', 'پ', 'ا', 'ی', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ب', 'ا', 'ر', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ر', 'م', 'ا', 'ی', 'ش']\n",
            "PRED 404: sargord saraasime raa baa negaahi sarzaneshbaar va bi moqaddame goft sharaayet e bi\n",
            "PRED SCORE: -1.9619\n",
            "\n",
            "SENT 405: ['ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '\\u200c', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ن', 'ت', 'ظ', 'ا', 'ر', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 405: bishtar az aan bud ke parviz maaneash daasht\n",
            "PRED SCORE: -0.8371\n",
            "\n",
            "SENT 406: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'چ', 'و', 'ن', '<b>', 'پ', 'ا', 'س', 'خ', 'ی', '<b>', 'ن', 'ش', 'ن', 'ی', 'د', '<b>', 'ک', 'م', 'ی', '<b>', 'ب', 'ا', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ا', 'و', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', 'ز', 'ی', 'ر', '<b>', 'ا', 'ن', 'د', 'ا', 'خ', 'ت', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ق', 'ص', 'د', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'ت', 'ا', 'ب', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', 'ن', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'ب', 'ا', '<b>', 'ج', 'س', 'ا', 'ر', 'ت', '<b>', 'د', 'و', '<b>', 'ق', 'د', 'م', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ب', 'خ', 'ش', 'ی', 'د']\n",
            "PRED 406: farrokhzaad eyd e chon chizhaai va baa qaateiyat dar khaane khire shod va saaf dar anduh e u forud shod\n",
            "PRED SCORE: -3.4749\n",
            "\n",
            "SENT 407: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', 'ش', '<b>', 'ب', 'ر', 'گ', 'ش', 'ت']\n",
            "PRED 407: sargord dobaare be tarafash bargasht\n",
            "PRED SCORE: -0.0038\n",
            "\n",
            "SENT 408: ['م', 'ی', '<b>', 'ت', 'و', 'ا', 'ن', 'س', 'ت', '<b>', 'ا', 'ز', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ب', 'ف', 'ه', 'م', 'د', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ت', 'ا', '<b>', 'چ', 'ه', '<b>', 'ح', 'د', '<b>', 'پ', 'ی', 'ش', '<b>', 'ب', 'ر', 'د', 'ه', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'ر', 'ی', 'س', 'ک', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ا', 'ر', 'ز', 'ی', 'د']\n",
            "PRED 408: mibaayad az nazar budan bolandash taa che ham be hesaab miaayad\n",
            "PRED SCORE: -2.9192\n",
            "\n",
            "SENT 409: ['ب', 'ا', '<b>', 'ت', 'ه', '<b>', 'م', 'ا', 'ن', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ه', 'ا', 'م', 'ت', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ب', 'خ', 'ش', 'ی', 'د', '<b>', 'ج', 'ن', 'ا', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ع', 'ر', 'ض', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', 'م']\n",
            "PRED 409: baa hess e aan sum goft be har haal kami daashtam\n",
            "PRED SCORE: -3.3215\n",
            "\n",
            "SENT 410: ['ح', 'ا', 'ل', 'ا', '<b>', 'ح', 'ر', 'ک', 'ت', '<b>', 'ع', 'ض', 'ل', 'ا', 'ت', '<b>', 'ف', 'ک', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ر', 'ا', '<b>', 'ز', 'ی', 'ر', '<b>', 'پ', 'و', 'س', 'ت', 'ش', '<b>', 'ح', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 410: haalaa ashk e dokhtari fekr zad raa zir e nazarash mikard\n",
            "PRED SCORE: -4.0759\n",
            "\n",
            "SENT 411: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'ا', 'و', '<b>', 'ک', 'ا', 'ر', '<b>', 'ر', 'ا', '<b>', 'س', 'خ', 'ت', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'گ', 'ر', 'چ', 'ه', '<b>', 'ط', 'ی', '<b>', 'ت', 'ص', 'م', 'ی', 'م', 'ی', '<b>', 'ن', 'ا', 'گ', 'ه', 'ا', 'ن', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ح', 'ر', 'ف', '<b>', 'ز', 'د', 'ن', '<b>', 'ج', 'ل', 'و', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'ن', 'ت', 'ظ', 'ا', 'ر', '<b>', 'ک', 'م', 'ی', '<b>', 'ن', 'ر', 'م', 'ش', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ا', 'و', '<b>', 'م', 'ث', 'ل', '<b>', 'ی', 'ک', '<b>', 'ن', 'ظ', 'ا', 'م', 'ی', '<b>', 'م', 'غ', 'ر', 'و', 'ر', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', 'ش', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ت', 'ح', 'ک', 'م', '<b>', 'و', '<b>', 'ش', 'ا', 'ی', 'د', '<b>', 'ت', 'ح', 'ق', 'ی', 'ر', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 411: be nazarash sardi u kaar raa sakht karde bud va shaayad istaad o shaayad istaad\n",
            "PRED SCORE: -0.9387\n",
            "\n",
            "SENT 412: ['د', 'ل', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', 'ی', 'ا', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'ا', 'ی', 'د', '<b>', 'م', 'و', 'د', 'ب', 'ا', 'ن', 'ه', '<b>', 'ن', 'ب', 'ا', 'ش', 'ه', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ب', 'گ', 'م', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ص', 'ر', 'ا', 'ح', 'ت', '<b>', 'و', '<b>', 'ت', 'ح', 'ک', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'ک', 'ه', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'م', 'ر', 'د', '<b>', 'ج', 'و', 'ا', 'ن']\n",
            "PRED 412: del be davaazdah daad o goft shaayad mas rif ke ahmaq\n",
            "PRED SCORE: -3.8341\n",
            "\n",
            "SENT 413: ['ی', 'ع', 'ن', 'ی', '<b>', 'ا', 'ی', 'ن', 'و', '<b>', 'ب', 'ه', 'ت', '<b>', 'ی', 'ا', 'د', '<b>', 'ن', 'د', 'ا', 'د', 'ن', 'د', '<b>', 'د', 'ر', '<b>', 'ک', 'ا', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه', 'ا', '<b>', 'د', 'خ', 'ا', 'ل', 'ت', '<b>', 'ن', 'ک', 'ن', 'ی']\n",
            "PRED 413: ya ni ino behet yaad nabaashid dar e kaar e naqshaa\n",
            "PRED SCORE: -2.4897\n",
            "\n",
            "SENT 414: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'م', 'ر', 'ت', 'ع', 'ش', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ق', '<b>', 'ب', 'ا', '<b>', 'ش', 'م', 'ا', 'س', 'ت', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'خ', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'م', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'ر', 'ا', '<b>', 'ق', 'ط', 'ع', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 414: parviz baa sedaa ye larzaani goft haqq baa shomaa chenin talkh sorkh kard\n",
            "PRED SCORE: -3.2817\n",
            "\n",
            "SENT 415: ['ه', 'ر', '<b>', 'چ', 'ی', '<b>', 'ل', 'ا', 'ز', 'م', '<b>', 'ب', 'و', 'د', 'ه', '<b>', 'ب', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'ت', '<b>', 'گ', 'ف', 'ت', 'م']\n",
            "PRED 415: har vaqt laazem bude be maadaret goftam\n",
            "PRED SCORE: -0.5554\n",
            "\n",
            "SENT 416: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'ش', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'ی', 'د', '<b>', 'م', 'ن', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'م', '<b>', 'ب', 'گ', 'م']\n",
            "PRED 416: parviz goft ammaa shomaa ke nemiduni man chi mikhaam begam\n",
            "PRED SCORE: -0.8684\n",
            "\n",
            "SENT 417: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ع', 'م', 'ی', 'ق', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ه', 'م', 'ی', 'د', 'ن', 'ش', '<b>', 'ز', 'ی', 'ا', 'د', '<b>', 'س', 'خ', 'ت', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ج', 'و', 'و', 'ن']\n",
            "PRED 417: farrokhzaad baa negaahi amiq goft sirus ziaad sakht nist jun\n",
            "PRED SCORE: -2.4358\n",
            "\n",
            "SENT 418: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ی', '<b>', 'پ', 'ر', 'د', 'ه', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ش', 'م', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'چ', 'ی', '<b>', 'م', 'خ', 'ا', 'ل', 'ف', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 418: parviz bi moqaddame porsid shomaa baraaye chi motalaashi mikonid\n",
            "PRED SCORE: -1.1636\n",
            "\n",
            "SENT 419: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ک', 'م', 'ی', '<b>', 'ج', 'ا', '<b>', 'خ', 'و', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'د', 'ه', 'ا', 'ن', '<b>', 'ب', 'ا', 'ز', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 419: foruq kifash kami jaa khord va baa tekaan baaz kard\n",
            "PRED SCORE: -1.3243\n",
            "\n",
            "SENT 420: ['د', 'ر', '<b>', 'ح', 'ق', 'ی', 'ق', 'ت', '<b>', 'ا', 'ز', '<b>', 'ج', 'س', 'ا', 'ر', 'ت', 'ش', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'ب', 'و', 'د']\n",
            "PRED 420: dar haqiqat az pol ma d bud\n",
            "PRED SCORE: -1.1919\n",
            "\n",
            "SENT 421: ['خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ج', 'م', 'ع', '<b>', 'و', '<b>', 'ج', 'و', 'ر', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ل', 'ی', 'ل', 'ی', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ب', 'ی', 'ن', 'م', '<b>', 'ج', 'و', 'ا', 'ب', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'د', 'م']\n",
            "PRED 421: khodesh raa jam o gush kard va goft doaa nemikonam arusit\n",
            "PRED SCORE: -1.4180\n",
            "\n",
            "SENT 422: ['ه', 'م', 'ی', 'ن', '<b>', 'ق', 'د', 'ر', '<b>', 'ه', 'م', '<b>', 'ر', 'ع', 'ا', 'ی', 'ت', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', 'ی', '<b>', 'ر', 'و', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'و', 'گ', 'ر', 'ن', 'ه', '<b>', 'ح', 'ق', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ز', 'ی', 'ر', '<b>', 'پ', 'ا', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', 'ن', '<b>', 'ر', 'س', 'م', '<b>', 'و', '<b>', 'ر', 'س', 'و', 'م', '<b>', 'ا', 'د', 'ب', 'ت', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 422: hamin qadr ham raaayat e eftekhaar ro kardam haal o pustame be khaater e maajeraai\n",
            "PRED SCORE: -1.5544\n",
            "\n",
            "SENT 423: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ن', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'د', 'و', 'ن', 'م', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'س', 'ر', 'گ', 'ر', 'د']\n",
            "PRED 423: parviz goft ammaa man baayad bachcheat jenaab e sargord\n",
            "PRED SCORE: -1.5422\n",
            "\n",
            "SENT 424: ['ا', 'ی', 'ن', '<b>', 'ح', 'ق', '<b>', 'م', 'ن', 'ه']\n",
            "PRED 424: in haqq e mane\n",
            "PRED SCORE: -0.0003\n",
            "\n",
            "SENT 425: ['م', 'ن', '<b>', 'ک', 'ه', '<b>', 'ب', 'چ', 'ه', '<b>', 'ن', 'ی', 'س', 'ت', 'م']\n",
            "PRED 425: man ke bachche nistam\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 426: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'س', 'ن', '<b>', 'و', '<b>', 'س', 'ا', 'ل', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ر', 'خ', '<b>', 'ن', 'ک', 'ش', '<b>', 'ج', 'و', 'و', 'ن']\n",
            "PRED 426: farrokhzaad baa qaateiyat goft zan o showhari ro be shomaa nakesh jun\n",
            "PRED SCORE: -1.8594\n",
            "\n",
            "SENT 427: ['م', 'ن', '<b>', 'م', 'ی', 'د', 'م', '<b>', 'ر', 'و', 'ز', 'ی', '<b>', 'د', 'و', '<b>', 'ج', 'ی', 'ن', '<b>', 'م', 'ث', 'ل', '<b>', 'ت', 'و', '<b>', 'ر', 'و', '<b>', 'ز', 'ی', 'ر', '<b>', 'ا', 'ف', 'ت', 'ا', 'ب', '<b>', 'پ', 'و', 'س', 'ت', '<b>', 'ب', 'ک', 'ن', 'ن', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ل', 'ق', 'م', 'ه', '\\u200c', 'ی', '<b>', 'د', 'ه', 'ن', '<b>', 'ت', 'و', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 427: man midam parviz do baar mesl e to ro qeyr e to ro qeyr e to nist goftam\n",
            "PRED SCORE: -1.9694\n",
            "\n",
            "SENT 428: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ر', 'ا']\n",
            "PRED 428: parviz goft cheraa\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 429: ['چ', 'و', 'ن', '<b>', 'د', 'و', '<b>', 'س', 'ه', '<b>', 'ت', 'ا', '<b>', 'س', 'ر', 'د', 'و', 'ش', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'ش', 'و', 'ن', 'ه', '<b>', 'ه', 'ا', 'م', '<b>', 'ب', 'ر', 'ق', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ه']\n",
            "PRED 429: chon do se taa sarneveshtemun ru ye khunast naader\n",
            "PRED SCORE: -2.6531\n",
            "\n",
            "SENT 430: ['ی', 'ا', '<b>', 'چ', 'و', 'ن', '<b>', 'ع', 'م', 'ا', 'ر', 'ت', '<b>', 'ب', 'ی', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'ت', 'ه', '<b>', 'ا', 'ج', 'د', 'ا', 'د', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'م']\n",
            "PRED 430: yaa chon bemiram bi sar o tah e lebaasesh nadaaram\n",
            "PRED SCORE: -1.7306\n",
            "\n",
            "SENT 431: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'د', 'ر', '<b>', 'ح', 'ا', 'ل', 'ی', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'و', 'ش', 'ی', 'د', '<b>', 'خ', 'و', 'د', 'د', 'ا', 'ر', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'و', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ا', 'ت', '<b>', 'پ', 'س', 'ر', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 431: sargord asabaani dar taariki midavid e khalaaf goft boro khune pesar e foruqe\n",
            "PRED SCORE: -2.5822\n",
            "\n",
            "SENT 432: ['ه', 'ر', '<b>', 'چ', 'ی', '<b>', 'ل', 'ا', 'ز', 'م', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ه', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ت', '<b>', 'گ', 'ف', 'ت', 'م']\n",
            "PRED 432: har vaqt laazem bude be she r goftam\n",
            "PRED SCORE: -1.7571\n",
            "\n",
            "SENT 433: ['د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ق', 'ص', 'د', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 433: dobaare qasd e raftan kard ke parviz goft man khoshgeltar mikonam\n",
            "PRED SCORE: -0.8049\n",
            "\n",
            "SENT 434: ['ق', 'و', 'ل', '<b>', 'ش', 'ر', 'ف', '<b>', 'م', 'ی', 'د', 'م']\n",
            "PRED 434: qowl e lotf midam\n",
            "PRED SCORE: -1.1246\n",
            "\n",
            "SENT 435: ['و', 'ل', 'ی', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'ن', 'ی', 'م', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ن', 'ی', 'ا', 'ن', 'د', 'ا', 'خ', 'ت', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'د', 'و', 'ر', '<b>', 'ش', 'د']\n",
            "PRED 435: vali foru daad hattaa chenin negaah be u i az u dur shod\n",
            "PRED SCORE: -1.5300\n",
            "\n",
            "SENT 436: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'م', 'ی', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'د', 'و', 'ر', '<b>', 'ش', 'د', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ن', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ر', 'ا', 'ض', 'ی', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ق', 'ی', 'ص', 'ر', '<b>', 'م', 'غ', 'ر', 'و', 'ر']\n",
            "PRED 436: parviz kami dar sokut barandaazash kard va vaqti kaamelan paa mizanam zemzeme mikonam\n",
            "PRED SCORE: -2.6674\n",
            "\n",
            "SENT 437: ['ج', 'ا', '<b>', 'س', 'ی', 'گ', 'ا', 'ر', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ی', 'ز', '<b>', 'م', 'م', 'ل', 'و', '<b>', 'ا', 'ز', '<b>', 'ت', 'ه', '<b>', 'س', 'ی', 'گ', 'ا', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 437: jeddan sigaari ru ye rizi e marg az u bud\n",
            "PRED SCORE: -2.9920\n",
            "\n",
            "SENT 438: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'س', 'ی', 'گ', 'ا', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ر', 'و', 'ی', '<b>', 'ل', 'ا', 'ش', 'ه', '\\u200c', 'ی', '<b>', 'ی', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'س', 'ی', 'گ', 'ا', 'ر', 'ه', 'ا', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'خ', 'ا', 'م', 'و', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ر', 'و', 'ی', '<b>', 'ت', 'خ', 'ت', '<b>', 'ف', 'ن', 'ر', 'د', 'ا', 'ر', 'ش', '<b>', 'غ', 'ل', 'ط', 'ی', 'د']\n",
            "PRED 438: parviz sigaarash raa ru ye goftoguhaa yeki az saakhtemaan khaarej kard va ru ye khaarej o taariki\n",
            "PRED SCORE: -4.6084\n",
            "\n",
            "SENT 439: ['ا', 'ز', '<b>', 'م', 'د', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'ق', 'ب', 'ل', '<b>', 'د', 'س', 'ت', '<b>', 'و', '<b>', 'د', 'ل', 'ش', '<b>', 'ب', 'ه', '<b>', 'ک', 'ا', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت']\n",
            "PRED 439: az raftan e qabl dast o delash be kaar nemiresidand\n",
            "PRED SCORE: -1.2407\n",
            "\n",
            "SENT 440: ['ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ا', 'ز', '<b>', 'ص', 'ب', 'ح', '<b>', 'ب', 'ه', '<b>', 'ک', 'ل', 'ی', '<b>', 'ت', 'ک', 'ا', 'ن', 'ش', '<b>', 'د', 'ا', 'د', 'ه', '<b>', 'و', '<b>', 'ک', 'م', 'ی', '<b>', 'ن', 'ا', 'ا', 'م', 'ی', 'د', 'ش', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 440: harfhaa ye sargord az sobh be kasi barmiqasht va kami baaqi karde bud\n",
            "PRED SCORE: -0.6655\n",
            "\n",
            "SENT 441: ['ا', 'ن', '<b>', 'ه', 'م', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'ش', 'م', 'س', 'ی']\n",
            "PRED 441: aanham az raftan e shamsi\n",
            "PRED SCORE: -0.3781\n",
            "\n",
            "SENT 442: ['ا', 'ز', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'ا', 'م', '<b>', 'ح', 'ر', 'ف', '<b>', 'ن', 'ز', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'د', 'ر', 'ش', 'ت', 'ش', '<b>', 'ا', 'ز', '<b>', 'ف', 'ر', 'ط', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'و', 'ر', 'م', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 442: az vaqti be khaane aamade bud hattaa hattaa harf az chubrakhti bud\n",
            "PRED SCORE: -1.9005\n",
            "\n",
            "SENT 443: ['ب', 'ق', 'و', 'ل', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ه', 'م', 'ه', '<b>', 'و', 'ق', 'ت', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'س', 'ا', 'م', 'ا', 'ن', '<b>', 'د', 'ا', 'د', 'ن', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', 'ش', 'ا', 'ن', '<b>', 'ش', 'ا', 'د', 'ی', '<b>', 'و', '<b>', 'پ', 'ا', 'ی', 'ک', 'و', 'و', 'ب', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ن', 'د', '<b>', 'و', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ن', 'ه']\n",
            "PRED 443: be qowl e hamechi hame ye sar o amaan daadi o bellaa mikone\n",
            "PRED SCORE: -2.9715\n",
            "\n",
            "SENT 444: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ش', 'ه', 'ا', 'م', 'ت', '<b>', 'پ', 'ر', 'س', 'ی', 'د', 'ن', '<b>', 'س', 'و', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 444: parviz kalaafe porsid salaah az shamsi raa nadaasht\n",
            "PRED SCORE: -0.1232\n",
            "\n",
            "SENT 445: ['ن', 'ه', '<b>', 'ت', 'ن', 'ه', 'ا', '<b>', 'ش', 'ه', 'ا', 'م', 'ت', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '<b>', 'ه', 'م', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 445: na tanhaa saalhaast beshe ham ham nashod\n",
            "PRED SCORE: -1.1596\n",
            "\n",
            "SENT 446: ['ر', 'و', 'ی', '<b>', 'ش', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ر', 'ا', 'س', 'ت', 'ش', '<b>', 'غ', 'ل', 'ط', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ر', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 446: ru ye shaane ye saboki kubid va bar divaar dast keshid\n",
            "PRED SCORE: -2.4751\n",
            "\n",
            "SENT 447: ['ا', 'ی', 'ا', '<b>', 'ب', 'ه', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ت', 'ک', 'ا', 'پ', 'و', '<b>', 'ن', 'ت', 'ی', 'ج', 'ه', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 447: aayaa behtar haal az in e sobhaane natije migoft\n",
            "PRED SCORE: -1.7666\n",
            "\n",
            "SENT 448: ['چ', 'ن', 'د', 'ا', 'ن', '<b>', 'م', 'ط', 'م', 'ی', 'ن', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 448: chandaan motmaen nabud\n",
            "PRED SCORE: -0.2452\n",
            "\n",
            "SENT 449: ['د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ه', '<b>', 'ا', 'ر', 'ا', 'م', 'ی', '<b>', 'ب', 'ا', 'ز', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', 'و', 'ن', '<b>', 'ا', 'م', 'د']\n",
            "PRED 449: dar haqiqat be tarafeshaan baaz shod va shamsi be darun aamad\n",
            "PRED SCORE: -0.4855\n",
            "\n",
            "SENT 450: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ج', 'م', '<b>', 'ن', 'خ', 'و', 'ر', 'د']\n",
            "PRED 450: parviz kam nakard\n",
            "PRED SCORE: -0.3018\n",
            "\n",
            "SENT 451: ['ش', 'م', 'س', 'ی', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ی', 'د', 'ا', 'ر', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز']\n",
            "PRED 451: shamsi aaraam goft bist parviz\n",
            "PRED SCORE: -0.1421\n",
            "\n",
            "SENT 452: ['ب', 'ی', '<b>', 'ح', 'ر', 'ک', 'ت', '<b>', 'ج', 'و', 'ا', 'ب', '<b>', 'د', 'ا', 'د', '<b>', '<b>', 'ب', 'ل', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 452: biaa qeshqereq javaab daad beshe maadar\n",
            "PRED SCORE: -1.0911\n",
            "\n",
            "SENT 453: ['ک', 'ا', 'ر', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', 'ی', 'ن']\n",
            "PRED 453: kaari daashtin\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 454: ['ص', 'د', 'ا', 'ی', 'ش', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'و', '<b>', 'ن', 'ا', 'پ', 'ا', 'ی', 'د', 'ا', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 454: sedaayash goshud va sanjide bud\n",
            "PRED SCORE: -1.3319\n",
            "\n",
            "SENT 455: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'ص', 'ن', 'د', 'ل', 'ی', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', '<b>', 'م', 'ی', 'ز', '<b>', 'ن', 'ش', 'س', 'ت', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ج', 'ا', 'س', 'گ', 'ا', 'ر', 'ی', '<b>', 'چ', 'ش', 'م', '<b>', 'د', 'و', 'خ', 'ت']\n",
            "PRED 455: shamsi dar taariki ru ye ru ye zanhaa miaad va be aasemaan cheshm dukht\n",
            "PRED SCORE: -2.8706\n",
            "\n",
            "SENT 456: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', 'ش', '<b>', 'ب', 'ر', 'گ', 'ش', 'ت', '<b>', 'و', '<b>', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 456: parviz be tarafash bargasht va neshast\n",
            "PRED SCORE: -0.0008\n",
            "\n",
            "SENT 457: ['ش', 'م', 'ا', 'ی', 'ل', '<b>', 'ط', 'ل', 'ا', 'ی', '<b>', 'د', 'ر', 'ش', 'ت', 'ش', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'ب', 'ر', 'ق', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د']\n",
            "PRED 457: shaayadam javaan dorost dar taariki bastari nist\n",
            "PRED SCORE: -3.0020\n",
            "\n",
            "SENT 458: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ا', 'ن', 'د', 'و', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ب', 'ی', 'ن', '<b>', 'چ', 'ه', '<b>', 'ر', 'و', 'ز', 'گ', 'ا', 'ر', 'ی', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 458: shamsi baa anduh goft bebin che manzuri vaase khodet kardi maadar\n",
            "PRED SCORE: -1.3873\n",
            "\n",
            "SENT 459: ['ا', 'خ', 'ه', '<b>', 'ا', 'ی', 'ن', 'م', '<b>', 'ش', 'د', '<b>', 'ز', 'ن', 'د', 'گ', 'ی']\n",
            "PRED 459: aakhe inkenashod shod\n",
            "PRED SCORE: -0.1782\n",
            "\n",
            "SENT 460: ['ا', 'ص', 'ل', 'ا', '<b>', 'ب', 'ا', 'و', 'ر', 'م', '<b>', 'ن', 'ی', 'م', 'ش', 'ه', '<b>', 'ه', 'م', 'و', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'س', 'ا', 'ب', 'ق', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 460: aslan baavaram nemishod hamun parviz saaket baashi\n",
            "PRED SCORE: -1.0715\n",
            "\n",
            "SENT 461: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ی', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', 'ن', '<b>', 'ن', 'ص', 'ی', 'ح', 'ت', 'م', '<b>', 'ک', 'ن', 'ی', 'د', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 461: parviz bi howsele goft mikhaayn naay konin maadar\n",
            "PRED SCORE: -2.1300\n",
            "\n",
            "SENT 462: ['ب', 'ع', 'د', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'ز', 'خ', 'ن', 'د', '<b>', 'ا', 'ض', 'ا', 'ف', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'م', 'ن', '<b>', 'ا', 'ب', '<b>', 'ا', 'ز', '<b>', 'س', 'ر', 'م', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه']\n",
            "PRED 462: ba d baa puzkhand e shostan kard man be sarmaa gozashte\n",
            "PRED SCORE: -1.9143\n",
            "\n",
            "SENT 463: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ی', 'ف', '<b>', 'ا', 'ز', '<b>', 'ج', 'و', 'و', 'ن', 'ی', 'ت', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 463: shamsi goft defaa az junet nist\n",
            "PRED SCORE: -1.4825\n",
            "\n",
            "SENT 464: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ی', 'ن', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'م', 'ق', 'ص', 'ر', 'م', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 464: parviz goft towri harf mizani ke engaar daaiam maadar\n",
            "PRED SCORE: -0.6779\n",
            "\n",
            "SENT 465: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', 'ی', '<b>', 'ب', 'غ', 'ض', '<b>', 'ا', 'ل', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'م', 'ا', 'د', 'ر', 'م', '<b>', 'د', 'ل', 'م', '<b>', 'م', 'ی', '\\u200c', 'س', 'و', 'ز', 'ه']\n",
            "PRED 465: shamsi baa sedaai boqzaalud goft man maadaram maadaram mizane\n",
            "PRED SCORE: -0.2501\n",
            "\n",
            "SENT 466: ['ن', 'م', 'ی', '<b>', 'ت', 'و', 'ن', 'م', '<b>', 'ت', 'و', '<b>', 'ر', 'و', '<b>', 'ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ب', 'ب', 'ی', 'ن', 'م']\n",
            "PRED 466: nemitunam to ro injuri bebinam\n",
            "PRED SCORE: -0.9286\n",
            "\n",
            "SENT 467: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ت', 'ل', 'خ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'خ', 'و', 'ب', 'م', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ج', 'و', 'ن', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'ن', 'ب', 'ا', 'ش', 'ی', 'ن']\n",
            "PRED 467: parviz baa labkhandi talkh goft man ke maadar e mosen negaraan e negaraan zadane\n",
            "PRED SCORE: -1.6418\n",
            "\n",
            "SENT 468: ['ش', 'م', 'س', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ه', 'ر', '<b>', 'ک', 'ا', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'د', 'س', 'ت', 'م', '<b>', 'ب', 'ر', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 468: shamsi goft man harchi daari az dastam beram ke biaad\n",
            "PRED SCORE: -1.2079\n",
            "\n",
            "SENT 469: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'م', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 469: parviz baa mohabbat goft midunam maadar\n",
            "PRED SCORE: -0.0003\n",
            "\n",
            "SENT 470: ['ش', 'م', 'ا', '<b>', 'ت', 'ا', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ا', 'ل', 'ا', 'ن', 'م', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ک', 'ا', 'ر', 'ه', 'ا', '<b>', 'ک', 'ر', 'د', 'ی', 'ن']\n",
            "PRED 470: shomaa taa hamin alaanam kheyli baarhaa\n",
            "PRED SCORE: -0.9348\n",
            "\n",
            "SENT 471: ['ا', 'ز', 'ت', 'و', 'ن', '<b>', 'م', 'م', 'ن', 'و', 'ن', 'م']\n",
            "PRED 471: azatun mamnunam\n",
            "PRED SCORE: -0.3679\n",
            "\n",
            "SENT 472: ['ش', 'م', 'س', 'ی', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'خ', 'ه', '<b>', 'ت', 'و', '<b>', 'چ', 'ی']\n",
            "PRED 472: shamsi miaan e gerye goft vali aakhe to chi\n",
            "PRED SCORE: -0.0006\n",
            "\n",
            "SENT 473: ['ا', 'ی', 'ن', 'ج', 'و', 'ر', 'ی', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ا', 'ز', '<b>', 'ب', 'ی', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ر', 'ی']\n",
            "PRED 473: injuri khodeto az beyn bebari\n",
            "PRED SCORE: -0.0420\n",
            "\n",
            "SENT 474: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ز', 'ی', 'ر', '<b>', 'ن', 'ظ', 'ر', '<b>', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ف', 'ک', 'ر', '<b>', 'ک', 'ر', 'د', '<b>', 'چ', 'ه', '<b>', 'ک', 'ا', 'ر', '<b>', 'ع', 'ا', 'ق', 'ل', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', 'ب', 'ا', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'د', 'ی', 'د', 'ا', 'ر', 'ش', '<b>', 'ب', 'ا', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ن', 'گ', 'ف', 'ت']\n",
            "PRED 474: parviz dar taariki u raa zir e nagu gereft ke fekr kard ke dar ham eraane\n",
            "PRED SCORE: -0.9185\n",
            "\n",
            "SENT 475: ['ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'پ', 'ر', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'د', 'ت', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', '<b>', 'ن', 'ک', 'ن', 'ی', 'د', '<b>', 'م', 'ا', 'د', 'ر', 'ج', 'و', 'ن', '<b>', 'گ', 'ف', 'ت', 'م', '<b>', 'ک', 'ه', '<b>', 'م', 'ن', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'خ', 'و', 'ب', 'م']\n",
            "PRED 475: baa lahni por mohabbat goft aanqadr khodeto naaraahat ke man kaamelan mipaaid\n",
            "PRED SCORE: -2.0672\n",
            "\n",
            "SENT 476: ['ب', 'ه', 'ت', 'ر', 'ه', '<b>', 'ب', 'ر', 'ی', 'ن', '<b>', 'ا', 'س', 'ت', 'ر', 'ا', 'ح', 'ت', '<b>', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 476: behtare beri varaqesh konid\n",
            "PRED SCORE: -1.6034\n",
            "\n",
            "SENT 477: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'ا', 'ش', '<b>', 'م', 'ا', 'د', 'ر', '<b>', 'ب', 'و', 'د', 'ی', '<b>', 'و', '<b>', 'ح', 'ا', 'ل', '<b>', 'م', 'ن', 'و', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'ی', 'د', 'ی']\n",
            "PRED 477: shamsi baa sedaai larzaan goft kaash maadar budi o haal e mane\n",
            "PRED SCORE: -0.7594\n",
            "\n",
            "SENT 478: ['ن', 'م', 'ی', '<b>', 'د', 'و', 'ن', 'م', '<b>', 'ی', 'ک', '<b>', 'د', 'ف', 'ع', 'ه', '<b>', 'چ', 'ه', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', 'ی', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'م', 'و', 'ن', '<b>', 'ز', 'ی', 'ر', '<b>', 'و', '<b>', 'ر', 'و', '<b>', 'ش', 'د']\n",
            "PRED 478: nemidunam yek yek daf che eqtezaa oftaade o zendegit zir o ru shode\n",
            "PRED SCORE: -2.2325\n",
            "\n",
            "SENT 479: ['ا', 'خ', 'ه', '<b>', 'ت', 'و', '<b>', 'ت', 'ا', '<b>', 'ق', 'ب', 'ل', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', 'ن', '<b>', 'ن', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'و', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'و', '<b>', 'ح', 'س', 'ا', 'ب', 'ی', '<b>', 'د', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ی', '<b>', 'و', '<b>', 'ن', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'ر', 'ا', '<b>', 'ق', 'ط', 'ع', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ق', '<b>', 'ب', 'ا', 'ش', 'م', 'ا', 'س', 'ت', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 479: aakhe to taa qabl az un besuze darreie o na taaqat baasham\n",
            "PRED SCORE: -0.9686\n",
            "\n",
            "SENT 480: ['ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'س', 'ر', 'ی', 'ع', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', '<b>', 'ا', 'ف', 'ت', 'ا', 'د']\n",
            "PRED 480: hanuz chi kheyli sari ettefaaq oftaad\n",
            "PRED SCORE: -1.3165\n",
            "\n",
            "SENT 481: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'ب', 'ه', '<b>', 'د', 'س', 'ت', '<b>', 'ه', 'م', '<b>', 'د', 'ا', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 481: engaar hamechi bud be kolli ham khaahand bud\n",
            "PRED SCORE: -1.1254\n",
            "\n",
            "SENT 482: ['ش', 'م', 'س', 'ی', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'ی']\n",
            "PRED 482: shamsi dar takmil porsid kheyli dustesh daari\n",
            "PRED SCORE: -0.6522\n",
            "\n",
            "SENT 483: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'م', 'ا', 'ن', 'د', '<b>', 'و', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', '<b>', 'ز', 'ی', 'ر', '<b>', 'ا', 'ن', 'د', 'ا', 'خ', 'ت']\n",
            "PRED 483: parviz saaket maand va sar be zir andaakht\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 484: ['ش', 'م', 'س', 'ی', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'ا', 'و', 'ن', '<b>', 'ب', 'چ', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 484: shamsi zemzeme kard ammaa un bachchast\n",
            "PRED SCORE: -0.2371\n",
            "\n",
            "SENT 485: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'ز', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'ا', 'ی', 'د', 'م', '<b>', 'م', 'ن', '<b>', 'پ', 'ی', 'ر', '<b>', 'ش', 'د', 'م']\n",
            "PRED 485: parviz baa puzkhand goft shaayadam man pish shodam\n",
            "PRED SCORE: -0.1135\n",
            "\n",
            "SENT 486: ['ب', 'ع', 'د', '<b>', 'پ', 'س', '<b>', 'ا', 'ز', '<b>', 'م', 'ک', 'ث', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'چ', 'ه', '<b>', 'ج', 'و', 'ر', '<b>', 'د', 'خ', 'ت', 'ر', 'ی', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 486: ba d pas az maks e kutaahi porsid un che tarz e khodaa maadar\n",
            "PRED SCORE: -0.6665\n",
            "\n",
            "SENT 487: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'م', '<b>', 'ا', 'ز', '<b>', 'س', 'ن', 'ش', '<b>', 'ب', 'ی', 'ش', 'ت', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'ه']\n",
            "PRED 487: be nazaram az ezdevaaj bishtar mioftam\n",
            "PRED SCORE: -1.0223\n",
            "\n",
            "SENT 488: ['ق', 'ل', 'ب', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'ح', 'ا', 'ل', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'پ', 'ر', 'س', 'ش', '<b>', 'و', '<b>', 'ل', 'ح', 'ن', '<b>', 'ک', 'ل', 'ا', 'م', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ل', 'ر', 'ز', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', 'و', '<b>', 'ر', 'س', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'پ', 'س', 'ر', 'ش', '<b>', 'ع', 'ا', 'ش', 'ق', '<b>', 'ش', 'د', 'ه']\n",
            "PRED 488: qalb e shamsi az taariki ke dar e nimebaaz o pul e ashk be in shekl daasht va be in kaar\n",
            "PRED SCORE: -4.3063\n",
            "\n",
            "SENT 489: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ه', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'د', 'ی', 'د', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'و', '<b>', 'ش', 'م', 'ر', 'د', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'م', 'ک', 'ث', 'ی', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'ا', 'د', 'ا', 'م', 'ه', '<b>', 'د', 'ا', 'د', '<b>', '<b>', 'ب', 'ا', 'و', 'ر', '<b>', 'ک', 'ن', '<b>', 'ح', 'ت', 'ی', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ه', 'م', '<b>', 'ن', 'ف', 'ه', 'م', 'ی', 'د', 'م', '<b>', 'چ', 'ی', '<b>', 'ش', 'د', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 489: parviz ke u raa saaket did va afsorde az majalle daad\n",
            "PRED SCORE: -1.6948\n",
            "\n",
            "SENT 490: ['ا', 'ل', 'ا', 'ن', 'م', '<b>', 'م', 'د', 'ت', 'ی', 'ه', '<b>', 'ک', 'ه', '<b>', 'ف', 'ک', 'ر', 'م', '<b>', 'م', 'ا', 'ل', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 490: alaanam moddatie ke cheshm maal e khodam nist\n",
            "PRED SCORE: -0.7890\n",
            "\n",
            "SENT 491: ['ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ی', 'ک', '<b>', 'د', 'ف', 'ع', 'ه', '<b>', 'ج', 'ذ', 'ب', 'م', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 491: yekdaf e havaasam zibaai bud ke yek daf e zaifi kard\n",
            "PRED SCORE: -1.6292\n",
            "\n",
            "SENT 492: ['ش', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', 'م', '<b>', 'د', 'ل', 'خ', 'و', 'ر', '<b>', 'ن', 'ی', 'س', 'ت', 'ی', 'ن', '<b>', 'ه', 'س', 'ت', 'ی', 'د']\n",
            "PRED 492: shomaa ke esm e dastamo nist\n",
            "PRED SCORE: -1.2200\n",
            "\n",
            "SENT 493: ['ا', 'خ', 'ه', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'د', 'ل', 'ت', 'و', 'ن', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'خ', 'و', 'د', 'ت', 'و', 'ن', '<b>', 'ب', 'ر', 'ا', 'م', '<b>', 'ا', 'ن', 'ت', 'خ', 'ا', 'ب', '<b>', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 493: aakhe hamishe deltang mikhaast vagarna entekhaab konid\n",
            "PRED SCORE: -2.0313\n",
            "\n",
            "SENT 494: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'ه', 'ن', 'و', 'ز', 'م', '<b>', 'م', 'ع', 'ل', 'و', 'م', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ب', 'ه', 'م', 'و', 'ن', '<b>', 'ج', 'و', 'ا', 'ب', '<b>', 'م', 'ث', 'ب', 'ت', '<b>', 'ب', 'د', 'ن', '<b>', 'ی', 'ا', '<b>', 'ن', 'ه']\n",
            "PRED 494: shamsi baa mohabbat goft vali hanuzam ma rhaa budam yaa na\n",
            "PRED SCORE: -0.5259\n",
            "\n",
            "SENT 495: ['د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ب', 'ه', '<b>', 'ی', 'ا', 'د', 'ا', 'و', 'ر', 'د', 'ن', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'و', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ص', 'ب', 'ح', 'ش', '<b>', 'د', 'س', 'ت', 'خ', 'و', 'ش', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', '<b>', 'ش', 'د']\n",
            "PRED 495: dobaare parviz baa be tabaiyat sarzaneshbaar va harfhaa ye suznaakash lak shod\n",
            "PRED SCORE: -2.8766\n",
            "\n",
            "SENT 496: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'ر', 'ن', 'ج', 'ش', 'ی', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'ر', 'غ', 'ب', 'ت', '<b>', 'ن', 'ش', 'و', 'ن', '<b>', 'ن', 'م', 'ی', 'د', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'ه']\n",
            "PRED 496: shamsi baa mehri aashkaar goft foruq aadat hattaa harf bezane\n",
            "PRED SCORE: -2.3108\n",
            "\n",
            "SENT 497: ['م', 'ا', '<b>', 'ه', 'م', '<b>', 'ف', 'ق', 'ط', '<b>', 'د', 'ا', 'ر', 'ی', 'م', '<b>', 'خ', 'و', 'د', 'م', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ک', 'و', 'چ', 'ی', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', 'م']\n",
            "PRED 497: maa ham faqat daashtam khodemun ro begi mibini\n",
            "PRED SCORE: -2.1360\n",
            "\n",
            "SENT 498: ['ب', 'ی', 'چ', 'ا', 'ر', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن']\n",
            "PRED 498: bichaare turaan\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 499: ['م', 'و', 'ن', 'د', 'م', '<b>', 'چ', 'ط', 'و', 'ر', '<b>', 'ا', 'ی', 'ن', '\\u200c', 'ه', 'م', 'ه', '<b>', 'س', 'ا', 'ل', '<b>', 'ب', 'ا', 'ه', 'ا', 'ش', '<b>', 'س', 'ر', 'ک', 'ر', 'د', 'ه']\n",
            "PRED 499: manam chetowr intowr saal baahaash barmigarde\n",
            "PRED SCORE: -3.0605\n",
            "\n",
            "SENT 500: ['ا', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'ق', 'ل', 'د', 'ر', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'و', '<b>', 'ح', 'س', 'ا', 'ب', 'ی', 'ه']\n",
            "PRED 500: un yek qeshr dorost o hesaabie\n",
            "PRED SCORE: -0.8496\n",
            "\n",
            "SENT 501: ['م', 'ا', 'د', 'ر', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'ی', 'ا', 'م', 'ر', 'ز', 'م', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ق', 'ر', 'ا', 'ر', '<b>', 'ب', 'و', 'د', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ر', 'و', '<b>', 'ب', 'د', 'ن', '<b>', 'ب', 'ه', 'ش', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'ب', 'و', 'د']\n",
            "PRED 501: maadarbozorg biaaramesh bud qaraar bud turaan ro bede kheyli negaraan e kheyr bud\n",
            "PRED SCORE: -2.4347\n",
            "\n",
            "SENT 502: ['ا', 'ز', '<b>', 'ه', 'م', 'و', 'ن', '<b>', 'ا', 'و', 'ل', 'ش', '<b>', 'غ', 'د', '<b>', 'ب', 'و', 'د']\n",
            "PRED 502: az hamun avvalesh aah bud\n",
            "PRED SCORE: -1.0197\n",
            "\n",
            "SENT 503: ['م', 'ک', 'ث', 'ی', '<b>', 'ک', 'و', 'ت', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'ی', 'گ', 'م', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'چ', 'ک', 'ا', 'ر', '<b>', 'ک', 'ن', 'ی', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 503: maksi e man o varparide porsid bel akhare mikhaay chikaar koni maadar\n",
            "PRED SCORE: -1.6621\n",
            "\n",
            "SENT 504: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ز', 'و', 'ر', 'ک', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'ت', 'ا', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'چ', 'ک', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م']\n",
            "PRED 504: parviz baa labkhandi zuraki goft mage taa haalaa chikaar mikardam\n",
            "PRED SCORE: -0.0012\n",
            "\n",
            "SENT 505: ['ا', 'گ', 'ر', '<b>', 'ش', 'د', '<b>', 'ک', 'ه', '<b>', 'چ', 'ه', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'و', 'گ', 'ر', 'ن', 'ه', '<b>', 'ف', 'ع', 'ل', 'ا', '<b>', 'ق', 'ص', 'د', '<b>', 'ا', 'ز', 'د', 'و', 'ا', 'ج', '<b>', 'ن', 'د', 'ا', 'ر', 'م']\n",
            "PRED 505: agar shod ke che behtar vagarna neshun nadaaram\n",
            "PRED SCORE: -0.7846\n",
            "\n",
            "SENT 506: ['ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'ج', 'و', 'ا', 'ب', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', 'ش', 'ن', 'ی', '<b>', 'د', 'ر', 'ی', 'ا', 'ف', 'ت', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ا', '<b>', 'ق', 'ل', 'ب', 'ی', '<b>', 'پ', 'ر', 'م', 'ل', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'ج', 'ا', '<b>', 'ب', 'ر', 'خ', 'ا', 'س', 'ت', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ت', 'ا', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'د', 'ر', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 506: shamsi ke talaaqam raa be ru ye u jaa ye u raa taa jur u va parviz dar baraabarash neshast\n",
            "PRED SCORE: -1.9912\n",
            "\n",
            "SENT 507: ['ش', 'م', 'س', 'ی', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'ا', 'ز', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ب', 'ی', '\\u200c', 'ه', 'ی', 'چ', '<b>', 'ح', 'ر', 'ف', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د']\n",
            "PRED 507: shamsi yek baar e digar az hamaanjaa shode u ba d az otaaq khaarej shod va ba d az otaaq khaarej shod\n",
            "PRED SCORE: -1.6594\n",
            "\n",
            "SENT 508: ['ب', 'ه', 'ا', 'ر', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 508: behtar e qaribi bud\n",
            "PRED SCORE: -0.0417\n",
            "\n",
            "SENT 509: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'د', 'ر', '<b>', 'ه', 'و', 'ا', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'ه', 'ر', '<b>', 'س', 'ا', 'ل', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ف', 'ر', 'ق', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 509: engaar chizi dar havaa bud ke baa har saal baraaye foruq farq daasht\n",
            "PRED SCORE: -0.9556\n",
            "\n",
            "SENT 510: ['ی', 'ک', '<b>', 'ج', 'و', 'ر', '<b>', 'و', 'ح', 'ش', 'ت', '<b>', 'ن', 'ا', 'ش', 'ن', 'ا', 'خ', 'ت', 'ه', '\\u200c', 'ی', '<b>', 'د', 'ل', 'ن', 'ش', 'ی', 'ن']\n",
            "PRED 510: yek jur oftaadim naaraahatetun e duri e shekamu\n",
            "PRED SCORE: -2.2698\n",
            "\n",
            "SENT 511: ['ح', 'ا', 'ل', 'ا', '<b>', 'ه', 'ر', '<b>', 'ک', 'س', 'ی', '<b>', 'د', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'ق', 'ل', 'ب', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ی', 'خ', 'ت']\n",
            "PRED 511: haalaa har kasi dar mizad e qalb e foruq mirikht\n",
            "PRED SCORE: -0.3689\n",
            "\n",
            "SENT 512: ['م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'چ', 'و', 'ن', '<b>', 'ک', 'و', 'چ', 'ک', '\\u200c', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'س', 'ت', '<b>', 'ط', 'ب', 'ق', '<b>', 'ا', 'د', 'ا', 'ب', '<b>', 'و', '<b>', 'ر', 'س', 'و', 'م', '<b>', 'ه', 'ر', '<b>', 'س', 'ا', 'ل', '<b>', 'ا', 'و', 'ل', '<b>', 'ب', 'ه', '<b>', 'د', 'ی', 'د', 'ن', 'ش', 'ا', 'ن', '<b>', 'ب', 'ر', 'و', 'د']\n",
            "PRED 512: mitavaanest maadaresh baayad chon movaafeqand az khaale shamsi o zudam umad\n",
            "PRED SCORE: -2.2688\n",
            "\n",
            "SENT 513: ['ا', 'م', 'ا', '<b>', 'ا', 'ی', 'ن', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ا', 'م', 'د', '<b>', 'و', '<b>', 'ر', 'ف', 'ت', '<b>', 'ب', 'ا', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ر', 'ا', '<b>', 'م', 'م', 'ن', 'و', 'ع', '<b>', 'و', '<b>', 'م', 'ح', 'د', 'و', 'د', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ا', 'س', 'ت', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ا', '<b>', 'ا', 'ی', 'ن', '<b>', 'ح', 'ا', 'ل', '<b>', 'ب', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ج', 'و', '<b>', 'غ', 'ی', 'ر', 'ع', 'ا', 'د', 'ی', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 513: ammaa in raa ham dar pedarash harf e naame ast\n",
            "PRED SCORE: -4.1341\n",
            "\n",
            "SENT 514: ['ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'گ', 'و', 'ش', 'ه', '<b>', 'و', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'گ', 'ا', 'ر', 'ی', '<b>', 'م', 'ج', 'د', 'د', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'د', 'ر', '<b>', 'غ', 'ی', 'ا', 'ب', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'چ', 'و', 'ن', '<b>', 'ا', 'ز', '<b>', 'گ', 'ف', 'ت', 'گ', 'و', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'و', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'ی', '<b>', 'ا', 'ط', 'ل', 'ا', 'ع', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'ز', '<b>', 'د', 'ش', 'م', 'ن', 'ی', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'ا', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'س', 'خ', 'ت', '<b>', 'ش', 'گ', 'ف', 'ت', '\\u200c', 'ز', 'د', 'ه', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 514: albatte foruq az gereftan o saal motevajjeh e me yaarhaa ye parviz maaneash shode bud\n",
            "PRED SCORE: -2.3314\n",
            "\n",
            "SENT 515: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ه', '<b>', 'م', 'ح', 'ض', '<b>', 'ش', 'ن', 'ی', 'د', 'ن', '<b>', 'ن', 'ا', 'م', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'چ', 'ن', 'ا', 'ن', '<b>', 'م', 'ت', 'غ', 'ی', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ک', 'ه', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'د', 'ر', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', 'ش', '<b>', 'ن', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'د']\n",
            "PRED 515: sargord be mahz e didan e naam az aanhaa chandaan raft ke kaamelan baaqi mishod\n",
            "PRED SCORE: -3.3888\n",
            "\n",
            "SENT 516: ['ا', 'ب', 'ر', 'و', 'ه', 'ا', 'ی', '<b>', 'پ', 'ر', 'پ', 'ش', 'ت', 'ش', '<b>', 'د', 'ر', '<b>', 'ه', 'م', '<b>', 'گ', 'ر', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ر', 'د', '<b>', ',', '<b>', 'ع', 'ض', 'ل', 'ا', 'ت', '<b>', 'چ', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ب', 'ه', '\\u200c', 'س', 'خ', 'ت', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ی', 'د', '<b>', 'و', '<b>', 'س', 'ک', 'و', 'ت', 'ش', '<b>', 'ا', 'ز', '<b>', 'ص', 'د', '<b>', 'ف', 'ح', 'ش', '<b>', 'و', '<b>', 'ن', 'ا', 'س', 'ز', 'ا', '<b>', 'ب', 'د', 'ت', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 516: esraari hamunqadr dar ham hojum migi tamaashaa mikard va sokut e lezzatbakhshi mikhaast\n",
            "PRED SCORE: -6.3431\n",
            "\n",
            "SENT 517: ['ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ا', '<b>', 'ا', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'د', 'و', '<b>', 'ه', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ب', 'ر', 'ی', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ی', '<b>', 'خ', 'ب', 'ر', 'ی', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ه', 'ر', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ا', 'ز', 'ا', 'ر', 'ش', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ا', 'ن', 'س', 'ت', '<b>', 'ح', 'د', 'س', '<b>', 'ب', 'ز', 'ن', 'د', '<b>', 'ا', 'خ', 'ر', '<b>', 'م', 'ا', 'ج', 'ر', 'ا', '<b>', 'چ', 'ه', '<b>', 'خ', 'و', 'ا', 'ه', 'د', '<b>', 'ش', 'د', '<b>', 'غ', 'ی', 'ر', 'ق', 'ا', 'ب', 'ل', '<b>', 'ت', 'ح', 'م', 'ل', '<b>', 'ب', 'و', 'د']\n",
            "PRED 517: foruq taa aan ruz dowr e do bud ke az har zamaan che e harf gozaraand\n",
            "PRED SCORE: -3.6569\n",
            "\n",
            "SENT 518: ['ر', 'و', 'ز', 'ه', 'ا', '<b>', 'م', 'ث', 'ل', '<b>', 'م', 'ر', 'غ', '<b>', 'س', 'ر', 'ک', 'ن', 'د', 'ه', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'ق', 'د', 'م', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'و', '<b>', 'م', 'ث', 'ل', '<b>', 'ک', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'م', 'ن', 'ت', 'ظ', 'ر', '<b>', 'ک', 'س', 'ی', '<b>', 'ی', 'ا', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'ل', 'ح', 'ظ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ش', 'ب', '\\u200c', 'ه', 'ا', '<b>', 'ت', 'ا', '<b>', 'پ', 'ا', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'ش', 'ب', '<b>', 'ب', 'ه', '<b>', 'س', 'ق', 'ف', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 518: ruz mesl e marg e kudaki dar otaaq bozorg shavad ke mesl e yakh baashad\n",
            "PRED SCORE: -4.5363\n",
            "\n",
            "SENT 519: ['ن', 'ه', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ط', 'ا', 'ل', 'ع', 'ه', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ن', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'و', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'م', 'ص', 'ا', 'ح', 'ب', 'ت', '<b>', 'ب', 'ا', '<b>', 'ک', 'س', 'ی']\n",
            "PRED 519: na qabule inham daasht o na haal o havaa ye mostaqel aadde\n",
            "PRED SCORE: -3.4590\n",
            "\n",
            "SENT 520: ['چ', 'ن', 'د', '<b>', 'ب', 'ا', 'ر', '<b>', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'د', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ص', 'ح', 'ب', 'ت', '<b>', 'ک', 'ن', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ز', 'و', 'د', '<b>', 'پ', 'ش', 'ی', 'م', 'ا', 'ن', '<b>', 'ش', 'د']\n",
            "PRED 520: chand baar baraat dar in baashe baa puraan sohbat konad ammaa khaane maaneash shod\n",
            "PRED SCORE: -1.3129\n",
            "\n",
            "SENT 521: ['ش', 'ب', '<b>', 'پ', 'ن', 'ج', 'م', '<b>', 'د', 'ر', '<b>', 'ح', 'ا', 'ل', 'ی', 'ک', 'ه', '<b>', 'ه', 'م', 'گ', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ص', 'ر', 'ف', '<b>', 'ش', 'ا', 'م', '<b>', 'گ', 'ر', 'د', '<b>', 'س', 'ف', 'ر', 'ه', '<b>', 'ن', 'ش', 'س', 'ت', 'ه', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'ا', '<b>', 'ح', 'ض', 'و', 'ر', '<b>', 'ن', 'ا', '<b>', 'ب', 'ه', '<b>', 'ه', 'ن', 'گ', 'ا', 'م', '<b>', 'خ', 'و', 'د', '<b>', 'ه', 'م', 'ه', '<b>', 'ر', 'ا', '<b>', 'ش', 'گ', 'ف', 'ت', '\\u200c', 'ز', 'د', 'ه', '<b>', 'ک', 'ر', 'د', 'ن', 'د']\n",
            "PRED 521: shab manzuram dar taariki e havaa baraaye sar e daryaa gor kardand\n",
            "PRED SCORE: -2.7311\n",
            "\n",
            "SENT 522: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ا', 'ش', 'ا', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'س', 'ا', 'ک', 'ت', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'م', 'ه', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ن', 'ظ', 'ر', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ر', 'ا', 'ن', 'د', '<b>', 'گ', 'و', 'ش', '<b>', 'ت', 'ی', 'ز', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 522: foruq baa eshaare dast e saaket kard va mostaqim ham az nazar gozaraand va mostaqim raa khord\n",
            "PRED SCORE: -3.2524\n",
            "\n",
            "SENT 523: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'س', 'ت', 'ق', 'ب', 'ا', 'ل', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'م', 'ل', 'ت', 'م', 'س', 'ا', 'ن', 'ه', '<b>', 'ب', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ق', 'ا', '<b>', 'ش', 'م', 'ا', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ح', 'ر', 'ف', 'ی', '<b>', 'ن', 'ز', 'ن', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'م', 'ک', 'د', 'ر', '<b>', 'ب', 'ش', 'ن']\n",
            "PRED 523: turaan hamaantowr ke baraaye halqet miraft eshaaratist be khodaa harfi bedan\n",
            "PRED SCORE: -3.5938\n",
            "\n",
            "SENT 524: ['ب', 'ه', 'ر', 'ح', 'ا', 'ل', '<b>', 'م', 'ه', 'م', 'و', 'ن', 'ن', 'د']\n",
            "PRED 524: be har haal ma ram\n",
            "PRED SCORE: -1.4301\n",
            "\n",
            "SENT 525: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'ج', 'ا']\n",
            "PRED 525: farrokhzaad baa asabaaniyat goft kojaa\n",
            "PRED SCORE: -0.0610\n",
            "\n",
            "SENT 526: ['ب', 'م', 'و', 'ن', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'م', 'ی', 'ر', 'م']\n",
            "PRED 526: befahm khodam misham\n",
            "PRED SCORE: -0.2608\n",
            "\n",
            "SENT 527: ['ف', 'ر', 'و', 'غ', '<b>', 'ف', 'و', 'ر', 'ا', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'پ', 'ر', 'د', 'ه', '<b>', 'ب', 'ه', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'د', 'ی', 'د', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'و', '<b>', 'پ', 'د', 'ر', '<b>', 'و', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'م', 'ا', 'ت', 'ش', '<b>', 'ب', 'ر', 'د']\n",
            "PRED 527: foruq charkhi be surat e panjare raft va az posht e parde qablash kard va pedar e porsesh shod\n",
            "PRED SCORE: -3.5421\n",
            "\n",
            "SENT 528: ['ه', 'م', 'ا', 'ن', '<b>', 'ج', 'ا', '<b>', 'پ', 'ا', 'ی', 'ی', 'ن', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '<b>', 'ن', 'ش', 'س', 'ت', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'د', 'ی', 'و', 'ا', 'ر', '<b>', 'س', 'ر', 'د', '<b>', 'ت', 'ک', 'ی', 'ه', '<b>', 'د', 'ا', 'د']\n",
            "PRED 528: hamaanjaa geryeash paain neshast va be divaar sorkh daad\n",
            "PRED SCORE: -1.0182\n",
            "\n",
            "SENT 529: ['ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ر', 'ا', '<b>', 'ب', 'ر', 'ق', '<b>', 'ر', 'و', '<b>', 'ر', 'و', 'ش', 'ن', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 529: fereydun goft cheraa baraat ruberaah nemikonid\n",
            "PRED SCORE: -0.7431\n",
            "\n",
            "SENT 530: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ل', 'ا', 'ز', 'م', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 530: foruq be zahmat goft laazem nist\n",
            "PRED SCORE: -0.0236\n",
            "\n",
            "SENT 531: ['ح', 'ا', 'ل', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'س', 'ر', 'د', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'خ', 'و', 'ش', 'ا', 'م', 'د', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت']\n",
            "PRED 531: haalaa sedaa ye sarash pedarash raa mishenid ke be kaarhaam ye khubam miraft\n",
            "PRED SCORE: -3.1964\n",
            "\n",
            "SENT 532: ['د', 'ر', 'س', 'ت', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'د', 'ش', 'ا', 'ن', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د']\n",
            "PRED 532: dorost be hamaan sardi ke baa hamsafaraanash harf mizad\n",
            "PRED SCORE: -1.0498\n",
            "\n",
            "SENT 533: ['ص', 'د', 'ا', 'ی', '<b>', 'پ', 'د', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'و', 'ش', 'ی', 'د', '<b>', 'ب', 'ا', '<b>', 'چ', 'ن', 'د', '<b>', 'ن', 'ف', 'س', '<b>', 'ع', 'م', 'ی', 'ق', '<b>', 'ط', 'پ', 'ش', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'ر', 'ا', '<b>', 'ت', 'س', 'ک', 'ی', 'ن', '<b>', 'د', 'ه', 'د']\n",
            "PRED 533: sedaa ye pedar e parviz o shamsi raa ham va ta d baa zanesh khord raa tekraar kard\n",
            "PRED SCORE: -4.0480\n",
            "\n",
            "SENT 534: ['ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ب', 'ا', '<b>', 'ش', 'ی', 'ط', 'ن', 'ت', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ا', 'و', 'م', 'د', 'ن', 'د', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'گ', 'ا', 'ر', 'ی']\n",
            "PRED 534: fereydun baa sheytanat porsid odokolonet khaasti\n",
            "PRED SCORE: -1.7405\n",
            "\n",
            "SENT 535: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'غ', 'ر', 'ی', 'د', '<b>', '<b>', 'ف', 'ر', 'ی', '<b>', 'د', 'ه', 'ن', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'ب', 'ن', 'د']\n",
            "PRED 535: foruq baa asabaaniat amiq goft shomaa ro bokhor\n",
            "PRED SCORE: -2.4065\n",
            "\n",
            "SENT 536: ['گ', 'ل', 'و', 'ر', 'ی', 'ا', '<b>', 'ب', 'ه', '\\u200c', 'ر', 'غ', 'م', '<b>', 'ب', 'چ', 'گ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ح', 'م', 'ق', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ت', 'و', '<b>', 'ب', 'ش', 'ن', 'و', 'ه']\n",
            "PRED 536: gloriaa be surat e bachche goft haddeaqal mikhaay baabaa badtar besuze\n",
            "PRED SCORE: -1.9373\n",
            "\n",
            "SENT 537: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ه', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 537: foruq be zahmat be ru ye righaa eshaare zad va mostaqim labkhand zad\n",
            "PRED SCORE: -1.2775\n",
            "\n",
            "SENT 538: ['ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ح', 'ت', 'ی', '<b>', 'ش', 'ا', 'م', 'ش', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'ت', 'ا', '<b>', 'ا', 'خ', 'ر', '<b>', 'ن', 'خ', 'و', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ن', 'د']\n",
            "PRED 538: aanhaa hattaa tamaam raa taa aakhar neshun budand\n",
            "PRED SCORE: -1.9833\n",
            "\n",
            "SENT 539: ['ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ی', 'ا', 'د', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ا', 'ر', 'ز', 'و', '<b>', 'ک', 'ر', 'د', '<b>', 'ک', 'ا', 'ش', '<b>', 'م', 'ث', 'ل', '<b>', 'ا', 'و', '<b>', 'م', 'ر', 'د', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ا', 'ن', 'س', 'ت', '<b>', 'ب', 'ه', '<b>', 'ب', 'ه', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'خ', 'د', 'م', 'ت', '<b>', 'ا', 'ز', '<b>', 'م', 'ح', 'ی', 'ط', '<b>', 'خ', 'ف', 'ق', 'ا', 'ن', '<b>', 'ا', 'و', 'ر', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ف', 'ر', 'ا', 'ر', '<b>', 'ک', 'ن', 'د', '<b>', 'ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'ه', '<b>', 'ز', 'ن', 'د', 'ا', 'ن', 'ب', 'ا', 'ن', 'ی', '<b>', 'ش', 'ب', 'ی', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'ز', 'ن', 'د', 'ا', 'ن', '<b>', 'ا', 'ش', 'ت', 'ب', 'ا', 'ه', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 539: age be yaad e amir oftaad va sokunash kard ke khaane ye u raa be derakht mikhord\n",
            "PRED SCORE: -4.4652\n",
            "\n",
            "SENT 540: ['ا', 'م', 'ی', 'ر', '<b>', 'د', 'و', '<b>', 'ر', 'و', 'ز', '<b>', 'ا', 'و', 'ل', '<b>', 'ع', 'ی', 'د', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ش', 'ر', 'ا', 'ی', 'ط', '<b>', 'س', 'خ', 'ت', '<b>', 'خ', 'د', 'م', 'ت', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'ه', '<b>', 'ن', 'ا', 'ز', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'ی', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', 'ش', '<b>', 'د', 'ل', '<b>', 'م', 'ی', '\\u200c', 'س', 'و', 'ز', 'ا', 'ن', 'د', 'ن', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ع', 'ق', 'ی', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'و', 'ض', 'ع', 'ی', 'ت', '<b>', 'خ', 'و', 'د', 'ش', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'م', 'ر', 'ا', 'ت', 'ب', '<b>', 'ر', 'ق', 'ت', '<b>', 'ا', 'ن', 'گ', 'ی', 'ز', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'ب', 'و', 'د']\n",
            "PRED 540: amir do ruz u raa did be khaane maande maand va az u bargereft\n",
            "PRED SCORE: -4.8073\n",
            "\n",
            "SENT 541: ['ی', 'ک', '<b>', 'ل', 'ح', 'ظ', 'ه', '<b>', 'د', 'ل', 'ش', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'و', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'س', 'و', 'خ', 'ت', '<b>', 'و', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'ا', 'ش', 'ک', 'ش', '<b>', 'س', 'ر', 'ا', 'ز', 'ی', 'ر', '<b>', 'ش', 'د']\n",
            "PRED 541: yek lahze delesh be haal e khodash va nadide ashkash va naakhodaagaah ashkash saraazir shod\n",
            "PRED SCORE: -1.8105\n",
            "\n",
            "SENT 542: ['ب', 'ه', '\\u200c', 'س', 'ر', 'ع', 'ت', '<b>', 'ب', 'ا', '<b>', 'ا', 'س', 'ت', 'ی', 'ن', '<b>', 'ل', 'ب', 'ا', 'س', 'ش', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'ا', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'پ', 'ش', 'ت', '<b>', 'ا', 'ن', '<b>', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 542: be behtare aabestan aadde cheshm raftaar kard va posht e be otaaq raft va posht e be otaaq raft va posht e aan hayaat be hayaat\n",
            "PRED SCORE: -3.4616\n",
            "\n",
            "SENT 543: ['ه', 'ی', 'چ', '<b>', 'ص', 'د', 'ا', 'ی', 'ی', '<b>', 'ج', 'ز', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ت', 'ع', 'ا', 'ر', 'ف', 'ا', 'ت', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'و', '<b>', 'خ', 'ا', 'ل', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '<b>', 'گ', 'و', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ر', 'س', 'ی', 'د']\n",
            "PRED 543: hichvaqt mowqe e khore e dishabi maadarbozorg va khaale be zehnash nemiresidand\n",
            "PRED SCORE: -2.9902\n",
            "\n",
            "SENT 544: ['گ', 'و', 'ش', '<b>', 'ت', 'ی', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ش', 'ن', 'و', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '\\u200c', 'ی', '<b>', 'ز', 'ی', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'م', 'ا', 'ن', 'ع', 'ش', '<b>', 'ش', 'د']\n",
            "PRED 544: gushash haal kard balke sedaa ye pedarash raa badanash ammaa otaaq e maamaano taa otaaq e maast\n",
            "PRED SCORE: -3.3791\n",
            "\n",
            "SENT 545: ['م', 'د', 'ت', 'ی', '<b>', 'ا', 'و', 'ض', 'ا', 'ع', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'م', 'ن', 'و', 'ا', 'ل', '<b>', 'ب', 'و', 'د', '<b>', 'ت', 'ا', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ق', 'د', 'م', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ش', 'ت', 'ا', 'ب', '\\u200c', 'ز', 'د', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 545: mokhaatabash e owzaa be hamintowr bud taa inke sedaa ye maadarash raa shenaakht\n",
            "PRED SCORE: -2.6095\n",
            "\n",
            "SENT 546: ['ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'ا', 'ز', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'د', 'ر', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ا', 'ز', '<b>', 'ش', 'د']\n",
            "PRED 546: ajulaane az surat e dar e kuche az otaaq dar naa baaz shod\n",
            "PRED SCORE: -2.1294\n",
            "\n",
            "SENT 547: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ا', 'ر', 'ا', 'م', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'چ', 'ر', 'ا', '<b>', 'ت', 'و', 'ی', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', 'ی', '<b>', 'ن', 'ش', 'س', 'ت', 'ی', 'د']\n",
            "PRED 547: turaan be aaraami porsid cheraa tu ye taariki e baabaast\n",
            "PRED SCORE: -0.6122\n",
            "\n",
            "SENT 548: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'چ', 'ی', '<b>', 'ش', 'د', 'ه', '<b>', 'م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 548: foruq baa negaraani porsid chi shode maamaan\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 549: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'د', 'س', 'ت', 'پ', 'ا', 'چ', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'پ', 'ا', 'ش', 'و', '<b>', 'ب', 'ر', 'و', '<b>', 'چ', 'ا', 'ی', 'ی', '<b>', 'ب', 'ر', 'ی', 'ز']\n",
            "PRED 549: turaan ke khodesh ham da bud goft hichchi pashm chizie\n",
            "PRED SCORE: -2.2792\n",
            "\n",
            "SENT 550: ['خ', 'و', 'د', 'م', '<b>', 'م', 'ی', 'ا', 'م', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ر', 'م']\n",
            "PRED 550: khodam mizaari miaam\n",
            "PRED SCORE: -0.4742\n",
            "\n",
            "SENT 551: ['خ', 'و', 'ا', 'س', 'ت', '<b>', 'ا', 'ز', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ب', 'ر', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ص', 'د', 'ا', 'ی', 'ش', '<b>', 'ز', 'د']\n",
            "PRED 551: khaast az otaaq birun bolandash ke foruq maaneash zad\n",
            "PRED SCORE: -0.1695\n",
            "\n",
            "SENT 552: ['م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 552: maamaan\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 553: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ب', 'ر', 'گ', 'ش', 'ت', '<b>', 'و', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'د', 'ق', 'ت', '<b>', 'د', 'ر', '<b>', 'پ', 'ن', 'ا', 'ه', '<b>', 'ن', 'و', 'ر', 'ی', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ب', 'ه', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ا', 'ب', 'ی', 'د', '<b>', 'ک', 'ا', 'و', 'ی', 'د']\n",
            "PRED 553: turaan dobaare be aqab bargardad va surat e foruq raa baa otaaq be hayaat barkhaast\n",
            "PRED SCORE: -1.4456\n",
            "\n",
            "SENT 554: ['ن', 'ه']\n",
            "PRED 554: na\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 555: ['ب', 'چ', 'ه', '\\u200c', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ت', 'ا', 'ب', '<b>', 'ب', 'ی', 'ا', 'و', 'ر', 'د']\n",
            "PRED 555: bespaarid az aan bud ke haal biaad\n",
            "PRED SCORE: -1.2497\n",
            "\n",
            "SENT 556: ['چ', 'ی', 'ه']\n",
            "PRED 556: chie\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 557: ['ح', 'ا', 'ل', 'ا', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 557: haalaa foruq sokut kard\n",
            "PRED SCORE: -0.0040\n",
            "\n",
            "SENT 558: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'س', 'ر', 'س', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'ا', 'ن', 'د', 'ا', 'خ', 'ت', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ب', 'ه', '<b>', 'گ', 'ل', 'و', 'ر', 'ی', 'ا', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'ا', 'د', 'ر', 'ا', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'خ', 'و', 'ا', 'ب', 'و', 'ن', '<b>', 'پ', 'س', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ا', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'پ', 'ا', 'ه', 'ا', 'ی', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'ا', 'ز', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'و', 'ر', 'د', 'ن', '<b>', 'چ', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ح', 'ی', 'ا', 'ط', '<b>', 'ت', 'ا', 'ر', 'ی', 'ک', '<b>', 'ر', 'ف', 'ت']\n",
            "PRED 558: turaan negaah e sardargomi be bachche ye digar haasel az otaaq shod va baraaye raftan e u baa aayne daad shod\n",
            "PRED SCORE: -2.9146\n",
            "\n",
            "SENT 559: ['ر', 'و', 'ی', '<b>', 'ا', 'ی', 'و', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'د', 'ی', 'د', 'ن', '<b>', 'ک', 'ف', 'ش', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'چ', 'ن', 'د', '<b>', 'ث', 'ا', 'ن', 'ی', 'ه', '<b>', 'م', 'ک', 'ث', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 559: ru ye aayne baa didan e khabarnegaarhaa ye ma resh barandaazash kard\n",
            "PRED SCORE: -2.3283\n",
            "\n",
            "SENT 560: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ا', 'ز', '<b>', 'د', 'ل', 'ش', '<b>', 'ک', 'ن', 'د', 'ه', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'و', '<b>', 'ر', 'ی', 'خ', 'ت']\n",
            "PRED 560: engaar chizi az delash kande shod va foruq rikht\n",
            "PRED SCORE: -0.1142\n",
            "\n",
            "SENT 561: ['ا', 'ز', '<b>', 'ت', 'ه', '<b>', 'د', 'ل', '<b>', 'ا', 'ز', '<b>', 'خ', 'د', 'ا', '<b>', 'ک', 'م', 'ک', '<b>', 'خ', 'و', 'ا', 'س', 'ت']\n",
            "PRED 561: az haqq dah az khodaa khord e khoshbakht\n",
            "PRED SCORE: -1.6020\n",
            "\n",
            "SENT 562: ['ی', 'ک', '<b>', 'د', 'ف', 'ع', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ا', 'ش', 'پ', 'ز', 'خ', 'ا', 'ن', 'ه', '<b>', 'د', 'ی', 'د']\n",
            "PRED 562: yek daf e khodash raa dar angoshtaanash did\n",
            "PRED SCORE: -0.0904\n",
            "\n",
            "SENT 563: ['م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ی', 'ک', '<b>', 'ر', 'و', 'ز', '<b>', 'خ', 'ا', 'ن', 'م', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', 'ش', 'د']\n",
            "PRED 563: migoft yek ruz khaanome e khaane baashad\n",
            "PRED SCORE: -1.1001\n",
            "\n",
            "SENT 564: ['ف', 'ن', 'ج', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'چ', 'ی', 'د', '<b>', 'ه', 'ر', '<b>', 'ی', 'ک', '<b>', 'ر', 'ا', '<b>', 'چ', 'ا', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', '<b>', 'ن', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ا', 'ط', 'م', 'ی', 'ن', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ج', 'ه', 'ت', '<b>', 'ر', 'ن', 'گ', 'ش', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'م', 'ی', '\\u200c', 'چ', 'ی', 'د']\n",
            "PRED 564: khaane raa dar chenin chiz e har hessi be aqab barmiqasht va baqalash mikard\n",
            "PRED SCORE: -3.6925\n",
            "\n",
            "SENT 565: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ا', 'ز', '<b>', 'ر', 'ن', 'گ', '<b>', 'و', '<b>', 'ر', 'و', 'ی', '<b>', 'چ', 'ا', 'ی', 'ش', '<b>', 'ا', 'ی', 'ر', 'ا', 'د', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 565: puraan hamishe az rang o ru ye biaabaan milarzid\n",
            "PRED SCORE: -1.0663\n",
            "\n",
            "SENT 566: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ی', 'ا', 'د', 'ا', 'و', 'ر', 'ی', '<b>', 'ا', 'و', '<b>', 'ن', 'ا', 'خ', 'و', 'د', 'ا', 'گ', 'ا', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 566: foruq baa qaateiyat u naakhodaagaah labkhand zad\n",
            "PRED SCORE: -1.2521\n",
            "\n",
            "SENT 567: ['ب', 'ا', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'چ', 'ا', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ش', 'پ', 'ز', 'خ', 'ا', 'ن', 'ه', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'پ', 'ل', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ا', 'ل', 'ا', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', 'ل', 'ی', '<b>', 'ق', 'ب', 'ل', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'و', 'ر', 'و', 'د', 'ی', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', 'ز', '<b>', 'ک', 'ن', 'د', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'د', 'ی', 'د']\n",
            "PRED 567: baa sini e chaay az aashpazkhaane be jaam baalaa khord va az khaane raa baaz konad\n",
            "PRED SCORE: -1.6933\n",
            "\n",
            "SENT 568: ['چ', 'ه', 'ر', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'ع', 'ص', 'ب', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'چ', 'ا', 'ی', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'ص', 'د', 'ا', 'ی', 'ش', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ل', 'ر', 'ز', 'ی', 'د']\n",
            "PRED 568: golestaan negaraan o asabi bud va vaqti chizi az foruq milarzid\n",
            "PRED SCORE: -2.5483\n",
            "\n",
            "SENT 569: ['ب', 'د', 'ه', '<b>', 'ب', 'ه', '<b>', 'م', 'ن']\n",
            "PRED 569: bedune be man\n",
            "PRED SCORE: -1.0549\n",
            "\n",
            "SENT 570: ['خ', 'و', 'د', 'ت', '<b>', 'ه', 'م', '<b>', 'ب', 'ر', 'و', '<b>', 'ت', 'و', 'ی', '<b>', 'ا', 'ت', 'ا', 'ق']\n",
            "PRED 570: khodet ham boro tu ye otaaq\n",
            "PRED SCORE: -0.7168\n",
            "\n",
            "SENT 571: ['ف', 'ر', 'و', 'غ', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ک', 'ه', '<b>', 'ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ط', 'ر', 'ف', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'ب', 'ا', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', '<b>', 'و', '<b>', 'ت', 'ع', 'ج', 'ب', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ق', 'ب', 'ل', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ر', 'و', 'د', '<b>', 'ت', 'و', 'ی', '<b>', 'ه', 'ا', 'ل', '<b>', 'ک', 'م', 'ی', '<b>', 'م', 'ک', 'ث', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 571: foruq u raa ke ajulaane be taraf e otaaq ye jaalebetun baa otaaq az aanhaa miresidam dukht\n",
            "PRED SCORE: -3.1538\n",
            "\n",
            "SENT 572: ['ص', 'د', 'ا', 'ه', 'ا', '<b>', 'ا', 'و', 'ج', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'خ', 'ش', 'ک', '<b>', 'و', '<b>', 'س', 'ر', 'د', '<b>', 'و', '<b>', 'ج', 'د', 'ی', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د']\n",
            "PRED 572: sedaa ye goftogu gerefte va pedarash baa rabti harf mizad va sarash harf mizad\n",
            "PRED SCORE: -3.6678\n",
            "\n",
            "SENT 573: ['خ', 'ا', 'ن', 'و', 'م', '<b>', 'م', 'ن', '<b>', 'ق', 'ب', 'ل', 'ا', '<b>', 'ج', 'و', 'ا', 'ب', 'م', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ش', 'م', 'ا', '<b>', 'د', 'ا', 'د', 'م']\n",
            "PRED 573: khaanum e man qablan jelow ro be shomaa daadam\n",
            "PRED SCORE: -1.1766\n",
            "\n",
            "SENT 574: ['ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م', '<b>', 'ر', 'ک', '<b>', 'و', '<b>', 'پ', 'و', 'س', 'ت', '<b>', 'ک', 'ن', 'د', 'ه', '<b>', 'گ', 'ف', 'ت', 'م']\n",
            "PRED 574: fekr mikardam pas va pust e kohne goftam\n",
            "PRED SCORE: -1.3266\n",
            "\n",
            "SENT 575: ['ح', 'ا', 'ل', 'ا', '<b>', 'چ', 'ه', '<b>', 'ا', 'ص', 'ر', 'ا', 'ر', 'ی', 'ه', '<b>', 'ح', 'ت', 'م', 'ا', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'م', 'ن', '<b>', 'ب', 'ش', 'ه', '<b>', 'ع', 'ر', 'و', 'س', 'ت', 'و', 'ن']\n",
            "PRED 575: haalaa che aakharin hatman dokhtar e man bude gerefti\n",
            "PRED SCORE: -2.7671\n",
            "\n",
            "SENT 576: ['م', 'ا', 'ش', 'ا', 'ل', 'ا', '<b>', 'ت', 'و', '<b>', 'ا', 'ی', 'ن', '<b>', 'ش', 'ه', 'ر', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ک', 'ه', '<b>', 'ز', 'ی', 'ا', 'د', 'ه', '<b>', 'د', 'خ', 'ت', 'ر']\n",
            "PRED 576: maashaallaa to in shahr e giji ke ziaad dokhtar\n",
            "PRED SCORE: -1.9890\n",
            "\n",
            "SENT 577: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'پ', 'د', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ا', 'ن', '<b>', 'ق', 'د', 'ر', '<b>', 'س', 'ف', 'ت', '<b>', 'ن', 'ب', 'ا', 'ش']\n",
            "PRED 577: shaapur pedar e parviz goft khaahesh e sargord e inkalame nabaashe\n",
            "PRED SCORE: -1.4987\n",
            "\n",
            "SENT 578: ['خ', 'د', 'ا', '<b>', 'ر', 'و', '<b>', 'خ', 'و', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ی', 'ا', 'د']\n",
            "PRED 578: khodaa ro khosh nemiaad\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 579: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ز', '<b>', 'ش', 'م', 'ا', '<b>', 'ت', 'ع', 'ج', 'ب', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ا', 'ق', 'ا', 'ی', '<b>', 'ش', 'ا', 'پ', 'و', 'ر']\n",
            "PRED 579: sargord bi moqaddame goft az shomaa albatte aaqaaye shaapur\n",
            "PRED SCORE: -1.0149\n",
            "\n",
            "SENT 580: ['ش', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'م', 'ا', 'ش', 'ا', 'ل', 'ا', '<b>', 'چ', 'ه', 'ا', 'ر', '<b>', 'ت', 'ا', '<b>', 'پ', 'ی', 'ر', 'ه', 'ن', '<b>', 'ا', 'ز', '<b>', 'م', 'ا', '<b>', 'ب', 'ی', 'ش', 'ت', 'ر', '<b>', 'پ', 'ا', 'ر', 'ه', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'و', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'چ', 'ق', 'د', 'ر', '<b>', 'س', 'خ', 'ت', '<b>', 'ش', 'د', 'ه']\n",
            "PRED 580: shomaa ke maashaallaa chikaar taa bachcharo az maa khalaas kardi o behtar mikone\n",
            "PRED SCORE: -3.5950\n",
            "\n",
            "SENT 581: ['ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'ش', 'م', 'ا', '<b>', 'ا', 'م', 'س', 'ا', 'ل', '<b>', 'م', 'ا', '<b>', 'ر', 'و', '<b>', 'ش', 'ر', 'م', 'ن', 'د', 'ه', '<b>', 'ک', 'ر', 'د', 'ی', 'ن', '<b>', 'و', '<b>', 'ق', 'ب', 'ل', '<b>', 'ا', 'ز', '<b>', 'م', 'ا', '<b>', 'ت', 'ش', 'ر', 'ی', 'ف', '<b>', 'ا', 'و', 'ر', 'د', 'ی', 'ن', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ذ', 'ا', 'ر', 'ی', 'ن', '<b>', 'ت', 'ش', 'ر', 'ر', 'ی', 'ف', '<b>', 'ف', 'ر', 'م', 'ا', 'ی', 'ی', 'ت', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ب', 'ذ', 'ا', 'ر', 'ی', 'م', '<b>', 'ب', 'ه', '\\u200c', 'ح', 'س', 'ا', 'ب', '<b>', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ا', 'ز', 'د', 'ی', 'د', '<b>', 'ع', 'ی', 'د']\n",
            "PRED 581: inke shomaa unjaa maa ro gerun jor o jur miforushand aavard\n",
            "PRED SCORE: -2.5141\n",
            "\n",
            "SENT 582: ['م', 'ن', '<b>', 'ق', 'ب', 'ل', 'ا', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ن', 'و', 'م', '<b>', 'گ', 'ف', 'ت', 'م']\n",
            "PRED 582: man ke be nerkh e goftam\n",
            "PRED SCORE: -1.4956\n",
            "\n",
            "SENT 583: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ن', '<b>', 'ب', 'چ', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 583: foruq man bachchast\n",
            "PRED SCORE: -0.1184\n",
            "\n",
            "SENT 584: ['م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'د', 'ر', 'س', '<b>', 'ب', 'خ', 'و', 'ن', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'ر', 'ا', '<b>', 'ق', 'ط', 'ع', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ش', 'و', 'ه', 'ر', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 584: mikhaad dars bekhune shamsi harfash raa qat o goft vali dokhtar e baayad baalaa kone\n",
            "PRED SCORE: -1.2348\n",
            "\n",
            "SENT 585: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'س', 'ر', 'د', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ل', 'ه']\n",
            "PRED 585: farrokhzaad daad be zahmat beshe\n",
            "PRED SCORE: -1.4212\n",
            "\n",
            "SENT 586: ['ا', 'م', 'ا', '<b>', 'ن', 'ه', '<b>', 'ب', 'ا', '<b>', 'م', 'ر', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'پ', 'ا', 'ن', 'ز', 'د', 'ه', '<b>', 'س', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه']\n",
            "PRED 586: ammaa na baa mardi ke maast saal az khodesh besuze\n",
            "PRED SCORE: -1.7814\n",
            "\n",
            "SENT 587: ['ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ا', 'ن', '<b>', 'ج', 'و', 'ا', 'ن', '<b>', 'م', 'ع', 'ق', 'و', 'ل', '<b>', 'و', '<b>', 'م', 'ت', 'ی', 'ن', 'ی', '<b>', 'ا', 'ن', 'د']\n",
            "PRED 587: albatte parviz jaan gushi e mahsur ma r ast\n",
            "PRED SCORE: -2.0381\n",
            "\n",
            "SENT 588: ['ا', 'م', 'ا', '<b>', 'ر', 'ک', '<b>', 'ب', 'گ', 'م', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'م', 'ن', '<b>', 'ت', 'ح', 'م', 'ل', '<b>', 'س', 'خ', 'ت', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'ن', 'د']\n",
            "PRED 588: ammaa rokk begam bachchehaa ye man tamum nadaashtam\n",
            "PRED SCORE: -1.1082\n",
            "\n",
            "SENT 589: ['ش', 'ا', 'پ', 'و', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'س', 'خ', 'ت', '<b>', 'ن', 'گ', 'ی', 'ر', '<b>', 'م', 'ر', 'د']\n",
            "PRED 589: shaapur goft sakht nagir mard\n",
            "PRED SCORE: -0.0023\n",
            "\n",
            "SENT 590: ['ه', 'ر', 'د', 'و', 'ش', 'و', 'ن', '<b>', 'ج', 'و', 'و', 'ن', 'ن', 'د']\n",
            "PRED 590: hanuzam sukht\n",
            "PRED SCORE: -0.2632\n",
            "\n",
            "SENT 591: ['د', 'ل', 'گ', 'ر', 'م', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ش', 'ن', 'د', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'س', 'ا', 'ز', 'ن', 'د']\n",
            "PRED 591: delam ke baashand chekaarash ro id\n",
            "PRED SCORE: -1.3649\n",
            "\n",
            "SENT 592: ['خ', 'و', 'د', 'م', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ی', 'ا', 'د', 'ت', '<b>', 'ر', 'ف', 'ت', 'ه']\n",
            "PRED 592: khodemun ro qabz e rafte\n",
            "PRED SCORE: -0.8926\n",
            "\n",
            "SENT 593: ['ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ه', '<b>', 'ج', 'و', 'و', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ف', 'ر', 'ص', 'ت', '<b>', 'د', 'ا', 'د']\n",
            "PRED 593: baayad be zud forsat daad\n",
            "PRED SCORE: -0.2071\n",
            "\n",
            "SENT 594: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'ب', 'ح', 'ث', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'م', 'و', 'د', 'ب', 'ا', 'ن', 'ه', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'ش', 'د']\n",
            "PRED 594: parviz miaan e boqz bahaanegir moaddabaane\n",
            "PRED SCORE: -1.4509\n",
            "\n",
            "SENT 595: ['ب', 'ب', 'خ', 'ش', 'ی', 'د', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'س', 'ر', 'گ', 'ر', 'د']\n",
            "PRED 595: be sakhti khasteid\n",
            "PRED SCORE: -0.2763\n",
            "\n",
            "SENT 596: ['ه', 'م', 'ه', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'ش', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ق', 'ل', 'ب', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ی', 'خ', 'ت']\n",
            "PRED 596: hame saaket shode va qalb e foruq rikht\n",
            "PRED SCORE: -0.9479\n",
            "\n",
            "SENT 597: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'و', 'ش', 'ی', 'د', '<b>', 'خ', 'و', 'د', 'د', 'ا', 'ر', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ط', 'ف', 'ر', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'د', 'ر', '<b>', 'ا', 'د', 'ا', 'م', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ب', 'خ', 'ش', 'ی', 'د', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', 'م', '<b>', 'ا', 'گ', 'ه', '<b>', 'ا', 'ج', 'ا', 'ز', 'ه', '<b>', 'ب', 'ف', 'ر', 'م', 'ا', 'ی', 'ی', 'د', '<b>', 'م', 'ط', 'ل', 'ب', 'ی', '<b>', 'ر', 'و', '<b>', 'ع', 'ر', 'ض', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 597: parviz ke nayaavard khodeto baad e homaayun ke az naahaar benevisid\n",
            "PRED SCORE: -3.1429\n",
            "\n",
            "SENT 598: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'ا', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'ر', 'س', 'م', '<b>', 'ن', 'ب', 'و', 'د', 'ه', '<b>', 'د', 'ر', '<b>', 'م', 'ج', 'ا', 'ل', 'س', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'گ', 'ا', 'ر', 'ی', '<b>', 'پ', 'س', 'ر', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'ه']\n",
            "PRED 598: farrokhzaad bi aqli goft taa emruz esm e neshun harf bezane\n",
            "PRED SCORE: -3.0322\n",
            "\n",
            "SENT 599: ['ش', 'م', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', 'ت', 'ر', 'ه', '<b>', 'ت', 'ا', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه', 'ا', '<b>', 'ه', 'س', 'ت', 'ن', 'د', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ح', 'ر', 'ف', 'ش', '<b>', 'ر', 'ا', '<b>', 'ق', 'ط', 'ع', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ر', 'م', 'ا', 'ی', 'ش', '<b>', 'ش', 'م', 'ا', '<b>', 'د', 'ر', 'س', 'ت', 'ه', '<b>', 'و', 'ل', 'ی', '<b>', 'ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', '<b>', 'ا', 'و', 'ل', 'ی', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'ک', 'ه', '<b>', 'ا', 'ی', 'ن', 'و', '<b>', 'ب', 'ه', 'ت', 'و', 'ن', '<b>', 'گ', 'ف', 'ت', 'م']\n",
            "PRED 599: shomaa ham behtare taa tajrobehaa ro parviz harfash ke ino be injaast bezanam\n",
            "PRED SCORE: -2.5784\n",
            "\n",
            "SENT 600: ['ا', 'و', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ه', 'م', '<b>', 'ک', 'ه', '<b>', 'ه', 'م', 'د', 'ی', 'گ', 'ه', '<b>', 'ر', 'و', '<b>', 'ت', 'و', 'ی', '<b>', 'خ', 'ی', 'ا', 'ب', 'و', 'ن', '<b>', 'د', 'ی', 'د', 'ی', 'م', '<b>', 'ا', 'ی', 'ن', '<b>', 'م', 'س', 'ا', 'ل', 'ه', '<b>', 'ر', 'و', '<b>', 'ت', 'ذ', 'ک', 'ر', '<b>', 'د', 'ا', 'د', 'م']\n",
            "PRED 600: un ruz ham ke nashod ro tu ye in majalle ye in sarzamine\n",
            "PRED SCORE: -2.0557\n",
            "\n",
            "SENT 601: ['م', 'ا', '<b>', 'ش', 'ا', 'ی', 'د', '<b>', 'ا', 'ز', '<b>', 'ا', 'س', 'ب', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', 'ه', '<b>', 'ب', 'ا', 'ش', 'ی', 'م', '<b>', 'و', 'ل', 'ی', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ا', 'ز', '<b>', 'ا', 'ص', 'ل', '<b>', 'ن', 'ی', 'ف', 'ت', 'ا', 'د', 'ی', 'م', '<b>', 'پ', 'س', 'ر', 'ج', 'و', 'ن']\n",
            "PRED 601: maa shaayad az qabl eraade baashi vali az nazar daadim\n",
            "PRED SCORE: -2.8120\n",
            "\n",
            "SENT 602: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ق', 'د', 'ر', 'ی', '<b>', 'ز', 'ا', 'ن', 'و', 'ا', 'ن', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ا', 'ر', 'ز', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ب', 'ه', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ر', 'س', 'ا', 'ن', 'د']\n",
            "PRED 602: foruq be qadri goft mitarsid ke be zahmat naakhunak miaad\n",
            "PRED SCORE: -2.6668\n",
            "\n",
            "SENT 603: ['پ', 'س', '<b>', 'ق', 'ب', 'ل', 'ا', '<b>', 'ب', 'ا', '<b>', 'پ', 'د', 'ر', '<b>', 'ح', 'ر', 'ف', '<b>', 'ز', 'د', 'ه']\n",
            "PRED 603: pas qablan baa pedar harf zade\n",
            "PRED SCORE: -0.0177\n",
            "\n",
            "SENT 604: ['م', 'و', '<b>', 'ب', 'ه', '<b>', 'ت', 'ن', 'ش', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د']\n",
            "PRED 604: mu be tanam istaad\n",
            "PRED SCORE: -0.0050\n",
            "\n",
            "SENT 605: ['ص', 'د', 'ا', 'ی', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د']\n",
            "PRED 605: sedaa ye sargord hanuz miaamad\n",
            "PRED SCORE: -0.1348\n",
            "\n",
            "SENT 606: ['ز', 'م', 'ا', 'ن', '<b>', 'م', 'ا', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ق', 'ر', 'ا', 'ر', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ر', 'ا', 'م', 'و', 'ن', '<b>', 'ز', 'ن', '<b>', 'ب', 'گ', 'ی', 'ر', 'ن', 'د', '<b>', 'ح', 'ت', 'ی', '<b>', 'ح', 'ق', '<b>', 'ا', 'ن', 'ت', 'خ', 'ا', 'ب', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'ی', 'م']\n",
            "PRED 606: zamaan maa vaqti qaraar bud baraam zan e dorostie tarsu nadaashti\n",
            "PRED SCORE: -2.7266\n",
            "\n",
            "SENT 607: ['ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ر', 'ی', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'خ', 'ت', 'ن', 'د']\n",
            "PRED 607: bespaarid midunid va midunand\n",
            "PRED SCORE: -0.8517\n",
            "\n",
            "SENT 608: ['ح', 'ا', 'ل', 'ا', '<b>', 'د', 'ر', 'س', 'ت', 'ه', '<b>', 'ک', 'ه', '<b>', 'ش', 'م', 'ا', '<b>', 'ب', 'چ', 'ه', '<b>', 'ن', 'ی', 'س', 'ت', 'ی', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ه', 'ر', 'ح', 'ا', 'ل', '<b>', 'ا', 'د', 'ب', '<b>', 'ح', 'ک', 'م', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه', '<b>', 'ک', 'ا', 'ر', '<b>', 'ر', 'و', '<b>', 'ب', 'س', 'پ', 'ا', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه', 'ا']\n",
            "PRED 608: haalaa doroste ke shomaa bachche nisti vali honarhaa ye qossehaam e man ro khaastid\n",
            "PRED SCORE: -2.3869\n",
            "\n",
            "SENT 609: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ش', 'ر', 'م', 'ن', 'د', 'ه', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', '<b>', 'ز', 'ی', 'ر', '<b>', 'ا', 'ن', 'د', 'ا', 'خ', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', 'ت', '<b>', 'ز', 'د', 'ه', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ا', 'ر', '<b>', 'و', '<b>', 'ص', 'ر', 'ا', 'ح', 'ت', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'ر', '<b>', 'ج', 'ا', '<b>', 'خ', 'ش', 'ک', 'ش', '<b>', 'ز', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ی', 'ک', '<b>', 'س', 'ط', 'ل', '<b>', 'ا', 'ب', '<b>', 'ر', 'و', 'ی', '<b>', 'س', 'ر', 'ش', '<b>', 'پ', 'ا', 'ش', 'ی', 'د', 'ه', '<b>', 'ب', 'ا', 'ش', 'ن', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'گ', 'ی', 'ج', '<b>', 'و', '<b>', 'م', 'ن', 'گ', '<b>', 'ب', 'و', 'د']\n",
            "PRED 609: turaan ranjide sar be zir andaakht va shamsi boqz foru ke aanqadr gereftand\n",
            "PRED SCORE: -3.1588\n",
            "\n",
            "SENT 610: ['گ', 'ر', 'چ', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 610: garche haal e foruq ham dar angoshtaanash behtar az u zende nabud\n",
            "PRED SCORE: -0.7736\n",
            "\n",
            "SENT 611: ['ز', 'م', 'ا', 'ن', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ا', 'م', 'د', '<b>', 'ک', 'ه', '<b>', 'م', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'د', 'ر', '<b>', 'ح', 'ا', 'ل', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ب', 'و', 'د', 'ن', 'د']\n",
            "PRED 611: dahaanash be khodash aamad ke righaa ye dar haal e raftan budand\n",
            "PRED SCORE: -1.3216\n",
            "\n",
            "SENT 612: ['ا', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', '<b>', 'ت', 'ع', 'ا', 'ر', 'ف', 'ا', 'ت', '<b>', 'ب', 'ه', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ر', 'ف', 'ت', 'ن', '<b>', 'ع', 'ج', 'ل', 'ه', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'پ', 'ن', 'ج', 'ر', 'ه', '<b>', 'د', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'ش', 'م', 'س', 'ی', '<b>', 'ح', 'ت', 'ی', '<b>', 'ب', 'ا', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ب', 'ه', '<b>', 'ع', 'ا', 'د', 'ت', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ر', 'و', 'ب', 'و', 'س', 'ی', '<b>', 'ن', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ه', 'م', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ب', 'د', 'ر', 'ق', 'ه', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'و', 'ا', 'ن', '<b>', 'ج', 'ل', 'و', 'ت', 'ر', '<b>', 'ن', 'ر', 'ف', 'ت']\n",
            "PRED 612: in baar qesmat be sardi e surat e parviz baraaye posht e panjare ye parviz ham baraaye aayne be maadarash khire daasht\n",
            "PRED SCORE: -3.3180\n",
            "\n",
            "SENT 613: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'غ', 'ض', 'ی', '<b>', 'د', 'ر', '<b>', 'گ', 'ل', 'و', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'ی', 'د', '<b>', 'خ', 'ف', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ک', 'ن', 'د', '<b>', 'د', 'ر', '<b>', 'و', 'ا', 'ق', 'ع', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ا', 'ب', '<b>', 'پ', 'ا', 'ک', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ی', 'خ', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 613: foruq be sakhti dar lebaas e ke mitarsid khaan dast e pedarash baa shetaab gerye foru rikht\n",
            "PRED SCORE: -4.7196\n",
            "\n",
            "SENT 614: ['د', 'س', 'ت', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'ر', 'و', 'ی', '<b>', 'گ', 'و', 'ش', '\\u200c', 'ه', 'ا', 'ی', 'ش', '<b>', 'ف', 'ش', 'ا', 'ر', '<b>', 'د', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'ش', 'ن', 'و', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ا', 'و', '<b>', 'ب', 'ل', 'ن', 'د', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ش', 'و', 'د', '<b>', 'ف', 'ر', 'ا', 'ر', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 614: dastaanash raa ru ye hamshahri shenow va sedaa ye khodash raa nashenaakht ke badanash u raa nashenaakht\n",
            "PRED SCORE: -2.6251\n",
            "\n",
            "SENT 615: ['ب', 'ی', 'چ', 'ا', 'ر', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'ش']\n",
            "PRED 615: bichaare maadar\n",
            "PRED SCORE: -0.0035\n",
            "\n",
            "SENT 616: ['م', 'ی', '\\u200c', 'ک', 'و', 'ش', 'ی', 'د', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'ک', 'ن', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ح', 'ر', 'ی', 'ف', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ش', 'د']\n",
            "PRED 616: migoft u raa kenaar konad ammaa havaasesh mikeshad\n",
            "PRED SCORE: -1.3958\n",
            "\n",
            "SENT 617: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', '<b>', 'پ', 'س', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'س', 'م', 'و', 'ن', '<b>', 'ج', 'ل', '<b>', 'خ', 'ج', 'ا', 'ل', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ش', 'ه']\n",
            "PRED 617: sargord faryaad mizad dowre ye azam jelow nemikone\n",
            "PRED SCORE: -2.2507\n",
            "\n",
            "SENT 618: ['ف', 'ک', 'ر', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'م', 'ن', '<b>', 'م', 'ا', 'د', 'ر', 'ش', 'م', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'ق', 'د', '<b>', 'و', '<b>', 'ب', 'ا', 'ل', 'ا', 'ش', '<b>', 'ذ', 'و', 'ق', '<b>', 'ک', 'ن', 'م', '<b>', 'و', '<b>', 'د', 'ل', 'م', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'ز', 'د', 'ن', 'ش', '<b>', 'ر', 'ی', 'س', 'ه', '<b>', 'ب', 'ر', 'ه']\n",
            "PRED 618: fekr karde man maadaram ke be har haal o baalaa harf e sofrei\n",
            "PRED SCORE: -2.6548\n",
            "\n",
            "SENT 619: ['م', 'گ', 'ه', '<b>', 'ق', 'د', 'غ', 'ن', '<b>', 'ن', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'ا', 'ی', 'ن', '<b>', 'پ', 'س', 'ر', 'ه', '<b>', 'و', '<b>', 'ک', 'س', '<b>', 'و', '<b>', 'ک', 'ا', 'ر', 'ش', '<b>', 'ن', 'ی', 'ا', 'ن', '<b>', 'ا', 'ی', 'ن', 'ج', 'ا']\n",
            "PRED 619: mage qadeqan nakarde budam in pesare o baavar nakon injaa\n",
            "PRED SCORE: -2.1355\n",
            "\n",
            "SENT 620: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'و', '<b>', 'م', 'ح', 'ت', 'ا', 'ط', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ا', 'ل', 'ا', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ن', '<b>', 'ر', 'و', 'ح', 'م', '<b>', 'ه', 'م', '<b>', 'خ', 'ب', 'ر', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'ا', 'ق', 'ا']\n",
            "PRED 620: turaan baa sedaai larzaan o molaaheze goft vaase khodaa aashpazi miaam aaqaa\n",
            "PRED SCORE: -2.5042\n",
            "\n",
            "SENT 621: ['ح', 'ت', 'ی', '<b>', 'ا', 'م', 'س', 'ا', 'ل', '<b>', 'ع', 'ی', 'د', '<b>', 'د', 'ی', 'د', 'ن', 'ی', '<b>', 'ه', 'م', '<b>', 'ن', 'ر', 'ف', 'ت', 'م']\n",
            "PRED 621: hattaa engaar pish e chenin ham nemide\n",
            "PRED SCORE: -2.2567\n",
            "\n",
            "SENT 622: ['چ', 'ه', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'ا', 'و', 'ن', 'ا', '<b>', 'م', 'ی', 'ا', 'ن']\n",
            "PRED 622: che midunam unaa miaan e man\n",
            "PRED SCORE: -1.6283\n",
            "\n",
            "SENT 623: ['م', 'ن', '<b>', 'ک', 'ه', '<b>', 'ک', 'ف', '<b>', 'د', 'س', 'ت', 'م', 'و', '<b>', 'ب', 'و', '<b>', 'ن', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م']\n",
            "PRED 623: man ke ke dastam ke hanuz budam\n",
            "PRED SCORE: -2.4229\n",
            "\n",
            "SENT 624: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'ر', 'و', '<b>', 'پ', 'ر', 'و', '<b>', 'ج', 'ل', 'و', '<b>', 'م', 'ن', 'و', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'ز', 'ل', '<b>', 'ز', 'د', 'ه', '<b>', 'ت', 'و', '<b>', 'چ', 'ش', 'م', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'م', 'ن', '<b>', 'م', 'ی', 'گ', 'ه', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', '<b>', 'ر', 'و', '<b>', 'خ', 'و', 'ش', 'ب', 'خ', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 624: fardaa daad mizane goft foruq por jush mano aazaar mikonam\n",
            "PRED SCORE: -3.2608\n",
            "\n",
            "SENT 625: ['ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ق', 'س', 'م', '<b>', 'ب', 'ه', '<b>', 'ا', 'ر', 'و', 'ا', 'ح', '<b>', 'خ', 'ا', 'ک', '<b>', 'پ', 'د', 'ر', 'م', '<b>', 'ا', 'گ', 'ه', '<b>', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', 'ی', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ه', 'م', 'و', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', 'م', '<b>', 'ت', 'و', 'ی', '<b>', 'د', 'ه', 'ن', 'ش', '<b>', 'ک', 'ه', '<b>', 'د', 'ن', 'د', 'و', 'ن', '<b>', 'ب', 'ر', 'ا', 'ش', '<b>', 'ن', 'م', 'و', 'ن', 'ه']\n",
            "PRED 625: be khodaa rahm be ehsaasam aql e pedaram neshun nabaasham ke dur nistam ke konam\n",
            "PRED SCORE: -4.1549\n",
            "\n",
            "SENT 626: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'م', 'ن', '<b>', 'ن', 'گ', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د', 'ی', 'ن']\n",
            "PRED 626: turaan goft be man mo harfhaa budi\n",
            "PRED SCORE: -0.8845\n",
            "\n",
            "SENT 627: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '\\u200c', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ق', 'ب', 'ل', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'ز', 'د', '<b>', '<b>', 'ا', 'ی', 'ن', 'ا', '<b>', 'ه', 'م', 'ش', '<b>', 'ت', 'ق', 'ص', 'ی', 'ر', '<b>', 'ت', 'و', 'ی', 'ه']\n",
            "PRED 627: sargord asabaanitar az qabl faryaad zad inaa hamash qaabel e foruqe\n",
            "PRED SCORE: -1.5648\n",
            "\n",
            "SENT 628: ['م', 'ن', '<b>', 'ه', 'ر', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'م', '<b>', 'ا', 'ز', '<b>', 'د', 'س', 'ت', '<b>', 'ت', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'م']\n",
            "PRED 628: man har chiz e mohkam az dast e to migardam\n",
            "PRED SCORE: -2.7175\n",
            "\n",
            "SENT 629: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'چ', 'ه', '<b>', 'ت', 'ق', 'ص', 'ی', 'ر', 'ی', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ا', 'ق', 'ا']\n",
            "PRED 629: turaan miaan e gerye goft man che taqsiri daaram aaqaa\n",
            "PRED SCORE: -0.0049\n",
            "\n",
            "SENT 630: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'ه', 'ی', '<b>', 'ک', 'س', '<b>', 'و', '<b>', 'ک', 'ا', 'ر', 'ت', '<b>', 'ر', 'و', '<b>', 'و', 'ع', 'د', 'ه', '<b>', 'ن', 'گ', 'ی', 'ر', 'ی', '<b>', 'و', '<b>', 'د', 'خ', 'ت', 'ر', 'ا', 'ت', '<b>', 'ر', 'و', '<b>', 'ن', 'م', 'ا', 'ی', 'ش', '<b>', 'ن', 'د', 'ی', '<b>', 'ه', 'ر', '<b>', 'ک', 'س', '<b>', 'و', '<b>', 'ن', 'ا', 'ک', 'س', 'ی', '<b>', 'ر', 'ا', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ا', 'ف', 'ت', 'ه', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'د', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ر', 'و', '<b>', 'ب', 'ز', 'ن', 'ه']\n",
            "PRED 630: sargord goft age hichvqt ke marize ro labkhand o mimire\n",
            "PRED SCORE: -2.9484\n",
            "\n",
            "SENT 631: ['م', 'ن', '<b>', 'ب', 'ه', '<b>', 'گ', 'و', 'ر', '<b>', 'پ', 'د', 'ر', 'م', '<b>', 'م', 'ی', '\\u200c', 'خ', 'ن', 'د', 'م', '<b>', 'ب', 'ا', '<b>', 'ی', 'ک', 'ی', '<b>', 'د', 'و', '<b>', 'ب', 'ا', 'ر', '<b>', 'ف', 'ا', 'م', 'ی', 'ل', '<b>', 'ش', 'م']\n",
            "PRED 631: man be zur e pedaram emoshkel baa yeki do baar amali kaafie\n",
            "PRED SCORE: -3.0535\n",
            "\n",
            "SENT 632: ['ه', 'م', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'ب', 'ا', 'ر', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'ه', 'ف', 'ت', '<b>', 'پ', 'ش', 'ت', 'م', '<b>', 'ب', 'س', 'ه']\n",
            "PRED 632: hamun yek baar vaase haft poshtam bokon\n",
            "PRED SCORE: -0.6429\n",
            "\n",
            "SENT 633: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ه', '<b>', 'ج', 'ه', 'ت', '<b>', 'د', 'ف', 'ا', 'ع', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ر', 'و', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', 'ش', 'ه', '<b>', 'ق', 'ا', 'ی', 'م', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'ا', 'ق', 'ا']\n",
            "PRED 633: turaan be aqab tekye shod va goft dokhtar ro ke nemishe\n",
            "PRED SCORE: -1.2912\n",
            "\n",
            "SENT 634: ['ش', 'م', 'ا', '<b>', 'چ', 'ه', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ی', 'د']\n",
            "PRED 634: shomaa che harfhaa mikonid\n",
            "PRED SCORE: -0.6091\n",
            "\n",
            "SENT 635: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'د', 'س', 'ت', 'ه', '<b>', 'گ', 'ل', 'ی', '<b>', 'ر', 'ا', '<b>', 'ک', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'و', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', 'س', 'ط', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'پ', 'ر', 'ت', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', 'ا', 'ی', '<b>', 'م', 'ن', '<b>', 'گ', 'و', 'ش', 'ه', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ب', 'پ', 'و', 'س', 'ن', 'د', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'د', 'ش', 'و', 'ن', '<b>', 'ر', 'و', '<b>', 'ز', 'ی', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'ک', 'ن', 'ن', 'د']\n",
            "PRED 635: farrokhzaad kojaast e kutaahi dastur e chenin raa ke parviz e man behet az une ke maast\n",
            "PRED SCORE: -4.5104\n",
            "\n",
            "SENT 636: ['ف', 'ق', 'ط', '<b>', 'ا', 'گ', 'ه', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ف', 'ق', 'ط', '<b>', 'ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'پ', 'س', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'و', 'ک', 'ل', 'ی', '<b>', 'پ', 'ا', 'ش', 'و', '<b>', 'ا', 'ز', '<b>', 'د', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ب', 'ذ', 'ا', 'ر', 'ه', '<b>', 'ت', 'و', '<b>', 'ب', 'ه', '<b>', 'ا', 'ر', 'و', 'ا', 'ح', '<b>', 'خ', 'ا', 'ک', '<b>', 'پ', 'د', 'ر', 'م', '<b>', 'س', 'ر', 'ش', 'و', '<b>', 'م', 'ی', 'ذ', 'ا', 'ر', 'م', '<b>', 'ر', 'و', '<b>', 'س', 'ی', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ا', 'ی', 'ن', '<b>', 'خ', 'ط', '<b>', 'ا', 'ی', 'ن', '<b>', 'ن', 'ش', 'و', 'ن']\n",
            "PRED 636: faqat age yek baar faqat yek feshaar e dige be injaash barmiqasht\n",
            "PRED SCORE: -2.2943\n",
            "\n",
            "SENT 637: ['ف', 'ر', 'و', 'غ', '<b>', 'س', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ب', 'ا', 'ل', 'ش', '<b>', 'ف', 'ر', 'و', 'ک', 'ر', 'د', '<b>', 'ت', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ه', 'ق', '<b>', 'ه', 'ق', '<b>', 'گ', 'ر', 'ی', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ب', 'ه', '<b>', 'گ', 'و', 'ش', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ن', 'ر', 'س', 'د', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'د', 'ن', 'ی', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ب', 'ه', '<b>', 'ا', 'خ', 'ر', '<b>', 'ر', 'س', 'ی', 'د', 'ه', '<b>', 'و', '<b>', 'ا', 'ر', 'ز', 'و', 'ی', 'ی', '<b>', 'ج', 'ز', '<b>', 'م', 'ر', 'گ', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 637: foruq sarash raa dar baalesh e dastaanash taa sedaa ye engaar hamraahi konad\n",
            "PRED SCORE: -2.2389\n",
            "\n",
            "SENT 638: ['پ', 'د', 'ر', 'ش', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ک', 'ل', 'ی', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'و', '<b>', 'ت', 'ه', 'د', 'ی', 'د', '<b>', 'م', 'ث', 'ل', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'د', 'ف', 'ع', 'ا', 'ت', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'ب', 'ی', '<b>', 'خ', 'د', 'ا', 'ح', 'ا', 'ف', 'ظ', 'ی', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ر', 'ا', '<b>', 'ت', 'ر', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', '<b>', 'خ', 'و', 'ر', 'د', 'ن', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ش', 'ب', '<b>', 'ر', 'ا', '<b>', 'ش', 'ک', 'س', 'ت']\n",
            "PRED 638: pedarash ba d az maksi daade va faryaad o polis be ham khord\n",
            "PRED SCORE: -2.5535\n",
            "\n",
            "SENT 639: ['ا', 'ی', 'ا', '<b>', 'ک', 'س', 'ی', '<b>', 'ح', 'ق', '<b>', 'ا', 'ع', 'ت', 'ر', 'ا', 'ض', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 639: aayaa kolli haqq e naagofte daasht\n",
            "PRED SCORE: -1.0235\n",
            "\n",
            "SENT 640: ['ا', 'و', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'د', 'ر', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'ا', 'ن', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'د', 'ل', 'ش', '<b>', 'ر', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ص', 'ا', 'ح', 'ب', '<b>', 'ج', 'س', 'م', '<b>', 'و', '<b>', 'ر', 'و', 'ح', '<b>', 'و', '<b>', 'و', 'ل', 'ی', '<b>', 'ن', 'ع', 'م', 'ت', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت']\n",
            "PRED 640: u hamishe dar tamaam e in aasheq be donbaal e delash raft ammaa vali raa mizanid\n",
            "PRED SCORE: -2.6618\n",
            "\n",
            "SENT 641: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'ر', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ک', 'ی', 'ن', 'ه', '<b>', 'و', '<b>', 'ن', 'ف', 'ر', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ق', 'ا', 'ب', 'ل', '<b>', 'ق', 'ب', 'و', 'ل', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'م', 'ر', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'پ', 'س', '<b>', 'ا', 'ز', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'م', 'ش', 'ت', 'ر', 'ک', '<b>', 'و', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', '<b>', 'چ', 'ن', 'د', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ی', '<b>', 'ق', 'د', '<b>', 'و', '<b>', 'ن', 'ی', 'م', '<b>', 'ق', 'د', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'د', 'ل', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ر', 'و', 'د', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ا', 'ز', '<b>', 'ع', 'ش', 'ق', '<b>', 'ن', 'د', 'ا', 'ن', 'د']\n",
            "PRED 641: foruq dar e qabl haalaa dige dige nakard az dast e qabl hess mikard ke daasht movaajeh nemikard\n",
            "PRED SCORE: -4.1210\n",
            "\n",
            "SENT 642: ['ا', 'ی', 'ن', 'ج', 'ا', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ع', 'ل', 'ی', '<b>', 'ر', 'غ', 'م', '<b>', 'م', 'ی', 'ل', 'ش', '<b>', 'ب', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'ن', 'ت', 'ی', 'ج', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ر', 'س', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'م', 'و', 'ج', 'و', 'د', 'ی', '<b>', 'خ', 'و', 'د', 'خ', 'و', 'ا', 'ه', '<b>', 'و', '<b>', 'م', 'س', 'ت', 'ب', 'د', '<b>', 'ا', 'س', 'ت']\n",
            "PRED 642: injaa bud ke kasi ham be in natije miresid ke mibinand\n",
            "PRED SCORE: -2.3865\n",
            "\n",
            "SENT 643: ['چ', 'ر', 'ا', '<b>', 'ا', 'و', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ه', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', 'ی', 'ی', '<b>', 'ت', 'ص', 'م', 'ی', 'م', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', '<b>', 'چ', 'ه', '<b>', 'ب', 'خ', 'و', 'ر', 'ن', 'د', '<b>', 'چ', 'ه', '<b>', 'ب', 'پ', 'و', 'ش', 'ن', 'د', '<b>', 'چ', 'ه', '<b>', 'ب', 'خ', 'و', 'ا', 'ن', 'ن', 'د', '<b>', 'و', '<b>', 'چ', 'ه', '<b>', 'ب', 'گ', 'و', 'ی', 'ن', 'د']\n",
            "PRED 643: cheraa u baayad be tanhaai e hadsash be tanhaai che mibord che shokkast\n",
            "PRED SCORE: -3.0557\n",
            "\n",
            "SENT 644: ['ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'د', 'س', 'ت', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ه', 'م', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 644: foruq az dast e maadarsh ham asabaanie bud\n",
            "PRED SCORE: -0.8033\n",
            "\n",
            "SENT 645: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'م', 'ن', 'ف', 'ع', 'ل', '<b>', 'ب', 'و', 'د', 'ن', '<b>', 'و', '<b>', 'ا', 'ط', 'ا', 'ع', 'ت', '<b>', 'م', 'ح', 'ض', '<b>', 'ا', 'و', '<b>', 'پ', 'ر', '<b>', 'و', '<b>', 'ب', 'ا', 'ل', '<b>', 'ب', 'ی', 'ش', 'ت', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'د']\n",
            "PRED 645: be nazarash khodash bedune o haalaa mowqe e u az pedarash paride midaad\n",
            "PRED SCORE: -3.8217\n",
            "\n",
            "SENT 646: ['ا', 'و', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ن', 'م', 'و', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ت', 'ع', 'ر', 'ی', 'ف', '<b>', 'ش', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ز', 'ن', '<b>', 'د', 'ر', '<b>', 'ذ', 'ه', 'ن', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ب', 'و', 'د']\n",
            "PRED 646: u dorost nemune ta vat shodast dar zehnash feshord bud\n",
            "PRED SCORE: -3.5492\n",
            "\n",
            "SENT 647: ['ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'ز', 'ن', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'م', 'و', 'ج', 'و', 'د', 'ی', '<b>', 'م', 'ط', 'ی', 'ع', '<b>', 'و', '<b>', 'ص', 'ب', 'و', 'ر', '<b>', 'ب', 'ا', 'ش', 'د', '<b>', 'و', '<b>', 'ه', 'ر', 'گ', 'ز', '<b>', 'ح', 'ت', 'ی', '<b>', 'ف', 'ک', 'ر', '<b>', 'ن', 'ک', 'ن', 'د', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'م', 'ر', 'د', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'د', '<b>', 'ب', 'ر', '<b>', 'ا', 'ش', 'ت', 'ب', 'ا', 'ه', 'ا', 'ت', '<b>', 'م', 'ر', 'د', 'ش', '<b>', 'س', 'ر', 'پ', 'و', 'ش', '<b>', 'ب', 'گ', 'ذ', 'ا', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ص', 'ل', 'ا', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ف', 'ر', 'ا', 'م', 'و', 'ش', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 647: inke zan baayad dar in vaz iyat e fekr az mard e khodash paride konad\n",
            "PRED SCORE: -3.9670\n",
            "\n",
            "SENT 648: ['ا', 'ی', 'ن', '<b>', 'ب', 'ی', '<b>', 'ا', 'ن', 'ص', 'ا', 'ف', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 648: in bi entezaari bud\n",
            "PRED SCORE: -0.5350\n",
            "\n",
            "SENT 649: ['گ', 'ر', 'ی', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ق', 'ب', 'ل', '<b>', 'ش', 'د', 'ت', '<b>', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 649: gerye ye foruq bish az qabl sheddat gereft\n",
            "PRED SCORE: -0.2053\n",
            "\n",
            "SENT 650: ['ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'م', 'ش', 'ت', '<b>', 'ک', 'و', 'ب', 'ی', 'د', '<b>', 'و', '<b>', 'ت', 'ک', 'ر', 'ا', 'ر', '<b>', 'ک', 'ر', 'د', '<b>', 'چ', 'ر', 'ا']\n",
            "PRED 650: asabaani ru ye qarib posht e ajibi o tekraar kard cheraa\n",
            "PRED SCORE: -1.4459\n",
            "\n",
            "SENT 651: ['چ', 'ر', 'ا', '<b>', 'چ', 'ر', 'ا']\n",
            "PRED 651: cheraa cheraa\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 652: ['ح', 'ا', 'ل', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 652: haalaa sedaa ye gerye e maadarash raa ham mishenid\n",
            "PRED SCORE: -1.6378\n",
            "\n",
            "SENT 653: ['ش', 'ا', 'ی', 'د', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ت', 'س', 'ک', 'ی', 'ن', 'ش', '<b>', 'ا', 'ز', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ف', 'ت', '<b>', 'ا', 'م', 'ا', '<b>', 'ق', 'ل', 'ب', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'م', 'ج', 'ر', 'و', 'ح', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'ب', 'و', 'د']\n",
            "PRED 653: shaayad baayad baraaye makhaarej az otaaq birun milarzid ammaa qalban khodash az u khord\n",
            "PRED SCORE: -2.4417\n",
            "\n",
            "SENT 654: ['ب', 'ه', '<b>', 'ی', 'ا', 'د', '<b>', 'ی', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ش', 'ع', 'ا', 'ر', '<b>', 'ن', 'ی', 'م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ا', 'خ', 'ی', 'ر', 'ا', '<b>', 'خ', 'و', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'گ', 'ف', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'ت', 'ا', 'ز', 'ا', '<b>', 'ت', 'ا', 'خ', 'ت', 'م', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'چ', 'ه']\n",
            "PRED 654: be yaad e yeki az amir naaraahatam ke e donyaa keshaandash ke meylete\n",
            "PRED SCORE: -2.0129\n",
            "\n",
            "SENT 655: ['گ', 'ف', 'ت', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'س', 'ا', 'ز', 'ا', '<b>', 'س', 'ا', 'خ', 'ت', 'م', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'چ', 'ه']\n",
            "PRED 655: goftin ke baabaa bozorgesh e digeie\n",
            "PRED SCORE: -1.8146\n",
            "\n",
            "SENT 656: ['ف', 'ی', '<b>', 'ا', 'ل', 'ج', 'م', 'ل', 'ه', '<b>', 'د', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'ن', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'د', 'ش', '<b>', 'ز', 'ت', 'و', '<b>', 'ب', 'و', 'د', '<b>', 'م', 'ن', '<b>', 'ی', 'ک', 'س', 'ر', 'ه', '<b>', 'ه', 'ر', '<b>', 'چ', 'ه', '<b>', 'ب', 'ا', 'خ', 'ت', 'م', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'چ', 'ه']\n",
            "PRED 656: faqat mitunesti dar in mosht ke gij avaz e man miresad shahzaade ye maqrur\n",
            "PRED SCORE: -4.6388\n",
            "\n",
            "SENT 657: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'ظ', 'ر', 'ف', '<b>', 'غ', 'ذ', 'ا', '<b>', 'و', 'ا', 'ر', 'د', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'ر', 'ا', '<b>', 'ب', 'س', 'ت']\n",
            "PRED 657: puraan baa lahni cheshmash kojaa vaared e otaaq shod va dar raa bast\n",
            "PRED SCORE: -1.4648\n",
            "\n",
            "SENT 658: ['س', 'ی', 'ن', 'ی', '<b>', 'ر', 'ا', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'ر', 'و', 'ی', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ب', 'ه', '\\u200c', 'ص', 'و', 'ر', 'ت', '<b>', 'ر', 'ن', 'گ', '<b>', 'پ', 'ر', 'ی', 'د', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', 'ا', 'ز', '<b>', 'ک', 'ش', 'ی', 'د', 'ه', '<b>', 'و', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ب', 'س', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 658: kolli raa aaraam ru ye zamin gozaasht va be taraf e qaab e aks khire shod\n",
            "PRED SCORE: -2.9160\n",
            "\n",
            "SENT 659: ['ه', 'ل', 'ا', 'ل', '<b>', 'س', 'ی', 'ا', 'ه', '<b>', 'ر', 'ن', 'گ', 'ی', '<b>', 'ز', 'ی', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ن', 'ق', 'ش', '<b>', 'ب', 'س', 'ت', 'ه', '<b>', 'و', '<b>', 'پ', 'ل', 'ک', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ن', 'ا', 'ز', 'ک', 'ش', '<b>', 'ا', 'ز', '<b>', 'ف', 'ر', 'ط', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'و', '<b>', 'ب', 'ی', '<b>', 'ت', 'ا', 'ب', 'ی', '<b>', 'ق', 'ر', 'م', 'ز', '<b>', 'و', '<b>', 'م', 'ت', 'و', 'ر', 'م', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 659: saal e zanaaneat ru ye zir e cheshmaanash naqsh az az foruq gerye az derakht gerye bud\n",
            "PRED SCORE: -4.3132\n",
            "\n",
            "SENT 660: ['ق', 'ل', 'ب', 'ش', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', 'د', '<b>', 'ا', 'م', 'د']\n",
            "PRED 660: qalbash be dard aamad\n",
            "PRED SCORE: -0.0359\n",
            "\n",
            "SENT 661: ['ف', 'ق', 'ط', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت', '<b>', 'ن', 'س', 'ب', 'ت', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', '<b>', 'و', '<b>', 'ب', 'ر', 'ا', 'د', 'ر', 'ه', 'ا', 'ی', '<b>', 'ک', 'و', 'چ', 'ک', '\\u200c', 'ت', 'ر', 'ش', '<b>', 'چ', 'ه', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ی', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 661: faqat khodaa midune hejdah be khaahar o bachchashun zowq daasht\n",
            "PRED SCORE: -1.4469\n",
            "\n",
            "SENT 662: ['ا', 'ر', 'ا', 'م', '<b>', 'د', 'س', 'ت', '<b>', 'س', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ی', '<b>', 'ر', 'م', 'ق', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ا', 'ز', '<b>', 'پ', 'ا', '<b>', 'د', 'ر', '<b>', 'م', 'ی', 'ا', 'ر', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'پ', 'ا', 'ش', 'و', '<b>', 'ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'خ', 'و', 'ر']\n",
            "PRED 662: aaraam dast kard va bi mard khaahar raa az maa bargereft\n",
            "PRED SCORE: -1.3214\n",
            "\n",
            "SENT 663: ['ا', 'ش', 'ک', '<b>', 'ا', 'ز', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ب', 'س', 'ت', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ج', 'ا', 'ر', 'ی', '<b>', 'ش', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ح', 'ر', 'ف', 'ی', '<b>', 'ن', 'ز', 'د']\n",
            "PRED 663: ashk az cheshmaan e ba zi be foruq ye foruq ammaa harfi nazad\n",
            "PRED SCORE: -1.7767\n",
            "\n",
            "SENT 664: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ق', 'د', 'ر', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 664: puraan goft cheqadr gerye mikoni\n",
            "PRED SCORE: -0.1167\n",
            "\n",
            "SENT 665: ['ل', 'ا', 'ا', 'ق', 'ل', '<b>', 'ب', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ا', 'م', 'ا', 'ن', '<b>', 'ب', 'ا', 'ش', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'ا', 'ز', '<b>', 'غ', 'ص', 'ه', '<b>', 'د', 'ق', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه']\n",
            "PRED 665: laaaqal be fekr e maamaanam baash daare az qosse jodaa mikone\n",
            "PRED SCORE: -0.4301\n",
            "\n",
            "SENT 666: ['پ', 'ا', 'ش', 'و', '<b>', 'ی', 'ک', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ت', 'و', 'ی', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'ب', 'ن', 'د', 'ا', 'ز', '<b>', 'ش', 'د', 'ی', '<b>', 'م', 'ث', 'ل', '<b>', 'ا', 'س', 'ک', 'ل', 'ت']\n",
            "PRED 666: paasho yek negaah be khodet tu ye aayne sabz shodi\n",
            "PRED SCORE: -1.3467\n",
            "\n",
            "SENT 667: ['م', 'گ', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ک', 'ی', 'ه', '<b>', 'ک', 'ه', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', 'ش', '<b>', 'ا', 'ز', '<b>', 'ب', 'ی', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ر', 'ی']\n",
            "PRED 667: mage in parviz kie ke daari khodeto be khaateresh az khaateresh mibaram\n",
            "PRED SCORE: -2.1417\n",
            "\n",
            "SENT 668: ['گ', 'ر', 'ی', 'ه', '\\u200c', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ش', 'د', 'ت', '<b>', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 668: gerye ye foruq sheddat gereft\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 669: ['ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'ا', 'م', 'و', 'ا', 'ج', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'ا', 'ش', 'ک', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', 'ش', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'ا', 'و', '<b>', 'ه', 'م', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 669: az posht e maamaanet sorkh ashk be labaanash negaah kard u ham yakh mikard\n",
            "PRED SCORE: -3.0392\n",
            "\n",
            "SENT 670: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'س', 'ی', 'ن', 'ی', '<b>', 'غ', 'ذ', 'ا', '<b>', 'ر', 'ا', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', 'ش', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'ا', 'ش', 'و', '<b>', 'ب', 'ا', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'س', 'ه', '<b>', 'ر', 'و', 'ز', 'ه', '<b>', 'ک', 'ه', '<b>', 'ل', 'ب', '<b>', 'ب', 'ه', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ن', 'ز', 'د', 'ی']\n",
            "PRED 670: puraan hichchi tebq raa moqaabelash gozaasht va goft paasho baa hichchi lajbaazi ke\n",
            "PRED SCORE: -3.1410\n",
            "\n",
            "SENT 671: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'س', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ی', 'ل', '<b>', 'ن', 'د', 'ا', 'ر', 'م', '<b>', 'ل', 'ط', 'ف', 'ا', '<b>', 'ت', 'ن', 'ه', 'ا', 'م', '<b>', 'ب', 'ذ', 'ا', 'ر']\n",
            "PRED 671: foruq dastash raa pas zad va goft mige chahaardah tanhaam ebraahim\n",
            "PRED SCORE: -2.2938\n",
            "\n",
            "SENT 672: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ل', 'ح', 'ن', 'ی', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'ب', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'خ', 'ر', 'ش', '<b>', 'چ', 'ی']\n",
            "PRED 672: puraan baa lahni sarzaneshbaar goft esmesh chi\n",
            "PRED SCORE: -1.1045\n",
            "\n",
            "SENT 673: ['ت', 'و', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ر', 'و', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ا', 'س', 'ی']\n",
            "PRED 673: to ke baabaa ro miduni\n",
            "PRED SCORE: -0.5075\n",
            "\n",
            "SENT 674: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'ح', 'ق', '<b>', 'ن', 'د', 'ا', 'ر', 'ه', '<b>', 'ب', 'ه', '\\u200c', 'ج', 'ا', 'ی', '<b>', 'م', 'ا', '<b>', 'ت', 'ص', 'م', 'ی', 'م', '<b>', 'ب', 'گ', 'ی', 'ر', 'ه']\n",
            "PRED 674: foruq miaan e gerye goft un haqq nadaare be aasemaan begir\n",
            "PRED SCORE: -2.5530\n",
            "\n",
            "SENT 675: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ه', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', '<b>', 'ر', 'ا', 'ه', 'ت', 'ر', '<b>', 'و', '<b>', 'ص', 'ب', 'و', 'ر', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'ب', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ه', 'ی', 'چ', '<b>', 'پ', 'د', 'ر', '<b>', 'و', '<b>', 'م', 'ا', 'د', 'ر', 'ی', '<b>', 'ب', 'د', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'و', '<b>', 'ن', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'د']\n",
            "PRED 675: puraan ke hamishe sar be raah o zaaherash goft hich pedari bud\n",
            "PRED SCORE: -3.4599\n",
            "\n",
            "SENT 676: ['ح', 'ت', 'م', 'ا', '<b>', 'ص', 'ل', 'ا', 'ح', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'ک', 'ا', 'ر', 'ه']\n",
            "PRED 676: hatman salaahi tu ye zehneshe\n",
            "PRED SCORE: -1.7226\n",
            "\n",
            "SENT 677: ['ف', 'ر', 'و', 'غ', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ت', 'م', 'ا', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ر', 'ا', 'ض', 'ی', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'ز', 'ن', '<b>', 'س', 'ی', 'ر', 'و', 'س', '<b>', 'ب', 'ش', 'ی', '<b>', 'ا', 'ر', 'ه']\n",
            "PRED 677: foruq asabaani goft hatman baa hamin harfhaa ye khodeto raazi kon\n",
            "PRED SCORE: -2.0566\n",
            "\n",
            "SENT 678: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ن', '<b>', 'ز', 'ن', 'د', 'ه', '\\u200c', 'ا', 'م', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'م', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'م', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'خ', 'ف', 'ه', '<b>', 'م', 'ی', 'ش', 'م']\n",
            "PRED 678: puraan man zendegim mikhaam harf bezanam zadan midam\n",
            "PRED SCORE: -0.6909\n",
            "\n",
            "SENT 679: ['ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'خ', 'ف', 'ه', '<b>', 'م', 'ی', 'ش', 'م']\n",
            "PRED 679: be khodaa daaram khaste mishe\n",
            "PRED SCORE: -0.4402\n",
            "\n",
            "SENT 680: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', '<b>', 'پ', 'د', 'ر', '<b>', 'و', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'د', 'ر', 'د', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'خ', 'و', 'ر', 'ه']\n",
            "PRED 680: puraan dar ta yidash e pedar va maadarash goft vali parviz be komakash nagir\n",
            "PRED SCORE: -1.7182\n",
            "\n",
            "SENT 681: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ث', 'ل', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ل', 'ج', 'ب', 'ا', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ن', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'م', '<b>', 'ز', 'ن', 'ش', '<b>', 'ب', 'ش', 'م']\n",
            "PRED 681: foruq mesl e dokhtar e bachchei goft ammaa man dustesh daaram khord\n",
            "PRED SCORE: -2.3126\n",
            "\n",
            "SENT 682: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ا', 'ه', 'س', 'ت', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ج', 'ا', 'ل', 'ت', '<b>', 'ب', 'ک', 'ش', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'گ', 'س', 'ت', 'ا', 'خ', 'ی', '<b>', 'ه', 'م', '<b>', 'ح', 'د', 'ی', '<b>', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 682: puraan aaheste goft khejaalat baash foruq ham hattaa daare\n",
            "PRED SCORE: -0.8244\n",
            "\n",
            "SENT 683: ['ز', 'ش', 'ت', 'ه']\n",
            "PRED 683: zeshte\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 684: ['ب', 'ق', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'و', 'ن', 'د']\n",
            "PRED 684: baqiye midunand\n",
            "PRED SCORE: -0.6698\n",
            "\n",
            "SENT 685: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ج', 'ا', 'ج', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'و', 'ل', 'ی', '<b>', 'م', 'ن', '<b>', 'ب', 'ا', 'ه', 'ا', 'ش', '<b>', 'ا', 'ز', 'د', 'و', 'ا', 'ج', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م']\n",
            "PRED 685: foruq baa lejaajat goft vali man baahaash laazemesh mikonam\n",
            "PRED SCORE: -0.6501\n",
            "\n",
            "SENT 686: ['ح', 'ا', 'ل', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ی', 'ن', 'ی', '<b>', 'ا', 'گ', 'ه', '<b>', 'ن', 'ذ', 'ا', 'ر', 'ن', '<b>', 'خ', 'و', 'د', 'م', 'و', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ش', 'م']\n",
            "PRED 686: haalaa mibini age natuni khodemun mishi\n",
            "PRED SCORE: -1.4381\n",
            "\n",
            "SENT 687: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ت', 'ا', 'ث', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ت', 'ر', 'س']\n",
            "PRED 687: puraan baa taassor goft maadar\n",
            "PRED SCORE: -0.3747\n",
            "\n",
            "SENT 688: ['ه', 'م', 'ی', 'ن', '<b>', 'ح', 'ا', 'ل', 'ا', 'م', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'م', 'ی', '\\u200c', 'م', 'ی', 'ر', 'ی']\n",
            "PRED 688: haminjaa daari amir\n",
            "PRED SCORE: -1.1528\n",
            "\n",
            "SENT 689: ['ر', 'ی', 'خ', 'ت', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'د', 'ی', 'د', 'ی']\n",
            "PRED 689: raasti khodeto didi\n",
            "PRED SCORE: -0.1058\n",
            "\n",
            "SENT 690: ['ب', 'ی', 'چ', 'ا', 'ر', 'ه']\n",
            "PRED 690: bichaare\n",
            "PRED SCORE: -0.0029\n",
            "\n",
            "SENT 691: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'پ', 'ا', 'ن', 'ز', 'د', 'ه', '<b>', 'ش', 'ا', 'ن', 'ز', 'د', 'ه', '<b>', 'س', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'ت', 'و', '<b>', 'ب', 'ز', 'ر', 'گ', 'ت', 'ر', 'ه']\n",
            "PRED 691: parviz maande maand saal az to ajale beshe\n",
            "PRED SCORE: -2.2561\n",
            "\n",
            "SENT 692: ['ن', 'ک', 'ن', 'ه', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ز', 'ن', '<b>', 'ی', 'ک', '<b>', 'پ', 'ی', 'ر', 'م', 'ر', 'د', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 692: nakone mikhaay zan e yek mard baashi\n",
            "PRED SCORE: -1.3315\n",
            "\n",
            "SENT 693: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'ا', 'م', '<b>', 'م', 'ه', 'م', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 693: foruq miaan e gerye goft baraam mohemm nist\n",
            "PRED SCORE: -0.2885\n",
            "\n",
            "SENT 694: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'س', '<b>', 'چ', 'ی', '<b>', 'ب', 'ر', 'ا', 'ت', '<b>', 'م', 'ه', 'م', 'ه']\n",
            "PRED 694: puraan asabaani goft pas chi baraat bege\n",
            "PRED SCORE: -1.0465\n",
            "\n",
            "SENT 695: ['ن', 'ک', 'ن', 'ه', '<b>', 'ه', 'و', 'س', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'س', 'ر', 'ا', 'غ', 'ت']\n",
            "PRED 695: nakone havas kardi baabaa qarq biaad\n",
            "PRED SCORE: -1.5419\n",
            "\n",
            "SENT 696: ['ب', 'ی', 'چ', 'ا', 'ر', 'ه', '<b>', 'م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 696: bichaare maamaan\n",
            "PRED SCORE: -0.0009\n",
            "\n",
            "SENT 697: ['چ', 'ق', 'د', 'ر', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ا', 'ز', '<b>', 'د', 'س', 'ت', '<b>', 'ش', 'م', 'ا', 'ه', 'ا', '<b>', 'ب', 'ک', 'ش', 'ه']\n",
            "PRED 697: cheqadr baayad az dast e raah beshe\n",
            "PRED SCORE: -0.1179\n",
            "\n",
            "SENT 698: ['ه', 'ی', 'چ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'ی', '<b>', 'ا', 'گ', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ب', 'و', '<b>', 'ب', 'ب', 'ر', 'ه', '<b>', 'چ', 'ی', 'ک', 'ا', 'ر', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه']\n",
            "PRED 698: hichchi miduni age baabaa ham beshe chikaaret mikone\n",
            "PRED SCORE: -1.5462\n",
            "\n",
            "SENT 699: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ج', 'س', 'ا', 'ر', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ر', 'ه', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'م', 'ی', 'ا', 'د', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'ت', 'ی', 'ن', 'ش', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'ل', 'گ', 'د', '<b>', 'م', 'ی', 'ز', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'د', 'ر', 'د', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'م', '<b>', 'ب', 'پ', 'ی', 'چ', 'م']\n",
            "PRED 699: foruq baa jesaarat goft aare dobaare miaad ke az sharresh khalaas ke khodam\n",
            "PRED SCORE: -1.6484\n",
            "\n",
            "SENT 700: ['م', 'گ', 'ه', '<b>', 'ب', 'ا', 'ل', 'ا', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'س', 'ی', 'ا', 'ه', 'ی', '<b>', 'ه', 'م', '<b>', 'ر', 'ن', 'گ', 'ی', '<b>', 'ه', 'س', 'ت']\n",
            "PRED 700: mage bel akhare az vazaayef ham majles hast\n",
            "PRED SCORE: -1.2337\n",
            "\n",
            "SENT 701: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ن', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'م']\n",
            "PRED 701: puraan man dust daaram\n",
            "PRED SCORE: -0.3921\n",
            "\n",
            "SENT 702: ['ب', 'ه', 'ش', 'و', 'ن', '<b>', 'ب', 'گ', 'و', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'ق', 'ر', 'ا', 'ن', '<b>', 'ن', 'گ', 'ن', '<b>', 'ن', 'ه']\n",
            "PRED 702: be befahm e to ro hamintowr\n",
            "PRED SCORE: -2.0229\n",
            "\n",
            "SENT 703: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'س', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'ع', 'ل', 'ا', 'م', 'ت', '<b>', 'ت', 'ا', 'س', 'ف', '<b>', 'ت', 'ک', 'ا', 'ن', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ت', 'و', '<b>', 'ح', 'ا', 'ض', 'ر', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ت', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ق', 'ی', 'م', 'ت', '<b>', 'ل', 'ج', 'ب', 'ا', 'ز', 'ی', '<b>', 'س', 'ی', 'ا', 'ه', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 703: puraan sari be alaamat e taassof tekaan daad va goft daaram fekr mikonam\n",
            "PRED SCORE: -0.3351\n",
            "\n",
            "SENT 704: ['ا', 'خ', 'ه', '<b>', 'ا', 'و', 'ن', '<b>', 'ک', 'ی', 'ه', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', 'ش', '<b>', 'ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ا', 'ل', 'ت', 'م', 'ا', 'س', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 704: aakhe un kie ke be khaater e intowri shaad mikoni\n",
            "PRED SCORE: -0.7389\n",
            "\n",
            "SENT 705: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ی', '<b>', 'ا', 'ش', 'ک', 'ب', 'ا', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 705: foruq baa cheshmaan e aashkaari negaahash kard va be zahmat neshast\n",
            "PRED SCORE: -0.9094\n",
            "\n",
            "SENT 706: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ت', 'و', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ی', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'ی', '<b>', 'م', 'ن', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', 'گ', 'م', '<b>', 'م', 'گ', 'ه', '<b>', 'ن', 'ه']\n",
            "PRED 706: puraan to miduni hamishe fahmid man chi mage na\n",
            "PRED SCORE: -0.8964\n",
            "\n",
            "SENT 707: ['ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'م', 'ن', '<b>', 'خ', 'س', 'ت', 'ه', '<b>', 'ش', 'د', 'م', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ه', 'ر', '<b>', 'چ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'ه', 'م', 'و', 'ن', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'ا', 'م', 'ا', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م']\n",
            "PRED 707: be khodaa man khaste shodam hamishe har hamun arzesh ammaa dige tamaamesh kardam\n",
            "PRED SCORE: -2.8205\n",
            "\n",
            "SENT 708: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'س', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ا', 'غ', 'و', 'ش', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'م', 'و', 'ه', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'و', 'ا', 'ز', 'ش', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 708: puraan sarash raa dar aaqush keshid va muhaayash ye piraahanash raa nashenid\n",
            "PRED SCORE: -2.1170\n",
            "\n",
            "SENT 709: ['چ', 'ر', 'ا', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'ی']\n",
            "PRED 709: cheraa nemiaayn\n",
            "PRED SCORE: -0.8630\n",
            "\n",
            "SENT 710: ['م', 'گ', 'ه', '<b>', 'چ', 'ه', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', 'ی', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', 'ه']\n",
            "PRED 710: mage che ettefaaqi oftaade\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 711: ['خ', 'و', 'ا', 'ه', 'ر', '<b>', 'ب', 'ی', 'چ', 'ا', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ن']\n",
            "PRED 711: khaahar e bichaare ye man\n",
            "PRED SCORE: -0.3006\n",
            "\n",
            "SENT 712: ['د', 'ی', 'گ', 'ه', '<b>', 'ب', 'س', 'ه']\n",
            "PRED 712: dige base\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 713: ['خ', 'ی', 'ل', '<b>', 'خ', 'ب', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ب', 'س', 'ه']\n",
            "PRED 713: khis kon dige beshan\n",
            "PRED SCORE: -1.1436\n",
            "\n",
            "SENT 714: ['ف', 'ک', 'ر', '<b>', 'ن', 'ک', 'ن', 'م', '<b>', 'ج', 'ر', 'ی', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', 'ه', '<b>', 'ب', 'ا', 'ش', 'ی', '<b>', 'ا', 'ی', 'ن', '<b>', 'ح', 'ر', 'ف', 'ه', 'ا', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'گ', 'ی']\n",
            "PRED 714: fekr nakonam jor daashte baashi in harfhaai ham baabaa ham begi\n",
            "PRED SCORE: -0.0768\n",
            "\n",
            "SENT 715: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ج', 'ا', 'ج', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ی', 'گ', 'م', '<b>', 'ب', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ی', 'گ', 'م']\n",
            "PRED 715: foruq baa lejaajat goft migam be baabaa ham migam\n",
            "PRED SCORE: -0.0696\n",
            "\n",
            "SENT 716: ['ا', 'و', 'ن', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ا', 'ج', 'ا', 'ز', 'ه', '<b>', 'ب', 'د', 'ه', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'خ', 'د', 'ا', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ا', 'ج', 'ا', 'ز', 'ه', '<b>', 'ب', 'د', 'ه']\n",
            "PRED 716: un baayad alaan beshe be khaater e khodaa baayad azat baashe\n",
            "PRED SCORE: -0.8859\n",
            "\n",
            "SENT 717: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'خ', 'و', 'ر']\n",
            "PRED 717: puraan goft yek chizi behesh\n",
            "PRED SCORE: -0.9157\n",
            "\n",
            "SENT 718: ['ش', 'ا', 'ی', 'د', '<b>', 'ا', 'م', 'ر', 'و', 'ز', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'ا', 'ی', 'ن', 'ج', 'ا']\n",
            "PRED 718: shaayad emruz baabaa biaad injaa\n",
            "PRED SCORE: -0.1019\n",
            "\n",
            "SENT 719: ['د', 'ر', 'س', 'ت', '<b>', 'ش', 'د', 'ی', '<b>', 'ع', 'ی', 'ن', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'م', 'و', 'ن', 'د', 'م', '<b>', 'چ', 'ط', 'و', 'ر', 'ی', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ی', 'ک', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ر', 'و', '<b>', 'ا', 'د', 'ا', 'ر', 'ه', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 719: dorost shodand eyn e bachchehaa jangi chetowri yek zendegi ro nadaare yek zendegi koni\n",
            "PRED SCORE: -2.7694\n",
            "\n",
            "SENT 720: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ز', '<b>', 'د', 'ا', 'ر', '<b>', 'د', 'ن', 'ی', 'ا', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ن', 'د', 'ا', 'ر', 'ه', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'ی']\n",
            "PRED 720: parviz az daakhel e pushidan e hichchi nadaare midunesti\n",
            "PRED SCORE: -1.0042\n",
            "\n",
            "SENT 721: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ا', 'ز', 'ش', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'م']\n",
            "PRED 721: foruq miaan e gerye goft man hichchi aavordi azash nemikhaam\n",
            "PRED SCORE: -0.9648\n",
            "\n",
            "SENT 722: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ت', 'م', 'س', 'خ', 'ر', 'ا', 'م', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'خ', 'د', 'ا', '<b>', 'ت', 'و', '<b>', 'د', 'ی', 'و', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ی']\n",
            "PRED 722: puraan baa labkhandi tamaskhoraamiz goft be khodaa to divunei\n",
            "PRED SCORE: -0.0360\n",
            "\n",
            "SENT 723: ['ن', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'ی', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'چ', 'ی', 'ک', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی']\n",
            "PRED 723: nemitunesti daari chikaar mikoni\n",
            "PRED SCORE: -0.5223\n",
            "\n",
            "SENT 724: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ت', 'ص', 'م', 'ی', 'م', 'م', '<b>', 'ر', 'و', '<b>', 'گ', 'ر', 'ف', 'ت', 'م', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ی', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ی', 'ا', '<b>', 'ه', 'ی', 'چ', '\\u200c', 'ک', 'س']\n",
            "PRED 724: foruq baa qaateiyat goft man haalaam goftam yaa parviz yaa parviz\n",
            "PRED SCORE: -1.3019\n",
            "\n",
            "SENT 725: ['ت', 'و', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'ی']\n",
            "PRED 725: to ke nemiduni\n",
            "PRED SCORE: -0.0230\n",
            "\n",
            "SENT 726: ['ا', 'و', 'ن', '<b>', 'ش', 'د', 'ه', '<b>', 'ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'م', '<b>', 'چ', 'ه', '<b>', 'ت', 'و', 'ی', '<b>', 'خ', 'و', 'ا', 'ب', '<b>', 'چ', 'ه', '<b>', 'ت', 'و', 'ی', '<b>', 'ب', 'ی', 'د', 'ا', 'ر', 'ی']\n",
            "PRED 726: un shode nave ye zendegim che tu ye zanhaa o tu ye biaare\n",
            "PRED SCORE: -2.2971\n",
            "\n",
            "SENT 727: ['ن', 'ه', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ن', 'ه', '<b>', 'ب', 'ی', '\\u200c', 'ا', 'ع', 'ت', 'ن', 'ا', 'ی', 'ی', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'ن', 'ه', '<b>', 'ت', 'ه', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'ت', 'ن', 'ب', 'ی', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ه', 'ی', 'چ', '<b>', 'ی', 'ک', '<b>', 'پ', 'ی', 'ش', '<b>', 'ن', 'ب', 'ر', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ع', 'ا', 'ق', 'ب', 'ت', '<b>', 'ب', 'ه', '<b>', 'ق', 'د', 'ر', 'ی', '<b>', 'م', 'ق', 'ا', 'و', 'م', 'ت', '<b>', 'ک', 'ر', 'د', '<b>', 'ا', 'ش', 'ک', '<b>', 'ر', 'ی', 'خ', 'ت', '<b>', 'و', '<b>', 'س', 'م', 'ا', 'ج', 'ت', '<b>', 'ن', 'ش', 'ا', 'ن', '<b>', 'د', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'م', 'و', 'ا', 'ف', 'ق', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ا', 'ع', 'ل', 'ا', 'م', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 727: na sarzaneshash e puraan na bimaarestaan e turaan o tanhaa negaahash kard taa hazz nakard\n",
            "PRED SCORE: -4.2882\n",
            "\n",
            "SENT 728: ['ا', 'ن', '<b>', 'ش', 'ب', '<b>', 'ش', 'ب', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 728: aan shakk shakk e qaribi bud\n",
            "PRED SCORE: -0.5989\n",
            "\n",
            "SENT 729: ['ف', 'ر', 'و', 'غ', '<b>', 'پ', 'ش', 'ت', '<b>', 'د', 'ر', '<b>', 'ا', 'ت', 'ا', 'ق', '<b>', 'ا', 'ز', '<b>', 'ش', 'د', 'ت', '<b>', 'ش', 'ا', 'د', 'ی', '<b>', 'ا', 'ش', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ی', 'خ', 'ت', '<b>', 'و', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ا', 'ن', '<b>', 'ط', 'ر', 'ف', '<b>', 'د', 'ر', '<b>', 'ب', 'ی', '\\u200c', 'و', 'ق', 'ف', 'ه', '<b>', 'ب', 'د', '<b>', 'و', '<b>', 'ب', 'ی', 'ر', 'ا', 'ه', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت']\n",
            "PRED 729: foruq posht e dar e otaaq az ashkash shod va sarash aan belaataklifi bad migoft\n",
            "PRED SCORE: -2.7001\n",
            "\n",
            "SENT 730: ['ب', 'ه', '<b>', 'ج', 'ه', 'ن', 'م']\n",
            "PRED 730: be jahannam\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 731: ['خ', 'ر', '<b>', 'خ', 'ا', 'ک', '<b>', 'م', 'ی', 'خ', 'و', 'ر', 'ه', '<b>', 'د', 'ل', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'د', 'ر', 'د', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ی', 'ر', 'ه']\n",
            "PRED 731: kheyl e zahmat kardin dah khodesh sharmandeam\n",
            "PRED SCORE: -2.7189\n",
            "\n",
            "SENT 732: ['ش', 'ا', 'ن', '<b>', 'ا', 'و', 'ن', '<b>', 'ب', 'ی', '<b>', 'ش', 'ع', 'و', 'ر', '<b>', 'ب', 'ی', 'ش', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 732: sha un bi she r bishtar az in nist\n",
            "PRED SCORE: -0.7451\n",
            "\n",
            "SENT 733: ['م', 'ن', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'س', 'ت', 'م']\n",
            "PRED 733: man mishnaasamet\n",
            "PRED SCORE: -0.4181\n",
            "\n",
            "SENT 734: ['ب', 'ر', 'ه', '<b>', 'ب', 'ب', 'ی', 'ن', 'م', '<b>', 'چ', 'ه', '<b>', 'غ', 'ل', 'ط', 'ی', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'ب', 'ک', 'ن', 'ه']\n",
            "PRED 734: bere bebinam che fekri beshe bokone\n",
            "PRED SCORE: -1.2810\n",
            "\n",
            "SENT 735: ['ل', 'ی', 'ا', 'ق', 'ت', 'ش', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ع', 'م', 'ر', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'ت', 'ه', 'ر', 'و', 'ن', '<b>', 'پ', 'ا', 'ش', 'ه', '<b>', 'ب', 'ا', '<b>', 'پ', 'س', 'ر', 'ه', '<b>', 'ب', 'ر', 'ه', '<b>', 'ج', 'ن', 'و', 'ب']\n",
            "PRED 735: laaaqal ine ke ba d az zamin zendegi tu ye halqam baa majalle berese\n",
            "PRED SCORE: -2.8217\n",
            "\n",
            "SENT 736: ['ی', 'ک', '<b>', 'ج', 'و', 'ر', 'ی', '<b>', 'ب', 'ه', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'خ', 'ب', 'ر', '<b>', 'ب', 'د', 'ه', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'ک', 'ا', 'ر', 'ه', 'ا', '<b>', 'ر', 'و', '<b>', 'ر', 'ا', 'س', '<b>', 'و', '<b>', 'ر', 'ی', 'س', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 736: yek juri be maadareshe ye zandaari bude baayad kojaa o ru kone\n",
            "PRED SCORE: -3.2277\n",
            "\n",
            "SENT 737: ['م', 'ن', '<b>', 'ن', 'م', 'ی', 'د', 'و', 'ن', 'م', '<b>', 'ا', 'ی', 'ن', '<b>', 'پ', 'د', 'ر', '<b>', 'س', 'و', 'خ', 'ت', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ر', 'ت', 'ق', '<b>', 'ب', 'ه', '<b>', 'ک', 'ی', '<b>', 'ب', 'ر', 'د', 'ه', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ی', '<b>', 'ک', 'ل', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 737: man nemidunam in fekr e saadei sarzaneshash be ki karde ke entekhaab konid\n",
            "PRED SCORE: -3.7933\n",
            "\n",
            "SENT 738: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ت', 'و', 'ن', '<b>', 'ب', 'ر', 'د', 'ه']\n",
            "PRED 738: turaan goft bale be khodetun naresi\n",
            "PRED SCORE: -1.1276\n",
            "\n",
            "SENT 739: ['ا', 'ق', 'ا', '<b>', 'ج', 'و', 'و', 'ن', 'ی', 'ه', 'ا', 'ت', 'و', 'ن', '<b>', 'ی', 'ا', 'د', 'ت', 'و', 'ن', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 739: aaqaa junam qashang nist\n",
            "PRED SCORE: -0.3319\n",
            "\n",
            "SENT 740: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ف', 'ر', 'ی', 'ا', 'د', '<b>', 'ز', 'د', '<b>', '<b>', 'م', 'ن', '<b>', 'غ', 'ل', 'ط', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م', '<b>', 'ب', 'ا', 'ل', 'ا', 'ی', '<b>', 'ح', 'ر', 'ف', '<b>', 'پ', 'د', 'ر', 'م', '<b>', 'ح', 'ر', 'ف', 'ی', '<b>', 'ب', 'ز', 'ن', 'م']\n",
            "PRED 740: farrokhzaad faryaad zad zad man avaz mikardam harf e pedaram bezanam\n",
            "PRED SCORE: -3.3270\n",
            "\n",
            "SENT 741: ['ب', 'ه', 'ش', '<b>', 'ب', 'گ', 'و', '<b>', 'ا', 'گ', 'ه', '<b>', 'پ', 'س', 'ر', 'ه', '<b>', 'و', 'ا', 'س', 'ت', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'م', 'ه', 'م', 'ه', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', 'ش', '<b>', 'ب', 'م', 'ی', 'ر', 'ی', '<b>', 'خ', 'ب', '<b>', 'ب', 'ر', 'و']\n",
            "PRED 741: behesh begu age sarhang aanqadr aanqadr zerang ke mikhaay be khaateresh berin\n",
            "PRED SCORE: -1.6059\n",
            "\n",
            "SENT 742: ['ف', 'ق', 'ط', '<b>', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', 'ت', '<b>', 'ا', 'گ', 'ه', '<b>', 'ب', 'ش', 'ن', 'و', 'م', '<b>', 'ج', 'ا', '<b>', 'ز', 'د', 'ی', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'ت', 'و', '<b>', 'ب', 'م', 'ی', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', 'ن', '<b>', 'ت', 'و', '<b>', 'ب', 'م', 'ی', 'ر', 'ی', '\\u200c', 'ه', 'ا', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 742: faqat vaqthaa be haalat e age uliyat jaa ye in moddat e dige nasaakhtand\n",
            "PRED SCORE: -2.4095\n",
            "\n",
            "SENT 743: ['م', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ا', 'س', 'ه', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ک', 'ل', 'ه', '<b>', 'خ', 'ر', 'ت', 'ر', 'م']\n",
            "PRED 743: manam ke shir az khodash bachchast\n",
            "PRED SCORE: -2.2979\n",
            "\n",
            "SENT 744: ['ی', 'ک', '<b>', 'ع', 'م', 'ر', '<b>', 'خ', 'ر', 'ج', 'ش', '<b>', 'ر', 'و', '<b>', 'ن', 'د', 'ا', 'د', 'م', '<b>', 'ک', 'ه', '<b>', 'ن', 'ع', 'ش', 'ش', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ا', 'و', 'ن', '<b>', 'پ', 'س', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ج', 'ع', 'ل', 'ق', '<b>', 'ب', 'ک', 'ش', 'م', '<b>', 'ب', 'ی', 'ر', 'و', 'ن']\n",
            "PRED 744: yek nazm e amiq ro nadide ke vaz ro be kheyr e un besuze\n",
            "PRED SCORE: -4.5472\n",
            "\n",
            "SENT 745: ['ف', 'ک', 'ر', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'ا', 'د', 'م', 'ه', '<b>', 'و', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'د', '<b>', 'و', 'ا', 'س', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ک', 'س', 'ی', '<b>', 'ب', 'ا', 'ش', 'ه']\n",
            "PRED 745: fekr kardam edaame o nesbat vaase khodesh jodaa baashe\n",
            "PRED SCORE: -1.5010\n",
            "\n",
            "SENT 746: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ش', 'م', 'ا', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ر', 'ا', '<b>', 'ع', 'ذ', 'ا', 'ب', '<b>', 'ن', 'د', 'ه', '<b>', 'ا', 'ق', 'ا']\n",
            "PRED 746: turaan goft haalaa shomaa enqadr khodet sobhaanaro nakon aaqaa\n",
            "PRED SCORE: -1.2094\n",
            "\n",
            "SENT 747: ['ف', 'ر', 'خ', '<b>', 'ز', 'ا', 'د', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ن', 'ا', '<b>', 'د', 'س', 'ت', '<b>', 'پ', 'ر', 'و', 'ر', 'د', 'ه', '\\u200c', 'ی', '<b>', 'خ', 'و', 'د', 'ت', 'ن', 'د']\n",
            "PRED 747: foruq daad e ajibi goft inaa dast e jodaabaafte khundand\n",
            "PRED SCORE: -2.3233\n",
            "\n",
            "SENT 748: ['ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'ش', 'د', 'ت', '<b>', 'ش', 'و', 'ق', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'خ', 'ن', 'د', 'ی', 'د']\n",
            "PRED 748: foruq az sheddat e she nidaari miaan e gerye khandid\n",
            "PRED SCORE: -1.6251\n",
            "\n",
            "SENT 749: ['پ', 'ا', 'چ', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ل', 'و', 'ا', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ک', 'م', 'ی', '<b>', 'ب', 'ا', 'ل', 'ا', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ن', 'ق', 'ش', '<b>', 'ک', 'ب', 'و', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'ح', 'ا', 'ص', 'ل', '<b>', 'ت', 'ن', 'ب', 'ی', 'ه', '<b>', 'ا', 'و', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ا', 'ه', 'ی', 'چ', 'ه', '\\u200c', 'ی', '<b>', 'پ', 'ا', 'ی', '<b>', 'ر', 'ا', 'س', 'ت', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 749: elaahi showharesh raa kami baalaa zad va be nimrokh e lezzatbakhshi khire shod\n",
            "PRED SCORE: -2.8745\n",
            "\n",
            "SENT 750: ['چ', 'ه', '<b>', 'ر', 'ن', 'ج', '\\u200c', 'ه', 'ا', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ر', 'س', 'ی', 'د', 'ن', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ت', 'ح', 'م', 'ل', '<b>', 'ن', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 750: che panjare ke baraaye shaanehaa ye panjarehaa be parviz nakarde bud\n",
            "PRED SCORE: -2.0444\n",
            "\n",
            "SENT 751: ['ا', 'ی', 'ن', '<b>', 'ن', 'خ', 'س', 'ت', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ب', 'و', 'د', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 751: in vaqthaa baashi ke haalaa barkhord nemikard\n",
            "PRED SCORE: -1.9522\n",
            "\n",
            "SENT 752: ['ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'م', 'و', 'ا', 'ف', 'ق', 'ت', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ص', 'ر', 'ف', 'ا', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'پ', 'ا', 'ف', 'ش', 'ا', 'ر', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'س', 'ا', 'م', 'ا', 'ن', '<b>', 'د', 'ا', 'د', 'ن', '<b>', 'ب', 'ه', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ع', 'ج', 'ل', 'ه', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'م', 'گ', 'ر', '<b>', 'ن', 'ه', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'د', 'ل', '<b>', 'د', 'ر', '<b>', 'گ', 'ر', 'و', '<b>', 'ز', 'ن', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'ه', 'ر', '<b>', 'چ', 'ه', '<b>', 'ز', 'و', 'د', 'ت', 'ر', '<b>', 'م', 'س', 'ی', 'و', 'ل', 'ی', 'ت', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'ش', 'ا', 'ن', 'ه', '<b>', 'ب', 'ر', 'د', 'ا', 'ر', 'د']\n",
            "PRED 752: albatte mowqe e sargord sorkh be khaater e foruq ham az aanche jodaa daasht bachchehaa\n",
            "PRED SCORE: -1.3121\n",
            "\n",
            "SENT 753: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'س', 'ر', 'ت', 'ق', '\\u200c', 'ت', 'ر', 'ی', 'ن', '<b>', 'و', '<b>', 'ی', 'ک', '<b>', 'د', 'ن', 'د', 'ه', '\\u200c', 'ت', 'ر', 'ی', 'ن', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', 'ش', '<b>', 'ب', 'و', 'د']\n",
            "PRED 753: be nazarash foruq sareto va yek dokhtarbachche bud\n",
            "PRED SCORE: -1.9062\n",
            "\n",
            "SENT 754: ['ی', 'ک', '<b>', 'ن', 'م', 'و', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ک', 'و', 'چ', 'ک', '<b>', 'ش', 'د', 'ه', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'د', 'ر', '<b>', 'ق', 'ا', 'ل', 'ب', '<b>', 'ی', 'ک', '<b>', 'ز', 'ن']\n",
            "PRED 754: yek honarmand ye haft shode az khodash yek haalat e yek zan\n",
            "PRED SCORE: -1.8370\n",
            "\n",
            "SENT 755: ['ا', 'و', '<b>', 'گ', 'ر', 'چ', 'ه', '<b>', 'ظ', 'ا', 'ه', 'ر', 'ا', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', '<b>', 'و', '<b>', 'ت', 'ن', 'ب', 'ی', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ق', 'ل', 'ب', 'ا', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'س', 'ت', 'و', 'د']\n",
            "PRED 755: u garche saraazir sarzaneshash o tanhaai mikard ammaa hamishe harekati u raa mipaaid\n",
            "PRED SCORE: -2.6847\n",
            "\n",
            "SENT 756: ['ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ا', 'و', 'ا', 'ن', '<b>', 'ک', 'و', 'د', 'ک', 'ی', '<b>', 'ی', 'ک', '<b>', 'د', 'ن', 'د', 'ه', '<b>', 'و', '<b>', 'ل', 'ج', 'ب', 'ا', 'ز', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ا', 'ر', 'ه', 'ا', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ح', 'ا', 'ض', 'ر', 'ج', 'و', 'ا', 'ب', 'ی', '<b>', 'ک', 'ت', 'ک', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'ا', 'و', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ج', 'س', 'ا', 'ر', 'ت', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ز', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ز', 'د', '<b>', 'و', '<b>', 'ا', 'گ', 'ر', '<b>', 'د', 'ل', 'ی', 'ل', 'ی', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'ن', 'ج', 'ا', 'م', '<b>', 'ک', 'ا', 'ر', 'ی', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'ب', 'ی', '<b>', 'پ', 'ر', 'د', 'ه', '<b>', 'س', 'و', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'چ', 'ر', 'ا']\n",
            "PRED 756: foruq az hamaanjaa alaan mikushid yek do o paarche ammaa u anjaam mikard\n",
            "PRED SCORE: -3.9868\n",
            "\n",
            "SENT 757: ['ه', 'ن', 'گ', 'ا', 'م', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'و', 'ا', 'ک', 'ن', 'ش', '<b>', 'ش', 'د', 'ی', 'د', 'ی', '<b>', 'ن', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ع', 'و', 'ا', 'ق', 'ب', '<b>', 'ک', 'ا', 'ر', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ج', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'خ', 'ر', 'ی', 'د']\n",
            "PRED 757: hanuzam josse ye saaniei shadidtar na midaad o salaah be jaan mennat be jaan\n",
            "PRED SCORE: -2.6890\n",
            "\n",
            "SENT 758: ['ج', 'س', 'ا', 'ر', 'ت', 'ش', '<b>', 'ب', 'ه', '<b>', 'ح', 'د', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ا', 'گ', 'ر', '<b>', 'ا', 'و', '<b>', 'م', 'ر', 'د', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ب', 'ی', '\\u200c', 'گ', 'م', 'ا', 'ن', '<b>', 'ج', 'ن', 'گ', 'ج', 'و', 'ی', '<b>', 'م', 'ب', 'ا', 'ر', 'ز', '<b>', 'و', '<b>', 'د', 'ل', 'ا', 'و', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ب', '<b>', 'د', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ا', 'م', 'د']\n",
            "PRED 758: dastaanash be hattaa bud ke sareto hamishe fekr mikard o hazz az u birun\n",
            "PRED SCORE: -3.4270\n",
            "\n",
            "SENT 759: ['س', 'ر', 'س', 'خ', 'ت', 'ا', 'ن', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ر', 'س', 'ی', 'د', 'ن', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', 'چ', 'ه', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'م', 'ب', 'ا', 'ر', 'ز', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ا', 'و', 'ر', 'د', '<b>', 'و', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ا', 'ی', 'ن', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ز', 'ر', 'گ', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'ز', 'د', 'و', 'ا', 'ج', '<b>', 'م', 'ق', 'ا', 'ب', 'ل', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', 'ه', '<b>', 'و', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'ا', '<b>', 'ت', 'ک', 'ر', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 759: sarhang baraaye ru boland ke mikhaast mikhaast ke lak raa tekraar mikard\n",
            "PRED SCORE: -4.0248\n",
            "\n",
            "SENT 760: ['س', 'ر', 'گ', 'ر', 'د', '<b>', 'ا', 'ن', '<b>', 'ر', 'و', 'ز', '<b>', 'ب', 'ا', '<b>', 'د', 'ل', 'خ', 'و', 'ر', 'ی', '<b>', 'و', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'خ', 'ا', 'ر', 'ج', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ل', 'ا', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ر', 'ف', 'ت', 'ن', 'ش', '<b>', 'ن', 'ز', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ج', 'د', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ک', 'ا', 'ر', '<b>', 'خ', 'و', 'د', 'ت', 'و', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'چ', 'ش', '<b>', 'س', 'ف', 'ی', 'د']\n",
            "PRED 760: sargord aan ruz baa delkhori va asabaanie az khaane raft va turaan az khaane khaarej shod\n",
            "PRED SCORE: -3.6690\n",
            "\n",
            "SENT 761: ['ف', 'ق', 'ط', '<b>', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', 'ت', '<b>', 'ا', 'گ', 'ه', '<b>', 'ب', 'ا', 'ع', 'ث', '<b>', 'س', 'ر', 'ش', 'ک', 'س', 'ت', 'گ', 'ی', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '<b>', 'ب', 'ش', 'ی']\n",
            "PRED 761: faqat vaqti be haalat e age baashe aaqaaye khaanevaade beduni\n",
            "PRED SCORE: -2.5957\n",
            "\n",
            "SENT 762: ['خ', 'ب', 'ر', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'م', 'د', 'ت', 'ی', '<b>', 'ب', 'ر', 'ه', '<b>', 'ج', 'ن', 'و', 'ب', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'ا', 'ه', 'و', 'ا', 'ز', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 762: khabar daari parviz baayad moddati bere khune o dar ahvaaz\n",
            "PRED SCORE: -1.6858\n",
            "\n",
            "SENT 763: ['ت', 'و', '<b>', 'چ', 'ط', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'ی', '<b>', 'ا', 'و', 'ن', 'ج', 'ا', '<b>', 'ت', 'ک', '<b>', 'و', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'د', 'و', 'ا', 'م', '<b>', 'ب', 'ی', 'ا', 'ر', 'ی']\n",
            "PRED 763: to chetowr mituni unjaa hess o tanhaa beri\n",
            "PRED SCORE: -0.3968\n",
            "\n",
            "SENT 764: ['ه', 'ی', 'چ', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'ی', '<b>', 'م', 'ج', 'ب', 'و', 'ر', 'ی', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'ر', 'و', '<b>', 'ن', 'ی', 'م', 'ه', '<b>', 'ک', 'ا', 'ر', 'ه', '<b>', 'و', 'ل', '<b>', 'ک', 'ن', 'ی', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ت', '<b>', 'ب', 'ر', 'س', 'ی']\n",
            "PRED 764: hichvaqt ma naayash dorost ro na kaarhaa o be injaash beresam\n",
            "PRED SCORE: -1.6465\n",
            "\n",
            "SENT 765: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ق', 'ا', 'ط', 'ع', 'ی', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م', '<b>', 'م', 'ا', 'م', 'ا', 'ن', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ع', 'ص', 'ب', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م']\n",
            "PRED 765: foruq baa qaateiyat goft man mitunam maamaan turaan goft man mitarsam\n",
            "PRED SCORE: -2.1799\n",
            "\n",
            "SENT 766: ['م', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'م']\n",
            "PRED 766: man mitunam\n",
            "PRED SCORE: -0.0054\n",
            "\n",
            "SENT 767: ['ج', 'و', 'ن', '<b>', 'ت', 'و', '<b>', 'ج', 'و', 'ن', 'ت', '<b>', 'ک', 'ن', 'ن', 'د', '<b>', 'ب', 'ر', 'د', 'ی', '<b>', 'ب', 'ه', '<b>', 'ا', 'و', 'ن', '<b>', 'ب', 'ا', 'ب', 'ا', 'ی', '<b>', 'ک', 'ل', 'ه', '<b>', 'ش', 'ق', 'ت']\n",
            "PRED 767: jun e to kutaahe konand hichkas be un nemiresidand\n",
            "PRED SCORE: -1.0939\n",
            "\n",
            "SENT 768: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ر', 'د', '<b>', 'خ', 'و', 'ب', '<b>', 'و', '<b>', 'م', 'ه', 'ر', 'ب', 'و', 'ن', 'ی', 'ه', '<b>', 'م', 'ا', 'م', 'ا', 'ن', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'گ', 'ه', '<b>', 'ن', 'ت', 'و', 'ن', 'ه', '<b>', 'ب', 'ر', 'ا', 'ت', '<b>', 'ع', 'ر', 'و', 'س', 'ی', '<b>', 'ب', 'گ', 'ی', 'ر', 'ه', '<b>', 'ب', 'ا', 'ز', 'م', '<b>', 'م', 'ر', 'د', '<b>', 'خ', 'و', 'ب', 'ی', 'ه']\n",
            "PRED 768: foruq goft parviz mard e qalat o motevajjeh e maamaan goft age hastam\n",
            "PRED SCORE: -3.3509\n",
            "\n",
            "SENT 769: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ر', 'و', 'ی', 'ا', 'ی', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ا', 'ز', 'ش', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'م', '<b>', 'م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 769: foruq baa labkhandi zuraki goft man hichchi azash nemikhaam maamaan\n",
            "PRED SCORE: -0.6468\n",
            "\n",
            "SENT 770: ['ا', 'و', 'ن', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ج', 'و', 'و', 'ن', 'ه']\n",
            "PRED 770: un hanuz kheyli javune\n",
            "PRED SCORE: -0.0125\n",
            "\n",
            "SENT 771: ['ن', 'م', 'ی', 'خ', 'و', 'ا', 'م', '<b>', 'ب', 'ه', 'ش', '<b>', 'ف', 'ش', 'ا', 'ر', '<b>', 'ب', 'ی', 'ا', 'د']\n",
            "PRED 771: nemikhaam biaad shaaer biaad\n",
            "PRED SCORE: -0.1770\n",
            "\n",
            "SENT 772: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'س', 'ر', 'ی', '<b>', 'ب', 'ع', 'ل', 'ا', 'م', 'ت', '<b>', 'ت', 'ا', 'س', 'ف', '<b>', 'ت', 'ک', 'ا', 'ن', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ع', 'ی', 'ن', '<b>', 'ز', 'ن', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'پ', 'ن', 'ج', 'ا', 'ه', '<b>', 'س', 'ا', 'ل', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ی']\n",
            "PRED 772: turaan sari be alaamat e taassof tekaan daad va goft eyb e mosen mizani\n",
            "PRED SCORE: -2.2967\n",
            "\n",
            "SENT 773: ['ن', 'ی', 'س', '<b>', 'ک', 'ه', '<b>', 'ت', 'و', '<b>', 'ب', 'ی', 'و', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'ا', 'ی', 'د', 'م', '<b>', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'و', '<b>', 'ب', 'ک', 'ن', 'ی']\n",
            "PRED 773: nim ke to zendeam baayad ma r ro bebin\n",
            "PRED SCORE: -2.1675\n",
            "\n",
            "SENT 774: ['م', 'ن', '<b>', 'ن', 'م', 'ی', 'د', 'و', 'ن', 'م', '<b>', 'ا', 'ی', 'ن', '<b>', 'پ', 'س', 'ر', 'ه', '<b>', 'چ', 'ی', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'ک', 'ه', '<b>', 'ق', 'ا', 'پ', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'د', 'ز', 'د', 'ی', 'د', 'ه', '<b>', 'و', 'ل', 'ی', '<b>', 'ا', 'ی', 'ن', 'و', '<b>', 'م', 'ی', 'د', 'و', 'ن', 'م', '<b>', 'ک', 'ه', '<b>', 'ح', 'ت', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'خ', 'و', 'ا', 'ب', '<b>', 'ه', 'م', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ی', '<b>', 'د', 'ر', 'د', 'س', 'ر', '<b>', 'ص', 'ا', 'ح', 'ا', 'ب', '<b>', 'ز', 'ن', '<b>', 'و', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'ب', 'ش', 'ه']\n",
            "PRED 774: man nemidunam in dowre daare ke haal e to ro nemiduni khune ke\n",
            "PRED SCORE: -3.5185\n",
            "\n",
            "SENT 775: ['ب', 'ق', 'و', 'ل', '<b>', 'ب', 'ا', 'ب', 'ا', 'ت', '<b>', 'ت', 'ا', '<b>', 'ا', 'ب', 'ل', 'ه', '<b>', 'د', 'ر', '<b>', 'ج', 'ه', 'ا', 'ن', 'ه', '<b>', 'م', 'ف', 'ل', 'س', '<b>', 'د', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'م', 'و', 'ن', 'ه']\n",
            "PRED 775: be baabaa taa taaze dar saretun mashhur dar haqqeshun nemishe\n",
            "PRED SCORE: -3.4869\n",
            "\n",
            "SENT 776: ['م', 'ا', '<b>', 'ک', 'ه', '<b>', 'ر', 'و', 'ی', '<b>', 'ح', 'س', 'ا', 'ب', '<b>', 'ک', 'ت', 'ا', 'ب', '<b>', 'ش', 'و', 'ه', 'ر', '<b>', 'ک', 'ر', 'د', 'ی', 'م', '<b>', 'ع', 'ا', 'ق', 'ب', 'ت', 'م', 'و', 'ن', '<b>', 'ا', 'ی', 'ن', 'ه', '<b>', 'و', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'ت', 'و']\n",
            "PRED 776: maa ke ru ye qalb e dars showhar kardan be haal e inke khor be haal istaad\n",
            "PRED SCORE: -2.8408\n",
            "\n",
            "SENT 777: ['خ', 'د', 'ا', '<b>', 'ا', 'خ', 'ر', '<b>', 'و', '<b>', 'ع', 'ا', 'ق', 'ب', 'ت', 'ت', '<b>', 'ر', 'و', '<b>', 'خ', 'ت', 'م', '<b>', 'ب', 'ه', '<b>', 'خ', 'ی', 'ر', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 777: khodaa nazar o baraadarim ro kheyr be kheyr kone\n",
            "PRED SCORE: -2.9273\n",
            "\n",
            "SENT 778: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ی', '<b>', 'پ', 'ر', 'د', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'د', 'و', 'س', 'ت', 'ش', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 778: foruq bi rudarbaasi goft man zudtar daaram maamaan\n",
            "PRED SCORE: -1.1951\n",
            "\n",
            "SENT 779: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ل', 'ب', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'د', 'ا', 'ن', '<b>', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ز', 'ی', 'ر', '<b>', 'ل', 'ب', '<b>', 'غ', 'ر', 'ی', 'د', '<b>', '<b>', 'خ', 'و', 'ب', 'ه']\n",
            "PRED 779: turaan lab be dandaan gereft va zir e lab qorrid khube\n",
            "PRED SCORE: -0.1271\n",
            "\n",
            "SENT 780: ['خ', 'و', 'ب', 'ه']\n",
            "PRED 780: khube\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 781: ['د', 'خ', 'ت', 'ر', 'ه', '<b>', 'پ', 'ا', 'ک', '<b>', 'ح', 'ی', 'ا', '<b>', 'ر', 'و', '<b>', 'خ', 'و', 'ر', 'د', 'ه']\n",
            "PRED 781: dokhtare paak aaqaa ey khorde\n",
            "PRED SCORE: -1.6404\n",
            "\n",
            "SENT 782: ['ن', 'م', 'ی', 'گ', 'ه', '<b>', 'م', 'ا', '<b>', 'ت', 'و', 'ی', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'ه', 'م', 'س', 'ر', '<b>', 'ا', 'ب', 'ر', 'و', '<b>', 'د', 'ا', 'ر', 'ی', 'م']\n",
            "PRED 782: nemige maa tu ye sar o hamun aaberum daarim\n",
            "PRED SCORE: -0.3577\n",
            "\n",
            "SENT 783: ['ا', 'خ', 'ه', '<b>', 'م', 'ر', 'د', 'م', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', 'گ', 'ن']\n",
            "PRED 783: aakhe mardom chi migan\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 784: ['ن', 'م', 'ی', 'گ', 'ن', '<b>', 'ل', 'ا', 'ب', 'د', '<b>', 'د', 'خ', 'ت', 'ر', 'ه', '<b>', 'ع', 'ی', 'ب', '<b>', 'و', '<b>', 'ع', 'ل', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ب', 'ی', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'ص', 'د', 'ا', '<b>', 'ر', 'ف', 'ت', '<b>', 'خ', 'و', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'خ', 'ت']\n",
            "PRED 784: nemigi laabod dokhtarhaa eyb o eshq daashte ke enqadr bi sedaa ye bi sedaa ye khune ye qadd\n",
            "PRED SCORE: -3.6505\n",
            "\n",
            "SENT 785: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ح', 'ر', 'ف', '<b>', 'م', 'ر', 'د', 'م', '<b>', 'ا', 'ص', 'ل', 'ا', '<b>', 'و', 'ا', 'س', 'م', '<b>', 'م', 'ه', 'م', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 785: foruq baa labkhand goft harf e mardom aslan mohemm nist\n",
            "PRED SCORE: -0.0990\n",
            "\n",
            "SENT 786: ['م', 'ن', '<b>', 'ت', 'ص', 'م', 'ی', 'م', 'م', '<b>', 'ر', 'و', '<b>', 'گ', 'ر', 'ف', 'ت', 'م', '<b>', 'م', 'ا', 'م', 'ا', 'ن']\n",
            "PRED 786: man aaram ro goftam maamaan\n",
            "PRED SCORE: -1.4826\n",
            "\n",
            "SENT 787: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ت', 'ا', 'س', 'ف', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ا', 'ر', 'م', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ی', 'ن', 'م']\n",
            "PRED 787: turaan baa taassof goft daaram mibini\n",
            "PRED SCORE: -0.0875\n",
            "\n",
            "SENT 788: ['ا', 'و', 'ن', '<b>', 'ب', 'ا', 'ب', 'ا', 'ی', '<b>', 'ب', 'د', 'ب', 'خ', 'ت', 'ت', '<b>', 'ر', 'ا', 'س', 'ت', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', '<b>', 'ک', 'ه', '<b>', 'ت', 'و', 'ی', '<b>', 'ک', 'ل', 'ه', '<b>', 'ا', 'ت', '<b>', 'ی', 'ک', '<b>', 'ج', 'و', '<b>', 'ع', 'ق', 'ل', '<b>', 'ن', 'د', 'ا', 'ر', 'ی']\n",
            "PRED 788: un baabaa ba d owqaat ke tu ye bachche ro taa zan nadaari\n",
            "PRED SCORE: -0.4856\n",
            "\n",
            "SENT 789: ['و', 'ق', 'ت', 'ی', '<b>', 'ع', 'ا', 'ق', 'د', '<b>', 'خ', 'ط', 'ب', 'ه', '\\u200c', 'ی', '<b>', 'ع', 'ق', 'د', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ن', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', 'چ', 'ن', 'ا', 'ن', '<b>', 'گ', 'ی', 'ج', '<b>', 'ب', 'و', 'د']\n",
            "PRED 789: vaqti ziaad khaste ye rizi mibarid foruq hamun chiz bud\n",
            "PRED SCORE: -2.5989\n",
            "\n",
            "SENT 790: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'چ', 'ی', '<b>', 'ش', 'د', 'ه', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 790: parviz aaraam porsid chi shode foruq\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 791: ['د', 'ر', '<b>', 'ح', 'ا', 'ل', 'ت', 'ی', '<b>', 'ب', 'ی', 'ن', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'و', '<b>', 'ا', 'س', 'م', 'ا', 'ن', '<b>', 'ب', 'و', 'د']\n",
            "PRED 791: dar taariki e bi gomaan o a aar bud\n",
            "PRED SCORE: -1.0315\n",
            "\n",
            "SENT 792: ['ع', 'ا', 'ق', 'د', '<b>', 'ب', 'ا', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ب', 'ا', 'ر', '<b>', 'س', 'و', 'م', '<b>', 'ت', 'ک', 'ر', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ع', 'ر', 'و', 'س', '<b>', 'خ', 'ا', 'ن', 'م', '<b>', 'ب', 'ه', '<b>', 'ب', 'ن', 'د', 'ه', '<b>', 'و', 'ک', 'ا', 'ل', 'ت', '<b>', 'م', 'ی', '\\u200c', 'د', 'ه', 'ی', 'د', '<b>', 'ش', 'م', 'ا', '<b>', 'ر', 'ا', '<b>', 'ع', 'ق', 'د', '<b>', 'د', 'ا', 'ی', 'م', '<b>', 'ج', 'ن', 'ا', 'ب', '<b>', 'ا', 'ق', 'ا', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'د', 'ر', 'ا', 'و', 'ر', 'م']\n",
            "PRED 792: ziaad baa vojud goft baraaye nazar e jush qaael mikonam aaqaa\n",
            "PRED SCORE: -1.9593\n",
            "\n",
            "SENT 793: ['س', 'ک', 'و', 'ت', '<b>', 'س', 'ن', 'گ', 'ی', 'ن', 'ی', '<b>', 'ب', 'ر', '<b>', 'ج', 'م', 'ع', '<b>', 'ح', 'ا', 'ک', 'م', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 793: sokut e sangini bar jam haakem shode bud\n",
            "PRED SCORE: -0.0015\n",
            "\n",
            "SENT 794: ['ف', 'ر', 'و', 'غ', '<b>', 'ز', 'ی', 'ر', 'چ', 'ش', 'م', 'ی', '<b>', 'ب', 'ه', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'ج', 'و', 'ا', 'ب', '<b>', 'م', 'ث', 'ب', 'ت', '<b>', 'د', 'ا', 'د']\n",
            "PRED 794: foruq qaafelgir be parviz negaah kard va baa sedaa ye larzaani sokut daad\n",
            "PRED SCORE: -0.5311\n",
            "\n",
            "SENT 795: ['ب', 'ا', 'و', 'ر', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'د', 'ر', '<b>', 'ن', 'ی', '<b>', 'ن', 'ی', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'م', '\\u200c', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 795: baavarash nemishod engaar dar naa sangini e vojud gardesh bud\n",
            "PRED SCORE: -1.3060\n",
            "\n",
            "SENT 796: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ز', 'ی', 'ر', '<b>', 'ل', 'ب', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ت', 'و', 'ج', 'ه', '<b>', 'ن', 'ش', 'د', '<b>', 'ف', 'ق', 'ط', '<b>', 'د', 'ل', 'ش', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ا', 'و', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'پ', 'ی', 'ش', '<b>', 'ف', 'ر', 'و', '<b>', 'ر', 'و', 'د']\n",
            "PRED 796: parviz zir e lab goft ammaa motevajjeh e mojassame faqat dur mikhaast\n",
            "PRED SCORE: -3.2322\n",
            "\n",
            "SENT 797: ['ا', 'ق', 'و', 'ا', 'م', '<b>', 'ی', 'ک', 'ی', '<b>', 'ی', 'ک', 'ی', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ب', 'و', 'س', 'ی', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ت', 'ب', 'ر', 'ی', 'ک', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', 'ن', 'د']\n",
            "PRED 797: haalaam yeki yeki surat raa ehsaas o tarbiat miparidand\n",
            "PRED SCORE: -3.1036\n",
            "\n",
            "SENT 798: ['ف', 'ض', 'ا', '<b>', 'ف', 'ض', 'ا', 'ی', '<b>', 'خ', 'ا', 'ص', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 798: fe lan ketaab e khaane bud\n",
            "PRED SCORE: -1.1264\n",
            "\n",
            "SENT 799: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'چ', 'ش', 'م', '<b>', 'ح', 'ا', 'ض', 'ر', 'ی', 'ن', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'ف', 'ش', 'ر', 'د']\n",
            "PRED 799: parviz dur az cheshm e taslim e zebrash raa dar dast feshord\n",
            "PRED SCORE: -2.2818\n",
            "\n",
            "SENT 800: ['ا', 'ی', 'ن', '<b>', 'م', 'ج', 'ل', 'س', '<b>', 'س', 'ا', 'د', 'ه', '\\u200c', 'ی', '<b>', 'س', 'ر', 'و', 'ر', '<b>', 'ا', 'ن', '<b>', 'ج', 'ش', 'ن', 'ی', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'د', 'ر', '<b>', 'ذ', 'ه', 'ن', '<b>', 'ت', 'ص', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 800: in khodash kaarie sartaasar e aan gonaahash nabud ke hamishe dar aks e tasavvor mikard\n",
            "PRED SCORE: -3.0113\n",
            "\n",
            "SENT 801: ['ش', 'م', 'س', 'ی', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ی', '<b>', 'ر', 'و', 'ی', '<b>', 'پ', 'ا', '<b>', 'ب', 'ن', 'د', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ا', 'ن', '<b>', 'ه', 'ی', 'ک', 'ل', '<b>', 'س', 'ن', 'گ', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'ش', 'ا', 'د', 'ی', '<b>', 'و', '<b>', 'پ', 'ا', 'ی', 'ک', 'و', 'ب', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ض', 'ع', 'ی', 'ف', '<b>', 'ا', 'ل', 'ج', 'ث', 'ه', '<b>', 'ب', 'ی', 'ش', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 801: shamsi az khoshhaali ru ye ru ye boqz boland zad ke baa aan daad ke engaar tamaamesh mikard\n",
            "PRED SCORE: -3.4714\n",
            "\n",
            "SENT 802: ['ن', 'گ', 'ا', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'د', 'ر', '<b>', 'ا', 'ن', '<b>', 'ب', 'ی', 'ن', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ش', 'د']\n",
            "PRED 802: negaah e foruq dar aan baaz motevajjeh e pedarash shod\n",
            "PRED SCORE: -1.7074\n",
            "\n",
            "SENT 803: ['م', 'غ', 'م', 'و', 'م', '<b>', 'و', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', 'ا', 'ن', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 803: ma naa o saaat barandaazash mikard\n",
            "PRED SCORE: -0.9712\n",
            "\n",
            "SENT 804: ['ا', 'ب', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', 'د', 'و', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'و', 'ش', 'ا', 'ن', 'د']\n",
            "PRED 804: aslan az anduh e suratash raa ravaan\n",
            "PRED SCORE: -1.1002\n",
            "\n",
            "SENT 805: ['ا', 'ی', 'ا', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'ا', 'ن', '<b>', 'س', 'ر', 'د', 'ا', 'ر', '<b>', 'ج', 'ن', 'گ', 'ج', 'و', '<b>', 'ر', 'ا', '<b>', 'ش', 'ک', 'س', 'ت', '<b>', 'د', 'ا', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 805: aayaa baa aan sor at e zendegish raa shekast bud\n",
            "PRED SCORE: -2.3272\n",
            "\n",
            "SENT 806: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'س', 'ی', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ر', 'ض', 'ا', 'ی', 'ت', 'ش', '<b>', 'ر', 'و', '<b>', 'ج', 'ل', 'ب', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', 'م']\n",
            "PRED 806: parviz mokhtasar negaahash raa kenaar kard va aaraam goft baa ham behtari mikonam\n",
            "PRED SCORE: -1.3909\n",
            "\n",
            "SENT 807: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ا', 'م', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ی', '<b>', 'گ', 'ف', 'ت', 'ی']\n",
            "PRED 807: foruq be khodash aamad va goft chi nagofti\n",
            "PRED SCORE: -0.0417\n",
            "\n",
            "SENT 808: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ه', 'ر', 'ب', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'گ', 'ف', 'ت', 'م', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ن', 'ب', 'ا', 'ش']\n",
            "PRED 808: parviz baa mehrbaani goft goftam negaraan nemikoni\n",
            "PRED SCORE: -0.0112\n",
            "\n",
            "SENT 809: ['ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'م', 'ی', 'ش', 'ه']\n",
            "PRED 809: hameche dorost mishe\n",
            "PRED SCORE: -0.0184\n",
            "\n",
            "SENT 810: ['ت', 'و', '<b>', 'ک', 'ه', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'م', 'و', 'ض', 'و', 'ع', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', '<b>', 'ن', 'ی', 'س', 'ت', 'ی']\n",
            "PRED 810: to ke az in mowzu nadaari nisti\n",
            "PRED SCORE: -0.2109\n",
            "\n",
            "SENT 811: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 811: foruq moteajjeb negaahash kard\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 812: ['چ', 'ر', 'ا', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ا', 'ش', 'م']\n",
            "PRED 812: cheraa baayad baasham\n",
            "PRED SCORE: -0.1514\n",
            "\n",
            "SENT 813: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ق', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ع', 'ر', 'و', 'س', 'ی', '<b>', 'ا', 'ن', 'چ', 'ن', 'ا', 'ن', 'ی', '<b>', 'ن', 'ت', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'ب', 'ر', 'ا', 'ت', '<b>', 'ب', 'گ', 'ی', 'ر', 'م']\n",
            "PRED 813: parviz baa sedaaqat goft sarkub ye aanhaa tamaam e baraat baraat konim\n",
            "PRED SCORE: -3.1843\n",
            "\n",
            "SENT 814: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ب', 'ه', '<b>', 'ا', 'ی', 'ن', '<b>', 'چ', 'ی', 'ز', 'ه', 'ا', '<b>', 'ا', 'ه', 'م', 'ی', 'ت', '<b>', 'ن', 'م', 'ی', 'د', 'م']\n",
            "PRED 814: foruq goft man be in chizhaa enerzhi e sakhti\n",
            "PRED SCORE: -0.9952\n",
            "\n",
            "SENT 815: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ع', 'ا', 'ش', 'ق', 'ا', 'ن', 'ه', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ی', 'ک', '<b>', 'م', 'و', 'ج', 'و', 'د', '<b>', 'ا', 'س', 'ت', 'ث', 'ن', 'ا', 'ی', 'ی', '<b>', 'ه', 'س', 'ت', 'ی']\n",
            "PRED 815: parviz baa negaahi saakhtegi tow kard va aaraam goft to yek kam shokke hasti\n",
            "PRED SCORE: -2.4416\n",
            "\n",
            "SENT 816: ['ی', 'ک', '<b>', 'ف', 'ر', 'ش', 'ت', 'ه', '<b>', 'م', 'ی', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'م', 'ی', 'ل', 'ی', 'و', 'ن', '<b>', 'د', 'خ', 'ت', 'ر']\n",
            "PRED 816: yek forsat migan yek migan dokhtar\n",
            "PRED SCORE: -2.0633\n",
            "\n",
            "SENT 817: ['ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'ت', 'ه', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ر', 'س', 'ی']\n",
            "PRED 817: foruq az tah e ashk labkhand zad va goft mardi\n",
            "PRED SCORE: -0.8681\n",
            "\n",
            "SENT 818: ['ر', 'ا', 'س', 'ت', 'ش', '<b>', 'ه', 'م', 'ه', '<b>', 'چ', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'س', 'ر', 'ی', 'ع', '<b>', 'ا', 'ت', 'ف', 'ا', 'ق', '<b>', 'ا', 'ف', 'ت', 'ا', 'د', '<b>', 'ک', 'ه', '<b>', 'ه', 'ن', 'و', 'ز', 'م', '<b>', 'ن', 'ا', 'ب', 'ا', 'و', 'ر', 'م']\n",
            "PRED 818: raastesh hamechi aanqadr mohaafezekaar ettefaaq ke hanuzam bokhori\n",
            "PRED SCORE: -2.9431\n",
            "\n",
            "SENT 819: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ع', 'ت', 'ر', 'ا', 'ف', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 819: parviz atraafash kard\n",
            "PRED SCORE: -0.7533\n",
            "\n",
            "SENT 820: ['ا', 'گ', 'ه', '<b>', 'پ', 'د', 'ر', 'ت', '<b>', 'م', 'و', 'ا', 'ف', 'ق', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'چ', 'ی', 'ک', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م']\n",
            "PRED 820: age posht e tokhm e cheshaam nemidunam chikaar mikardam\n",
            "PRED SCORE: -1.7580\n",
            "\n",
            "SENT 821: ['ی', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ق', 'و', 'ا', 'م', '<b>', 'ن', 'ز', 'د', 'ی', 'ک', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ع', 'د', 'ا', '<b>', 'ی', 'ک', '<b>', 'ع', 'ا', 'ل', 'م', 'ه', '<b>', 'و', 'ق', 'ت', '<b>', 'د', 'ا', 'ر', 'ی', 'د', '<b>', 'ک', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'ی', 'د']\n",
            "PRED 821: yeki az tamaam nazdik shod va be shukhi goft ba d az zohr daashtam ke harf bezanid\n",
            "PRED SCORE: -2.7732\n",
            "\n",
            "SENT 822: ['ی', 'ا', 'ل', 'ا', '<b>', 'پ', 'ا', 'ش', 'ی', 'ن']\n",
            "PRED 822: yaadgaar e maali\n",
            "PRED SCORE: -0.3531\n",
            "\n",
            "SENT 823: ['م', 'ر', 'ا', 'س', 'م', '<b>', 'ع', 'ق', 'د', '<b>', 'د', 'ر', '<b>', 'ف', 'ض', 'ا', 'ی', '<b>', 'س', 'ا', 'د', 'ه', '<b>', 'و', '<b>', 'ب', 'ی', '<b>', 'ا', 'ل', 'ا', 'ی', 'ش', 'ی', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ق', 'ر', 'ا', 'ر', '<b>', 'ش', 'د', '<b>', 'ت', 'ا', '<b>', 'ز', 'م', 'ا', 'ن', '<b>', 'م', 'ا', 'م', 'و', 'ر', 'ی', 'ت', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'ا', 'م', 'ز', 'د', '<b>', 'ب', 'م', 'ا', 'ن', 'ن', 'د', '<b>', 'ت', 'ا', '<b>', 'د', 'ر', '<b>', 'ا', 'ی', 'ن', '<b>', 'ف', 'ا', 'ص', 'ل', 'ه', '<b>', 'ج', 'ه', 'ی', 'ز', 'ی', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'م', 'ا', 'د', 'ه', '<b>', 'ش', 'و', 'د', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ب', 'ی', '<b>', 'س', 'ر', '<b>', 'و', '<b>', 'ص', 'د', 'ا', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'م', 'ش', 'ت', 'ر', 'ک', 'ش', 'ا', 'ن', '<b>', 'ر', 'ا', '<b>', 'ا', 'غ', 'ا', 'ز', '<b>', 'ک', 'ن', 'ن', 'د']\n",
            "PRED 823: maa maraa dar aqide ye chaap o bi saabeqei taa qaraar shod ammaa qaraar konand\n",
            "PRED SCORE: -4.1815\n",
            "\n",
            "SENT 824: ['ا', 'ن', '<b>', 'ر', 'و', 'ز', 'ه', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'و', 'ز', 'ه', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ی', 'ا', 'د', '<b>', 'م', 'ا', 'ن', 'د', 'ن', 'ی', '<b>', 'و', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'ب', 'و', 'د']\n",
            "PRED 824: aan ruzhaa baraaye foruq aamadanash be yaad e khaane o riz bud\n",
            "PRED SCORE: -3.0778\n",
            "\n",
            "SENT 825: ['ح', 'ا', 'ل', 'ت', 'ش', '<b>', 'ط', 'و', 'ر', 'ر', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'د', 'ر', '<b>', 'ا', 'س', 'م', 'ا', 'ن', '<b>', 'ر', 'و', 'ی', '<b>', 'ا', 'ب', 'ر', 'ه', 'ا', '<b>', 'س', 'ی', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 825: haalash towri bud ke engaar dar ahvaaz ru mikard\n",
            "PRED SCORE: -1.9731\n",
            "\n",
            "SENT 826: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ر', 'د', 'ی', '<b>', 'ص', 'ب', 'و', 'ر', '<b>', 'و', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'ه', 'ر', '<b>', 'چ', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ه', 'د', '<b>', 'ب', 'گ', 'و', 'ی', 'د', '<b>', 'و', '<b>', 'ه', 'ر', '<b>', 'ک', 'ا', 'ر', 'ی', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ه', 'د', '<b>', 'ب', 'ک', 'ن', 'د']\n",
            "PRED 826: parviz mardi baqalash o aaraam bud va shaqiqeash har kaari mikhaast\n",
            "PRED SCORE: -2.5436\n",
            "\n",
            "SENT 827: ['م', 'ی', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'س', 'ا', 'ع', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ا', 'ر', 'ز', 'و', 'ه', 'ا', '<b>', 'و', '<b>', 'ا', 'ف', 'ک', 'ا', 'ر', 'ش', '<b>', 'ب', 'ی', '\\u200c', 'و', 'ق', 'ف', 'ه', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'د', '<b>', 'ب', 'ی', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'خ', 'س', 'ت', 'گ', 'ی', '<b>', 'ی', 'ا', '<b>', 'ب', 'ی', '<b>', 'ح', 'و', 'ص', 'ل', 'گ', 'ی', '<b>', 'ک', 'ن', 'د', '<b>', 'و', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ک', 'ه', '<b>', 'م', 'ر', 'د', 'ه', 'ا', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'س', 'ب', 'ک', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ش', 'ن', 'ا', 'خ', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ه', 'ی', 'ج', 'ا', 'ن', '<b>', 'ا', 'ن', 'گ', 'ی', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ن', 'م', 'و', 'د']\n",
            "PRED 827: miduni siaahilashgar baraaye shaanehaa az nahifash naft harf mizanid\n",
            "PRED SCORE: -5.0650\n",
            "\n",
            "SENT 828: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ن', 'ه', '<b>', 'ت', 'ن', 'ه', 'ا', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ق', 'ا', 'و', 'م', 'ت', '<b>', 'و', '<b>', 'م', 'خ', 'ا', 'ل', 'ف', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ب', 'ل', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', 'ش', '<b>', 'ت', 'س', 'ل', 'ی', 'م', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'گ', 'ر', '<b>', 'ا', 'ش', 'ت', 'ب', 'ا', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'ب', 'ه', '<b>', 'ن', 'ر', 'م', 'ی', '<b>', 'م', 'ی', '\\u200c', 'خ', 'ن', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ش', 'ت', '<b>', 'ا', 'گ', 'ر', '<b>', 'پ', 'ی', 'ش', 'ن', 'ه', 'ا', 'د', '<b>', 'م', 'ی', 'د', 'ا', 'د', '<b>', 'س', 'ر', 'ز', 'ن', 'ش', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 828: parviz na alaan dar baraabar e khune ye foruq lak miaad bud\n",
            "PRED SCORE: -2.2436\n",
            "\n",
            "SENT 829: ['ب', 'ر', 'ا', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ک', 'ت', 'ا', 'ب', '\\u200c', 'ه', 'ا', '<b>', 'و', '<b>', 'ا', 'ش', 'ع', 'ا', 'ر', 'ی', '<b>', 'ک', 'ه', '<b>', 'ا', 'خ', 'ی', 'ر', 'ا', '<b>', 'خ', 'و', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ص', 'ح', 'ب', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ا', 'ی', 'ن', '\\u200c', 'ه', 'م', 'ه', '<b>', 'د', 'ر', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ا', 'ت', '<b>', 'ت', 'ا', 'ز', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'د', 'س', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ی', 'ا', 'ف', 'ت']\n",
            "PRED 829: laaaqal az ba d o zohr ke astaqforellaah khune be injaast\n",
            "PRED SCORE: -2.9713\n",
            "\n",
            "SENT 830: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ن', 'ا', 'گ', 'ه', 'ا', 'ن', '<b>', 'پ', 'س', '<b>', 'ا', 'ز', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'ا', '<b>', 'ک', 'ش', 'ف', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'ا', 'ک', 'ت', 'ش', 'ا', 'ف', '<b>', 'ب', 'ه', '\\u200c', 'ش', 'د', 'ت', '<b>', 'ش', 'گ', 'ف', 'ت', '\\u200c', 'ز', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 830: engaar naagahaan pas az bachchehaayash ye khodash raa za d az in qiaas be sheddat mikard va az in\n",
            "PRED SCORE: -3.7659\n",
            "\n",
            "SENT 831: ['ح', 'ا', 'ل', 'ا', '<b>', 'ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', '<b>', 'ب', 'ه', '<b>', 'م', 'ع', 'ن', 'ی', '<b>', 'و', 'ا', 'ق', 'ع', 'ی', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'م', 'ه', '<b>', 'د', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'و', '<b>', 'ج', 'ل', 'ب', '<b>', 'ر', 'ض', 'ا', 'ی', 'ت', '<b>', 'ا', 'و', '<b>', 'خ', 'ل', 'ا', 'ص', 'ه', '\\u200c', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ک', 'ه', '<b>', 'ح', 'ت', 'ی', '<b>', 'ر', 'ا', 'ض', 'ی', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'ذ', 'ر', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ب', 'ه', '<b>', 'ه', 'ر', '<b>', 'د', 'ل', 'ی', 'ل', 'ی', '<b>', 'ب', 'ر', 'ن', 'ج', 'د']\n",
            "PRED 831: haalaa hame ye zendegish be ma f e vaaqei yek aaqaa dar har haal enkaar nabud\n",
            "PRED SCORE: -2.3880\n",
            "\n",
            "SENT 832: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ح', 'ک', 'م', '<b>', 'پ', 'د', 'ر', '<b>', 'گ', 'م', '\\u200c', 'ش', 'د', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ر', 'ا', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'ک', 'ه', '<b>', 'س', 'ا', 'ل', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'ب', 'ا', 'ل', 'ش', '<b>', 'ب', 'و', 'د', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ا', 'م', 'ن', 'ی', 'ت', '<b>', 'ن', 'ا', 'ش', 'ن', 'ا', 'خ', 'ت', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ر', 'س', 'ی', 'د', 'ن', '<b>', 'ب', 'ه', '<b>', 'ا', 'ن', '<b>', 'ح', 'ا', 'ض', 'ر', '<b>', 'ب', 'و', 'د', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', 'ش', '<b>', 'ر', 'ا', '<b>', 'ف', 'د', 'ا', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 832: parviz baraaye foruq qasam paak naraft mardhaa raa daasht ke haalaa be aan haal naaraahat konad\n",
            "PRED SCORE: -4.4983\n",
            "\n",
            "SENT 833: ['ح', 'ا', 'ل', 'ا', '<b>', 'ه', 'ر', '<b>', 'و', 'ق', 'ت', '<b>', 'ب', 'ا', '<b>', 'ا', 'و', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ت', '<b>', 'د', 'ر', 'و', 'ن', 'ش', '<b>', 'د', 'ر', '<b>', 'ق', 'ا', 'ل', 'ب', '<b>', 'ک', 'ل', 'م', 'ا', 'ت', 'ی', '<b>', 'م', 'و', 'ز', 'و', 'ن', '<b>', 'د', 'ر', '<b>', 'د', 'ر', 'و', 'ن', 'ش', '<b>', 'ش', 'ک', 'ل', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ر', 'ف', 'ت', 'ن', 'د', '<b>', 'و', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ب', 'ه', '<b>', 'و', 'ا', 'ق', 'ع', '<b>', 'ا', 'ز', '<b>', 'ل', 'ذ', 'ت', '<b>', 'ع', 'ش', 'ق', '<b>', 'س', 'ر', 'م', 'س', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'د', 'ا', 'ن', 'ی', '<b>', 'ا', 'ز', '<b>', 'ز', 'ن', 'د', 'گ', 'ی', '<b>', 'چ', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ه', 'م']\n",
            "PRED 833: haalaa har vaqt baa u bud e zajresh dur mishodand o khodesh tamaamesh mishe o khodash be vaaqe\n",
            "PRED SCORE: -4.4525\n",
            "\n",
            "SENT 834: ['م', 'ن', '<b>', 'چ', 'ط', 'و', 'ر', 'ی', '<b>', 'ا', 'ز', '<b>', 'ا', 'ح', 'س', 'ا', 'س', 'ت', '<b>', 'ق', 'ل', 'ب', 'ی', 'م', '<b>', 'ب', 'گ', 'م']\n",
            "PRED 834: man chetowri az teraafhaat nemitunestam begam\n",
            "PRED SCORE: -0.5624\n",
            "\n",
            "SENT 835: ['پ', 'ی', 'ش', '<b>', 'ت', 'و', '<b>', 'ز', 'ب', 'و', 'ن', 'م', '<b>', 'ق', 'ا', 'ص', 'ر', '<b>', 'و', '<b>', 'ن', 'ا', 'ت', 'و', 'ا', 'ن', 'ه']\n",
            "PRED 835: pish e to bedunam ke shojaaie\n",
            "PRED SCORE: -1.5691\n",
            "\n",
            "SENT 836: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ع', 'ا', 'ش', 'ق', 'ا', 'ن', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'ع', 'ک', 'س', '<b>', 'ا', 'ی', 'ن', '<b>', 'ک', 'ا', 'ر', 'ت', 'و', 'س', 'ت', '<b>', 'پ', 'ر', 'و', 'ی', 'ز']\n",
            "PRED 836: foruq baa negaahi saakhtegi goft bar e peykare\n",
            "PRED SCORE: -1.5830\n",
            "\n",
            "SENT 837: ['ا', 'ی', 'ن', '<b>', 'ت', 'و', '<b>', 'ب', 'و', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'س', 'ب', 'ب', '<b>', 'ش', 'د', 'ی', '<b>', 'ک', 'ل', 'م', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ا', 'ی', 'ن', 'ط', 'و', 'ر', 'ی', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'ه', 'م', '<b>', 'ق', 'ر', 'ا', 'ر', '<b>', 'ب', 'گ', 'ی', 'ر', 'ن', 'د']\n",
            "PRED 837: in to budi ke sobh shodand paache ye amni ro qaraar konid\n",
            "PRED SCORE: -2.9560\n",
            "\n",
            "SENT 838: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'خ', 'ن', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'م', 'و', 'ه', 'ا', 'ی', '<b>', 'س', 'ی', 'ا', 'ه', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د']\n",
            "PRED 838: parviz baa mohabbat khandid o muhaa ye lebaasash raa busid\n",
            "PRED SCORE: -1.0786\n",
            "\n",
            "SENT 839: ['ع', 'ج', 'ب']\n",
            "PRED 839: ajab\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 840: ['پ', 'س', '<b>', 'م', 'ن', '<b>', 'ا', 'ل', 'ه', 'ا', 'م', '<b>', 'د', 'ه', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'و', '<b>', 'خ', 'ب', 'ر', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'م']\n",
            "PRED 840: pas man age deltang e badanam o khabar nadaare\n",
            "PRED SCORE: -2.3122\n",
            "\n",
            "SENT 841: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ق', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ی', 'ش', 'ب', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'و', '<b>', 'ب', 'ه', 'ت', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'م', '<b>', 'ک', 'ل', 'م', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ه', '<b>', 'ذ', 'ه', 'ن', 'م', '<b>', 'ا', 'و', 'م', 'د', 'ن', 'د']\n",
            "PRED 841: foruq baa sedaaqat goft dishab hamin showhar ke tanhaa budam be ham chasbaand\n",
            "PRED SCORE: -1.8801\n",
            "\n",
            "SENT 842: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ک', 'ن', 'ج', 'ک', 'ا', 'و', 'ی', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'ت', 'و', '<b>', 'ق', 'ب', 'ل', 'ا', '<b>', 'ه', 'م', '<b>', 'ش', 'ع', 'ر', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', 'ی']\n",
            "PRED 842: parviz baa konjkaavi porsid mage to aashpazi ham she r mishe\n",
            "PRED SCORE: -1.0717\n",
            "\n",
            "SENT 843: ['ف', 'ر', 'و', 'غ', '<b>', 'ن', 'ف', 'س', '<b>', 'ع', 'م', 'ی', 'ق', 'ی', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه', '<b>', 'ب', 'ا', 'ب', 'ا', 'م', '<b>', 'ه', 'ی', 'چ', '<b>', 'و', 'ق', 'ت', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'ش', 'ع', 'ر', '<b>', 'ب', 'گ', 'م']\n",
            "PRED 843: foruq nafasi amiq keshid va goft na baabaa dustet begam she r besham\n",
            "PRED SCORE: -1.2014\n",
            "\n",
            "SENT 844: ['ی', 'ا', 'د', 'م', 'ه', '<b>', 'ی', 'ک', '<b>', 'ب', 'ا', 'ر', '<b>', 'ی', 'ک', 'ی', '<b>', 'د', 'و', '<b>', 'س', 'ا', 'ل', '<b>', 'ق', 'ب', 'ل', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'ک', 'ی', '<b>', 'ا', 'ز', '<b>', 'ش', 'ع', 'ر', 'ا', 'م', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', 'ش', '<b>', 'ن', 'ش', 'و', 'ن', '<b>', 'د', 'ا', 'د', 'م', '<b>', 'و', 'ر', 'ق', 'ه', '<b>', 'ر', 'و', '<b>', 'ب', 'ا', '<b>', 'ع', 'ص', 'ب', 'ا', 'ن', 'ی', 'ت', '<b>', 'پ', 'ا', 'ر', 'ه', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 844: yaadame yek baar yeki do saal qabl e donyaa sabr daadan e she r didam gerye ro behesh daadam\n",
            "PRED SCORE: -3.8671\n",
            "\n",
            "SENT 845: ['م', 'ن', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'گ', 'ف', 'ت', 'ن', 'ش', '<b>', 'ک', 'ل', 'ی', '<b>', 'ز', 'ح', 'م', 'ت', '<b>', 'ک', 'ش', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م']\n",
            "PRED 845: man baraaye gusht e kasi aasheq e azaast\n",
            "PRED SCORE: -1.4316\n",
            "\n",
            "SENT 846: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'م', 'ا', '<b>', 'م', 'ن', '<b>', 'ب', 'ه', 'ت', '<b>', 'ا', 'ف', 'ت', 'خ', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'و', '<b>', 'د', 'س', 'ت', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ه', 'ن', 'ر', 'م', 'ن', 'د', 'ت', '<b>', 'و', '<b>', 'م', 'ی', '\\u200c', 'ب', 'و', 'س', 'م']\n",
            "PRED 846: parviz goft ammaa man behet nadaari mikonam o bachchehaa ye behtari o mikhunam\n",
            "PRED SCORE: -1.9828\n",
            "\n",
            "SENT 847: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', 'و', 'ر', '<b>', 'ک', 'ن', '<b>', 'م', 'د', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'ا', 'ی', 'ن', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ر', 'و', '<b>', 'گ', 'م', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'م', '<b>', 'ت', 'ا', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'م', 'د', 'ت', '\\u200c', 'ه', 'ا', '<b>', 'پ', 'ی', 'د', 'ا', 'ی', 'ش', '<b>', 'ک', 'ر', 'د', 'م', '<b>', 'و', '<b>', 'م', 'ط', 'م', 'ی', 'ن', 'م', '<b>', 'و', 'ج', 'و', 'د', '<b>', 'ت', 'و', '<b>', 'ب', 'ی', '<b>', 'ت', 'ا', 'ث', 'ی', 'ر', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 847: foruq goft baavar kon moddati in ehsaas ro az inke behesh kardand\n",
            "PRED SCORE: -3.3315\n",
            "\n",
            "SENT 848: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'ی', '<b>', 'ی', 'ک', '<b>', 'ق', 'و', 'ل', 'ی', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', '<b>', 'ب', 'د', 'ی']\n",
            "PRED 848: parviz mituni yek baar be ham bedi\n",
            "PRED SCORE: -1.5560\n",
            "\n",
            "SENT 849: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ل', 'ب', 'ت', 'ه', '<b>', 'ع', 'ز', 'ی', 'ز', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ا', 'ک', 'ی', 'د', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ی', 'ک', '<b>', 'ق', 'و', 'ل', '<b>', 'و', 'ا', 'ق', 'ع', 'ی']\n",
            "PRED 849: parviz goft albatte azizam foruq ta kid kard yek agar khaasti\n",
            "PRED SCORE: -1.9674\n",
            "\n",
            "SENT 850: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ن', 'د', 'ی', 'د']\n",
            "PRED 850: parviz khandid\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 851: ['م', 'گ', 'ه', '<b>', 'ق', 'و', 'ل', '<b>', 'غ', 'ی', 'ر', '<b>', 'و', 'ا', 'ق', 'ع', 'ی', '<b>', 'ه', 'م', '<b>', 'د', 'ا', 'ر', 'ی', 'م']\n",
            "PRED 851: mage qowl e dir khubiyat daarin\n",
            "PRED SCORE: -1.5052\n",
            "\n",
            "SENT 852: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ا', 'ض', 'ط', 'ر', 'ا', 'ب', 'ی', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ن', '<b>', 'ج', 'د', 'ی', '<b>', 'م', 'ی', 'گ', 'م']\n",
            "PRED 852: foruq baa qaateiyat aashkaar goft man jeddi migam\n",
            "PRED SCORE: -0.9846\n",
            "\n",
            "SENT 853: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'م', 'ا', 'ن', 'د']\n",
            "PRED 853: parviz be suratash khire maand\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 854: ['چ', 'ه', '<b>', 'ق', 'و', 'ل', 'ی']\n",
            "PRED 854: che qowli\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 855: ['ا', 'گ', 'ه', '<b>', 'ب', 'ع', 'د', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '\\u200c', 'ه', 'م', 'ه', '<b>', 'ا', 'ز', '<b>', 'خ', 'و', 'د', '<b>', 'گ', 'ذ', 'ش', 'ت', 'گ', 'ی', 'ت', '<b>', 'ق', 'ب', 'و', 'ل', '<b>', 'ن', 'ک', 'ن', 'م', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ب', 'ی', '<b>', 'و', 'ج', 'د', 'ا', 'ن', 'م']\n",
            "PRED 855: age ba d az inke az khodet gozashte qabl kheyli yaa daashtin\n",
            "PRED SCORE: -3.1707\n",
            "\n",
            "SENT 856: ['ب', 'گ', 'و', '<b>', 'چ', 'ی', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 856: begu chi mikhaay foruq\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 857: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'س', 'ت', 'پ', 'ا', 'چ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', 'ن', 'ک', 'ه', '<b>', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 857: foruq kalaafe goft inke hamishe haminqadr baashi\n",
            "PRED SCORE: -0.6776\n",
            "\n",
            "SENT 858: ['ه', 'م', 'ی', 'ن', '<b>', 'ر', 'ن', 'گ', 'ی']\n",
            "PRED 858: hamin parviz\n",
            "PRED SCORE: -0.8593\n",
            "\n",
            "SENT 859: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ا', 'خ', 'م', 'ی', '<b>', 'ا', 'م', 'ی', 'خ', 'ت', 'ه', '<b>', 'ب', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ک', 'د', 'و', 'م', '<b>', 'ر', 'ن', 'گ', 'ی']\n",
            "PRED 859: parviz baa akhmi baashe be labkhand goft kodum penhaan\n",
            "PRED SCORE: -1.6157\n",
            "\n",
            "SENT 860: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'ج', 'د', 'ی', '<b>', 'ج', 'د', 'ی', '<b>', 'ش', 'ا', 'ع', 'ر', '<b>', 'ش', 'د', 'ی']\n",
            "PRED 860: engaar jeddi jeddi shaaer shodi\n",
            "PRED SCORE: -0.1063\n",
            "\n",
            "SENT 861: ['ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'خ', 'ن', 'د', 'ی', 'د']\n",
            "PRED 861: foruq ham khandid\n",
            "PRED SCORE: 0.0000\n",
            "\n",
            "SENT 862: ['ر', 'ن', 'گ', '<b>', 'ا', 'س', 'م', 'و', 'ن', 'ی']\n",
            "PRED 862: bekhosus aakhari\n",
            "PRED SCORE: -0.6919\n",
            "\n",
            "SENT 863: ['ه', 'م', 'ی', 'ن', '<b>', 'ق', 'د', 'ر', '<b>', 'م', 'ه', 'ر', 'ب', 'و', 'ن']\n",
            "PRED 863: haminjaa bemun\n",
            "PRED SCORE: -1.4701\n",
            "\n",
            "SENT 864: ['ه', 'م', 'ی', 'ن', '<b>', 'ق', 'د', 'ر', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', 'ن', 'ی']\n",
            "PRED 864: haminjaa dust daarand\n",
            "PRED SCORE: -1.3365\n",
            "\n",
            "SENT 865: ['ق', 'و', 'ل', '<b>', 'م', 'ی', 'د', 'ی']\n",
            "PRED 865: qowl midi\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 866: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'گ', 'ه', '<b>', 'ق', 'ر', 'ا', 'ر', 'ه', '<b>', 'ا', 'و', 'ض', 'ا', 'ع', '<b>', 'ف', 'ر', 'ق', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 866: parviz moteajjeb goft mage qaraare pishesh farqi kone\n",
            "PRED SCORE: -1.0207\n",
            "\n",
            "SENT 867: ['ف', 'ر', 'و', 'غ', '<b>', 'س', 'ا', 'ک', 'ت', '<b>', 'م', 'ا', 'ن', 'د']\n",
            "PRED 867: foruq saaket maand\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 868: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'چ', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ا', '<b>', 'د', 'س', 'ت', '<b>', 'ب', 'ا', 'ل', 'ا', '<b>', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'ا', 'د', 'ا', 'م', 'ه', '<b>', 'د', 'ا', 'د', '<b>', '<b>', 'ش', 'ا', 'ی', 'د', '<b>', 'ا', 'ش', 'ک', 'ا', 'ل', '<b>', 'ا', 'ز', '<b>', 'م', 'ن', 'ه', '<b>', 'ک', 'ه', '<b>', 'ن', 'ت', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'ب', 'ه', 'ت', '<b>', 'ث', 'ا', 'ب', 'ت', '<b>', 'ک', 'ن', 'م', '<b>', 'چ', 'ق', 'د', 'ر', '<b>', 'د', 'و', 'س', 'ت', '<b>', 'د', 'ا', 'ر', 'م']\n",
            "PRED 868: parviz shaaneash raa baa dast baalaa gereft va shaqiqeash behet daaram ke nemitunam\n",
            "PRED SCORE: -3.2129\n",
            "\n",
            "SENT 869: ['ا', 'ن', '\\u200c', 'ق', 'د', 'ر', '<b>', 'ک', 'ه', '<b>', 'م', 'ن', 'و', '<b>', 'ب', 'ه', '<b>', 'ز', 'ا', 'ن', 'و', '<b>', 'د', 'ر', 'ا', 'و', 'ر', 'د', 'ی', '<b>', 'ک', 'ا', 'ف', 'ی', '<b>', 'ن', 'ی', 'س', 'ت', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'ی', '<b>', 'م', 'ط', 'ل', 'ق', 'ش', '<b>', 'ک', 'ن', 'ی']\n",
            "PRED 869: enqadr ke mano be khaater e busidanash nist nist sowhaan koni\n",
            "PRED SCORE: -2.1736\n",
            "\n",
            "SENT 870: ['ت', 'و', '<b>', 'ه', 'م', 'ه', '<b>', 'ه', 'د', 'ف', '\\u200c', 'ه', 'ا', '<b>', 'و', '<b>', 'ا', 'ر', 'ز', 'و', 'ه', 'ا', '<b>', 'و', '<b>', 'ر', 'و', 'ی', 'ا', 'ه', 'ا', 'ی', '<b>', 'م', 'ن', 'ی', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 870: to hamechi o baraadarim o faqr ye man foruq\n",
            "PRED SCORE: -2.3350\n",
            "\n",
            "SENT 871: ['ا', 'خ', 'ر', '<b>', 'ه', 'م', 'ش', 'و', 'ن']\n",
            "PRED 871: aakh arusie\n",
            "PRED SCORE: -0.6093\n",
            "\n",
            "SENT 872: ['ا', 'ش', 'ک', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ج', 'م', 'ع', '<b>', 'ش', 'د']\n",
            "PRED 872: ashk dar cheshmaan e foruq jam shod\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 873: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'س', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'ا', 'غ', 'و', 'ش', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ت', 'ر', 'س', '<b>', 'ع', 'ز', 'ی', 'ز', '<b>', 'م', 'ن', '<b>', 'ت', 'ا', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ه', 'س', 'ت', '<b>', 'ن', 'ت', 'ر', 'س']\n",
            "PRED 873: parviz sarash raa dar aaqush keshid va baa mohabbat goft natarsidi e man taa vaqti azizam\n",
            "PRED SCORE: -1.0631\n",
            "\n",
            "SENT 874: ['ه', 'ر', 'ک', 'ا', 'ر', 'ی', '<b>', 'خ', 'و', 'ش', 'ح', 'ا', 'ل', 'ت', '<b>', 'م', 'ی', 'ک', 'ن', 'ه', '<b>', 'ا', 'ن', 'ج', 'ا', 'م', '<b>', 'ب', 'د', 'ه', '<b>', 'ف', 'ق', 'ط', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ن', 'ک', 'ن']\n",
            "PRED 874: har khoshhaal talaafish engaar bede faqat gerye nakon\n",
            "PRED SCORE: -2.6662\n",
            "\n",
            "SENT 875: ['ت', 'و', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'م', 'ن', '<b>', 'ق', 'و', 'ل', '<b>', 'م', 'ی', 'د', 'ی']\n",
            "PRED 875: to ham be man begu mishin\n",
            "PRED SCORE: -1.1839\n",
            "\n",
            "SENT 876: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'ت', 'ا', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ق', 'ط', 'ر', 'ا', 'ت', '<b>', 'ل', 'غ', 'ز', 'ا', 'ن', '<b>', 'ا', 'ش', 'ک', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'پ', 'ا', 'ک', '<b>', 'ک', 'ن', 'د', '<b>', 'و', '<b>', 'ا', 'ن', 'گ', 'ا', 'ه', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'س', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'د', 'ر', '<b>', 'س', 'ی', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'پ', 'ن', 'ه', 'ا', 'ن', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 876: foruq motealleq taa parviz haalati lebaas e ashk az cheshmaanash mochaale konad va zabaanash paak konad\n",
            "PRED SCORE: -3.4351\n",
            "\n",
            "SENT 877: ['ا', 'و', 'ا', 'خ', 'ر', '<b>', 'ش', 'ه', 'ر', 'ی', 'و', 'ر', 'م', 'ا', 'ه', '<b>', '1', '3', '2', '8', '<b>', 'ر', 'و', 'ز', '<b>', 'خ', 'د', 'ا', 'ح', 'ا', 'ف', 'ظ', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '<b>', 'و', '<b>', 'ش', 'ه', 'ر', 'ش', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'و', '<b>', 'ه', 'و', 'ا', 'ی', '<b>', 'غ', 'ر', 'ی', 'ب', 'ی', '<b>', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 877: agar cheshmhaayash eshq e pazirande eshaaratist az a maaq e khaane daasht va hamaanjaa yakh daasht\n",
            "PRED SCORE: -4.4852\n",
            "\n",
            "SENT 878: ['ش', 'ب', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'ب', 'س', 'ت', 'گ', 'ا', 'ن', '<b>', 'ن', 'ز', 'د', 'ی', 'ک', '<b>', 'د', 'ر', '<b>', 'م', 'ن', 'ز', 'ل', '<b>', 'پ', 'د', 'ر', '<b>', 'ع', 'ر', 'و', 'س', '<b>', 'گ', 'ر', 'د', '<b>', 'ه', 'م', '<b>', 'ا', 'م', 'د', 'ه', '<b>', 'و', '<b>', 'ع', 'ر', 'و', 'س', '<b>', 'و', '<b>', 'د', 'ا', 'م', 'ا', 'د', '<b>', 'ر', 'ا', '<b>', 'ر', 'د', '<b>', 'ش', 'ر', 'ا', 'ی', 'ط', 'ی', '<b>', 'ب', 'س', 'ی', 'ا', 'ر', '<b>', 'س', 'ا', 'د', 'ه', '<b>', 'و', '<b>', 'د', 'و', 'ر', '<b>', 'ا', 'ز', '<b>', 'ت', 'ش', 'ر', 'ی', 'ف', 'ا', 'ت', '<b>', 'د', 'س', 'ت', '<b>', 'ب', 'ه', '<b>', 'د', 'س', 'ت', '<b>', 'ه', 'م', '<b>', 'ک', 'ر', 'د', 'ن', 'د']\n",
            "PRED 878: shab gozashte paamo nadaarin dar e qabl sorkh shavad o dur raa kardand\n",
            "PRED SCORE: -2.8863\n",
            "\n",
            "SENT 879: ['ا', 'ن', '<b>', 'ر', 'و', 'ز', 'ه', 'ا', '<b>', 'ی', 'ک', '<b>', 'چ', 'ش', 'م', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ا', 'ش', 'ک', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'خ', 'و', 'ن']\n",
            "PRED 879: aangaah e yek ruzhaa turaan turaan e turaan bud va digari khune\n",
            "PRED SCORE: -2.5777\n",
            "\n",
            "SENT 880: ['ه', 'ر', '<b>', 'و', 'ق', 'ت', '<b>', 'ه', 'ر', 'ج', 'ا', '<b>', 'ا', 'س', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ش', 'ن', 'ی', 'د', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 880: har vaqt har vaqt foruq raa mifahmid baa sedaa ye boland gerye mikard\n",
            "PRED SCORE: -2.3388\n",
            "\n",
            "SENT 881: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ه', 'م', '<b>', 'ح', 'ا', 'ل', 'ی', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ا', 'و', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 881: puraan ham haali behtar az u nadaasht\n",
            "PRED SCORE: -0.9425\n",
            "\n",
            "SENT 882: ['خ', 'ا', 'ن', 'و', 'ا', 'د', 'ه', '<b>', 'م', 'ث', 'ل', '<b>', 'ی', 'ک', '<b>', 'پ', 'ا', 'ز', 'ل', '<b>', 'ا', 'ز', '<b>', 'ه', 'م', '<b>', 'پ', 'ا', 'ش', 'ی', 'د', 'ه', '<b>', 'ه', 'ر', '<b>', 'ی', 'ک', '<b>', 'ب', 'ه', '<b>', 'س', 'م', 'ت', 'ی', '<b>', 'ب', 'ه', '<b>', 'ر', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ه', 'ر', '<b>', 'ز', 'م', 'ا', 'ن', '<b>', 'د', 'ی', 'گ', 'ر', 'ی', '<b>', 'ا', 'ح', 'س', 'ا', 'س', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', 'ی', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 882: aanvaqt mesl e yek saal az ham oftaade va turaan movaajeh mikard\n",
            "PRED SCORE: -2.8574\n",
            "\n",
            "SENT 883: ['ح', 'ا', 'ل', 'ا', '<b>', 'ا', 'ز', '<b>', 'ا', 'ن', '<b>', 'خ', 'ا', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ش', 'ل', 'و', 'غ', '<b>', 'و', '<b>', 'پ', 'ر', 'ه', 'ی', 'ا', 'ه', 'و', '<b>', 'د', 'و', '<b>', 'س', 'ه', '<b>', 'ب', 'چ', 'ه', '<b>', 'ق', 'د', '<b>', 'و', '<b>', 'ن', 'ی', 'م', '<b>', 'ق', 'د', '<b>', 'م', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'و', '<b>', 'ی', 'ک', '<b>', 'ز', 'ن', '<b>', 'پ', 'ا', 'ک', '<b>', 'ب', 'ا', 'خ', 'ت', 'ه']\n",
            "PRED 883: haalaa az aan saanie she r o paaktare do maah bude yaa sinamaa\n",
            "PRED SCORE: -2.3760\n",
            "\n",
            "SENT 884: ['ش', 'م', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ج', 'د', 'ا', 'ی', 'ی', '<b>', 'ف', 'ر', 'ز', 'ن', 'د', '<b>', 'م', 'ح', 'ب', 'و', 'ب', 'ش', '<b>', 'ح', 'ا', 'ل', 'ی', '<b>', 'ب', 'ه', 'ت', 'ر', '<b>', 'ا', 'ز', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'و', 'ش', 'ی', 'د', '<b>', 'ا', 'ر', 'ا', 'م', 'ش', '<b>', 'ک', 'ن', 'د']\n",
            "PRED 884: shamsi ke khodesh ham be khaater e sedaai e jaalebetun az turaan saaket maand\n",
            "PRED SCORE: -1.7146\n",
            "\n",
            "SENT 885: ['ب', 'س', 'ه', '<b>', 'ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ج', 'و', 'ن']\n",
            "PRED 885: base turaan jun\n",
            "PRED SCORE: -0.7300\n",
            "\n",
            "SENT 886: ['پ', 'ش', 'ت', '<b>', 'س', 'ر', '<b>', 'م', 'س', 'ا', 'ف', 'ر', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ش', 'گ', 'و', 'ن', '<b>', 'ن', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 886: posht e sar e mizaaramesh gerye ye kabude nadaare\n",
            "PRED SCORE: -1.6266\n",
            "\n",
            "SENT 887: ['م', 'ی', 'ا', 'ن', '<b>', 'ب', 'ه', 'م', 'و', 'ن', '<b>', 'س', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ز', 'ن', 'ن', 'د', '<b>', 'ب', 'س', '<b>', 'ک', 'ن', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'خ', 'د', 'ا']\n",
            "PRED 887: miaan e bekhosus sar mikonand bas kon khodaa ro khodaa\n",
            "PRED SCORE: -1.0164\n",
            "\n",
            "SENT 888: ['د', 'خ', 'ت', 'ر', 'ه', '<b>', 'ر', 'ن', 'گ', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', '<b>', 'ن', 'د', 'ا', 'ر', 'ه']\n",
            "PRED 888: dokhtare rang be ru nadaare\n",
            "PRED SCORE: -0.2105\n",
            "\n",
            "SENT 889: ['ف', 'ر', 'و', 'غ', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'م', 'ا', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', 'ی', '<b>', 'ب', 'غ', 'ض', '<b>', 'ا', 'ل', 'و', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ا', 'م', 'ا', 'ن', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'خ', 'د', 'ا', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ن', 'ک', 'ن']\n",
            "PRED 889: foruq surat e maadarash raa busid va baa sedaa ye khoshk goft maamaan gerye nakon\n",
            "PRED SCORE: -1.2553\n",
            "\n",
            "SENT 890: ['ا', 'م', 'ا', '<b>', 'ا', 'ش', 'ک', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ه', 'م', '<b>', 'س', 'ر', 'ا', 'ز', 'ی', 'ر', '<b>', 'ش', 'د']\n",
            "PRED 890: ammaa ashk e khodash ham saraazir shod\n",
            "PRED SCORE: -0.0164\n",
            "\n",
            "SENT 891: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ز', 'ی', 'ر', '<b>', 'ل', 'ب', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ر', 'ا', 'ن', 'د', 'ا', 'ز', 'ش', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ل', 'م', '<b>', 'د', 'ا', 'ر', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'ک', 'ه', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 891: turaan zir e lab qorrid baraa ke barandaazash daare maadar jun\n",
            "PRED SCORE: -2.0984\n",
            "\n",
            "SENT 892: ['خ', 'ی', 'ل', 'ی', '<b>', 'و', 'ا', 'س', 'ت', '<b>', 'ز', 'و', 'د', '<b>', 'ب', 'و', 'د']\n",
            "PRED 892: kheyli vaqte zud bud\n",
            "PRED SCORE: -1.0003\n",
            "\n",
            "SENT 893: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ب', 'ا', 'ل', 'ا', 'خ', 'ر', 'ه', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'ب', 'ر', 'ه', '<b>', 'خ', 'و', 'ن', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'خ', 'ت', '<b>', 'ع', 'و', 'ض', '<b>', 'ا', 'ی', 'ن', 'ک', 'ا', 'ر', 'ه', 'ا', '<b>', 'و', 'ا', 'س', 'ش', 'و', 'ن', '<b>', 'د', 'ع', 'ا', '<b>', 'ک', 'ن']\n",
            "PRED 893: shamsi baa mohabbat goft ey baabaa baahaat dokhtar e khune ye khaabaavare\n",
            "PRED SCORE: -3.0220\n",
            "\n",
            "SENT 894: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ا', 'ط', 'م', 'ی', 'ن', 'ا', 'ن', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'ک', 'ه', '<b>', 'ش', 'د', 'ه', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ن', 'ک', 'ن', 'ی', 'د']\n",
            "PRED 894: parviz baa akhmi yekbari goft be khaater e foruq ham ke shode nemikard\n",
            "PRED SCORE: -0.8032\n",
            "\n",
            "SENT 895: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'م', 'ل', 'ت', 'م', 'س', 'ا', 'ن', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'و', 'ا', 'ظ', 'ب', 'ش', '<b>', 'ب', 'ا', 'ش', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ا', 'ن']\n",
            "PRED 895: turaan moltamesaane goft movaazeb baash parviz jaan\n",
            "PRED SCORE: -1.3409\n",
            "\n",
            "SENT 896: ['ا', 'و', 'ن', '<b>', 'ه', 'ن', 'و', 'ز', '<b>', 'ب', 'چ', 'ه', '<b>', 'س', 'ت']\n",
            "PRED 896: un hanuz bachchast\n",
            "PRED SCORE: -0.0385\n",
            "\n",
            "SENT 897: ['خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ه', 'ی', 'چ', 'ی', '<b>', 'ر', 'و', '<b>', 'ج', 'د', 'ی', '<b>', 'ن', 'گ', 'ر', 'ف', 'ت', 'ه']\n",
            "PRED 897: khiaal mikonam hichchi ro jeddi mushmushak\n",
            "PRED SCORE: -1.1039\n",
            "\n",
            "SENT 898: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ی', '<b>', 'ص', 'م', 'ی', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ا', 'ط', 'ر', 'ت', 'و', 'ن', '<b>', 'ا', 'س', 'و', 'د', 'ه', '<b>', 'ب', 'ا', 'ش', 'ه']\n",
            "PRED 898: parviz baa labkhandi samimi goft maadar aqlab baashe\n",
            "PRED SCORE: -0.9809\n",
            "\n",
            "SENT 899: ['ا', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ش', 'م', 'ا', '<b>', 'چ', 'ر', 'ا', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', 'د', '<b>', 'م', 'ا', 'د', 'ر']\n",
            "PRED 899: ey baabaa shomaa cheraa gerye mikonid maadar\n",
            "PRED SCORE: -0.1389\n",
            "\n",
            "SENT 900: ['ش', 'م', 'س', 'ی', '<b>', 'ب', 'ه', '\\u200c', 'س', 'ر', 'ع', 'ت', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'پ', 'ا', 'ک', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ن', 'م', 'و', 'ن', 'ی', 'د', '<b>', 'ه', 'ر', '<b>', 'و', 'ق', 'ت', '<b>', 'ت', 'و', 'ن', 'س', 'ت', 'ی', 'د', '<b>', 'ب', 'ی', 'ا', 'ی', 'ن', '<b>', 'ت', 'ه', 'ر', 'ا', 'ن']\n",
            "PRED 900: shamsi be surat e cheshmaanash raa paak kard va goft tanhaa ye amale bitaabi e mane\n",
            "PRED SCORE: -2.7660\n",
            "\n",
            "SENT 901: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ش', 'م', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'ه', 'م', 'و', 'ن', '<b>', 'س', 'ر', '<b>', 'ب', 'ز', 'ن', 'ی', 'د']\n",
            "PRED 901: parviz goft shomaa ham behetun sar bezanid\n",
            "PRED SCORE: -0.7300\n",
            "\n",
            "SENT 902: ['ب', 'ع', 'د', '<b>', 'د', 'س', 'ت', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ب', 'ر', 'ی', 'م']\n",
            "PRED 902: ba d dast e foruq raa feshord va porsid bar aks\n",
            "PRED SCORE: -0.1075\n",
            "\n",
            "SENT 903: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 903: foruq be pedarash negaah kard\n",
            "PRED SCORE: -0.0004\n",
            "\n",
            "SENT 904: ['ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ب', 'ه', '<b>', 'ج', 'د', 'ی', 'ت', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 904: suratash be sheddat e golestaan bud\n",
            "PRED SCORE: -0.8376\n",
            "\n",
            "SENT 905: ['ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ب', 'خ', 'ش', 'ی', 'د', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'س', 'ر', 'گ', 'ر', 'د', '<b>', 'ب', 'س', 'ر', 'د', 'ی', '<b>', 'ه', 'م', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'چ', 'ش', 'م', '<b>', 'ب', 'ه', '<b>', 'ز', 'م', 'ی', 'ن', '<b>', 'د', 'و', 'خ', 'ت', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 905: aaraam goft bebakhshid baabaa baabaa sarzaneshash ke cheshm be zamin nagoftand\n",
            "PRED SCORE: -1.3103\n",
            "\n",
            "SENT 906: ['د', 'ر', '<b>', 'پ', 'ن', 'ا', 'ه', '<b>', 'خ', 'د', 'ا']\n",
            "PRED 906: dar panaah e khodaa\n",
            "PRED SCORE: -0.0004\n",
            "\n",
            "SENT 907: ['س', 'ع', 'ی', '<b>', 'ک', 'ن', '<b>', 'م', 'ح', 'ک', 'م', '<b>', 'و', '<b>', 'س', 'ر', '<b>', 'ب', 'ه', '<b>', 'ر', 'ا', 'ه', '<b>', 'ب', 'ا', 'ش', 'ی']\n",
            "PRED 907: sa y kon mohkam o sar be raah baashi\n",
            "PRED SCORE: -0.1110\n",
            "\n",
            "SENT 908: ['ب', 'ع', 'د', '<b>', 'پ', 'ی', 'ش', 'ا', 'ن', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'د', 'س', 'ت', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د']\n",
            "PRED 908: ba d vaqthaa foruq raa busid va dast e parviz raa feshord\n",
            "PRED SCORE: -1.0690\n",
            "\n",
            "SENT 909: ['ح', 'ا', 'ل', 'ا', '<b>', 'ن', 'و', 'ب', 'ت', '<b>', 'ش', 'ا', 'پ', 'و', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 909: haalaa nowbat e shaapur bud\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 910: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'م', 'ح', 'ک', 'م', '<b>', 'ب', 'ه', '<b>', 'ا', 'غ', 'و', 'ش', '<b>', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 910: parviz raa mohkam be aaqush keshid\n",
            "PRED SCORE: -0.0008\n",
            "\n",
            "SENT 911: ['ب', 'ر', 'ا', 'د', 'ر', 'ش', '<b>', 'ه', 'م', 'ا', 'ی', 'و', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'د', 'ی', 'ر', 'ت', 'و', 'ن', '<b>', 'ن', 'ش', 'ه']\n",
            "PRED 911: baraadarash homaayun goft didamesh\n",
            "PRED SCORE: -0.3469\n",
            "\n",
            "SENT 912: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'غ', 'ل', '<b>', 'ک', 'ر', 'د']\n",
            "PRED 912: parviz u raa ham behtar kard\n",
            "PRED SCORE: -0.5680\n",
            "\n",
            "SENT 913: ['ه', 'م', 'ا', 'ی', 'و', 'ن', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'ط', 'م', 'ی', 'ن', 'ی', '<b>', 'ک', 'ه', '<b>', 'ن', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'ی', '<b>', 'ک', 'س', 'ی', '<b>', 'ب', 'ی', 'ا', 'د', '<b>', 'ت', 'ا', '<b>', 'ا', 'ی', 'س', 'ت', 'گ', 'ا', 'ه', '<b>', 'ق', 'ط', 'ا', 'ر', '<b>', 'ب', 'د', 'ر', 'ق', 'ه', '<b>', 'ت', 'و', 'ن']\n",
            "PRED 913: homaayun porsid mibini ke nemikhaay kolli biaad taa injaast qaraar bede\n",
            "PRED SCORE: -2.1809\n",
            "\n",
            "SENT 914: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'م', 'ی', 'خ', 'و', 'ا', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ا', '<b>', 'ا', 'ه', 'و', 'ا', 'ز', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ک', 'ن', 'ه']\n",
            "PRED 914: parviz aaraam goft nemikhaam foruq taa esm e gerye kone\n",
            "PRED SCORE: -2.0529\n",
            "\n",
            "SENT 915: ['ب', 'ه', 'ر', 'ح', 'ا', 'ل', '<b>', 'ب', 'ا', 'ی', 'د', '<b>', 'د', 'ل', '<b>', 'ب', 'ک', 'ن', 'ه', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ت', 'و', 'ج', 'ه', 'ی', '<b>', 'ب', 'چ', 'ه', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ک', 'و', 'چ', 'ک', '\\u200c', 'ت', 'ر', '<b>', 'ش', 'د']\n",
            "PRED 915: be yaad baayad del e cheshm foruq bachche ye mohemmie sheddat shod\n",
            "PRED SCORE: -3.1805\n",
            "\n",
            "SENT 916: ['ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ه', 'م', '<b>', 'م', 'ت', 'ا', 'ث', 'ر', '<b>', 'ا', 'ز', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', 'ن', 'د']\n",
            "PRED 916: aanhaa ham maa az baqiye gerye mikard\n",
            "PRED SCORE: -0.9612\n",
            "\n",
            "SENT 917: ['گ', 'ل', 'و', 'ر', 'ی', 'ا', '<b>', 'س', 'ف', 'ت', '<b>', 'ب', 'غ', 'ل', 'ش', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', 'ش', '<b>', 'ا', 'ی', 'س', 'ت', 'ا', 'د', '<b>', 'و', '<b>', 'ه', 'م', 'ا', 'ن', '<b>', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'پ', 'ه', 'ن', 'ا', 'ی', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ا', 'ش', 'ک', '<b>', 'م', 'ی', '\\u200c', 'ر', 'ی', 'خ', 'ت', '<b>', 'م', 'ث', 'ل', '<b>', 'ک', 'س', 'ی', '<b>', 'ک', 'ه', '<b>', 'ع', 'ز', 'ی', 'ز', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'خ', 'ر', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ب', 'ی', 'ن', 'د', '<b>', 'ب', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'ز', 'ل', '<b>', 'ز', 'د']\n",
            "PRED 917: gloriaa goft behesh kard o fereydun posht e sarash ashk be pushaand\n",
            "PRED SCORE: -1.6929\n",
            "\n",
            "SENT 918: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'و', 'ا', 'ظ', 'ب', '<b>', 'م', 'ا', 'م', 'ا', 'ن', '<b>', 'ب', 'ا', 'ش', '<b>', 'ف', 'ر', 'ی']\n",
            "PRED 918: foruq goft moteajjeb maamaan baashi\n",
            "PRED SCORE: -1.4807\n",
            "\n",
            "SENT 919: ['ح', 'ا', 'ل', 'ا', '<b>', 'م', 'ر', 'د', '<b>', 'خ', 'و', 'ن', 'ه', '<b>', 'ت', 'و', 'ی', 'ی']\n",
            "PRED 919: haalaa mard e khune toi\n",
            "PRED SCORE: -0.0065\n",
            "\n",
            "SENT 920: ['ف', 'ر', 'ی', 'د', 'و', 'ن', '<b>', 'ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'و', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ق', 'د', 'م', 'ه', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'س', 'ت', 'م', '<b>', 'ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'ه', 'ت', '<b>', 'ب', 'گ', 'م', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'و', 'ب', 'ا', 'ن', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'م', 'و', 'ه', 'ا', 'ت', '<b>', 'ر', 'و', '<b>', 'م', 'ن', '<b>', 'ر', 'ی', 'ش', 'ه', '\\u200c', 'ر', 'ی', 'ش', 'ه', '<b>', '\\u200c', 'ک', 'ر', 'د', 'م']\n",
            "PRED 920: fereydun ajulaane bi honarmand miaan e gerye goft mikhaastam yek chizi behet nakardam\n",
            "PRED SCORE: -1.8831\n",
            "\n",
            "SENT 921: ['ن', 'م', 'ی', '<b>', 'د', 'و', 'ن', 'م', '<b>', 'چ', 'ر', 'ا', '<b>', 'و', 'ل', 'ی', '<b>', 'ل', 'ج', 'م', '<b>', 'د', 'ر', 'ا', 'م', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '\\u200c', 'ص', 'و', 'ر', 'ت', '<b>', 'خ', 'ی', 'س', '<b>', 'ا', 'ز', '<b>', 'ا', 'ش', 'ک', 'ش', '<b>', 'د', 'س', 'ت', '<b>', 'ن', 'و', 'ا', 'ز', 'ش', '<b>', 'ک', 'ش', 'ی', 'د']\n",
            "PRED 921: nemidunam cheraa cheraa dige chetowr hejdah bud foruq az ashk e dast gerye keshid\n",
            "PRED SCORE: -2.9616\n",
            "\n",
            "SENT 922: ['ف', 'ر', 'ی', '<b>', 'ا', 'ح', 'م', 'ق', '<b>', 'م', 'ن', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'م', '<b>', 'و', 'ل', 'ی', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'م', 'ه', 'م', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 922: feri e khaali e man midunestam vali haalaa dige nist\n",
            "PRED SCORE: -1.3802\n",
            "\n",
            "SENT 923: ['ب', 'ر', 'ا', 'م', '<b>', 'ن', 'ا', 'م', 'ه', '<b>', 'ب', 'د', 'ه']\n",
            "PRED 923: baraam negaam beshe\n",
            "PRED SCORE: -0.3026\n",
            "\n",
            "SENT 924: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ه', '<b>', 'ش', 'ن', 'و', 'ن', 'د', 'ه', '\\u200c', 'ی', '<b>', 'ح', 'ر', 'ف', '\\u200c', 'ه', 'ا', 'ی', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'و', 'د', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ل', 'ا', 'ا', 'ق', 'ل', '<b>', 'ب', 'ذ', 'ا', 'ر', '<b>', 'م', 'ن', '<b>', 'و', '<b>', 'س', 'ی', 'ر', 'و', 'س', '<b>', 'ب', 'ی', 'ا', 'ی', 'ی', 'م', '<b>', 'ت', 'ا', '<b>', 'ا', 'ی', 'س', 'ت', 'گ', 'ا', 'ه', '<b>', 'ب', 'د', 'ر', 'ق', 'ه', '<b>', 'ت', 'و', 'ن']\n",
            "PRED 924: puraan ke puzkhand harfhaa ye aanhaa bud baa sedaa ye larzaani goft laaaqal base man\n",
            "PRED SCORE: -2.4978\n",
            "\n",
            "SENT 925: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ه', '\\u200c', 'ص', 'و', 'ر', 'ت', '<b>', 'س', 'ر', 'خ', '<b>', 'ا', 'ز', '<b>', 'ا', 'ش', 'ک', 'ش', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ق', 'ی', 'ا', 'ف', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'و', '<b>', 'ب', 'ب', 'ی', 'ن']\n",
            "PRED 925: foruq be surat e sarash az ashkash khire shod va be jelow goft e ru bezani\n",
            "PRED SCORE: -1.4964\n",
            "\n",
            "SENT 926: ['خ', 'ا', 'ک', '<b>', 'ب', 'ر', '<b>', 'س', 'ر', 'ت', 'و', 'ن']\n",
            "PRED 926: khodaa bar serteq\n",
            "PRED SCORE: -0.2987\n",
            "\n",
            "SENT 927: ['ب', 'ی', 'ن', '<b>', 'ش', 'م', 'ا', '<b>', 'ف', 'ق', 'ط', '<b>', 'م', 'ن', '<b>', 'ا', 'د', 'م', 'م']\n",
            "PRED 927: bebin shomaa faqat man aadamam\n",
            "PRED SCORE: -0.7285\n",
            "\n",
            "SENT 928: ['ه', 'ر', 'س', 'ه', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'گ', 'ر', 'ی', 'ه', '<b>', 'خ', 'ن', 'د', 'ی', 'د', 'ن', 'د']\n",
            "PRED 928: hargez miaan e gerye khandid\n",
            "PRED SCORE: -0.0150\n",
            "\n",
            "SENT 929: ['پ', 'و', 'ر', 'ا', 'ن', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ا', 'د', 'م', '<b>', 'ب', 'ش', 'و', '<b>', 'ن', 'ی', 'س', 'ت', 'ی']\n",
            "PRED 929: puraan goft to aadam e badi nisti\n",
            "PRED SCORE: -1.3701\n",
            "\n",
            "SENT 930: ['ا', 'خ', 'ر', 'ش', '<b>', 'ه', 'م', '<b>', 'ک', 'ا', 'ر', 'ی', '<b>', 'ر', 'و', '<b>', 'ک', 'ر', 'د', 'ی', '<b>', 'ک', 'ه', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', 'ی']\n",
            "PRED 930: aakharesh ham kaari ro kardi ke khodet misaaze\n",
            "PRED SCORE: -1.9002\n",
            "\n",
            "SENT 931: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ج', 'ل', 'و', '<b>', 'ا', 'م', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ر', 'ی', 'م', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 931: parviz jelo aamad va goft berim foruq\n",
            "PRED SCORE: -0.0965\n",
            "\n",
            "SENT 932: ['ف', 'ر', 'و', 'غ', '<b>', 'ع', 'ج', 'و', 'ل', 'ا', 'ن', 'ه', '<b>', 'ب', 'ا', '<b>', 'م', 'ه', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'م', 'ه', 'ر', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'د', 'خ', 'ی', '<b>', 'خ', 'و', 'ا', 'ه', 'ر', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'و', 'ب', 'و', 'س', 'ی', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ا', 'خ', 'ر', 'ی', 'ن', '<b>', 'ب', 'ا', 'ر', '<b>', 'د', 'ر', '<b>', 'ن', 'گ', 'ا', 'ه', 'ی', '<b>', 'ک', 'ل', 'ی', '<b>', 'ه', 'م', 'ه', '<b>', 'ر', 'ا', '<b>', 'ک', 'ن', 'ا', 'ر', '<b>', 'ه', 'م', '<b>', 'د', 'ر', '<b>', 'ق', 'ا', 'ب', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ج', 'ا', '<b>', 'د', 'ا', 'د']\n",
            "PRED 932: foruq ajulaane baa mehri o mostaqim va mostaqim khaahar kard va baraaye aasemaan e boqz raa daad\n",
            "PRED SCORE: -2.5743\n",
            "\n",
            "SENT 933: ['ج', 'ا', 'ی', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'خ', 'ا', 'ل', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ب', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه']\n",
            "PRED 933: jaa ye amir hamishe gelaaye bud va haalaa bish az gozashte\n",
            "PRED SCORE: -2.1855\n",
            "\n",
            "SENT 934: ['ی', 'ک', '\\u200c', 'ب', 'ا', 'ر', '<b>', 'د', 'ی', 'گ', 'ر', '<b>', 'س', 'ر', 'ک', 'و', 'چ', 'ه', '<b>', 'ا', 'ز', '<b>', 'د', 'و', 'ر', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ن', 'ظ', 'ر', '<b>', 'گ', 'ذ', 'ر', 'ا', 'ن', 'د', '<b>', 'ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'خ', 'ا', 'ط', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ن', '<b>', 'ا', 'ش', 'ک', '\\u200c', 'ه', 'ا', '<b>', 'و', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', 'ه', 'ا', '<b>', 'ت', 'ا', '<b>', 'ا', 'ب', 'د', '<b>', 'ج', 'ا', 'ی', 'ی', '<b>', 'د', 'ر', '<b>', 'ا', 'ع', 'م', 'ا', 'ق', '<b>', 'و', 'ج', 'و', 'د', 'ش', '<b>', 'ح', 'ک', '<b>', 'ش', 'د']\n",
            "PRED 934: yek baar e digar kalamaat az dur baqiye raa az chubrakhti sangin shod\n",
            "PRED SCORE: -1.1642\n",
            "\n",
            "SENT 935: ['ت', 'و', 'ر', 'ا', 'ن', '<b>', 'ک', 'ا', 'س', 'ه', '\\u200c', 'ی', '<b>', 'ا', 'ب', 'ی', '<b>', 'ر', 'ا', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', '<b>', 'د', 'س', 'ت', '<b>', 'د', 'ا', 'ش', 'ت', '<b>', 'پ', 'ش', 'ت', '<b>', 'س', 'ر', 'ش', 'ا', 'ن', '<b>', 'پ', 'ا', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'ح', 'س', 'ی', '<b>', 'ب', 'ن', 'ی', 'ا', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'د', '<b>', 'گ', 'و', 'ی', 'ی', '<b>', 'ا', 'ی', 'ن', '<b>', 'خ', 'ا', 'ط', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'ب', 'ی', '<b>', 'ت', 'ک', 'ر', 'ا', 'ر', '<b>', 'ر', 'ا', '<b>', 'ق', 'ب', 'ل', 'ا', '<b>', 'ج', 'ا', 'ی', 'ی', '<b>', 'د', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 935: turaan naagahaan baaz raa ke dar dast daasht va hesaabi bi baar gereftand\n",
            "PRED SCORE: -1.7469\n",
            "\n",
            "SENT 936: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ف', 'ش', 'ر', 'د']\n",
            "PRED 936: parviz baa mohabbat dastash raa feshord\n",
            "PRED SCORE: -0.0002\n",
            "\n",
            "SENT 937: ['ب', 'ر', 'ی', 'م', '<b>', 'ع', 'ز', 'ی', 'ز', 'م']\n",
            "PRED 937: berim azizam\n",
            "PRED SCORE: -0.0968\n",
            "\n",
            "SENT 938: ['ا', 'ز', '<b>', 'ق', 'ط', 'ا', 'ر', '<b>', 'ج', 'ا', '<b>', 'م', 'ی', '\\u200c', 'م', 'و', 'ن', 'ی', 'م', '<b>', '.', '<b>', 'ا', 'ز', '<b>', 'و', 'ق', 'ت', 'ی', '<b>', 'س', 'و', 'ا', 'ر', '<b>', 'ق', 'ط', 'ا', 'ر', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د', 'ن', 'د', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ح', 'ت', 'ی', '<b>', 'ی', 'ک', '<b>', 'ک', 'ل', 'ا', 'م', '<b>', 'ب', 'ه', '<b>', 'ز', 'ب', 'ا', 'ن', '<b>', 'ن', 'ی', 'ا', 'و', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 938: az qaraar jaa ye goftogu kubid\n",
            "PRED SCORE: -2.6241\n",
            "\n",
            "SENT 939: ['ح', 'ا', 'ل', 'ت', 'ش', '<b>', 'م', 'ث', 'ل', '<b>', 'ا', 'د', 'م', 'ی', '<b>', 'ک', 'ل', 'ا', 'ف', 'ه', '<b>', 'و', '<b>', 'گ', 'ی', 'ج', '<b>', 'و', '<b>', 'م', 'ض', 'ط', 'ر', 'ب', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'د', 'ل', 'ی', 'ل', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'ا', 'ن', 'س', 'ت']\n",
            "PRED 939: haalish mesl e raadio zibaai o chiz o maqz bud ke dahaanash raa misuzaand\n",
            "PRED SCORE: -3.3476\n",
            "\n",
            "SENT 940: ['خ', 'ن', 'د', 'ه', '<b>', 'د', 'ا', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 940: zehnash deqqat bud\n",
            "PRED SCORE: -0.8253\n",
            "\n",
            "SENT 941: ['ر', 'و', 'ز', 'ه', 'ا', '<b>', 'و', '<b>', 'ه', 'ف', 'ت', 'ه', '\\u200c', 'ه', 'ا', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت', '<b>', 'ج', 'ن', 'گ', 'ی', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'و', '<b>', 'ح', 'ا', 'ل', 'ا', '<b>', 'ک', 'ه', '<b>', 'ب', 'د', 'س', 'ت', 'ش', '<b>', 'ا', 'و', 'ر', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'م', 'ر', 'د', 'د', '<b>', 'و', '<b>', 'ا', 'ش', 'ف', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 941: ruz o notfe be khaater e chizi ke mikhaast tang o eqtedaar bud\n",
            "PRED SCORE: -2.1915\n",
            "\n",
            "SENT 942: ['ا', 'ن', 'گ', 'ا', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ت', 'ر', 'س', 'ی', 'د', '<b>', 'ا', 'ش', 'ت', 'ب', 'ا', 'ه', '<b>', 'ک', 'ر', 'د', 'ه', '<b>', 'ب', 'ا', 'ش', 'د']\n",
            "PRED 942: engaar mitarsid taavaan karde baashad\n",
            "PRED SCORE: -1.1846\n",
            "\n",
            "SENT 943: ['ا', 'ی', 'ا', '<b>', 'ا', 'ی', 'ن', '<b>', 'ب', 'ه', '<b>', 'س', 'ب', 'ب', '<b>', 'س', 'ر', 'د', 'ی', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ن', 'ب', 'و', 'د']\n",
            "PRED 943: aayaa in be vos sardi e pedarash nabud\n",
            "PRED SCORE: -0.1836\n",
            "\n",
            "SENT 944: ['ی', 'ا', 'د', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'ر', 'ا', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'د']\n",
            "PRED 944: yaad e pedarash qalbash raa larzaand\n",
            "PRED SCORE: -0.8709\n",
            "\n",
            "SENT 945: ['چ', 'ط', 'و', 'ر', '<b>', 'ت', 'ا', '<b>', 'پ', 'ی', 'ش', '<b>', 'ا', 'ز', '<b>', 'ا', 'ی', 'ن', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ر', 'ا', '<b>', 'م', 'ث', 'ل', '<b>', 'ز', 'ن', 'د', 'ا', 'ن', 'ی', '<b>', 'ت', 'ی', 'ر', 'ه', '<b>', 'و', '<b>', 'ت', 'ن', 'گ', '<b>', 'م', 'ی', '\\u200c', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'پ', 'د', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ز', 'ن', 'د', 'ا', 'ن', 'ب', 'ا', 'ن', '<b>', 'ا', 'ن']\n",
            "PRED 945: chetowr taa pish az in shaakhe raa mesl e sangin mide o pedaresh miofte\n",
            "PRED SCORE: -2.6760\n",
            "\n",
            "SENT 946: ['چ', 'گ', 'و', 'ن', 'ه', '<b>', 'ر', 'و', 'ز', 'گ', 'ا', 'ر', 'ی', '<b>', 'ب', 'ا', '<b>', 'ح', 'س', 'ر', 'ت', '<b>', 'ا', 'ر', 'ز', 'و', 'ی', '<b>', 'ر', 'ه', 'ا', 'ی', 'ی', '<b>', 'ا', 'ز', '<b>', 'ب', 'ن', 'د', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ه', '<b>', 'ح', 'ا', 'ل', '<b>', 'ا', 'م', 'ی', 'ر', '<b>', 'غ', 'ب', 'ط', 'ه', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ر', 'د']\n",
            "PRED 946: chon ruzi baa taajjob e chonin tasavvoraati az band aamad va be haal e amir boland mikard\n",
            "PRED SCORE: -3.2751\n",
            "\n",
            "SENT 947: ['ا', 'ی', 'ا', '<b>', 'ب', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ز', 'و', 'د', 'ی', '<b>', 'د', 'ل', 'ت', 'ن', 'گ', '<b>', 'خ', 'ا', 'ن', 'ه', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 947: aayaa be hamin zudi e unaast nabudan shode bud\n",
            "PRED SCORE: -1.5811\n",
            "\n",
            "SENT 948: ['ک', 'و', 'ش', 'ی', 'د', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'ف', 'ر', 'و', 'ر', 'ی', 'خ', 'ت', 'ن', '<b>', 'ا', 'ش', 'ک', '\\u200c', 'ه', 'ا', 'ی', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'گ', 'ی', 'ر', 'د', '<b>', 'ا', 'م', 'ا', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'د', 'ی', 'ر', '<b>', 'ش', 'د', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 948: qaddesh towri e parviz eltemaas raa begirad ammaa kheyli oq shode bud\n",
            "PRED SCORE: -3.7159\n",
            "\n",
            "SENT 949: ['ل', 'ب', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ر', '<b>', 'ه', 'م', '<b>', 'ف', 'ش', 'ر', 'د', '<b>', 'و', '<b>', 'چ', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ل', 'ر', 'ز', 'ی', 'د']\n",
            "PRED 949: dahaanash raa bar ham feshord va shaaneash larzid\n",
            "PRED SCORE: -1.1238\n",
            "\n",
            "SENT 950: ['ن', 'گ', 'ا', 'ه', 'ش', '<b>', 'ر', 'ا', '<b>', 'ر', 'و', 'ی', '<b>', 'م', 'ن', 'ا', 'ظ', 'ر', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'ش', 'ت', 'ا', 'ب', '<b>', 'ا', 'ز', '<b>', 'ب', 'ر', 'ا', 'ب', 'ر', 'ش', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ذ', 'ش', 'ت', 'ن', 'د', '<b>', 'م', 'ت', 'م', 'ر', 'ک', 'ز', '<b>', 'ک', 'ر', 'د', '<b>', 'و', '<b>', 'ا', 'ز', '<b>', 'پ', 'ش', 'ت', '<b>', 'ش', 'ی', 'ش', 'ه', '\\u200c', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', '<b>', 'ا', 'ش', 'ک', '<b>', 'ا', 'ن', '\\u200c', 'ه', 'ا', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', 'ن', 'ظ', 'ر', '<b>', 'گ', 'ذ', 'ر', 'ا', 'ن', 'د']\n",
            "PRED 950: negaahash raa ru ye maa birun ke baa sharaayet az aanhaa sarak kard\n",
            "PRED SCORE: -1.0664\n",
            "\n",
            "SENT 951: ['ا', 'ن', 'گ', 'ش', 'ت', 'ا', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'ا', 'ن', 'گ', 'ش', 'ت', 'ا', 'ن', 'ش', '<b>', 'گ', 'ر', 'ه', '<b>', 'خ', 'و', 'ر', 'د', '<b>', 'و', '<b>', 'ب', 'ع', 'د', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '\\u200c', 'ی', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', '<b>', 'و', '<b>', 'ن', 'ر', 'م', '<b>', 'ا', 'و', '<b>', 'ر', 'ا', '<b>', 'ش', 'ن', 'ی', 'د']\n",
            "PRED 951: aanvaqt parviz miaan e aanqadr gonaahash o ba d beparam va nazar u raa misuzaand\n",
            "PRED SCORE: -3.4706\n",
            "\n",
            "SENT 952: ['ف', 'ر', 'و', 'غ', '<b>', 'ت', 'ا', 'ب', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', 'ن', '<b>', 'د', 'ر', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت']\n",
            "PRED 952: foruq baaz khire shodand dar cheshmaanash raa nadaasht\n",
            "PRED SCORE: -0.5555\n",
            "\n",
            "SENT 953: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ا', 'ز', '<b>', 'ج', 'ی', 'ب', 'ش', '<b>', 'د', 'س', 'ت', 'م', 'ا', 'ل', '<b>', 'ت', 'م', 'ی', 'ز', 'ی', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'د', 'س', 'ت', 'ا', 'ن', 'ش', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت']\n",
            "PRED 953: parviz az daakhel e kotash oftaad birun dar bastarash sokut kard\n",
            "PRED SCORE: -3.8159\n",
            "\n",
            "SENT 954: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ص', 'د', 'ا', 'ی', '<b>', 'ل', 'ر', 'ز', 'ا', 'ن', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'م', 'ع', 'ذ', 'ر', 'ت', '<b>', 'م', 'ی', 'خ', 'و', 'ا', 'م', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '.', 'م', 'ن', '<b>', 'م', 'ن', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'خ', 'س', 'ت', 'ه', '\\u200c', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ']\n",
            "PRED 954: foruq baa sedaa ye larzaani goft ma zerat mikhaam parviz man mohabbat goft to khastei foruq\n",
            "PRED SCORE: -0.3299\n",
            "\n",
            "SENT 955: ['ب', 'ه', 'ت', 'ر', 'ه', '<b>', 'ی', 'ک', '\\u200c', 'ک', 'م', '<b>', 'ب', 'خ', 'و', 'ا', 'ب', 'ی']\n",
            "PRED 955: behtare yek balaai tanhaan\n",
            "PRED SCORE: -1.0877\n",
            "\n",
            "SENT 956: ['چ', 'ق', 'د', 'ر', '<b>', 'خ', 'و', 'ب', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'س', 'ی', 'ن', '<b>', 'ج', 'ی', 'م', 'ش', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د']\n",
            "PRED 956: cheqadr khub bud ke si e digari mikard\n",
            "PRED SCORE: -0.3370\n",
            "\n",
            "SENT 957: ['چ', 'ه', '<b>', 'خ', 'و', 'ب', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ح', 'ا', 'ل', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', '\\u200c', 'ف', 'ه', 'م', 'ی', 'د']\n",
            "PRED 957: che khub bud ke si raa mishenid\n",
            "PRED SCORE: -0.7505\n",
            "\n",
            "SENT 958: ['ف', 'ر', 'و', 'غ', '<b>', 'م', 'ا', 'ن', 'د', 'ه', '<b>', 'ب', 'و', 'د', '<b>', 'ا', 'گ', 'ر', '<b>', 'س', 'و', 'ا', 'ل', '<b>', 'پ', 'ی', 'چ', 'ش', '<b>', 'ک', 'ن', 'د', '<b>', 'چ', 'ه', '<b>', 'ج', 'و', 'ا', 'ب', 'ی', '<b>', 'ب', 'د', 'ه', 'د']\n",
            "PRED 958: foruq maande bud agar lebaas e maadarash che sathi bud\n",
            "PRED SCORE: -2.4959\n",
            "\n",
            "SENT 959: ['ب', 'ه', '<b>', 'ن', 'ظ', 'ر', 'ش', '<b>', 'ح', 'ا', 'ل', '<b>', 'و', '<b>', 'ح', 'و', 'ص', 'ل', 'ه', '\\u200c', 'ی', '<b>', 'ه', 'ی', 'چ', '<b>', 'چ', 'ی', 'ز', '<b>', 'و', '<b>', 'ه', 'ی', 'چ', '\\u200c', 'ک', 'س', '<b>', 'ر', 'ا', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'د', 'ر', '<b>', 'د', 'ر', 'و', 'ن', '<b>', 'ب', 'ا', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'و', '<b>', 'و', 'ج', 'د', 'ا', 'ن', 'ش', '<b>', 'د', 'ر', 'گ', 'ی', 'ر', '<b>', 'ب', 'و', 'د']\n",
            "PRED 959: be nazarash haal o howsele ye hich chiz baa khodesh labriz bud\n",
            "PRED SCORE: -2.5990\n",
            "\n",
            "SENT 960: ['ا', 'ی', 'ا', '<b>', 'ا', 'ن', '\\u200c', 'ط', 'و', 'ر', '<b>', 'ک', 'ه', '<b>', 'ب', 'ق', 'ی', 'ه', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ف', 'ت', 'ن', 'د', '<b>', 'م', 'ت', 'ا', 'ث', 'ر', '<b>', 'ا', 'ز', '<b>', 'ش', 'و', 'ر', '<b>', 'ج', 'و', 'ا', 'ن', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ر', 'ا', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'ه', '<b>', 'ب', 'و', 'د']\n",
            "PRED 960: aayaa intowr ke baayad begirimesh moqaabelash az she r e parviz raa nashenid\n",
            "PRED SCORE: -2.8503\n",
            "\n",
            "SENT 961: ['ا', 'ز', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'ن', 'ی', 'م', 'ه', '<b>', 'ب', 'ا', 'ز', '<b>', 'ب', 'ه', '<b>', 'ا', 'و', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د']\n",
            "PRED 961: az miaan e lbetun amn be u khire shod\n",
            "PRED SCORE: -1.1310\n",
            "\n",
            "SENT 962: ['ب', 'ی', '\\u200c', 'گ', 'م', 'ا', 'ن', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', 'ه', '\\u200c', 'ی', '<b>', 'و', 'ج', 'و', 'د', '<b>', 'ع', 'ا', 'ش', 'ق', 'ش', '<b>', 'ب', 'و', 'د']\n",
            "PRED 962: bi baa hame ye vojudash aasheq bud\n",
            "PRED SCORE: -2.0781\n",
            "\n",
            "SENT 963: ['چ', 'ه', 'ر', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ز', 'ی', 'ر', '<b>', 'ا', 'ن', 'و', 'ا', 'ر', '<b>', 'ن', 'ا', 'ر', 'ن', 'ج', 'ی', '<b>', 'و', '<b>', 'ط', 'ل', 'ا', 'ی', 'ی', '<b>', 'خ', 'و', 'ر', 'ش', 'ی', 'د', '<b>', 'م', 'غ', 'ر', 'ب', '<b>', 'ت', 'ص', 'و', 'ی', 'ر', 'ی', '<b>', 'ج', 'ا', 'د', 'و', 'ی', 'ی', '<b>', 'ب', 'ه', '<b>', 'خ', 'و', 'د', '<b>', 'گ', 'ر', 'ف', 'ت', 'ه', '<b>', 'و', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ا', 'ز', '<b>', 'ب', 'ر', 'ق', '<b>', 'ع', 'ش', 'ق', '<b>', 'و', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', 'ی', '<b>', 'م', 'ب', 'ه', 'م', 'ی', '<b>', 'م', 'ی', '\\u200c', 'د', 'ر', 'خ', 'ش', 'ی', 'د']\n",
            "PRED 963: golestaan zir e engaar naazok o khejaalati khord eydet be khodash gerefte\n",
            "PRED SCORE: -3.5211\n",
            "\n",
            "SENT 964: ['ا', 'ی', 'ن', '<b>', 'ت', 'م', 'ا', 'م', '<b>', 'ا', 'ن', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ب', 'و', 'د', '<b>', 'ک', 'ه', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ی', '\\u200c', 'خ', 'و', 'ا', 'س', 'ت']\n",
            "PRED 964: in tamaam e aan chizi bud ke foruq mikhaast\n",
            "PRED SCORE: -0.0001\n",
            "\n",
            "SENT 965: ['ب', 'ی', '\\u200c', 'ا', 'ع', 'ت', 'ن', 'ا', '<b>', 'ب', 'ه', '<b>', 'ط', 'پ', 'ش', '<b>', 'ق', 'ل', 'ب', 'ش', '<b>', 'د', 'ی', 'د', 'ه', '<b>', 'ب', 'ر', '<b>', 'ه', 'م', '<b>', 'گ', 'ذ', 'ا', 'ش', 'ت', '<b>', 'و', '<b>', 'ت', 'ن', '<b>', 'خ', 'س', 'ت', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ح', 'ر', 'ک', 'ت', '<b>', 'گ', 'ه', 'و', 'ا', 'ر', 'ه', '<b>', 'و', 'ا', 'ر', '<b>', 'ق', 'ط', 'ا', 'ر', '<b>', 'س', 'پ', 'ر', 'د', '<b>', 'و', 'ل', 'ی', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ز', 'و', 'د', '<b>', 'ب', 'ل', 'ن', 'د', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ص', 'ا', 'ف', '<b>', 'ن', 'ش', 'س', 'ت']\n",
            "PRED 965: banaabarin be komod e busidanash aamadanam dar ham saakhtegi o saal e aasaar sabz shod\n",
            "PRED SCORE: -4.2245\n",
            "\n",
            "SENT 966: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'و', 'ض', 'و', 'ع', '<b>', 'چ', 'ی', 'ه']\n",
            "PRED 966: parviz baa mohabbat porsid mowzu chie\n",
            "PRED SCORE: -0.1020\n",
            "\n",
            "SENT 967: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'ر', '<b>', 'س', 'ک', 'و', 'ت', '<b>', 'ب', 'ه', '<b>', 'ص', 'و', 'ر', 'ت', 'ش', '<b>', 'خ', 'ی', 'ر', 'ه', '<b>', 'ش', 'د', '<b>', 'و', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'ز', 'د']\n",
            "PRED 967: foruq dar sokut be suratash khire shod va labkhand zad\n",
            "PRED SCORE: -0.0170\n",
            "\n",
            "SENT 968: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'س', 'ت', '<b>', 'ر', 'ا', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'د', 'س', 'ت', 'ا', 'ن', '<b>', 'گ', 'ر', 'م', '<b>', 'و', '<b>', 'م', 'ر', 'د', 'ا', 'ن', 'ه', '\\u200c', 'ا', 'ش', '<b>', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', '<b>', 'م', 'ح', 'ت', 'ا', 'ط', '<b>', 'ب', 'و', 'س', 'ی', 'د', '<b>', 'و', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ا', 'ز', '<b>', 'ت', 'م', 'ا', 'س', '<b>', 'س', 'ب', 'ی', 'ل', 'ش', '<b>', 'ب', 'ا', '<b>', 'پ', 'و', 'س', 'ت', '<b>', 'ا', 'ن', 'گ', 'ش', 'ت', 'ا', 'ن', 'ش', '<b>', 'ق', 'ل', 'ق', 'ل', 'ک', 'ش', '<b>', 'ا', 'م', 'د']\n",
            "PRED 968: parviz dast e raastesh raa miaan e lab cheshm baa puzkhand gereft va saaf az chubrakhti andaakht\n",
            "PRED SCORE: -3.1377\n",
            "\n",
            "SENT 969: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ا', 'ر', 'ا', 'م', '<b>', 'د', 'ر', '<b>', 'ح', 'ا', 'ل', 'ی', 'ک', 'ه', '<b>', 'ب', 'ا', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ب', 'ا', 'ز', 'ی', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ر', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'چ', 'ی', '<b>', 'ا', 'م', 'ا', '<b>', 'ی', 'ک', '<b>', 'چ', 'ی', 'ز', 'ی', 'ت', '<b>', 'ه', 'س', 'ت']\n",
            "PRED 969: parviz kheyli aaraam dar qaateiyat baa dastash barandaazash mikard ammaa paasokhi chi nakard\n",
            "PRED SCORE: -3.0404\n",
            "\n",
            "SENT 970: ['ن', 'م', 'ی', '<b>', 'خ', 'و', 'ا', 'ی', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ح', 'ر', 'ف', '<b>', 'ب', 'ز', 'ن', 'ی', 'م']\n",
            "PRED 970: nemikhaay baa ham harf bezanim\n",
            "PRED SCORE: -0.1102\n",
            "\n",
            "SENT 971: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ی', '<b>', 'ا', 'ن', 'ک', 'ه', '<b>', 'ب', 'ه', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', 'ش', '<b>', 'ن', 'گ', 'ا', 'ه', '<b>', 'ک', 'ن', 'د', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 971: foruq bi aanke be cheshmaanash negaah konad goft chizi nist\n",
            "PRED SCORE: -0.4877\n",
            "\n",
            "SENT 972: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'ط', 'م', 'ی', 'ن', 'ی', '<b>', 'ک', 'ه', '<b>', 'د', 'ر', 'و', 'غ', '<b>', 'ن', 'م', 'ی', '\\u200c', 'گ', 'ی']\n",
            "PRED 972: parviz porsid mibini ke doruq mirin\n",
            "PRED SCORE: -0.2382\n",
            "\n",
            "SENT 973: ['ه', 'ر', '<b>', 'د', 'و', '<b>', 'خ', 'ن', 'د', 'ی', 'د', 'ن', 'د']\n",
            "PRED 973: har do khandidand\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 974: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'ا', 'ع', 'ت', 'م', 'ا', 'د', '<b>', 'ب', 'ه', '<b>', 'ن', 'ف', 'س', 'ی', '<b>', 'ا', 'ش', 'ک', 'ا', 'ر', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ب', 'ل', 'د', '<b>', 'ن', 'ی', 'س', 'ت', 'ی', '<b>', 'د', 'ر', 'و', 'غ', '<b>', 'ب', 'گ', 'ی', '<b>', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'س', 'ت', 'ی']\n",
            "PRED 974: parviz baa qaateiyat be negaahi ashkbaar goft to budi begi begi\n",
            "PRED SCORE: -2.4043\n",
            "\n",
            "SENT 975: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ل', 'ب', 'خ', 'ن', 'د', '<b>', 'م', 'ع', 'ن', 'ی', '<b>', 'د', 'ا', 'ر', 'ی', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ف', 'ک', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'م', 'ن', 'و', '<b>', 'ک', 'ا', 'م', 'ل', 'ا', '<b>', 'ش', 'ن', 'ا', 'خ', 'ت', 'ی']\n",
            "PRED 975: foruq baa labkhand e ma nidaari goft fekr mikoni mano kaamelan eraane\n",
            "PRED SCORE: -1.1284\n",
            "\n",
            "SENT 976: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ی', '\\u200c', 'م', 'ل', 'ا', 'ح', 'ظ', 'ه', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', 'ر', 'و', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'ا', 'م', 'ا', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'د', 'و', '<b>', 'س', 'ه', '<b>', 'س', 'ا', 'ع', 'ت', '<b>', 'پ', 'ی', 'ش', '<b>', 'ر', 'و', '<b>', 'چ', 'ر', 'ا', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'م', 'ت', 'ع', 'ج', 'ب', '<b>', 'و', '<b>', 'گ', 'ی', 'ج', '<b>', 'ب', 'ه', '<b>', 'چ', 'ش', 'م', 'ا', 'ن', '<b>', 'س', 'ی', 'ا', 'ه', 'ش', '<b>', 'ز', 'ل', '<b>', 'ز', 'د', '<b>', 'و', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'و', 'ب', 'ا', 'ر', 'ه', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ب', 'و', 'س', 'ی', 'د']\n",
            "PRED 976: parviz bi moqaddame goft to nemidunam ammaa foruq be cheshmaan e foruq bargasht\n",
            "PRED SCORE: -2.0295\n",
            "\n",
            "SENT 977: ['ا', 'ز', '<b>', 'م', 'ن', '<b>', 'ق', 'و', 'ل', '<b>', 'م', 'ی', '\\u200c', 'گ', 'ی', 'ر', 'ی', '<b>', 'ر', 'ن', 'گ', '<b>', 'ب', 'ه', '<b>', 'ر', 'ن', 'گ', '<b>', 'ن', 'ش', 'م', '<b>', 'و', '<b>', 'ه', 'م', 'ی', 'ش', 'ه', '<b>', 'ی', 'ک', 'ر', 'ن', 'گ', '<b>', 'ب', 'ا', 'ش', 'م', '<b>', 'ا', 'ن', 'و', 'ق', 'ت', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'د', 'ر', 'س', 'ت', '<b>', 'م', 'ث', 'ل', '<b>', 'چ', 'ه', 'ا', 'ر', '<b>', 'ف', 'ص', 'ل', '<b>', 'م', 'ی', '\\u200c', 'م', 'و', 'ن', 'ی']\n",
            "PRED 977: az man qowl migi mage be ruz e khodam o hamishe zowqi baasham\n",
            "PRED SCORE: -2.3308\n",
            "\n",
            "SENT 978: ['م', 'و', 'ض', 'و', 'ع', 'ی', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', 'ت', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه']\n",
            "PRED 978: makhluti naaraahatet mikone\n",
            "PRED SCORE: -0.8959\n",
            "\n",
            "SENT 979: ['چ', 'ه', '<b>', 'س', 'و', 'ا', 'ل', 'ی']\n",
            "PRED 979: che jur\n",
            "PRED SCORE: -0.2880\n",
            "\n",
            "SENT 980: ['م', 'ع', 'ل', 'و', 'م', 'ه', '<b>', 'ک', 'ه', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ه']\n",
            "PRED 980: ma lume ke hamin khune\n",
            "PRED SCORE: -0.4044\n",
            "\n",
            "SENT 981: ['ف', 'ر', 'و', 'غ', '<b>', 'د', 'س', 'ت', 'ش', '<b>', 'ر', 'ا', '<b>', 'ا', 'ز', '<b>', 'م', 'ی', 'ا', 'ن', '<b>', 'د', 'س', 'ت', 'ا', 'ن', '<b>', 'ا', 'و', '<b>', 'ب', 'ی', 'ر', 'و', 'ن', '<b>', 'ک', 'ش', 'ی', 'د', '<b>', 'و', '<b>', 'ل', 'ب', '<b>', 'ب', 'ه', '<b>', 'د', 'ن', 'د', 'ا', 'ن', '<b>', 'گ', 'ر', 'ف', 'ت']\n",
            "PRED 981: foruq dastash raa az miaan e dastaanash u birun be komakash gereft\n",
            "PRED SCORE: -1.2796\n",
            "\n",
            "SENT 982: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'پ', 'د', 'ر', 'ت', 'ه']\n",
            "PRED 982: parviz porsid be khaater e pedaret\n",
            "PRED SCORE: -0.0931\n",
            "\n",
            "SENT 983: ['ا', 'و', 'ن', '<b>', 'د', 'ر', 'ب', 'ا', 'ر', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ن', '<b>', 'ا', 'ش', 'ت', 'ب', 'ا', 'ه', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه']\n",
            "PRED 983: un darbaareye man eshtebaah mikone\n",
            "PRED SCORE: -1.4055\n",
            "\n",
            "SENT 984: ['گ', 'ر', 'چ', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ن', 'م', '<b>', 'ه', 'ی', 'چ', '<b>', 'و', 'ق', 'ت', '<b>', 'خ', 'و', 'د', 'ش', '<b>', 'ر', 'و', '<b>', 'ب', 'ه', '<b>', 'خ', 'ا', 'ط', 'ر', '<b>', 'س', 'پ', 'ر', 'د', 'ن', '<b>', 'د', 'خ', 'ت', 'ر', '<b>', 'ج', 'و', 'ا', 'ن', 'ش', '<b>', 'ب', 'ه', '<b>', 'د', 'س', 'ت', '<b>', 'ی', 'ک', '<b>', 'پ', 'ی', 'ر', 'م', 'ر', 'د', '<b>', 'ب', 'ب', 'خ', 'ش', 'ه']\n",
            "PRED 984: garche fekr nemikonam hichvaqt khosh be khaater e sarzanesh dokhtar biaaram\n",
            "PRED SCORE: -2.5820\n",
            "\n",
            "SENT 985: ['ف', 'ر', 'و', 'غ', '<b>', 'ه', 'م', '<b>', 'م', 'ث', 'ل', '<b>', 'ا', 'و', '<b>', 'خ', 'ن', 'د', 'ی', 'د']\n",
            "PRED 985: foruq ham mesl e u khandid\n",
            "PRED SCORE: -0.0009\n",
            "\n",
            "SENT 986: ['ت', 'و', '<b>', 'پ', 'ی', 'ر', '<b>', 'ن', 'ی', 'س', 'ت', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز', '<b>', 'و', 'ل', 'ی', '<b>', 'ب', 'ا', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'چ', 'ی', 'ز', 'ی', '<b>', 'ت', 'و', 'ی', '<b>', 'د', 'ل', 'ش', '<b>', 'ن', 'ی', 'س', 'ت']\n",
            "PRED 986: to miram nisti parviz vali baabaa ham chizi tu ye delam nist\n",
            "PRED SCORE: -0.7370\n",
            "\n",
            "SENT 987: ['م', 'ی', 'د', 'و', 'ن', 'ی']\n",
            "PRED 987: miduni\n",
            "PRED SCORE: -0.0000\n",
            "\n",
            "SENT 988: ['م', 'ن', '<b>', 'ه', 'ی', 'چ', '<b>', 'و', 'ق', 'ت', '<b>', 'ش', 'ه', 'ا', 'م', 'ت', '<b>', 'ز', 'ل', '<b>', 'ز', 'د', 'ن', '<b>', 'ت', 'و', 'ی', '<b>', 'چ', 'ش', 'م', 'ا', 'ش', '<b>', 'ر', 'و', '<b>', 'ن', 'د', 'ا', 'ش', 'ت', 'م']\n",
            "PRED 988: man hichvaqt mowqe e fahim ro zadan e digaraan ro nadaashti\n",
            "PRED SCORE: -1.8778\n",
            "\n",
            "SENT 989: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'د', 'ر', '<b>', 'ت', 'ا', 'ی', 'ی', 'د', 'ش', '<b>', 'ز', 'م', 'ز', 'م', 'ه', '<b>', 'ک', 'ر', 'د', '<b>', '<b>', 'ا', 'و', 'ن', '<b>', 'ی', 'ک', '<b>', 'ا', 'ر', 'ت', 'ش', 'ی', '<b>', 'ب', 'ه', '\\u200c', 'ت', 'م', 'ا', 'م', '\\u200c', 'م', 'ع', 'ن', 'ا', 'س', 'ت']\n",
            "PRED 989: parviz dar ta yidash kard dard kard un yek dokhtarbachchast\n",
            "PRED SCORE: -1.1028\n",
            "\n",
            "SENT 990: ['ا', 'گ', 'ه', '<b>', 'س', 'ی', 'گ', 'ا', 'ر', '<b>', 'ب', 'ک', 'ش', 'م', '<b>', 'ن', 'ا', 'ر', 'ا', 'ح', 'ت', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ش', 'ی']\n",
            "PRED 990: age sigaar besham naaraahatet mishi\n",
            "PRED SCORE: -1.3052\n",
            "\n",
            "SENT 991: ['ف', 'ر', 'و', 'غ', '<b>', 'ج', 'و', 'ا', 'ب', '<b>', 'ر', 'د', '<b>', 'د', 'ا', 'د']\n",
            "PRED 991: foruq javaab kard daad\n",
            "PRED SCORE: -0.0046\n",
            "\n",
            "SENT 992: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ت', 'ک', 'ی', 'ه', '<b>', 'د', 'ا', 'د', '<b>', 'و', '<b>', 'ب', 'ر', 'ا', 'ی', '<b>', 'ت', 'غ', 'ی', 'ی', 'ر', '<b>', 'م', 'س', 'ی', 'ر', '<b>', 'گ', 'ف', 'ت', 'گ', 'و', '<b>', 'پ', 'ر', 'س', 'ی', 'د', '<b>', '<b>', 'م', 'ی', '\\u200c', 'ت', 'و', 'ن', 'ی', '<b>', 'ح', 'د', 'س', '<b>', 'ب', 'ز', 'ن', 'ی', '<b>', 'ج', 'ا', 'ی', 'ی', '<b>', 'ک', 'ه', '<b>', 'م', 'ی', 'ر', 'ی', 'م', '<b>', 'چ', 'ه', '<b>', 'ج', 'و', 'ر', '<b>', 'ج', 'ا', 'ی', 'ی', 'ه']\n",
            "PRED 992: parviz be aqab tekye daad va baraaye khalaaf e aashpazkhaane moqaabelash mikone ke mishim\n",
            "PRED SCORE: -2.9215\n",
            "\n",
            "SENT 993: ['ف', 'ر', 'و', 'غ', '<b>', 'ب', 'ا', '<b>', 'ص', 'ر', 'ا', 'ح', 'ت', '<b>', 'و', '<b>', 'ص', 'د', 'ا', 'ق', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ب', 'ا', '<b>', 'ه', 'م', '<b>', 'ب', 'ا', 'ش', 'ی', 'م', '<b>', 'ب', 'ر', 'ا', 'م', '<b>', 'ف', 'ر', 'ق', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ه']\n",
            "PRED 993: foruq baa seraahat va sedaaqat goft baa ham baraam kutaah nemikone\n",
            "PRED SCORE: -1.4915\n",
            "\n",
            "SENT 994: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'خ', 'ن', 'د', 'ی', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ن', 'ه', '<b>', 'د', 'ی', 'گ', 'ه', '<b>', 'ف', 'ک', 'ر', '<b>', 'ن', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'ا', 'گ', 'ر', '<b>', 'ه', 'م', 'ی', 'ن', '<b>', 'ط', 'و', 'ر', 'ی', '<b>', 'پ', 'ی', 'ش', '<b>', 'ب', 'ر', 'ی', 'م', '<b>', 'م', 'م', 'ک', 'ن', 'ه', '<b>', 'س', 'و', 'ء', '<b>', 'ا', 'س', 'ت', 'ف', 'ا', 'د', 'ه', '<b>', 'ک', 'ن', 'م']\n",
            "PRED 994: parviz khandid va goft na dige fekr konam esteraahat konam\n",
            "PRED SCORE: -0.4759\n",
            "\n",
            "SENT 995: ['ف', 'ر', 'و', 'غ', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ت', 'و', '<b>', 'ه', 'م', 'چ', 'ی', 'ن', '<b>', 'ا', 'د', 'م', 'ی', '<b>', 'ن', 'ی', 'س', 'ت', 'ی', '<b>', 'پ', 'ر', 'و', 'ی', 'ز']\n",
            "PRED 995: foruq goft to hamechi aakharin parviz\n",
            "PRED SCORE: -1.2682\n",
            "\n",
            "SENT 996: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ش', 'و', 'خ', 'ی', '<b>', 'ک', 'م', 'ی', '<b>', 'س', 'ر', 'ش', '<b>', 'ر', 'ا', '<b>', 'ج', 'ل', 'و', 'ت', 'ر', '<b>', 'ب', 'ر', 'د', '<b>', 'و', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'ا', 'ز', '<b>', 'ک', 'ج', 'ا', '<b>', 'م', 'ع', 'ل', 'و', 'م']\n",
            "PRED 996: parviz be shukhi kami raa jelow kard va goft az kojaa e mane\n",
            "PRED SCORE: -2.0246\n",
            "\n",
            "SENT 997: ['ی', 'ک', '<b>', 'ا', 'ن', '<b>', 'ت', 'ر', 'س', 'ی', '<b>', 'غ', 'ر', 'ی', 'ب', '<b>', 'س', 'ر', 'ا', 'پ', 'ا', 'ی', '<b>', 'ف', 'ر', 'و', 'غ', '<b>', 'ر', 'ا', '<b>', 'ر', 'د', '<b>', 'ب', 'ر', 'گ', 'ر', 'ف', 'ت', '<b>', 'و', 'ل', 'ی', '<b>', 'خ', 'ی', 'ل', 'ی', '<b>', 'ز', 'و', 'د', '<b>', 'ن', 'گ', 'ر', 'ا', 'ن', 'ی', '<b>', 'ر', 'ا', '<b>', 'ب', 'ه', '<b>', 'ع', 'ق', 'ب', '<b>', 'ر', 'ا', 'ن', 'د']\n",
            "PRED 997: yek aan qorurash ye amiq saraazir foruq raa be aqab raand\n",
            "PRED SCORE: -3.0498\n",
            "\n",
            "SENT 998: ['پ', 'ر', 'و', 'ی', 'ز', '<b>', 'ب', 'ا', '<b>', 'م', 'ح', 'ب', 'ت', '<b>', 'گ', 'ف', 'ت', '<b>', '<b>', 'خ', 'ی', 'ا', 'ل', '<b>', 'م', 'ی', '\\u200c', 'ک', 'ن', 'ی', '<b>', 'ن', 'م', 'ی', '\\u200c', 'د', 'و', 'ن', 'م', '<b>', 'ب', 'ا', '<b>', 'پ', 'ش', 'ت', 'ی', 'ب', 'ا', 'ن', 'ی', '<b>', 'و', '<b>', 'ح', 'م', 'ا', 'ی', 'ت', '<b>', 'ا', 'ز', '<b>', 'م', 'ن', '<b>', 'و', '<b>', 'ن', 'گ', 'ر', 'ف', 'ت', 'ن', '<b>', 'ج', 'ش', 'ن', '<b>', 'ا', 'ب', 'ر', 'و', 'م', 'ن', 'د', '<b>', 'چ', 'ی', '<b>', 'ب', 'ه', '<b>', 'ر', 'و', 'ز', '<b>', 'خ', 'و', 'د', 'ت', '<b>', 'ا', 'و', 'ر', 'د', 'ی', '<b>', 'ف', 'ر', 'ش', 'ت', 'ه', '\\u200c', 'ی', '<b>', 'م', 'ن']\n",
            "PRED 998: parviz baa mohabbat goft khiaal mikoni nemidunam o mahfel az man\n",
            "PRED SCORE: -1.4597\n",
            "\n",
            "SENT 999: ['ف', 'ر', 'و', 'غ', '<b>', 'و', 'ا', 'ق', 'ع', 'ا', '<b>', 'م', 'ا', 'ی', 'ل', '<b>', 'ن', 'ب', 'و', 'د', '<b>', 'د', 'ر', '<b>', 'ا', 'ن', '<b>', 'ب', 'ا', 'ر', 'ه', '<b>', 'ص', 'ح', 'ب', 'ت', '<b>', 'ک', 'ن', 'د', '<b>', 'چ', 'و', 'ن', '<b>', 'د', 'ر', '<b>', 'ا', 'ن', '<b>', 'ص', 'و', 'ر', 'ت', '<b>', 'م', 'ج', 'ب', 'و', 'ر', '<b>', 'م', 'ی', '\\u200c', 'ش', 'د', '<b>', 'گ', 'ذ', 'ش', 'ت', 'ه', '<b>', 'ر', 'ا', '<b>', 'ج', 'ل', 'و', 'ی', '<b>', 'چ', 'ش', 'م', '<b>', 'ب', 'ی', 'ا', 'و', 'ر', 'د']\n",
            "PRED 999: foruq vaaqean maayel nabud dar aan qadamiash konjkaavi maand\n",
            "PRED SCORE: -2.7801\n",
            "\n",
            "SENT 1000: ['خ', 'و', 'د', 'م', '<b>', 'خ', 'و', 'ا', 'س', 'ت', 'م']\n",
            "PRED 1000: khodam khube\n",
            "PRED SCORE: -1.1512\n",
            "PRED AVG SCORE: -0.1735, PRED PPL: 1.1894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51reqKrt6RzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "1cab8069-215c-4e1b-eb3e-c5adab5c56ad"
      },
      "source": [
        "!perl  OpenNMT-py/tools/multi-bleu.perl Transliteration/test.en < Transliteration/Transliteration_pred.txt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU = 26.38, 67.3/44.1/30.4/21.4 (BP=0.708, ratio=0.743, hyp_len=9475, ref_len=12751)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bldFMhE1rjqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "4bb55eab-f889-45f0-e048-bf2f08db5e5b"
      },
      "source": [
        "!pip install editdistance==0.3.1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting editdistance==0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/08/97ed5b60023ab4b67a46ee24bf1d3db93a9abc5b3be7e8f90de18160aaed/editdistance-0.3.1.tar.gz\n",
            "Building wheels for collected packages: editdistance\n",
            "  Building wheel for editdistance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for editdistance: filename=editdistance-0.3.1-cp36-cp36m-linux_x86_64.whl size=186660 sha256=6112361d6b6aeb0f32367ef206b710d021069f29628226996f5cb73ab2d2f705\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/02/5e/65498155acc7b20ecaaf50daec563c78b58a32272f7cbd82ba\n",
            "Successfully built editdistance\n",
            "Installing collected packages: editdistance\n",
            "  Found existing installation: editdistance 0.5.3\n",
            "    Uninstalling editdistance-0.5.3:\n",
            "      Successfully uninstalled editdistance-0.5.3\n",
            "Successfully installed editdistance-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey0D200AsDuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import editdistance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGDM-gCS6Rgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "goal_sentences, predicted_sentences = [], []\n",
        "distance_values = []\n",
        "with open('Transliteration/test.en', 'r') as fp:\n",
        "  goal_sentences = fp.read().split('\\n')\n",
        "with open('Transliteration/Transliteration_pred.txt', 'r') as fp:\n",
        "  predicted_sentences = fp.read().split('\\n')\n",
        "\n",
        "for sent_id in range(len(goal_sentences)):\n",
        "  s1 = goal_sentences[sent_id]\n",
        "  s2 = predicted_sentences[sent_id]\n",
        "  d = editdistance.eval(s1, s2)\n",
        "  distance_values.append(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvyu9W7Qs0TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cadb2253-6a01-4081-8530-a40f568b1136"
      },
      "source": [
        "distance_values[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA570Cwss70O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c060bf43-a769-4361-9361-9a7247f4ad8e"
      },
      "source": [
        "sum(distance_values)/len(distance_values), min(distance_values), max(distance_values)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31.034, 0, 204)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5oM-tVOs939",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff728040-0598-438a-c1c0-5176d97dbe95"
      },
      "source": [
        "import statistics\n",
        "statistics.median(distance_values)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLNZN4bvtaHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}